from backend.api.utils import llms

from langchain.chains.llm import LLMChain
from langchain.prompts import PromptTemplate

myLLm = llms.langchain_openai()

def combine_summaries():
    prompt_template = """
    You are trying to cumulativeluy build your knowledge of a code base.
    You are provided with the input in following format:
    ```
    {
        "CurrentCodebase": "This flutter code shows the home screen of the app. It has a button to navigate to the journal screen.",
        "CodeChange": ""diff --git a/frontend/lib/screens/home.dart b/frontend/lib/screens/home.dart\nindex 6872dd6..60e84f4 100644\n--- a/frontend/lib/screens/home.dart\n+++ b/frontend/lib/screens/home.dart\n@@ -118,7 +118,7 @@ class _HomeScreenState extends State<HomeScreen> {\n                       Theme.of(context).colorScheme.tertiaryContainer),\n                 ),\n                 onPressed: () async {\n-                  await testOpenApi();\n+                  //await testOpenApi();\n                   Navigator.pushNamed(context, \"/journal\");\n                 },\n                 child: Text("",
    }
    ```
    CurrrentCodebase is the description of what the current codebase does. It lists all the functionalities.
    CodeChange is the code diff generated by git on top of the current codebase.
    
    
    detailed description of w
    Imagine the following text in
    triple quotes is from a concatenated tweetstorm. 
    Generate a concise headline, maximum 1-2 sentences long, 
    such the reader gets the gist just by reading the headline. 
    If the text is empty, just generate an empty text as headline. 
    Also, directly print the headline without any filler text like 'the headline is':
    "{text}"
    headline:"""
    prompt = PromptTemplate.from_template(prompt_template)

    llm_chain = LLMChain(llm=myLLm, prompt=prompt)