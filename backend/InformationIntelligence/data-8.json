{"message":{"0":"56567a463a7600fd2f87789c","1":"56567a610d627297620cd9ff","2":"56567a7c92aa9746647b93c9","3":"56567b573a7600fd2f8778a7","4":"56567b900d627297620cda0c","5":"565682ebf59a8f0758a6ef39","6":"565682fe0d143098620f4123","7":"5656830f92aa9746647b9477","8":"5658dc8b28c5280777268851","9":"5658ddbb9991fe124e1581fa","10":"5658e0e349e74fad21eb72cb","11":"5658fa3628c5280777268aab","12":"5658fa5428c5280777268ab1","13":"5658faa128c5280777268ab9","14":"5659013d49fc2afe4a4f7de3","15":"565a32252753fafb4af5ee1d","16":"565a59d349e74fad21eb8f03","17":"565a953028c528077726a6df","18":"565ad722c3d575114e6c9270","19":"565c9df03734bd42649a2ad5","20":"565c9e703a0962562964a458","21":"565c9e9bfd59645429ec3c5f","22":"565c9eea84678bd7053fb3bb","23":"565c9f8cf0893e5f6b729649","24":"565c9fecf0893e5f6b72965c","25":"565ca0206693bfd6058dcb5a","26":"565cc058fd59645429ec42a1","27":"565de2fe19eee17f78e269bd","28":"565de30222df37d14f93593c","29":"565de45f5993bcb005d2c832","30":"565de6996ddbc1b32747c36b","31":"565e04ad480c6db2051725db","32":"565e0a376ddbc1b32747cadb","33":"565e0d28480c6db2051727f4","34":"565e0d535993bcb005d2d07c","35":"565e1867480c6db205172a72","36":"565e189f480c6db205172a7f","37":"565e3e26480c6db205173069","38":"565e3e4722df37d14f936a42","39":"565e3f005993bcb005d2d8ed","40":"565e3fcb5993bcb005d2d906","41":"565e4f882488cc8078749137","42":"565e7cb219eee17f78e280a5","43":"565e81d0480c6db2051736a3","44":"565e82979a969fd24f3c11cf","45":"565e86a422df37d14f937104","46":"565e8aac2488cc807874968c","47":"565e8ab165c2a5b027d73b4e","48":"565e8ad819eee17f78e281d5","49":"565e8b0f22df37d14f937167","50":"565e8b1f65c2a5b027d73b5a","51":"565e8b282488cc8078749697","52":"565e8b5465c2a5b027d73b5d","53":"565e8b7d19eee17f78e281e0","54":"565f257e22df37d14f938953","55":"565f274a19eee17f78e29a41","56":"565f2933480c6db205175059","57":"565f4224480c6db2051755b9","58":"565f42285993bcb005d2fde5","59":"565f423f65c2a5b027d7585c","60":"565f42c922df37d14f938f62","61":"565f42f49a969fd24f3c3055","62":"565f4310480c6db2051755d3","63":"565f436c22df37d14f938f78","64":"565f43fd65c2a5b027d75894","65":"565f440522df37d14f938f8d","66":"565f4441480c6db2051755fc","67":"565f4468480c6db2051755ff","68":"565f447522df37d14f938f9f","69":"565f44e79a969fd24f3c30a9","70":"565f450522df37d14f938fb1","71":"565f453e9a969fd24f3c30b7","72":"565f45509a969fd24f3c30bb","73":"565f459a22df37d14f938fd4","74":"565f45ae22df37d14f938fd9","75":"565f45af9a969fd24f3c30c9","76":"565f45cb480c6db205175641","77":"565f45d12488cc807874b468","78":"565f460c6ddbc1b32747f8a8","79":"565f460f22df37d14f938fea","80":"565f462c2488cc807874b473","81":"565f46369a969fd24f3c30de","82":"565f463f480c6db205175658","83":"565f464622df37d14f938ffe","84":"565f466b2488cc807874b485","85":"565f46816ddbc1b32747f8b6","86":"565f468a65c2a5b027d758f7","87":"565f46af6ddbc1b32747f8be","88":"565f46cb5993bcb005d2fe7d","89":"565f46cc6ddbc1b32747f8c0","90":"565f46de19eee17f78e2a0c7","91":"565f46e59a969fd24f3c30fd","92":"565f471419eee17f78e2a0cb","93":"565f4719480c6db205175673","94":"565f474e6ddbc1b32747f8dc","95":"565f476d6ddbc1b32747f8de","96":"565f47842488cc807874b4b1","97":"565f47955993bcb005d2fea0","98":"565f479d480c6db20517568e","99":"565f479d480c6db20517128e"},"time":{"0":"2015-11-26T03:19:34.353Z","1":"2015-11-26T03:20:01.644Z","2":"2015-11-26T03:20:28.938Z","3":"2015-11-26T03:24:07.640Z","4":"2015-11-26T03:25:04.590Z","5":"2015-11-26T03:56:27.576Z","6":"2015-11-26T03:56:46.503Z","7":"2015-11-26T03:57:03.385Z","8":"2015-11-27T22:43:23.412Z","9":"2015-11-27T22:48:27.576Z","10":"2015-11-27T23:01:55.538Z","11":"2015-11-28T00:49:58.430Z","12":"2015-11-28T00:50:28.860Z","13":"2015-11-28T00:51:45.408Z","14":"2015-11-28T01:19:57.442Z","15":"2015-11-28T23:00:53.827Z","16":"2015-11-29T01:50:11.387Z","17":"2015-11-29T06:03:28.184Z","18":"2015-11-29T10:44:50.507Z","19":"2015-11-30T19:05:20.625Z","20":"2015-11-30T19:07:28.495Z","21":"2015-11-30T19:08:11.023Z","22":"2015-11-30T19:09:30.716Z","23":"2015-11-30T19:12:12.952Z","24":"2015-11-30T19:13:48.593Z","25":"2015-11-30T19:14:40.615Z","26":"2015-11-30T21:32:08.257Z","27":"2015-12-01T18:12:14.203Z","28":"2015-12-01T18:12:18.177Z","29":"2015-12-01T18:18:07.763Z","30":"2015-12-01T18:27:37.331Z","31":"2015-12-01T20:35:57.707Z","32":"2015-12-01T20:59:35.613Z","33":"2015-12-01T21:12:08.751Z","34":"2015-12-01T21:12:51.830Z","35":"2015-12-01T22:00:07.760Z","36":"2015-12-01T22:01:03.420Z","37":"2015-12-02T00:41:10.015Z","38":"2015-12-02T00:41:43.883Z","39":"2015-12-02T00:44:48.620Z","40":"2015-12-02T00:48:11.256Z","41":"2015-12-02T01:55:20.856Z","42":"2015-12-02T05:08:02.508Z","43":"2015-12-02T05:29:52.346Z","44":"2015-12-02T05:33:11.130Z","45":"2015-12-02T05:50:28.400Z","46":"2015-12-02T06:07:40.238Z","47":"2015-12-02T06:07:45.863Z","48":"2015-12-02T06:08:24.473Z","49":"2015-12-02T06:09:19.622Z","50":"2015-12-02T06:09:35.108Z","51":"2015-12-02T06:09:44.808Z","52":"2015-12-02T06:10:28.341Z","53":"2015-12-02T06:11:09.677Z","54":"2015-12-02T17:08:14.521Z","55":"2015-12-02T17:15:54.774Z","56":"2015-12-02T17:24:03.103Z","57":"2015-12-02T19:10:28.451Z","58":"2015-12-02T19:10:32.175Z","59":"2015-12-02T19:10:55.705Z","60":"2015-12-02T19:13:13.131Z","61":"2015-12-02T19:13:56.054Z","62":"2015-12-02T19:14:24.448Z","63":"2015-12-02T19:15:56.637Z","64":"2015-12-02T19:18:21.197Z","65":"2015-12-02T19:18:29.359Z","66":"2015-12-02T19:19:29.592Z","67":"2015-12-02T19:20:08.568Z","68":"2015-12-02T19:20:21.435Z","69":"2015-12-02T19:22:15.122Z","70":"2015-12-02T19:22:45.511Z","71":"2015-12-02T19:23:42.434Z","72":"2015-12-02T19:24:00.717Z","73":"2015-12-02T19:25:14.050Z","74":"2015-12-02T19:25:34.086Z","75":"2015-12-02T19:25:35.966Z","76":"2015-12-02T19:26:03.176Z","77":"2015-12-02T19:26:09.435Z","78":"2015-12-02T19:27:08.115Z","79":"2015-12-02T19:27:11.302Z","80":"2015-12-02T19:27:40.358Z","81":"2015-12-02T19:27:50.573Z","82":"2015-12-02T19:27:59.324Z","83":"2015-12-02T19:28:06.654Z","84":"2015-12-02T19:28:43.229Z","85":"2015-12-02T19:29:05.126Z","86":"2015-12-02T19:29:14.717Z","87":"2015-12-02T19:29:51.555Z","88":"2015-12-02T19:30:19.517Z","89":"2015-12-02T19:30:20.952Z","90":"2015-12-02T19:30:38.961Z","91":"2015-12-02T19:30:45.733Z","92":"2015-12-02T19:31:32.369Z","93":"2015-12-02T19:31:37.068Z","94":"2015-12-02T19:32:30.406Z","95":"2015-12-02T19:33:01.438Z","96":"2015-12-02T19:33:24.469Z","97":"2015-12-02T19:33:41.146Z","98":"2015-12-02T19:33:49.792Z","99":"2015-12-02T19:35:49.792Z"},"user":{"0":"SamLau95","1":"SamLau95","2":"SamLau95","3":"stefanv","4":"SamLau95","5":"cboettig","6":"SamLau95","7":"SamLau95","8":"cboettig","9":"cboettig","10":"cboettig","11":"SamLau95","12":"SamLau95","13":"cboettig","14":"SamLau95","15":"cboettig","16":"SamLau95","17":"cboettig","18":"SamLau95","19":"cboettig","20":"stefanv","21":"cboettig","22":"stefanv","23":"stefanv","24":"cboettig","25":"cboettig","26":"SamLau95","27":"tap2k","28":"tap2k","29":"tap2k","30":"tap2k","31":"SamLau95","32":"tap2k","33":"tap2k","34":"SamLau95","35":"tap2k","36":"tap2k","37":"cboettig","38":"cboettig","39":"stefanv","40":"cboettig","41":"tap2k","42":"henryem","43":"cboettig","44":"henryem","45":"cboettig","46":"henryem","47":"henryem","48":"henryem","49":"henryem","50":"henryem","51":"henryem","52":"henryem","53":"henryem","54":"cboettig","55":"henryem","56":"cboettig","57":"cboettig","58":"stefanv","59":"stefanv","60":"cboettig","61":"cboettig","62":"cboettig","63":"stefanv","64":"stefanv","65":"cboettig","66":"stefanv","67":"cboettig","68":"stefanv","69":"cboettig","70":"cboettig","71":"stefanv","72":"stefanv","73":"cboettig","74":"cboettig","75":"stefanv","76":"stefanv","77":"cboettig","78":"stefanv","79":"cboettig","80":"stefanv","81":"stefanv","82":"stefanv","83":"stefanv","84":"cboettig","85":"stefanv","86":"cboettig","87":"stefanv","88":"stefanv","89":"cboettig","90":"cboettig","91":"stefanv","92":"stefanv","93":"stefanv","94":"cboettig","95":"cboettig","96":"stefanv","97":"stefanv","98":"stefanv","99":"stefanv"},"message.1":{"0":"hello world! this is the chat room for the datascience library","1":"feel free to ping me or the other devs here","2":"i hope this room serves as a useful alternative to email for simpler tasks for this library","3":"Hey, everyone! ","4":"in the ideal case, this room will lower the overhead of asking questions for the connector faculty","5":"Hey Sam, thanks for setting this up (and for your earlier answers).","6":"my pleasure! hope this is helpful","7":"ping me anytime and i\\u2019ll do my best to respond","8":"Hi folks -- where does that `tabledemos` repo that David Culler mentioned on the mailing list live? I'm not seeing it in github.com\/dsten","9":"Aha, looks like it's https:\/\/github.com\/deculler\/TableDemos I believe.","10":"Hmm, don't seem to be able to paste into the jupyter terminal.  Looks like that was a known issue https:\/\/github.com\/jupyter\/notebook\/issues\/104 but since resolved? ","11":"@cboettig looks like david has a bunch of IPython notebooks in his repo","12":"to open those notebooks, you can go to https:\/\/ds8.berkeley.edu\/hub\/home and upload them","13":"@SamLau95 thanks; I've just been using git through the Jupyter terminal to get things over.  nice, but the lack of copy-paste makes that a bit of a nuisance though","14":"@cboettig i don\\u2019t think i\\u2019m familiar with the Jupyter terminal. to clarify, you have the `.ipynb` files on your local machine and want to run the notebooks, right?\\n\\nif you\\u2019re okay with running the notebooks on ds8, the method i described is the easiest way to do so.\\n\\nif you want to run them on your own computer, you\\u2019ll have to run `ipython notebook` in your terminal to start a jupyter server locally to view them","15":"@SamLau95 From the Jupyter homepage there's an option to open a new Python 3 notebook, and under it an option to open a terminal which runs in the browser.  It's really convenient since I can then move my notebooks between my local machine, github, the hosted ds8.berkeley.edu site; seems to be pretty much a fully functional bash terminal except for the lack of copy-paste which is a bit of a nuisance.  ","16":"@cboettig ah i see, this is running on your local machine (eg. localhost)? it looks like if you open a terminal window and run\\n\\n    git clone https:\/\/github.com\/deculler\/TableDemos\\n\\nyou can switch back to the \\u2018Files\\u2019 tab and open the notebooks locally","17":"nope, terminal is running on ds8.berkeley.edu instance (though also works locally)","18":"ah, gotcha. that command should work both on ds8 and locally","19":"@SamLau95 Any recommendation for a style guide for python?  In particular, looking for clarification on when to use the notation `x.method()` vs the notation `method(x)`","20":"Is this specifically wrt numpy? ","21":"anything really, it's all pretty new to me.  does style differ wrt different modules?","22":"I think numpy has both class and normal methods available due to history, but in most other packages you have only one or the other. ","23":"Most of the time, we try to use Python's rich containers in combination with functions. Only when there's a lot of state being dragged around the system do we start looking at objects even. ","24":"that seems like a good starting point.  so just to be clear, you call `method(object)` function notation, and `object.method` to be object notation?","25":"it seems that plotting starts off with method notation in the textbook, but switch later into object notation?","26":"@cboettig do you have an example? we use stuff like\\n\\n    foo_table.hist()\\n\\nquite a bit, but when we needed plotting functionality that the table didn\\u2019t provide we switched to using matplotlib directly instead (the `plots` variable). for example, in http:\/\/data8.org\/text\/4_prediction.html#correlation we make a scatter plot using\\n\\n    plots.scatter(ht_pw['mat_ht'], ht_pw['mat_pw'], s=5, color='gold')\\n    plots.xlabel('height (inches)')\\n    plots.ylabel('pregnancy weight (pounds)\\u2019)\\n\\nthis is because the table class didn\\u2019t provide the functionality we wanted in order to make these plots; we typically try to use the Table class as much as possible","27":"Do I need to do anything special to show a Marker once Ive called the function?","28":"for maps","29":"basically the functionality Im looking for is to add circles one by one and then show the resulting map. possible?","30":"also - is there a way to change the datatype of a column? I need the lat, long values to be treated as floats for Circle.map to work","31":"@tap2k i believe they\\u2019ll show up automatically \\u2014 checkout david wagner\\u2019s lecture on privacy: http:\/\/data8.org\/text\/slides\/lec10.pdf\\n\\ni think what you want has been done before\\n\\nif you have a table called `foo_table` and a column called `x` with integers, you can change the type to floats with `Table.apply` like:\\n\\n    foo_table.apply(float, 'x')\\n","32":"thanks! helpful","33":"when I use the Circle.map or Marker.map functions how do I set the map center and zoom?","34":"not super sure myself \\u2014 @papajohn @alvinwan , do you know how?","35":"figured that out","36":"one issue I had is that Circle or Marker.map is not the last expression in the cell the map doesnt show. this makes it hard to wrap in a function unless someone has a workaround","37":"Curious if any connectors are touching on sql databases.  Just need some very simple imports from postgres, doesn't look like `psycopg2` is available.","38":"Guess I could just export the data to csv for them, but torn between wanting to give a light exposure to databases vs just streamlining things","39":"@cboettig Is postgres the system you have to use?  Because Python has built in sqlite, if you can port the DB to that.","40":"yeah, in this particular case data is already in postgres, though pedagogically maybe sqlite makes more sense then","41":"ok got it - chalk it up to the stupid question dept","42":"@cboettig Tables support a lot of SQL-like things (join, group by, where) that they learn about in the first month or so of the base class.   Could be easier to introduce database operations that way, without a new language.  (Sorry if you're already aware of that!)","43":"@henryem right, yes, and I'd probably stick with doing most of these manipulations in `tables` (though I'm still learning those myself!).  More just wondering about it as a data ingest step -- I often see students struggle with importing data from databases even when they are already well equipped to manipulate the data within a given framework once the data are imported.  Teaching all that is of course beyond the scope of what I can get into a connector, but just wondering if it's worth giving some glimpse of data read\/parse command that isn't `csv`.  More a pedagogy issue than a technical one I suppose, and I'm still on the fence.","44":"Ah, I see.  That sounds cool.","45":"Hmm, struggling to figure out the best python way to do an operation that is pretty simple in R's `dplyr`.... I have a table in which one column is a grouping factor, so for each group I want to apply a summary function.  Here's my R version: https:\/\/gist.github.com\/cboettig\/7ce0f311daa428b023f9","46":"I'm not 100% familiar with the dplyr syntax, but I think you would say:\\nvalues.select(['assessid', 'ssb']).group('assessid', collapsed)","47":"where collapsed is","48":"def collapsed(an_array):\\n  return an_array[-1] < 0.1*max(an_array)","49":"the main difference, as far as I can tell, is that the `tables` group() will apply the summary function to every column, whereas group_by lets you apply it only to some columns","50":"though I'm not sure what happens to the columns that are not summarized","51":"in dplyr's group_by, I mean","52":"anyway, the .select(['assessid', 'ssb']) pares down the columns to just the grouping factor and the column you wanted to summarize","53":"if you want to summarize several columns in different ways (or the same column in multiple ways) it takes several steps","54":"@henryem Thanks!  That looks very promising --  However, I'm a puzzled why I get different results in R vs python now!  how is `max` handling the `nan` values in python?","55":"Ah, it propagates them, so it will return `nan`.  Looks like there are two options: for `max` in particular there is `nanmax`, which ignores `nan`s.  In general you could use `np.ma.masked_array(my_array, np.isnan(my_array))` to get a view of `my_array` that doesn't include that `nan`s, and then do whatever computation you wanted on that view.","56":"thanks, that sounds handy.  Curiously I don't get any nans in the output from the original python version, but I get a different set of `True\/False` values in the new column... ","57":"hmm, looks like I just get an error on calling `np.ma.masked_array` on a datascience `Table` object","58":"I\\u2019d steer clear of masked arrays unless you really need them.It\\u2019s another layer of complexity on an already complex operation.","59":"Yes, that almost certainly won\\u2019t work.  NumPy does not know anything about Tables.","60":"right, okay, will avoid that.  Meanwhile still puzzled by the handling of nas and the different results between R and python here.","61":"e.g. starting from the gist, https:\/\/gist.github.com\/cboettig\/7ce0f311daa428b023f9 ,  I see the group`x = values.select([\\assessid\\ \\ssb\\]).where(\\assessid\\ \\AFSC-BKINGCRABPI-1960-2008-JENSEN\\)\\ncollapsed(x[\\ssb\\])` returns `False`","62":"note that `x` has `nan` values, so I'd have expected it to return `nan`.  And in R, when dropping nans, it returns true.","63":"Let me install R quickly and take a look at what you\\u2019re expecting","64":"What is \\u201ccollapsed\\u201d supposed to do?  Check whether the last element is smalled than 0.1 * max of the array, ignoring nans?","65":"yup","66":"Try replacing ``max(an_array)`` with ``np.nanmax(an_array)``","67":"throws error","68":"Can you show me the error?","69":"https:\/\/github.com\/boettiger-lab\/espm-88b\/blob\/master\/modules\/fish\/fish.ipynb","70":"(think the error shows up there, from `In [14]`)","71":"Hah, I did not expect an_array to be \\u201ca_list\\u201d :)","72":"I\\u2019ll take a quick look at what\\u2019s happening underneath the hood","73":"yeah, guess columns in Tables are `list` objects?  I'm still a bit foggy on the difference between a list and an array.  is an `array` a numpy object? for doubles only?","74":"and thanks much for the help!","75":"I\\u2019ve just tried it with the latest version of datascience and it seems to work OK for me","76":"Are you using the same dataset as in the gist?","77":"yup","78":"So, it looks like there\\u2019s at least one column with all NaNs","79":"is the latest version what is on ds8.berkeley.edu?  I could switch to that; I'm running Juypter from the jupyter\/datascience-notebook docker image, just did a `pip install datascience`.... not quite sure how to check my module version info","80":"Ah, I\\u2019m running the latest dev version, 0.3.dev21","81":"You can check the version with:","82":"``import datascience as ds\\nds.__version__\\n``","83":"At least, you can do that in the latest version ;)","84":"errors for me. guess that confirms I have an earlier version","85":"Also, in this version \\u201can_array\\u201d is an array","86":"that's good","87":"You should be able to pip install the latest version directly from git, but I guess it is important for you that your students can make it work, and I presume they\\u2019ll be running the latest released version.","88":"Perhaps this is a good time to release a new version\\u2014there\\u2019s been quite a few bug-fixes etc.","89":"looks like the berkeley server isn't up to date either, though I'm sure it will be by spring.  ","90":"hmm, how do  I tell pip to install from git?","91":"Let me find the magic incantation","92":"pip install git+git:\/\/github.com\/dsten\/datascience.git","93":"Untested","94":":thumbsup:  seems to be working","95":"looks like I'm missing some dependencies.  apt-get time","96":"You\\u2019ll need:\\n```\\nfolium\\nsphinx\\nnumpy\\nscipy\\nmatplotlib\\npandas\\nIPython\\n```","97":"I\\u2019d apt-get numpy, scipy, matplotlib, and pandas, and pip install the rest","98":"IPython should be replaced by ``jupyter``","99":"IPython should be replaced by ``jupyter`` the best"}}