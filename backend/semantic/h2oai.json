{"message":{"0":"555fcbaf27740b8f26db1e14","1":"555fd967c13de0840ffc2993","2":"555fee5a727234850fc771a4","3":"555fee9729921ce910487ac9","4":"555feed6a26bc38d26818897","5":"555ff06bd3bef97f1b59a248","6":"555ff205727234850fc771c1","7":"555ff216c42aede80f337105","8":"555ff23ac42aede80f337106","9":"555ff2a9727234850fc771c9","10":"555ff2c329921ce910487af2","11":"555ffac19439f229424d41b6","12":"555ffad417f8c79a4f8beb3d","13":"555ffad87890a72772d460c0","14":"5560077229921ce910487b8b","15":"556124ad17f8c79a4f8bfb7a","16":"556133cd533895a93087de28","17":"5565f763d21e5ed02ff06287","18":"5565f77bd21e5ed02ff06289","19":"5565f7937a71f1612c266df4","20":"5565f7adc1d06dce2f3967ec","21":"55660e387a5422696cc01e81","22":"55660e3c7a71f1612c267119","23":"55660e4b7a71f1612c26711c","24":"556611f0743a2a6c6c127bf5","25":"556611fe15218a642c9cd80e","26":"55661208d21e5ed02ff06663","27":"5566153115218a642c9cd879","28":"556618f815218a642c9cd901","29":"55661a847a71f1612c2672d6","30":"55661a90d21e5ed02ff0679e","31":"55661cb5743a2a6c6c127d74","32":"55661e44d21e5ed02ff0681f","33":"55661eaa743a2a6c6c127db9","34":"55661f137a71f1612c267372","35":"55661f7715218a642c9cda07","36":"55661fa0743a2a6c6c127dec","37":"55661fc17a5422696cc020d1","38":"55661fcdc1d06dce2f396d96","39":"5566203c743a2a6c6c127e03","40":"5566206f7a5422696cc020e9","41":"55662098c1d06dce2f396da9","42":"556621b4c1d06dce2f396ddd","43":"556621e47a71f1612c2673e5","44":"5566221b15218a642c9cda87","45":"5566223ac1d06dce2f396dec","46":"556623607a5422696cc02166","47":"55662378c1d06dce2f396e19","48":"556624337a5422696cc0217d","49":"5566243fc1d06dce2f396e3a","50":"556624467a71f1612c26744e","51":"5566244dd21e5ed02ff06933","52":"55662453743a2a6c6c127eda","53":"5566247c15218a642c9cdb04","54":"556624dd15218a642c9cdb0e","55":"556624ed7a71f1612c267460","56":"5566b51976f387d042581886","57":"55674b07def7b30f79ba269d","58":"55674b66def7b30f79ba26a3","59":"556754677f82721279ac7aa2","60":"55675d8cbeed96397ea72e4e","61":"556ee3788d1a52c22e872d00","62":"556ee44f8d1a52c22e872d22","63":"556ee53305c872ce6ac7b432","64":"556f07c5777c17d06a13c575","65":"556f4dfa05c872ce6ac7cd9a","66":"556f4e13f40a067d1c9b5540","67":"556f511205c872ce6ac7ce01","68":"556f6dd8777c17d06a13d655","69":"5572d81027d2203776cccdb8","70":"5572d81705c872ce6ac81e33","71":"5572d82605c872ce6ac81e34","72":"5573245af40a067d1c9ba802","73":"55754abb463d0c7c066e6038","74":"5576050a05c872ce6ac85275","75":"55764f69463d0c7c066e7c08","76":"557676ef777c17d06a145e3e","77":"5579d3db05c872ce6ac8b712","78":"557afa1931e09edf0c0ce508","79":"557b08386fee6add0cc21410","80":"557b0c3eb62c8de7435cb3ab","81":"557b1bc2392218e94305d489","82":"557b4081873bcf056fb4e98a","83":"557f12b234b840066f5dfe71","84":"557f12e27d5adaae3b4f2127","85":"557f147c34b840066f5dfe98","86":"557f147e873bcf056fb5215b","87":"557f2207873bcf056fb522ff","88":"557fd075f1cd32e97eca7c2f","89":"558067f11c3ba5ef5bfed388","90":"558068f91c3ba5ef5bfed3a4","91":"558080576f7465873a35a91a","92":"558088141c3ba5ef5bfed700","93":"55808b93f207aa853a8bb175","94":"55819e968fe007833a4ada52","95":"55819eb31c3ba5ef5bfef05a","96":"55819f7a3039387b1577ac53","97":"55819fb7deac73ee5b85802d","98":"5581a8176f7465873a35c561","99":"5581c3256f7465873a35c8bc","100":"5581cc461c3ba5ef5bfef6aa","101":"5581e3081c3ba5ef5bfef998","102":"5581e335deac73ee5b858925","103":"5581e3c06f7465873a35ccf7","104":"5581e437deac73ee5b85893e","105":"5581e43a3039387b1577b52c","106":"5581e43df207aa853a8bd418","107":"5581e8b96f7465873a35cd6c","108":"5581e8d01c3ba5ef5bfefa0c","109":"5581eb776f7465873a35cda5","110":"5582bde33039387b1577c5fd","111":"5582cf4cac9e2e79150db661","112":"5582cf7df207aa853a8be725","113":"5582d0243039387b1577c860","114":"5582e79df207aa853a8beaec","115":"5582e7ae6e4c427a15f468f1","116":"5582e800f207aa853a8beafd","117":"5582e80a6e4c427a15f468f9","118":"5582eb6bf207aa853a8beb9e","119":"5582eb76bb2c3e7c15868261","120":"5582f6121c3ba5ef5bff1220","121":"5582f69e6f7465873a35e5b4","122":"5582fa09f207aa853a8bed33","123":"55834d2f3039387b1577d7d2","124":"55834d7c6f7465873a35efec","125":"55834e75bb2c3e7c15868e2e","126":"55834ea03039387b1577d7ed","127":"5585bb2f6f7465873a361916","128":"55884740bb2c3e7c1586e320","129":"55884e873039387b15782e86","130":"558853556f7465873a3647ba","131":"5588583ff207aa853a8c5024","132":"55887fec6f7465873a364f59","133":"5588a4081c3ba5ef5bff80a7","134":"5588a90a6f7465873a365395","135":"558b3018461e01f542c87c06","136":"558b469f38e37bf74261cf63","137":"558c4f75e6702c3a57648927","138":"558c7262609a063b57876954","139":"558c744187625063017625bc","140":"558c84f3e6702c3a576490c5","141":"5591c41a92e368b167bd26af","142":"5595ad61b634f09d21d98aa8","143":"559acbd052cc8c664f50deff","144":"559ace645331f9985a7fa368","145":"559adb490edc4b6a7986ec6f","146":"559adc301c1634674f8a5068","147":"559b2832e9c8fd6779dc4bdd","148":"559b51c552cc8c664f50ebcf","149":"559e54ec9399a9015e9b5ad3","150":"559ea8160689b34a3bccc138","151":"559eaa0aac5618dd7b629627","152":"559eabeaac5618dd7b629680","153":"559eacea1bbf5a493b658b67","154":"559eb04d1bbf5a493b658bf3","155":"559f1dca36d6aaad30431e79","156":"559f1dcbc67809ab306357bd","157":"559f7567846f9d040c5260dd","158":"559f816ebc5b6ab156b42760","159":"559faebcc67809ab30636420","160":"55a1a26205d3e1f54c9f0df0","161":"55a221a7b8b45ca15bc7b5e6","162":"55a3df878e28b0c71ac96c21","163":"55a68415ea224d3609775036","164":"55a7151f584eabeb554a4fc7","165":"55a718fb584eabeb554a4ff9","166":"55a7198619007a694c57236b","167":"55a71aec0e1787706acd277e","168":"55a786b42fde815212f0fa6f","169":"55a7d7071a5d2fe320741e9b","170":"55a7f7a08f0333fe6bf77182","171":"55a7f833afbc665466c578d7","172":"55a8294ead99869443da9b20","173":"55a87460b83437005acb5b7d","174":"55a87e016551f5f12e71461d","175":"55a88a3a6551f5f12e7146ad","176":"55a8e54ac9a01815286cf38e","177":"55a8e8f0972e11b24adc1aad","178":"55a9594710521a7e525582c0","179":"55a959b610521a7e525582d8","180":"55ad5485ea4b0b3b25a4f0fd","181":"55aec38b3c1189fb1dc11091","182":"55aee43a3c1189fb1dc1139d","183":"55b102e45992e2977c418120","184":"55b11a69f2cdad46058b1e86","185":"55b11ff76e982043058b0e74","186":"55b1369a6e982043058b12f4","187":"55b138466e982043058b1344","188":"55b13a0f16ac52ff650f8269","189":"55b13ac56e982043058b13bc","190":"55b16a4716ac52ff650f89d1","191":"55b6772e7962623b2a0db2ba","192":"55b7b06f4c04f0cc22e70401","193":"55b8e02f4c04f0cc22e72c17","194":"55b94921b49857ca22385d33","195":"55b9591eaaa7fab9633df82d","196":"55ba80b112f77ab279a946d3","197":"55ba88f67978296537a2ba42","198":"55ba978143481e53375fef6a","199":"55ba98c2a0587bc54d68c1e0","200":"55ba99358deffbc44d8dde0b","201":"55ba9942a0587bc54d68c1f5","202":"55ba9bdd7978296537a2bd74","203":"55babe977978296537a2c111","204":"55bc65f28deffbc44d8e0bc0","205":"55be6dea12f77ab279a997ae","206":"55be865a8deffbc44d8e2edd","207":"55bfffaa68c869d67cf0133a","208":"55c032182c1b3bec31988202","209":"55c084ae7a6037e67c5971a6","210":"55c0850237816be77caf87a2","211":"55c3ab3c428d74fe28f76ace","212":"55c3ab5e9ecc6dfc28b58ac3","213":"55c3c74d5dab14832485c903","214":"55c3fa8ccac3038224f5f747","215":"55c40f97cac3038224f5f8de","216":"55c4f6b82ee3da6275c31d3f","217":"55d2857c9b45e15c4264a785","218":"55d2859d255950880cfbf4d2","219":"55d4c35131c67ec1498a0ddd","220":"55d4f005a92a8b4b219afaa5","221":"55d4f01b11c7afc2497862c1","222":"55df38d0e1e902fd09cf078a","223":"55df3d527ba498ed43f2c49c","224":"55df3d5c7ba498ed43f2c4a0","225":"55df3d7fc5601f830c8706ee","226":"55df4ccd3d0b019620af46f1","227":"55df4d53069069633605f837","228":"55df4db23d0b019620af4720","229":"55df515f069069633605f91f","230":"55df5ace069069633605fb7d","231":"55df5ed83d0b019620af4b6f","232":"55df63e77ba498ed43f2ccd8","233":"55df6433c5601f830c870f6b","234":"55df648cc5601f830c870f7d","235":"55df64bfe40e943746621167","236":"55df64c7e1e902fd09cf10ce","237":"55df64db069069633605fdae","238":"55df651b069069633605fdbf","239":"55df6546e1e902fd09cf10fb","240":"55df6593c5601f830c870fc0","241":"55df6617e1e902fd09cf111d","242":"55df664de1e902fd09cf1125","243":"55df665ae40e9437466211b6","244":"55df66857ba498ed43f2cd55","245":"55df66b5e40e9437466211d5","246":"55df66e1c5601f830c870ff7","247":"55df6704e40e9437466211e7","248":"55df67247ba498ed43f2cd7b","249":"55df6739e1e902fd09cf114c","250":"55df674bc5601f830c871012","251":"55df6769e40e9437466211f8","252":"55df6785c5601f830c871021","253":"55df6799c5601f830c871023","254":"55df67c5c5601f830c87102d","255":"55df78bf31f3baee64cab492","256":"55df79ceed5c1a937b95a6d1","257":"55df926c31f3baee64cab8e1","258":"55df946f33e556c746e34782","259":"55df9e3faa53caef647d3426","260":"55df9e401b9798c846ec7d8a","261":"55df9e6bcbf802f022f0b8b7","262":"55df9e921b9798c846ec7d9a","263":"55df9e9433e556c746e3488a","264":"55df9ed731f3baee64caba62","265":"55df9f8531f3baee64caba74","266":"55df9feb31f3baee64caba79","267":"55e0b5ad1b9798c846eca1fe","268":"55e0b65c33e556c746e36c8c","269":"55e0bd666d5732de5b76f08d","270":"55e0c1fd3d8fc2d12eaa2a29","271":"55e72041d231aa8e5918c822","272":"55e73d60a75db4b375c3b1a3","273":"55e743eff6fb4f034f6b5d6a","274":"55e74d40a75db4b375c3b502","275":"55e74d494efdf7f978eb23e5","276":"55e74d4fd231aa8e5918d1ee","277":"55e74d93a75db4b375c3b516","278":"55e772f317b2081605a56d52","279":"55e773272ec6bacd1e2da0e6","280":"55e77368f6fb4f034f6b66c0","281":"55e775012ec6bacd1e2da12e","282":"55e775c917b2081605a56dcf","283":"55e77762f6fb4f034f6b675e","284":"55e779754efdf7f978eb2c67","285":"55e779a54efdf7f978eb2c6e","286":"55e77bfca75db4b375c3bdd5","287":"55e77c02a75db4b375c3bdd7","288":"55e77c5ad231aa8e5918db40","289":"55e77cca2ec6bacd1e2da271","290":"55e77e444efdf7f978eb2d25","291":"55e77e85a75db4b375c3be2e","292":"55e77ef62ec6bacd1e2da2b6","293":"55e77f01d231aa8e5918db90","294":"55e77f4e2ec6bacd1e2da2c2","295":"55e77fa6a75db4b375c3be4b","296":"55e78077a75db4b375c3be63","297":"55e78090a75db4b375c3be64","298":"55e780cbd231aa8e5918dbc8","299":"55e7811ba75db4b375c3be7c","300":"55e781a017b2081605a56f6e","301":"55e78374f6fb4f034f6b68ee","302":"55e783d9d231aa8e5918dc32","303":"55e784b24efdf7f978eb2deb","304":"55e784cca75db4b375c3bedc","305":"55e78520a75db4b375c3bee2","306":"55e785cad231aa8e5918dc68","307":"55e78797f6fb4f034f6b6965","308":"55e787c62ec6bacd1e2da3ab","309":"55e78815d231aa8e5918dc90","310":"55e797e617b2081605a571a9","311":"55e86eb346dfeb9c3dbbeed6","312":"55e89bf2d231aa8e591907c3","313":"55e89bfed231aa8e591907c5","314":"55e8df0cd231aa8e59191285","315":"55e9f092b5c3114f7efe7965","316":"55ea2b3daa0b93be49621dc8","317":"55ef350ab69ff6ab0ec54695","318":"55ef409624362d5253fe4400","319":"55ef425396450ece4d8801bd","320":"55f1bc204b090e3d0be42386","321":"56046bf25c1379fe64597125","322":"56046c05131b784f781fc16f","323":"56046e9f5c1379fe645971a0","324":"56046ec8131b784f781fc1f4","325":"560471c35c1379fe6459723f","326":"560479688d1ef72d5a86d6de","327":"56098e6c329b1da05c3b600b","328":"56098ec8519547fc1e3add83","329":"5609be0a329b1da05c3b6908","330":"5609c1df519547fc1e3ae659","331":"5609c246a8546c0d12c50763","332":"5609c2532241dbf91ee57eac","333":"5609c3752241dbf91ee57ecc","334":"5609c393230869a25cc3e7dc","335":"5609c3e2329b1da05c3b69c9","336":"5609c3eca8546c0d12c50795","337":"5609c43da5b78d0e12a3f358","338":"5609c448230869a25cc3e7f3","339":"5609c450519547fc1e3ae6b0","340":"5609c4752241dbf91ee57ee4","341":"5609c884329b1da05c3b6a3c","342":"5609df53a8546c0d12c50a25","343":"5609e4d2a5b78d0e12a3f622","344":"560a1873519547fc1e3aeeb8","345":"560a3c35a5b78d0e12a3fd81","346":"560acc96552ed7913279d774","347":"560aceed081f3a9c044d75c5","348":"560ad0ab95756f1402bc7f59","349":"560aed3495756f1402bc8602","350":"560aed68081f3a9c044d7cbf","351":"560af37b95756f1402bc878a","352":"560af3cc95756f1402bc8798","353":"560b0d5ef4b61c106fb2b0ba","354":"560b38e7dfb3151302856e05","355":"560c11f3552ed791327a07ee","356":"560c24dedfb3151302858f56","357":"560c31c5f4b61c106fb2d9db","358":"560c33b7dfb3151302859257","359":"560c34a7dfb3151302859288","360":"560dc724bd0a2d24271887a9","361":"560dd884b6a13ea04467baf8","362":"560ddef2ff22c70f6faba914","363":"560de076bd0a2d24271889ca","364":"560de1a7ff22c70f6faba954","365":"560ebcf5f4b61c106fb33810","366":"56120b4776931cb7479f0717","367":"5612556276931cb7479f0faf","368":"5612abdcce6e633c45187410","369":"5612b36afd5c74d71413ee51","370":"5612c83076d984a358755167","371":"5612f1a1fd5c74d71413fafe","372":"5612f42d261e77ba2dbad4ae","373":"5612fd7ece6e633c451883f0","374":"5616f1991b0e279854bd76f9","375":"5616f1b50376066b0f8bb925","376":"5616f4c599bbd76f0f306d28","377":"5617029e0376066b0f8bbad4","378":"561798924e0fa3e55447cb55","379":"561798cd99bbd76f0f307f56","380":"561854f983b69fe7548d4f88","381":"56185a2c4e0fa3e55447eb72","382":"56185a386dc64436714a9c8a","383":"56185c604e0fa3e55447ebcb","384":"56185e074e0fa3e55447ebf4","385":"5618693483b69fe7548d519e","386":"5618693b4e0fa3e55447ed22","387":"5618b0b283b69fe7548d56af","388":"5618fa3183b69fe7548d5b2c","389":"5618fa691b0e279854bdb52b","390":"561918920376066b0f8bf96e","391":"561919650376066b0f8bf985","392":"561952d283b69fe7548d6428","393":"561952da99bbd76f0f30b2cc","394":"5619fa9f83b69fe7548d7226","395":"5619faab1b0e279854bdcc7d","396":"5619fae51b0e279854bdcc85","397":"5619fcfe1b0e279854bdcc9a","398":"561a024f4e0fa3e554480e79","399":"561a0c1f1b0e279854bdcd75","400":"561a0c2c6dc64436714abfb3","401":"561a0c3e0376066b0f8c0e27","402":"561a0c5a0376066b0f8c0e29","403":"561a0c794e0fa3e554480ef5","404":"561a0c7e99bbd76f0f30c16e","405":"561a17e81b0e279854bdce1f","406":"561a17f54e0fa3e554480f9b","407":"561a2a471b0e279854bdcf62","408":"561a85954e0fa3e5544816ef","409":"561b9deb0376066b0f8c3450","410":"561b9e2ca15f996e24c496f0","411":"561bec6ca15f996e24c4a63c","412":"561bf0e54e0fa3e554484722","413":"561c4ce618e9eaef64997e25","414":"561c4cfa99bbd76f0f310798","415":"561c7cb7773bc4af20ff1cc8","416":"561c85db99bbd76f0f310c9a","417":"561d3cf50376066b0f8c7526","418":"561d4c7699bbd76f0f312d63","419":"561de46c83b69fe7548df8b0","420":"561e8c50c87f4a670b9d7624","421":"561ec2e6c1c9c8640b033614","422":"561ec2edaa8d9347692bbca9","423":"561ec2f616268fc6428a0672","424":"561ec335c87f4a670b9d8330","425":"561ec8cdc1c9c8640b033736","426":"561ee072aa8d9347692bc119","427":"561ee23316268fc6428a0b50","428":"561ee30c16268fc6428a0b5f","429":"561ee3b03a0d3548695283a6","430":"561eec51c87f4a670b9d88cc","431":"561ef33016268fc6428a0d69","432":"561ef3d9c87f4a670b9d89a8","433":"561ef3f73a0d35486952859c","434":"561fe51834cd85cd6d5c33ae","435":"5622a1319fe8a6060a1ca676","436":"5622a15203c6b52d3c598051","437":"5622a1cce29b4f2c3cbe4c0c","438":"5625c350b485f05e21d3d6fe","439":"5626493610f1958006e8afa8","440":"56264ce0d02b056b102f621f","441":"562681968b37297f06feca85","442":"562e7859b1bb53dd7572120b","443":"562e7c2ba752d57c01914ffc","444":"562e7d4f70e3dd4b5039ac56","445":"562e7d74e8970e4c503e9946","446":"562e7db5738e06e175f43100","447":"562e7ded0791816c7a089632","448":"562e7ecae8970e4c503e99de","449":"562e80e870e3dd4b5039adb1","450":"562e938e738e06e175f433bd","451":"562e939e70e3dd4b5039b3b6","452":"562e93ce70e3dd4b5039b3c9","453":"562e997eb1bb53dd757215c8","454":"562e9998f2ca1c7f0130980e","455":"562ea332a029c1707af2dff8","456":"562ea54870e3dd4b5039b951","457":"562fea9e90cea42a05839ff4","458":"562fef0f90cea42a0583a183","459":"562ff68c6afab45a2ce5e17d","460":"563001f0b1bb53dd757235ab","461":"563002126afab45a2ce5e3ed","462":"563002506afab45a2ce5e3f8","463":"563002656afab45a2ce5e3fe","464":"563006906afab45a2ce5e4fb","465":"56300701b1bb53dd757235f8","466":"563008a56afab45a2ce5e56d","467":"563008bd6afab45a2ce5e572","468":"5630091d829f23db4a4b08e4","469":"5630095590cea42a0583a7ef","470":"5630097f6afab45a2ce5e599","471":"563009a96afab45a2ce5e5a0","472":"563009c290cea42a0583a7fd","473":"56300a146afab45a2ce5e5b6","474":"56300a3290cea42a0583a815","475":"56300a386afab45a2ce5e5b8","476":"56300a616afab45a2ce5e5bd","477":"56300a626afab45a2ce5e5bf","478":"56300a876afab45a2ce5e5c5","479":"56300ac0a752d57c01917459","480":"56300ae5b1bb53dd75723649","481":"56300b0b829f23db4a4b090b","482":"56300b3390cea42a0583a849","483":"56300b356afab45a2ce5e5f2","484":"56300b3c6afab45a2ce5e5f3","485":"56300b4790cea42a0583a84c","486":"56300b596afab45a2ce5e5f7","487":"56300b5d6afab45a2ce5e5f8","488":"56300bb4e16589782d93060c","489":"56300bc3738e06e175f45441","490":"56300bdab1bb53dd7572365a","491":"56300c2590cea42a0583a87c","492":"56300c4d738e06e175f4544a","493":"56300cf7e16589782d930626","494":"56300d61b1bb53dd7572366c","495":"56300dc6738e06e175f45461","496":"56300dfd1cc814df63f7c73f","497":"56300e09829f23db4a4b092e","498":"56300e301cc814df63f7c744","499":"56300ec590cea42a0583a915","500":"56300efd1cc814df63f7c752","501":"56300f1ab1bb53dd75723698","502":"56300f67a752d57c019174a6","503":"5630100190cea42a0583a96b","504":"56301017b1bb53dd757236a6","505":"5630102090cea42a0583a96f","506":"5630104e90cea42a0583a976","507":"5630107090cea42a0583a981","508":"5630113990cea42a0583a9aa","509":"563011d3a752d57c019174cf","510":"563011e090cea42a0583a9c8","511":"563011f26afab45a2ce5e753","512":"563012441cc814df63f7c780","513":"56301a546afab45a2ce5e8c2","514":"56301a556afab45a2ce5e8c4","515":"56301a6c90cea42a0583ab36","516":"56301dab6afab45a2ce5e993","517":"563142406afab45a2ce639d8","518":"56314407fee0347118af0cb1","519":"563144ee6afab45a2ce63a74","520":"56314b27fee0347118af0d5b","521":"56314b4ab1bb53dd7572525b","522":"56314bce738e06e175f470ae","523":"56314bea738e06e175f470af","524":"56314c111cc814df63f7e3ca","525":"56314c21829f23db4a4b2557","526":"56314c6090cea42a058400c3","527":"56314c7890cea42a058400ca","528":"56314c9090cea42a058400d3","529":"56314cb190cea42a058400de","530":"56314ce0738e06e175f470d1","531":"56314cecb1bb53dd7572528a","532":"56314d23b1bb53dd75725294","533":"56314d2afee0347118af0d8c","534":"56314d3f1cc814df63f7e3eb","535":"56314d71e16589782d93225d","536":"56314d78829f23db4a4b2577","537":"56314d87fee0347118af0da1","538":"56314d8c829f23db4a4b2579","539":"56314d99b1bb53dd757252a3","540":"56314daa1cc814df63f7e3f6","541":"56314dbe738e06e175f470ea","542":"56314e336afab45a2ce63d5b","543":"56314e536afab45a2ce63d63","544":"56314e781cc814df63f7e419","545":"5631503a90cea42a058401e4","546":"56315050e16589782d9322b2","547":"5631505c90cea42a058401f0","548":"5631508c6afab45a2ce63dba","549":"563150996afab45a2ce63dc0","550":"563150aab1bb53dd757252ed","551":"563150d9829f23db4a4b25d5","552":"563151166afab45a2ce63de6","553":"56315381fee0347118af0e36","554":"56315fc6e16589782d9323f4","555":"563181566afab45a2ce646d3","556":"5631818e1cc814df63f7e702","557":"5631825090cea42a05840b11","558":"563184b5fee0347118af10aa","559":"563186ab6afab45a2ce6477f","560":"563186e8fee0347118af10c3","561":"5631baa4e16589782d9327e9","562":"5632525d1eaef54003dd8ffd","563":"56325f83738e06e175f48815","564":"563264a7196bdeec543b8b84","565":"56326a531eaef54003dd9960","566":"56326a5d6afab45a2ce68638","567":"56326ad7738e06e175f48980","568":"5632a54f6afab45a2ce6986d","569":"5632a5806afab45a2ce69883","570":"5632a58ac60dc89d53ec6835","571":"5632a5a16afab45a2ce6988f","572":"5632a5f3de1b24f9462be903","573":"5632a718738e06e175f4904a","574":"5632a72beab237df570944e7","575":"5632a7376afab45a2ce698fb","576":"5632a739b1bb53dd757271b2","577":"5632a77bc60dc89d53ec689e","578":"5632a7c1fee0347118af2c1e","579":"5632a7c6c60dc89d53ec68b1","580":"5632a7e1eab237df57094500","581":"5632a7e6196bdeec543b92f6","582":"5632a809c60dc89d53ec68c7","583":"5632a84cb1bb53dd757271cf","584":"5632a85cc60dc89d53ec68e7","585":"5632a956738e06e175f4907f","586":"5632a9aa738e06e175f49089","587":"5632a9cefee0347118af2c47","588":"5632a9f6b1bb53dd757271f1","589":"5632aa8ade1b24f9462be967","590":"5632aabc196bdeec543b9333","591":"5632aabe196bdeec543b9334","592":"5632ad50de1b24f9462be9b7","593":"5632aeb7eab237df570945b4","594":"5632aee2b1bb53dd75727284","595":"5632b460c60dc89d53ec6b3d","596":"5632b462c60dc89d53ec6b3f","597":"5632c4f0196bdeec543b9510","598":"5632cbcdeab237df57094786","599":"5632d058c60dc89d53ec7034","600":"5632d0a9738e06e175f49311","601":"5632d0c9fee0347118af2eef","602":"5632d0dbc60dc89d53ec7054","603":"5632d143c60dc89d53ec706d","604":"5632d16a6afab45a2ce6a100","605":"5632d1b2c60dc89d53ec707d","606":"5632d3af6afab45a2ce6a1b5","607":"5632d3fceab237df57094809","608":"5632d418c60dc89d53ec7102","609":"5632d43cde1b24f9462bec30","610":"56339587643ae8fb655b2601","611":"5633af09195a24fc65bd59af","612":"5633d8ea44f10a06616c7f09","613":"5633d932e87b056a49cd9cb8","614":"5633df33195a24fc65bd6946","615":"5633e26b195a24fc65bd6a5b","616":"5633e5eee4bb7eee5380006b","617":"5633e68816a002076192042f","618":"5633f691643ae8fb655b4492","619":"5633fdca195a24fc65bd715b","620":"5634a4ac643ae8fb655b5afd","621":"5634a4dd643ae8fb655b5b04","622":"5634a4fa643ae8fb655b5b0a","623":"5634a504643ae8fb655b5b0c","624":"5634ec1744f10a06616c8dee","625":"56374cac8afec94a69a8af0d","626":"563788f655ebdc6924ad6709","627":"5637d97faefcbd6411ee1be3","628":"5637d9aa0800da954de68180","629":"5637d9f3a530033014e3a350","630":"5637da5c3003682f1408d5bf","631":"5637da76a530033014e3a381","632":"5637da8b3003682f1408d5dd","633":"5637da9a0800da954de681a8","634":"5637daa03003682f1408d5df","635":"5637daba3003682f1408d5ea","636":"5637dac83003682f1408d5f4","637":"5637daf1a530033014e3a3b2","638":"5637db0fa530033014e3a3c6","639":"5637db323003682f1408d616","640":"5637db5a3003682f1408d622","641":"5637dbaf64376ec44425d009","642":"5637dbc7aefcbd6411ee1c3f","643":"5637dbe30d4ff3974d48cf88","644":"5637dc09c74a90c7447908e6","645":"5637dc100d4ff3974d48cf8e","646":"5637dc18c74a90c7447908ea","647":"5637dc320d4ff3974d48cf94","648":"5637dc773bf3166611122441","649":"5637dc850800da954de681fa","650":"5637dcbd0d4ff3974d48cfaa","651":"5637df743003682f1408d78d","652":"5637f1d30800da954de683bd","653":"5637f1d40d4ff3974d48d16d","654":"5638fe880800da954de698ba","655":"5638feaeaefcbd6411ee3357","656":"5639064882077add3ea57bf4","657":"5639064f40bd5f195ff970b6","658":"563907f4c74a90c74479212b","659":"56390861c74a90c744792140","660":"56390bd00800da954de69a9d","661":"563940c55680530d2704174d","662":"563b4ffe5680530d2704988e","663":"563b50115680530d27049898","664":"563b502e5680530d270498a1","665":"563ba6932e8c19094ebff966","666":"563ba7b93264958d1dc5c06b","667":"563c30dd2e8c19094ec01ea2","668":"563c30e12e8c19094ec01ea4","669":"563c3132c712fe074e4dd9e6","670":"563c32ffb615876d0329b272","671":"563c3501b615876d0329b298","672":"563c563cc712fe074e4ddf23","673":"563c601db615876d0329b4bb","674":"563f0475c712fe074e4e5fbf","675":"563f04802e8c19094ec0a2c0","676":"563f04972e8c19094ec0a2c7","677":"563f049bc712fe074e4e5fc4","678":"563f049f2e8c19094ec0a2cc","679":"563f04a32e8c19094ec0a2cd","680":"563f04a92e8c19094ec0a2d0","681":"563f04afc712fe074e4e5fc6","682":"563f04b5c712fe074e4e5fc7","683":"563f04c52e8c19094ec0a2d3","684":"563f04c8c712fe074e4e5fc8","685":"563f04ccc712fe074e4e5fc9","686":"563f050f2e8c19094ec0a2da","687":"56410356565da33267ff6195","688":"5641039b565da33267ff61a4","689":"564105ebfa021fde389cdbd0","690":"5641060d565da33267ff62a1","691":"5641061f565da33267ff62a9","692":"5641062b6420c33467a0de75","693":"56410631fa021fde389cdbd7","694":"564106d58b872257348e1724","695":"564109696420c33467a0df2e","696":"564113e924b05a58349a31ac","697":"5641144824b05a58349a31b4","698":"564114b96420c33467a0e3aa","699":"564114cd94df6212290d77ee","700":"564115b5565da33267ff6826","701":"5641166904a883da3838c7fa","702":"56411693f3818b1329722e7e","703":"56411ef38b872257348e198e","704":"5641411104a883da3838cbeb","705":"56414136565da33267ff73e9","706":"5641550efa021fde389ce31d","707":"5641f1266420c33467a111fe","708":"5641f51e6420c33467a1132f","709":"5642c89594df6212290d9dce","710":"5642cb7c04a883da3838ee4f","711":"564362845f3db8f60ab60858","712":"5643eaffe87e46584ff8325d","713":"564524c696589f4338672bc8","714":"564575da6296df7f6efe8bde","715":"564575eb5b7a2ea84f080703","716":"564583685b7a2ea84f08077d","717":"564583806296df7f6efe8c70","718":"5646150310f6aea94fdd92e9","719":"5648c4648b242470793ddd25","720":"5648f1cbbb11d072795971bb","721":"5648f1ec8b242470793de608","722":"5648f20ebb11d072795971e0","723":"5648f220bb11d072795971e5","724":"5648f266bb11d07279597205","725":"5648f268bb11d07279597209","726":"5648f2758b242470793de63f","727":"5648f2858b242470793de643","728":"5648f33696589f4338676463","729":"5648f3c0bb11d07279597274","730":"5648f3fcbb11d07279597281","731":"5648f4718b242470793de6b6","732":"564b68674b1ce2051315002d","733":"564b73131b3afc352ce4019c","734":"564b8cb8aa93e61d2b3a777b","735":"564bbdcee1d84b04136fdfd3","736":"564bbf0209446b3b7461719e","737":"564bc1e4aa93e61d2b3a7e39","738":"564bc21994a38a3d746c2722","739":"564bc3844b1ce20513151f45","740":"564cf9555131832b69bf0b26","741":"564cf9a5078392d727fe1449","742":"564d236c7ae518a71d2fb6b7","743":"564d2685167ee3a91d43dab0","744":"564d4b707ae518a71d2fbcef","745":"564e6a7211ff1d3016e21912","746":"564e6a90b085313316562348","747":"564e6a96b08531331656234a","748":"564e6aa311ff1d3016e21923","749":"564e6ac4b08531331656235a","750":"564e6ad3b08531331656235b","751":"564e6b24b085313316562371","752":"564e6b4811ff1d3016e21953","753":"564edf4c65bc78376216f1bd","754":"564f692f1a00e4f00803be78","755":"564f6994051b93d13c8d5511","756":"564f69ff541ec57a66e2db7e","757":"5650c6f6541ec57a66e2f028","758":"5650c765ce18827866f509f8","759":"5650ed07a051fea34242fda1","760":"56536cadacb264dc163ac2e7","761":"56536cb6c83590a708fb4d7b","762":"56536cc9acb264dc163ac2ed","763":"56536cf453a476873d213cbd","764":"56536d0cacb264dc163ac2fc","765":"56536da177b7a53a219e18e6","766":"56536deac83590a708fb4daa","767":"56537d34f2bb4538210ad701","768":"565381df77b7a53a219e211d","769":"5653a537ed9779de16ee1202","770":"5653adb8acb264dc163ac9e8","771":"5653af5eed9779de16ee1285","772":"5653af9453a476873d214443","773":"5653b258acb264dc163aca26","774":"5655d0f392aa9746647b7ab4","775":"56560fb8cac1354864a6f1e0","776":"56564add92aa9746647b8fb4","777":"5657a2ab3a7600fd2f879e5d","778":"5657a2c663bfb30b58e49ee8","779":"5657a70363bfb30b58e49f28","780":"5657a7e2f59a8f0758a712ea","781":"5658bd702753fafb4af5d291","782":"5658d3149991fe124e1580ff","783":"5658d36f7b1084ab21a50413","784":"5658d51049e74fad21eb71c8","785":"5658d8a028c5280777268804","786":"5658d9927b1084ab21a504a5","787":"5658da46c3d575114e6c70fe","788":"5660a3d42cbea1d7054de927","789":"5660a3f75057376520db6e50","790":"5661c2e22cbea1d7054e104c","791":"5665afd1d2a5a7813cd4a81c","792":"5665c63c981d328249333a16","793":"5665c6597b5b888449a7e49b","794":"5665c68b868b8da62a253756","795":"5665c703accacb904891e7ce","796":"56660e03accacb904891f645","797":"5666abea868b8da62a25562f","798":"5666abf7981d328249335836","799":"5666ac04b692dc8f48f4e669","800":"566719d57b5b888449a8170c","801":"56672ffdb692dc8f48f4fde0","802":"5668ca60835961e946e23148","803":"5668caf8868b8da62a25ae69","804":"5668cb1d868b8da62a25ae6e","805":"567ae06335e1a316162e028e","806":"567ae073653b30761d75e263","807":"567ae0983c68940269249613","808":"567af975653b30761d75e5e8","809":"567b44d0653b30761d75ee0d","810":"568d4be99a5f8fe839217b02","811":"568da54f17dc78be33873695","812":"568daafa84fa46770b24fcac","813":"568e46bf9a19aa6404098975","814":"568ed2460712a5b63b4c2c76","815":"568ed49e7669220736027b14","816":"568f6e3687cb99b53b87e44c","817":"568f9507d739f50a36026b40","818":"568ff9deb1f439094a070e6c","819":"569017a2d739f50a360283c7","820":"5696f41428b4586d1c8c8717","821":"569c80f459e3d04215bc57ce","822":"569c909959e3d04215bc595e","823":"569c90a32bc35f6c1c1aac3a","824":"569cba1f59e3d04215bc5e8e","825":"569cba6c5de13b3f15e3aeed","826":"569d1d8628b4586d1c8d5570","827":"569d1db0c391361d48ebc973","828":"569d43945de13b3f15e3c900","829":"569d669ca03e28ad1adf7756","830":"569e8e722bc35f6c1c1b0318","831":"569e922e28b4586d1c8d965e","832":"569e9872c391361d48ec0c2c","833":"569fcae9da358920486fd7b9","834":"569fe6dac391361d48ec43ac","835":"56a0d7d32bc35f6c1c1b6053","836":"56a6e6ff586242210adf8592","837":"56a6e7178fbaf4220af95122","838":"56a6e7ea586242210adf85aa","839":"56a6e803eaf741c118d4e0e1","840":"56a6e900eaf741c118d4e0ff","841":"56a6e9188fbaf4220af95155","842":"56a6e9328fbaf4220af95158","843":"56a6e99caaae7a3a75931986","844":"56a6e9af80ad69394a7a7344","845":"56a6e9d1aaae7a3a7593198a","846":"56a6e9f8c54bc2bf180c0636","847":"56a6ea1ec54bc2bf180c063a","848":"56a6ea206b6468374a097fd8","849":"56a6ea3480ad69394a7a7350","850":"56a6ea3d586242210adf85e6","851":"56a6ea47dc33b33c7547dd7e","852":"56a6ea61586242210adf85ea","853":"56a6ea88dc33b33c7547dd85","854":"56a6ea99586242210adf85ef","855":"56a6eade6b6468374a097feb","856":"56a6ebb1aaae7a3a759319b3","857":"56a6ebe780ad69394a7a737f","858":"56a6ec0480ad69394a7a7382","859":"56a6ec64dc33b33c7547ddbf","860":"56a6edb5c54bc2bf180c068e","861":"56a6edc8c54bc2bf180c0691","862":"56a6ee07eaf741c118d4e160","863":"56a6ee5880ad69394a7a73b0","864":"56a6f0018fbaf4220af951e7","865":"56a6f3a9586242210adf86bb","866":"56a70bfec54bc2bf180c08e9","867":"56a70c086b6468374a09823b","868":"56a70c60eaf741c118d4e3b1","869":"56a70d278fbaf4220af9542f","870":"56a70de3dc33b33c7547e04e","871":"56a70e856b6468374a098264","872":"56a70e9080ad69394a7a7605","873":"56a71e7a586242210adf89e8","874":"56a72714c54bc2bf180c0ac9","875":"56a727268fbaf4220af95671","876":"56a7c9e06b6468374a09a626","877":"56a7cc646b6468374a09a6de","878":"56a7cc7880ad69394a7a9a32","879":"56a80482586242210adfb8c6","880":"56a804c98fbaf4220af983d1","881":"56a825b480ad69394a7aaa28","882":"56a825c6586242210adfbd9f","883":"56a83580aaae7a3a759352b8","884":"56a837948fbaf4220af98a90","885":"56a837a0c54bc2bf180c3fc6","886":"56a8392a8fbaf4220af98aaa","887":"56a83fedc54bc2bf180c4059","888":"56a8403a6b6468374a09b97e","889":"56a8a852586242210adfccd7","890":"56a9155f80ad69394a7ad13c","891":"56a97d948fbaf4220af9c324","892":"56a9b31180ad69394a7ae926","893":"56a9b5526b6468374a09f762","894":"56a9b5a5dc33b33c754854a4","895":"56a9b61880ad69394a7ae954","896":"56aa1e69586242210ae0108f","897":"56aa1e7b586242210ae01094","898":"56aaffd1c54bc2bf180cba59","899":"56aba3d5c54bc2bf180cd6ae","900":"56aba6736b6468374a0a50be","901":"56abd5cfc54bc2bf180ce19e","902":"56abd6f1aaae7a3a7593f28e","903":"56abd727c54bc2bf180ce1ef","904":"56aca34ceaf741c118d5cf3a","905":"56ae946a8fbaf4220afa74db","906":"56ae94bd8fbaf4220afa74e2","907":"56ae9518586242210ae0ab99","908":"56ae9686586242210ae0abbb","909":"56ae9692586242210ae0abbe","910":"56ae972a8fbaf4220afa7523","911":"56ae97ccc54bc2bf180d2a27","912":"56af9649586242210ae0d76e","913":"56afeb2cdc33b33c75493e17","914":"56afeb468fbaf4220afab251","915":"56b0e3a080ad69394a7bf886","916":"56b0e3edaaae7a3a7594a314","917":"56b0e4ee586242210ae1130a","918":"56b0e5148fbaf4220afadb71","919":"56b0e5b38fbaf4220afadb9c","920":"56b0e787c54bc2bf180d8fe6","921":"56b0ecf3586242210ae114d5","922":"56b123c4eaf741c118d675a4","923":"56b123e5586242210ae1211c","924":"56b123ea586242210ae1211f","925":"56b127ffaaae7a3a7594b24d","926":"56b12825dc33b33c7549759d","927":"56b16f7580ad69394a7c1255","928":"56b1703ac54bc2bf180da961","929":"56b17412aaae7a3a7594bded","930":"56b1dc83aaae7a3a7594cadd","931":"56b1eb97c54bc2bf180db9b2","932":"56b1edf0dc33b33c754990dd","933":"56b24fbc958093bc12d18c94","934":"56b261fc958093bc12d190ec","935":"56b263491191fcc8353b75a8","936":"56b263f63bb131bb121b28f8","937":"56b27e003bb131bb121b2ee1","938":"56b27e71a867d14059a35f12","939":"56b28409a867d14059a36054","940":"56b2a18b3bb131bb121b3450","941":"56b32d165245f2e110e739f1","942":"56b3bc95d58a7a680d1b0143","943":"56b3bd663bd55a660df5741c","944":"56b3bf0ad58a7a680d1b01e7","945":"56b3ed67d58a7a680d1b0a58","946":"56b47a9265d6cbe72904482c","947":"56b4815b70aea8e629e6721a","948":"56b516e32bb6eb8230a1ba4b","949":"56b51a97939ffd5d15f60de2","950":"56b51df7939ffd5d15f60e81","951":"56b5329f1c80c61f4d0a9fba","952":"56b554b91c80c61f4d0aa321","953":"56ba53029a395e5d1151eda7","954":"56ba5341bd3dfe40303df466","955":"56ba53809a395e5d1151edc6","956":"56ba53e09a395e5d1151eddb","957":"56ba53f59a395e5d1151ede1","958":"56ba542a9a395e5d1151eded","959":"56ba548abd3dfe40303df4c5","960":"56ba62a737ae7622436bc420","961":"56ba671c5e0e1860110b6883","962":"56ba6c9f9928374130b453e1","963":"56ba6ccf3fab8f985ec9915b","964":"56ba6d1137ae7622436bc64e","965":"56ba6d5237ae7622436bc65a","966":"56ba6da65e0e1860110b69ca","967":"56ba6dbd9a395e5d1151f3e5","968":"56ba6dc19928374130b4541b","969":"56ba6dcd37ae7622436bc671","970":"56ba6e129928374130b45429","971":"56ba6e2a9928374130b4542f","972":"56bcd6f5d9c5a252408ed737","973":"56bcd7121fbcdac178979217","974":"56bcdbadfa79226456f9c6a2","975":"56bcdc5b4dfe1fa71ffc31f1","976":"56bcdca637437b675608ae14","977":"56bcf16b1fbcdac1789797cf","978":"56bcfbaa38f56aa31f396683","979":"56c34f905b4d26c75821cf1a","980":"56c5617528357a987fbebf6c","981":"56c57ca1443730631ea979e3","982":"56c57e31611729797fd29c57","983":"56c57e3aafaa77c168107b38","984":"56c57ed4443730631ea97a4a","985":"56c583bbaa5f8e7a7f674923","986":"56c583d8443730631ea97b15","987":"56c583e7443730631ea97b18","988":"56c59fc71c98d5621ea7c034","989":"56c61e06d80d8e972442e47b","990":"56c6e092e1786831677bf7da","991":"56c6e0b01aea4f3067525a8d","992":"56c6f0347a66b5965f68d43b","993":"56c6f096833e58f50fb01de1","994":"56c75fa21aea4f306752772b","995":"56c75fd27a66b5965f68edd6","996":"56c760851aea4f3067527759","997":"56caa10c5c3b0559674dc483","998":"56caa9671aea4f306752cdee","999":"56caf7d7d12993d965570297","1000":"56caf7e87a66b5965f695065","1001":"56cb93a3631af87d5c45104d","1002":"56cbb33dd12993d965572d80","1003":"56cbb702a6edbb623dbb67ee","1004":"56cdfad6cefdb7b850f39688","1005":"56cdfade12b251b950ede4c3","1006":"56cdfb2fdbccfd8a4fd032ca","1007":"56cdfb5ebfb1cf9a7ff2cb32","1008":"56cdfc58dbccfd8a4fd0330e","1009":"56cdffb9dbccfd8a4fd033c4","1010":"56ce062abfb1cf9a7ff2cdf9","1011":"56ce4a8b5ccb80662433edcb","1012":"56ceb4f3dbccfd8a4fd05023","1013":"56ceb4fa8bbe6265248fa2f8","1014":"56d4e77b9b88648d7a092e30","1015":"56d4e8a3b79fb81f187b2cb1","1016":"56d4e9ea80c1170e6db72f8e","1017":"56d4e9fdb79fb81f187b2cfa","1018":"56d5397c5839ddd64ab42005","1019":"56d5399880c1170e6db73ebc","1020":"56d5399b712bb6033acfb968","1021":"56d53a868cfda8823613ee8d","1022":"56d53c03712bb6033acfb9c1","1023":"56d53c0a5839ddd64ab4207b","1024":"56d53c65b0c932986954faab","1025":"56d53c8b649ae49a694b9585","1026":"56d53ca3b79fb81f187b3ce9","1027":"56d54474649ae49a694b96f1","1028":"56d58d3fa9cbb2b1605f4a1a","1029":"56d6039e50b462292adf3802","1030":"56ddcbab19834f3c35358ccb","1031":"56ddcbd0126367383571a7d4","1032":"56ddd70e126367383571ab35","1033":"56ddd7b568ddef7764695cbe","1034":"56dddaf9ddfe3d4316287158","1035":"56ddeb74126367383571b189","1036":"56ddf0ccddfe3d431628781f","1037":"56ddf0f868ddef776469647f","1038":"56ddf27619834f3c353598e7","1039":"56ddf278a5492841166924a2","1040":"56ddf292817dfa1e41ed243c","1041":"56ddf2a0b0cc3f1b4150da90","1042":"56ddf2ab817dfa1e41ed2448","1043":"56ddf2c768ddef7764696527","1044":"56ddf300a5492841166924da","1045":"56deee5068ddef7764699cc1","1046":"56deee5fddfe3d431628b12a","1047":"56def3a968ddef7764699ea8","1048":"56def3f1a549284116695f19","1049":"56def453817dfa1e41ed5ebc","1050":"56def46da549284116695f49","1051":"56def48a68c07774648372e5","1052":"56def494ddfe3d431628b37c","1053":"56def4b7a549284116695f6c","1054":"56def4d9b0cc3f1b415114b6","1055":"56def4dc817dfa1e41ed5f00","1056":"56def4e868c0777464837303","1057":"56def524ddfe3d431628b3b2","1058":"56def53e68c0777464837328","1059":"56def548a549284116695fa8","1060":"56def56719834f3c3535d3cc","1061":"56def56bb0cc3f1b415114f1","1062":"56def5a468ddef7764699f7e","1063":"56def5de68c0777464837365","1064":"56def5e8a549284116695fd9","1065":"56def609126367383571ee9b","1066":"56def62268ddef7764699fb2","1067":"56def62d19834f3c3535d41c","1068":"56def63e19834f3c3535d424","1069":"56def648a549284116695ffc","1070":"56def656ddfe3d431628b435","1071":"56def66319834f3c3535d438","1072":"56def68268c07774648373ae","1073":"56def6a568ddef7764699fec","1074":"56def703ddfe3d431628b471","1075":"56df2689a5492841166971de","1076":"56dfaf1168ddef776469d0c4","1077":"56dfbd88b0cc3f1b415148fa","1078":"56dfbddb19834f3c35360867","1079":"56e03accb0cc3f1b41516cb6","1080":"56e07040f2e48add027c6d3e","1081":"56e078e481bce261378ac2ae","1082":"56e07ddc79cbb6944e1060be","1083":"56e07e51f2e48add027c71d1","1084":"56e081af0055f8f35a81b17e","1085":"56e13e01c7364f7926bda8bc","1086":"56e1420dc7364f7926bdaa02","1087":"56e1437d11a3dbf55acaaad1","1088":"56e144f93194fbd11095c4a3","1089":"56e14a8ec7364f7926bdacb1","1090":"56e14ae589dd3cce10052d7e","1091":"56e14b066fde057c268572a4","1092":"56e156d19f24605773d6df00","1093":"56e159eb3194fbd11095cae3","1094":"56e162320055f8f35a81e67f","1095":"56e171853194fbd11095d119","1096":"56e199c70055f8f35a81f90e","1097":"56e23e8511a3dbf55acaf54e","1098":"56e23f110055f8f35a8227e7","1099":"56e31579c7364f7926be2f3d","1100":"56e3157b11a3dbf55acb3069","1101":"56e31596c7364f7926be2f50","1102":"56e315a86fde057c2685f5c1","1103":"56e315ac89dd3cce1005ae68","1104":"56e315b40055f8f35a82633a","1105":"56e318c83194fbd110964667","1106":"56e3191111a3dbf55acb31cb","1107":"56e3194b3194fbd110964688","1108":"56e319599f24605773d75f2c","1109":"56e319d10055f8f35a8264d6","1110":"56e31a313194fbd1109646e3","1111":"56e31a46c7364f7926be30ee","1112":"56e31a790055f8f35a826521","1113":"56e327526fde057c2685fbc9","1114":"56e327a76fde057c2685fbf4","1115":"56e32be289dd3cce1005b584","1116":"56e32c0d11a3dbf55acb3824","1117":"56e32eedc7364f7926be37c0","1118":"56e32f0411a3dbf55acb391b","1119":"56e32f0611a3dbf55acb391c","1120":"56e32f13c7364f7926be37dc","1121":"56e32f206fde057c2685fe35","1122":"56e32f2dc7364f7926be37e1","1123":"56e32f2f9f24605773d7661a","1124":"56e32f5e9f24605773d76627","1125":"56e32f7b11a3dbf55acb3941","1126":"56e32fb1618c335373eb12ea","1127":"56e32fe2618c335373eb12f3","1128":"56e330943194fbd110964dd0","1129":"56e4722889dd3cce1005e6b0","1130":"56e693303194fbd11096cbba","1131":"56e725033194fbd1109700ad","1132":"56e7259e0055f8f35a832438","1133":"56e725ad9f24605773d81e4e","1134":"56e7b25fc7364f7926bf0e3d","1135":"56e907ba0055f8f35a839a90","1136":"56e99023c7364f7926bf92bc","1137":"56e9f4d09f24605773d8df27","1138":"56e9fe8c6fde057c26877a68","1139":"56e9fea09f24605773d8e11f","1140":"56e9feaa89dd3cce100727e2","1141":"56ea0018618c335373ec8e61","1142":"56ea002bc7364f7926bfb41e","1143":"56ea00426fde057c26877ab8","1144":"56ea461a11a3dbf55accbd2b","1145":"56ea46389f24605773d8ec97","1146":"56eae7c3d37167a26ea0c103","1147":"56eafc032316027b785e3ffe","1148":"56eafc10d37167a26ea0c876","1149":"56eafc63c081db78786b04a3","1150":"56eafd5f2316027b785e407c","1151":"56eb10c78f56f9a16e0d9621","1152":"56eb10d5de00745d3dd38058","1153":"56eb111c2316027b785e46b4","1154":"56eb11768f56f9a16e0d964c","1155":"56eb14d9c081db78786b0c6f","1156":"56eb15726fbc43bf4098f13a","1157":"56eb2364ec99d7bd40a0855b","1158":"56eb2386ec99d7bd40a08569","1159":"56eb23afc081db78786b114f","1160":"56eb23bec081db78786b1158","1161":"56eb23de2316027b785e4ca5","1162":"56eb23df2316027b785e4ca6","1163":"56eb23ea2316027b785e4ca9","1164":"56eb23ec6fbc43bf4098f644","1165":"56eb23f2c081db78786b1170","1166":"56eb24366fbc43bf4098f661","1167":"56eb24532316027b785e4cce","1168":"56eb246cd37167a26ea0d5cb","1169":"56eb2479d37167a26ea0d5d1","1170":"56eb247ede00745d3dd386b0","1171":"56eb2489c081db78786b119f","1172":"56eb248f2316027b785e4ce7","1173":"56eb2494c081db78786b11a4","1174":"56eb24a0d37167a26ea0d5d9","1175":"56eb24b6ec99d7bd40a085cf","1176":"56eb24c52316027b785e4cf7","1177":"56eb4625d37167a26ea0de99","1178":"56eb46382316027b785e5578","1179":"56eb4658c081db78786b1a95","1180":"56ec7adb0d69dfd122211560","1181":"56ee45060425c72f73f1687c","1182":"56ee452ece5b0c6e7a1c2439","1183":"56ee45ccbb4a1731739b5bc2","1184":"56ee464dbb4a1731739b5bc8","1185":"56ee46b00d69dfd122214ddc","1186":"56ee46f50d69dfd122214de4","1187":"56ee470d8680486236c1651e","1188":"56ee4750ce5b0c6e7a1c2451","1189":"56ee47680d69dfd122214dea","1190":"56ee47a58680486236c1652b","1191":"56ee47c1bb4a1731739b5be0","1192":"56ee47d80425c72f73f1689f","1193":"56ee47df8b806f6b7a18b743","1194":"56ee4832bb4a1731739b5bea","1195":"56ee485d654d30d022e47fda","1196":"56efaa6b8b806f6b7a18e762","1197":"56eff6cd590ecaef713a4072","1198":"56f02c56590ecaef713a53aa","1199":"56f0405eab8cc6f071f9cccb","1200":"56f0c96a0ac0de6626ff7e35","1201":"56f0ca15ab8cc6f071f9ecdc","1202":"56f0ca4aab8cc6f071f9ece2","1203":"56f0cafe0ac0de6626ff7e60","1204":"56f0cb270ac0de6626ff7e65","1205":"56f0cd28745dcc317038dbcf","1206":"56f0cfeaab8cc6f071f9edb3","1207":"56f0d007fb42f03070c5afdf","1208":"56f0d01d590ecaef713a79e8","1209":"56f1e7640d5edb734e67184e","1210":"56f1e7762d4bbff80a3fce2d","1211":"56f1e8310d5edb734e671877","1212":"56f1e8700d5edb734e671883","1213":"56f1ec9c2d4bbff80a3fcf31","1214":"56f1ecc5ddb288721eed2eed","1215":"56f1ece4a80ca7f40ae3206b","1216":"56f1ed040d5edb734e67194c","1217":"56f1f8822d4bbff80a3fd16a","1218":"56f1f8b3673d92744ee04874","1219":"56f1fa282d4bbff80a3fd1b9","1220":"56f1fbd7e247956f1e30330d","1221":"56f1fcbdddb288721eed31b0","1222":"56f1fce4a80ca7f40ae32328","1223":"56f1fda6a80ca7f40ae32355","1224":"56f1fdeba80ca7f40ae32365","1225":"56f1fe01a80ca7f40ae3236c","1226":"56f1fe16ba45ef634e8d94ef","1227":"56f1fe1bba45ef634e8d94f0","1228":"56f1fe47e247956f1e303367","1229":"56f1fed5673d92744ee0497b","1230":"56f1ff282d4bbff80a3fd26a","1231":"56f1ff3ce247956f1e30338e","1232":"56f1ffd2673d92744ee049a5","1233":"56f213fb0d5edb734e671fe4","1234":"56f214330d5edb734e671fe9","1235":"56f214492d4bbff80a3fd5a6","1236":"56f21476ddb288721eed358d","1237":"56f21491d8f8e9624e75e2dd","1238":"56f214fbddb288721eed35a2","1239":"56f2150eddb288721eed35a7","1240":"56f21517ba45ef634e8d98a3","1241":"56f2154be247956f1e303705","1242":"56f2154e0d5edb734e67202a","1243":"56f215912d4bbff80a3fd5e2","1244":"56f21647a80ca7f40ae32738","1245":"56f216d4673d92744ee04db0","1246":"56f21788ba45ef634e8d9903","1247":"56f217b8d8f8e9624e75e35d","1248":"56f218a0ddb288721eed3638","1249":"56f218dc0d5edb734e6720b7","1250":"56f21d262d4bbff80a3fd72f","1251":"56f21e0addb288721eed372a","1252":"56f2d9102873ab8d3c444628","1253":"56f2da17f2d91a947b64826e","1254":"56f2da232873ab8d3c444691","1255":"56f35519b94e9f676f04bd26","1256":"56f3588c0da6416b6f9bfbcd","1257":"56f40f15bbffcc665fa90eac","1258":"56f5888e11ea211749c1f9a3","1259":"56f5888fe4a8384a1bbc11c3","1260":"56f588bbbbffcc665fa96652","1261":"56f588d18d2a72471b7a41a0","1262":"56f588e011ea211749c1f9b9","1263":"56f588f9e4a8384a1bbc11e9","1264":"56f64803bbffcc665fa98306","1265":"56f648048f5147e119f0b120","1266":"56f6481cd39de41b495de7c0","1267":"56f652e5e4a8384a1bbc2f7f","1268":"56f652e7d39de41b495de895","1269":"56f652efe4a8384a1bbc2f82","1270":"56f652fb11ea211749c216f7","1271":"56f656a98d2a72471b7a5fe0","1272":"56f656b511ea211749c21732","1273":"56f65b028f5147e119f0b2bb","1274":"56f65b1dd39de41b495de926","1275":"56f8ac52d39de41b495e33ff","1276":"56f91a8676b6f9de194bc875","1277":"56f91aa08f5147e119f10e0a","1278":"56f91aade4a8384a1bbc8a35","1279":"56f9891f8f5147e119f12d0e","1280":"56f989b98f5147e119f12d40","1281":"56f98b1c76b6f9de194be74d","1282":"56fa24c6d9b73e635f672b94","1283":"56fa2519d39de41b495e801b","1284":"56fa2535d9b73e635f672bab","1285":"56fa259bd9b73e635f672bc0","1286":"56fa2c62e4a8384a1bbcc9c5","1287":"56fa2c7bbbffcc665faa18d0","1288":"56fa45aa76b6f9de194c0dc0","1289":"56fbfabd76b6f9de194c8cb4","1290":"56fbfbfb8f5147e119f1d355","1291":"56fc98acbbffcc665faac35f","1292":"56fc9d94bbffcc665faac422","1293":"56fcb2288d2a72471b7bac40","1294":"56fcb23876b6f9de194cbc7b","1295":"56fd1f65d39de41b495f525e","1296":"56fd3d04d39de41b495f5ebd","1297":"56fd3d49d39de41b495f5ee0","1298":"56fd46a776b6f9de194cea72","1299":"56fd5479d9b73e635f680b77","1300":"56fd5e69e4a8384a1bbdb18d","1301":"56fd5e6d76b6f9de194cf308","1302":"56fdb01dbbffcc665fab172c","1303":"56fdc2abe4a8384a1bbdcf69","1304":"56fdc2cb11ea211749c3b81b","1305":"56fdc2d9d9b73e635f682c90","1306":"56fdc33ae4a8384a1bbdcf84","1307":"56fdc374d478c81e2cbc0487","1308":"56fe26af8d2a72471b7c0f42","1309":"56fe9a4bd9b73e635f685ddf","1310":"56fe9b8311ea211749c3eaad","1311":"56fec9c4d478c81e2cbc465a","1312":"56fed07c76b6f9de194d551d","1313":"56fed08176b6f9de194d5523","1314":"56fed1808d2a72471b7c42ee","1315":"56fed184bbffcc665fab5c67","1316":"56fed1f1d9b73e635f686eaf","1317":"56fed24676b6f9de194d558f","1318":"56fed5dbd39de41b495fcd96","1319":"56fed654d39de41b495fcdbd","1320":"56fed73476b6f9de194d56f9","1321":"56fed864d39de41b495fce54","1322":"56fed87cd478c81e2cbc4ab0","1323":"56fed886d478c81e2cbc4ab3","1324":"56fed8e3e4a8384a1bbe14d6","1325":"56fed900d9b73e635f68707d","1326":"56fed9aae4a8384a1bbe151b","1327":"56fedabdd9b73e635f6870f6","1328":"56fedacdd39de41b495fcefd","1329":"56fedae58d2a72471b7c458e","1330":"56fedb18e4a8384a1bbe1583","1331":"56fedb27e4a8384a1bbe1588","1332":"56fedb32bbffcc665fab5efb","1333":"56fedb6bd9b73e635f687130","1334":"56fedb86d9b73e635f687136","1335":"56fedbaad39de41b495fcf37","1336":"56fedf83bbffcc665fab602f","1337":"56fedfa5d9b73e635f687256","1338":"56fedfb5d39de41b495fd056","1339":"56fee1178d2a72471b7c4738","1340":"56fee126d39de41b495fd0a7","1341":"56fef192d478c81e2cbc50af","1342":"56fef358d39de41b495fd4cc","1343":"56fef471d478c81e2cbc5172","1344":"56fef49fbbffcc665fab6514","1345":"56ff0c4fe4a8384a1bbe1f60","1346":"56ff0e9cbbffcc665fab69db","1347":"56ff0eb58d2a72471b7c5052","1348":"56ff4de7e4a8384a1bbe26ed","1349":"56ffc60e8d2a72471b7c645d","1350":"56ffc61676b6f9de194d76ba","1351":"56ffc645bbffcc665fab7de9","1352":"56ffc774d39de41b495fee6f","1353":"57043c158e22137808cc5260","1354":"57054482d6cbe1fd27fde2bf","1355":"57054518799f8c895eb4fee8","1356":"570545d5799f8c895eb4ff25","1357":"5705463b82aae5fc2799f701","1358":"5705463c9ef9b99902ae9177","1359":"5705466b799f8c895eb4ff63","1360":"57054670d62e7a1918de4637","1361":"57054686799f8c895eb4ff6f","1362":"57054694b17e698d5ef165a7","1363":"5705469b9ef9b99902ae919d","1364":"570546acd62e7a1918de4645","1365":"570547b682aae5fc2799f78c","1366":"570547f9799f8c895eb4ffdb","1367":"5705493a799f8c895eb50053","1368":"57054948d62e7a1918de471b","1369":"5705495bb12cb51618d29c87","1370":"570549769ef9b99902ae9287","1371":"5705498482aae5fc2799f822","1372":"57054996d62e7a1918de472d","1373":"570549adb12cb51618d29ca2","1374":"57054ac8d62e7a1918de4798","1375":"5705aad9f5db499c02184df8","1376":"5705acf482aae5fc279a14ea","1377":"5705af7382aae5fc279a1541","1378":"5705af9f82aae5fc279a1544","1379":"5705f63df5db499c021858e4","1380":"570608859ef9b99902aebd56","1381":"57060942799f8c895eb529db","1382":"570609719ef9b99902aebd89","1383":"57060974d62e7a1918de711a","1384":"57060984b12cb51618d2c6bc","1385":"57066f27d62e7a1918de90eb","1386":"57070cf7ddb5a2cf3bba7266","1387":"57070d0dc65c9a6f7f27c1d3","1388":"57070d21f55f5c717feb2ea1","1389":"57070d311ee04bd23b766657","1390":"57074626f55f5c717feb36ea","1391":"5707f6648b7b2f457634f2c2","1392":"57083e1b2a2f4d427612e855","1393":"57083e98ddb5a2cf3bbac0e9","1394":"570c05578b7b2f457635a79f","1395":"570d015b3ddb73ba105b4daf","1396":"570d13065cd40114649a90d4","1397":"570d46a9548df1be102c3dd4","1398":"570e6ab04c2125fc3f0209a2","1399":"570e77515cd40114649af473","1400":"570e77ceb30cfa0f384b11c9","1401":"570e7c76548df1be102c90cb","1402":"570e7d073ddb73ba105bbc67","1403":"570e7d463ddb73ba105bbc80","1404":"570e7dc74c2125fc3f021069","1405":"570e7ddd548df1be102c9141","1406":"570e7df73ddb73ba105bbccd","1407":"570e7eb9548df1be102c9185","1408":"570e7ed0b30cfa0f384b145f","1409":"570e7eea5ed5a4fd3fe2b0dd","1410":"570e7f61548df1be102c91cf","1411":"570e8be9af46361038643aa5","1412":"570e9a1daf46361038643f2b","1413":"570eaa92548df1be102ca101","1414":"570eb55e5ed5a4fd3fe2c2ce","1415":"570eb56eaf463610386448c4","1416":"570fbfd04c2125fc3f0262d3","1417":"57100ed1b30cfa0f384b8666","1418":"5710118b3ddb73ba105c3163","1419":"571025d25ed5a4fd3fe32530","1420":"5710268faf4636103864aceb","1421":"571501893ddb73ba105d1d0f","1422":"571537114c2125fc3f0376d7","1423":"571561a63ddb73ba105d3c9f","1424":"571563ed548df1be102e1053","1425":"57160f29548df1be102e3350","1426":"5716e5a45b5164bf56ee1c96","1427":"571a3e990eef754b5ea9857f","1428":"571a61086e3ae55e37e931bc","1429":"571a62d14bbb6abf7d5e36b1","1430":"571a62ec6e3ae55e37e93232","1431":"571a64637469496137b8587d","1432":"571a6a110eef754b5ea992d7","1433":"571a6af247b4c6480ff96dcc","1434":"571a6c69d47413c07dcc6979","1435":"571a97d19689a5440f7ab0a0","1436":"571b952cd47413c07dcc9908","1437":"571b9baf6e3ae55e37e96590","1438":"571e6ad2d47413c07dcd247f","1439":"571e78477469496137b919ed","1440":"571e83984bbb6abf7d5efa9a","1441":"571e83ded47413c07dcd2d96","1442":"571ea1126e3ae55e37ea03fa","1443":"571fd0bc9b4160fa760a17d7","1444":"57202c4f2cd01bf9764b0dae","1445":"57202f449b4160fa760a2bff","1446":"5720d8fa9b4160fa760a5a11","1447":"5722d4db961e8a522e640c81","1448":"5722d522b018414f2eda4906","1449":"57234534961e8a522e6426e4","1450":"5723d52a9afbb99c67e6f55b","1451":"572566c660e2f3e873665d13","1452":"57262dbad407319f67318dee","1453":"572665bdd407319f6731987c","1454":"57279ccb72798bd77be94cbb","1455":"57279d10d6d0f60219efd81a","1456":"57279d496871c4a646c112d2","1457":"5727a5e70149d6bb04b805a6","1458":"5727b846df1a01ff18fbce92","1459":"5729f07a944fc7ba04ccf381","1460":"5729f0a16871c4a646c1a973","1461":"5729f12adf1a01ff18fc5fa0","1462":"572a056c6871c4a646c1b12b","1463":"572b7a1cd6d0f60219f0e273","1464":"572b7b7cd6d0f60219f0e2f3","1465":"572b7be4474247a946a68b8a","1466":"572bae8f944fc7ba04cd73a7","1467":"572baed2d6d0f60219f0f4e8","1468":"572bb97b6871c4a646c22be1","1469":"572c9b59b51b0e29484fba28","1470":"572d52d9f16c0851066177b6","1471":"572d52faa351d8310951b19b","1472":"572d5482ed393f3409b07dc3","1473":"572d54aaed393f3409b07dcb","1474":"572d54d9b51b0e29484fec7a","1475":"572d55ebb51b0e29484fec9a","1476":"572d5640f16c085106617810","1477":"572d5ca112fa465406eaa646","1478":"572d5d98ed393f3409b07ea9","1479":"572ffb8712fa465406eb0790","1480":"572ffca9f36daf63798dba65","1481":"572fff0012fa465406eb07fe","1482":"572fff69f9a53a60793ce4c8","1483":"57300033f9a53a60793ce4eb","1484":"573002bd3170252648f51f68","1485":"5730030fa351d8310952153e","1486":"57316eb6b51b0e294850ae54","1487":"57316f0cf16c085106623b83","1488":"57316f27f16c085106623b8b","1489":"5731c924f9a53a60793d609c","1490":"5731e005f9a53a60793d6acb","1491":"57321e20ed393f3409b187b4","1492":"57321e32ed393f3409b187ba","1493":"57321eedf36daf63798e5cf0","1494":"57322ddc12fa465406ebb29d","1495":"573288be3170252648f5e2fd","1496":"5732b15912fa465406ebd5c0","1497":"5732b3cda351d8310952e3f9","1498":"5738fd8d0cb634927f7f1f32","1499":"5738fdcf64dbdadc7dec5170","1500":"5738fe260cb634927f7f1f44","1501":"5738fe28831fd2d97d9eb4c1","1502":"573b39f9c61823687d3cb023","1503":"573b3a1864dbdadc7decded6","1504":"573c7d1f38057d021653f233","1505":"573df015ff441ca333d310f4","1506":"573df0e9e675315635f8200a","1507":"573e16e1ff441ca333d31f3a","1508":"573e1717f240e50046a090ff","1509":"573e173cff441ca333d31f63","1510":"5742109a08a18f700b82a025","1511":"574210c5e675315635f8ed28","1512":"574247537aab25fb459dba44","1513":"5742a6a47aab25fb459dc7e6","1514":"57436a2acaaef2cd4fea080d","1515":"57436a42719c119b575b7914","1516":"5743888a56ccfef516a02805","1517":"5743888f28011d9f574b22e2","1518":"57438b14cd96cbcf4f700185","1519":"5743ff3063e41bd84befdbb1","1520":"5745727b28011d9f574ba598","1521":"5745751763e41bd84bf04f27","1522":"574575d1719c119b575c0461","1523":"5745761ccd96cbcf4f70860c","1524":"57457a6728011d9f574ba8d0","1525":"57457a6928011d9f574ba8d2","1526":"5745c6c810f0fed86f48097f","1527":"5745c70cf44fde236e5038f3","1528":"5745c786a78d5a256e37b3b5","1529":"5745def1f44fde236e50434f","1530":"5745df5110f0fed86f481411","1531":"5745e989f44fde236e5047a2","1532":"5745ecbc6bbc2d1d4dee1ae0","1533":"5746f1bf80352f204df2569f","1534":"57473327a78d5a256e3823e1","1535":"574733a780352f204df26fb0","1536":"5747340110f0fed86f487ab1","1537":"57473401a78d5a256e382432","1538":"5747340b454cb2be094f3e28","1539":"5747613f454cb2be094f4e52","1540":"57486ab3454cb2be094f90e4","1541":"5748d2e7a78d5a256e389723","1542":"5748d34180352f204df2e12e","1543":"5749c387ec10ddbb09db959b","1544":"574c37d26bbc2d1d4def6f33","1545":"574c6b396bbc2d1d4def808f","1546":"574c79f6a78d5a256e393572","1547":"574da7a180352f204df3ca9b","1548":"574dcd8df44fde236e521993","1549":"574eb377da3f93da6f224401","1550":"574eb3a7ec10ddbb09dca6f6","1551":"574eb3e880352f204df4134d","1552":"574f6b14da3f93da6f228887","1553":"574f6b9380352f204df45459","1554":"574f6b9aa78d5a256e3a12c3","1555":"574f6c00454cb2be09512715","1556":"574fb5a0454cb2be09513415","1557":"5750168eda3f93da6f22b001","1558":"57502821da3f93da6f22b61a","1559":"57502834f44fde236e52c6a5","1560":"5750285bec10ddbb09dd1688","1561":"5750289ff44fde236e52c6ba","1562":"57508a74454cb2be09517a24","1563":"57517ad3824488852c4e90c1","1564":"57518c4b6c75e0cd6958e81d","1565":"575458791097267921307a45","1566":"57557422e96484d0692ff78a","1567":"5755bb38c2a6e42f7e98d458","1568":"5756eef192fc7c915f579551","1569":"5756ef6e45cf128e5f1d3f83","1570":"5756ef8d662b042b7e5938ee","1571":"5757934f45cf128e5f1d6e56","1572":"575854b8e20024bd1ad19e7e","1573":"575abfde2eaa837d71e83b9f","1574":"575ac0b0064b9e7266f1482f","1575":"575ac60c97e1b2d245e190d2","1576":"575aee8e2eaa837d71e84fba","1577":"575aef1c064b9e7266f15b6d","1578":"575ba4842eaa837d71e878c4","1579":"575ba73be20024bd1ad2870a","1580":"575c1279814a568071421742","1581":"575c423aa1be01c01a7904c3","1582":"575c429fe20024bd1ad29fcc","1583":"575c42e5814a5680714220f5","1584":"575c44e0814a568071422167","1585":"575c4545064b9e7266f19c51","1586":"575c468997e1b2d245e1e3a3","1587":"575c4a5097e1b2d245e1e44b","1588":"575c86972eaa837d71e89ef6","1589":"575c87bb814a568071422e1a","1590":"575c888b6092456f663341f2","1591":"575c983f2eaa837d71e8a1c0","1592":"575e48112eaa837d71e8e78a","1593":"575e489f97e1b2d245e237ec","1594":"5761b8e563ea0987306b437c","1595":"5761b914da1c26b045367a52","1596":"5761b91e36c83a8802060cc7","1597":"5763051e36c83a8802068586","1598":"576308edb8ad3d5d7ee0f45f","1599":"576309077a851b587e6fa5d8","1600":"5765b20c2a4cd63745eaa793","1601":"5765eb8e4227fdc922985537","1602":"5767fe926577f032450cdcc4","1603":"57681369f0528c4c5bbad0b8","1604":"5768138df0528c4c5bbad0d2","1605":"576820476577f032450cee12","1606":"576a270fc417e36c69e5094c","1607":"576a2726c417e36c69e5094e","1608":"576abe742554bbe049baa210","1609":"576ac1fa80f1c6a5257de806","1610":"576b2c3f80f1c6a5257e150e","1611":"576c45bbc7061d590d53c85f","1612":"576c5589c7061d590d53ced3","1613":"576c76f96c39b96569608d99","1614":"5773f4b0a0c12d110fc2901f","1615":"5773f4d98c9263ba302d3772","1616":"5773f503265214c130a03e2a","1617":"57769e3b7b0ff7223148ddaf","1618":"5776b5ab5c023e194f513997","1619":"57781b19cdab7a1f4fcf4d9d","1620":"57781b3e35bfead37964f2a2","1621":"577875bed4b6d5012eb86223","1622":"57794cca5c023e194f6d7a1f","1623":"57798634d4b6d5012ec46ff9","1624":"577a9e1d4bee5c570920de55","1625":"577a9e5e3ac2a2dc14371d9c","1626":"577aa0284bee5c570920f3b5","1627":"577ef1c6064f828707dcb386","1628":"578039293eaf66535e52bc2b","1629":"578048a91ca34a944eccb121","1630":"578064cf7aeb080527876ad8","1631":"5783c99c1ca34a944ef04abb","1632":"57843b277aeb080527b07dca","1633":"578574df7aeb080527c07aa2","1634":"5785835159cfbd4c5e9086b5","1635":"578664b19f79ee4f2b9678cd","1636":"57874cc03c5129720e1a9bb0","1637":"57874e3f9f79ee4f2ba20542","1638":"578ab3f5196179690eef6f19","1639":"578e3a162d04e0585188e18b","1640":"578e3a550720fd587a9bd5b4","1641":"578e3a6d841e619d160bf729","1642":"578e3bc70720fd587a9bec6c","1643":"578e3ce0841e619d160c1532","1644":"578e3ce80720fd587a9c0ce1","1645":"578e3d269f35137e67d964a7","1646":"578e3d3316487c5e5153c77a","1647":"578e3d359f35137e67d964e0","1648":"578e3d4c841e619d160c1b64","1649":"578e3d7b3d74e5a01663283f","1650":"578e3d9a841e619d160c21e2","1651":"57903c73841e619d1625a8c2","1652":"5790e1803d74e5a016833ab3","1653":"5790e27675045f87671d571d","1654":"5794fdc632bd01d843b8a2bc","1655":"5794fde132bd01d843b8a2f5","1656":"579a167c37c95e2446bd7381","1657":"579a177c00c8ebdd0e2b6945","1658":"579a17a000c8ebdd0e2b69b2","1659":"579a18b400c8ebdd0e2b6cf5","1660":"579a238d93148c6b21e5f322","1661":"579a284e93148c6b21e6041f","1662":"579a2c3c8fb4820a466c0168","1663":"579a2cc893148c6b21e6140a","1664":"579a866798ae546362106827","1665":"579a8681ac80b5ea3f14c6f6","1666":"579a86a98df57475625f7d43","1667":"579b139d3eb00fbd1521f1ec","1668":"579b213fa8a477b51582f89c","1669":"579b2c258df574756260c075","1670":"579b2c6d95550f1a4ef5cbc8","1671":"579b2c8495550f1a4ef5cbfd","1672":"579b2ca01d6bf8244e2bbd31","1673":"579b2cb63eb00fbd152229e5","1674":"57a0ad5b836d2d02115d955d","1675":"57a0c98e47659bfb10888a12","1676":"57a1567d47659bfb1089d700","1677":"57a16a2b9e85d3e826821c05","1678":"57a16a5500663f5b1b463b9f","1679":"57a30659836d2d021162f89a","1680":"57a3066b9e85d3e82685d99d","1681":"57a306850bd017c16e3ad873","1682":"57a3644e0bd017c16e3bd1ab","1683":"57a364e11c2bf6621bbbfe56","1684":"57a36ff90bd017c16e3bf162","1685":"57a39578e2ff9ec76e57112b","1686":"57a465d3857442dc0f554721","1687":"57a465dbd097eb6b2cc73ca3","1688":"57a4661548422f8b49710bfd","1689":"57a46628d097eb6b2cc73d61","1690":"57aa8d8246610f17394d687b","1691":"57aa8dabf7f11a7936b0f9d9","1692":"57aa911316b0696856a81a45","1693":"57aa945346610f17394d7580","1694":"57aad258613cc1803675f167","1695":"57ab604aae838f6f56949b9a","1696":"57ab605846610f17394f6c58","1697":"57ab6081613cc18036777aee","1698":"57ab6088ae838f6f56949c23","1699":"57b4dd5c4f819cfa3da8eb3f","1700":"57b54d0d5a4ad6105684e828","1701":"57b602926981f5f269fb82e2","1702":"57b602ba187885ef4f5afb07","1703":"57b60a28bb6fad403ce761cc","1704":"57df599cc8af41d45f27ffaa","1705":"57e028af18291e104884ea1c","1706":"57e0290f33c63ba01a162128","1707":"57e0291f33c63ba01a162173","1708":"57e02975c3e7045a30611700","1709":"57e068badf21a757300eb024","1710":"57e21f75c8af41d45f325838","1711":"57e23da618291e10488c7e07","1712":"57ebe5fc857ab70f7d4b5f01","1713":"57ebe69035e0f31c6c4da161","1714":"57eeed70be5dec75500d4ed0","1715":"57eeed730ff4ef7a50f5356b","1716":"57eeed9234a8d5681cd0b1e6","1717":"57efee03c512d9653a5b8309","1718":"57efee1cd38f186520b7fc9f","1719":"57f2599929403a416fc1094f","1720":"57f259a1d45d7f0f525b818e","1721":"57f25c8bd45d7f0f525b8e54","1722":"57f25d0c8b26e33e7d22b91b","1723":"57f26170f69c94ad0985ccb3","1724":"57f29b183c59573f6f05b6a9","1725":"57f29b530ec6f9457d9b4d73","1726":"57f63aa3dfe82a365b00d513","1727":"57fddbf670fcb5db0c4d061d","1728":"57fddd090aa72e3c5bf54c9b","1729":"57fde32a4fde7203142d289e","1730":"57fde3674fde7203142d2987","1731":"57fde3a1dfe82a365b1a8e30","1732":"57fde3ad0aa72e3c5bf55fa9","1733":"57feaceb614116a2567ab0db","1734":"5804380f8eaaaea366a0cf08","1735":"5807d4c248292577613c3bfb","1736":"5807e6dd8d2babbd088aecde","1737":"5807e6e636d64226368970b7","1738":"58090fd536d64226368e19b4","1739":"580a22e5b827179842e26ee8","1740":"580ae91d015db84e6fb665d0","1741":"580aeb4e5af5969e7eec6ed7","1742":"580bae885af5969e7eeeb84a","1743":"580bbf0c577f2c227909bd4b","1744":"580dcdd656121b9c7eb47d89","1745":"580e357fab78365b2055661b","1746":"580f987f5a1cfa016e47fb57","1747":"580f98baba810c1d5fcf73fb","1748":"580f990d0a2d07ff118dc50d","1749":"580f99490e25dbfa116023c2","1750":"580f99789235851a45c82c57","1751":"580f9b000a2d07ff118dca75","1752":"580fa9350a2d07ff118df7bc","1753":"580fabdd0a2d07ff118e003b","1754":"580fabe683a2008d22d29fb6","1755":"580fac318ed1c0ff5c2baf98","1756":"580fbb140e25dbfa11608a43","1757":"580fc6910e25dbfa1160ab11","1758":"580fc6e8806316005dbe4286","1759":"580fcffb482c168b22b74f24","1760":"581072c90a2d07ff118ff449","1761":"5810ce27482c168b22baa4c5","1762":"5810ce36482c168b22baa525","1763":"5812c2bf8ed1c0ff5c37de63","1764":"5815828cc3569a036e337170","1765":"5815bd29c3569a036e3426a9","1766":"581a06a80e25dbfa118ea66d","1767":"581bb27f31c5cbef43b2151b","1768":"581cba68c2f2cf7275cdac0b","1769":"581cbab1c2f2cf7275cdada8","1770":"581d792345c9e3eb43fdc8d6","1771":"5822675e6cb7207630523c56","1772":"58226767e462097a30260052","1773":"5822677f78ec59ab054d2924","1774":"582267b2e462097a30260130","1775":"58279abec2f2cf7275023930","1776":"58279ac7e097df7575a2e7d4","1777":"58289768c2f2cf7275061bbc","1778":"582dd66bab171c5d1e67d2e5","1779":"582dd6752291180a7a60d925","1780":"582dd6c1e51081951ed9db6c","1781":"582dd735e51081951ed9df6b","1782":"582dd76b69eb65323c458c67","1783":"582dd81a69eb65323c4592cb","1784":"583402702db952670466cd05","1785":"5834a1b07f83e6c9771e25b6","1786":"5834a1c17f83e6c9771e266e","1787":"5834a1e0cc0ea2cf778275c1","1788":"5834ae297f83e6c9771e6f06","1789":"583eeffe444b377876762398","1790":"583ef0058255fe6b76e9886d","1791":"583faca08255fe6b76edb15a","1792":"58411cc989d179bf4df0896b","1793":"58411d1a444b37787681fc8d","1794":"58412a098d65e3830ec96fed","1795":"58412a781dec193f14191624","1796":"584130a173abd79c55c359ba","1797":"584130a516207f7b0ed23924","1798":"584130aa8d65e3830ec990a9","1799":"584188008255fe6b76f7bdb8","1800":"58475b391eb3d6486966fc36","1801":"58475b736b32e8704996acb4","1802":"58475bd66b32e8704996af1b","1803":"58475d77bc32453c289d97c0","1804":"58475e03f666c5a138dd52cb","1805":"58475e411eb3d64869670c22","1806":"5847c3cf1eb3d6486968df81","1807":"584882abbb7d528222ccda48","1808":"584882f0c29531ac5d33de65","1809":"5856f235c02c1a39598323d3","1810":"5857f8b70730ce6937e45ac2","1811":"5858bca2e7bdfe4e2976b6ec","1812":"5858f335c02c1a39598d4455","1813":"5858f4d0c895451b75fb2c4f","1814":"585936e00730ce6937eae888","1815":"5859374ac895451b75fc99c5","1816":"585bd460058ca967377bd4d7","1817":"585c9dbac5a4e0233bbd9c15","1818":"585d77cb7a3f79ef5d93f4fc","1819":"585d780cc02c1a3959a61e17","1820":"585d7823058ca96737846afc","1821":"585d7b50e7bdfe4e298f9cf1","1822":"585d7bc2c5a4e0233bc1fd45","1823":"585d7d907a3f79ef5d9411c3","1824":"585d888be7bdfe4e298fd839","1825":"585f2643058ca967378aef35","1826":"5865330caf6b364a290bc26b","1827":"5865331bc02c1a3959c67e84","1828":"5865338dc895451b75339d61","1829":"586534489d4cc4fc53545bf5","1830":"58689ab1c02c1a3959d447c6","1831":"5869eed4c02c1a3959d97376","1832":"586ad1c1c02c1a3959dda9f3","1833":"586c5acd058ca96737c58070","1834":"586c5b2c9e6f00e74af39d5b","1835":"586c5b59aa6be0472f046398","1836":"586c5bdd9d4cc4fc53730914","1837":"586c5bf0aa6be0472f04668b","1838":"586caa439e6f00e74af4d6bf","1839":"586caa629e6f00e74af4d76d","1840":"586caa7fc895451b75531e3c","1841":"586cc21dc895451b75539089","1842":"586cc23f9d4cc4fc53749510","1843":"586cc2457a3f79ef5dd4756a","1844":"586cc2627a3f79ef5dd4769a","1845":"586cc5d8c02c1a3959e650bd","1846":"586cc625aa6be0472f0649a4","1847":"58734f25074f7be763aa054d","1848":"58735209873d96e16d444a9b","1849":"587352b16c1635643c0416b1","1850":"5873ec5ecbcb2817704a05b8","1851":"5873ecde873d96e16d48130e","1852":"5875fd1cdec171b811d42478","1853":"5876d77adec171b811d99223","1854":"5876d79c873d96e16d586c16","1855":"5876d81c11e7a7f61d8529b4","1856":"5876e205dec171b811d9cb4c","1857":"58780f1f300f220a66decc2a","1858":"587838de11e7a7f61d8ce02e","1859":"58784611300f220a66dfcc7a","1860":"587d6277300f220a66f720e4","1861":"587d62b6074f7be763dc8e39","1862":"587f9c4b300f220a6602dde4","1863":"5880d2aa300f220a660947d7","1864":"58a37939238b1dae570d6a72","1865":"58a3794f872fc8ce623732d6","1866":"58a39922238b1dae570e1c44","1867":"58a4a376f045df0a2250b9b4","1868":"58a4a39400c00c3d4f42df74","1869":"58a4a3ad872fc8ce623dbcfd","1870":"58a4a3cd238b1dae5713edf0","1871":"58a4b36e872fc8ce623e286f","1872":"58a4b375aa800ee52c9df039","1873":"58a4b385872fc8ce623e28cf","1874":"58a4b387f045df0a225120ee","1875":"58a4b39800c00c3d4f434a89","1876":"58a4b3adf045df0a225121fb","1877":"58a4b3b221d548df2c1403af","1878":"58a4dbedf045df0a22520f10","1879":"58a4e4da0ad50ac3151faade","1880":"58a54a1600c00c3d4f463eda","1881":"58a54c47872fc8ce624130a6","1882":"58ae9ba7f1a33b62753add8e","1883":"58b252e7872fc8ce6285ae6c","1884":"58b252e91465c46a56b56335","1885":"58b4e3b7e961e53c7f783131","1886":"58b4e46f1465c46a56c2e613","1887":"58b4e5abe961e53c7f783a88","1888":"58b4e5f2e961e53c7f783b45","1889":"58b515ca7ceae5376a4c2c0d","1890":"58b6260521d548df2c72256c","1891":"58b626a21465c46a56cad6cb","1892":"58b6815d7ceae5376a5500e6","1893":"58b681677ceae5376a5500fc","1894":"58b8b4b5f1a33b627571e69d","1895":"58b8d9f91465c46a56dbb005","1896":"58b8da7ce961e53c7f90ddf3","1897":"58b8dab500c00c3d4fb1a803","1898":"58b913091465c46a56dcd05b","1899":"58b93ab6de504908223d2c33","1900":"58bbae81f1a33b62757fd201","1901":"58bbbc891465c46a56e9eeda","1902":"58bbf3cb00c00c3d4fc0cdbf","1903":"58bfa1bfde504908225df781","1904":"58c0b84bde5049082264451e","1905":"58c1f7a800c00c3d4fe55095","1906":"58c1f7ccdd08b4b859ac6619","1907":"58c1f8981465c46a560f1160","1908":"58c253667ceae5376a990905","1909":"58c6118821d548df2ccbda3d","1910":"58c61339e961e53c7fd9f713","1911":"58c827a421d548df2cd934c2","1912":"58c924fae961e53c7fed3f6d","1913":"58c93bf4dd08b4b859d442cb","1914":"58c9e1f57b3f37e754ff6535","1915":"58c9e3257b3f37e754ff6a7b","1916":"58c9e4fba84f611959ac466c","1917":"58cac67705a31d5a4a650b1e","1918":"58cac69705a31d5a4a650c01","1919":"58cbb58fa84f611959b4ebc2","1920":"58cd2f1105a31d5a4a6f2c14","1921":"58cd92142215a08f049e8445","1922":"58cf24c8fe6a638b1ae279a0","1923":"58cf662ffe6a638b1ae32d2e","1924":"58cf6663b809ca5f4a6134ce","1925":"58d246496701410e5862b177","1926":"58d2465a6d7eb18404f3303a","1927":"58d247477b3f37e75422468f","1928":"58d24748b809ca5f4a6da4ac","1929":"58d24757f7f7d48104425fcb","1930":"58d2487b5917e26076bf853f","1931":"58d25a59b809ca5f4a6dffa6","1932":"58d267d2590d72c864f36247","1933":"58d3c4cc58ad4eb028443afb","1934":"58da958e4cb8d09173366220","1935":"58daa65d8bb56c2d1150ecca","1936":"58daaa3f7ea420cc4214cdd7","1937":"58dabb2d4cb8d09173371a84","1938":"58ddb8b9f22385553df37d61","1939":"58ddb940f22385553df37e50","1940":"58ddb9ab0e4137042aca9a4f","1941":"58ddb9bd7ea420cc4221d75a","1942":"58ddd7198e4b63533d7f6d3a","1943":"58de1226408f90be66741696","1944":"58de12a2408f90be66741991","1945":"58de1629408f90be66742857","1946":"58de207e4cb8d091734522ae","1947":"58deb366f22385553df7c61c","1948":"58e2c0bc4cb8d09173565e38","1949":"58e3b475b52518ed4ddb5c8a","1950":"58e6679168bee3091f182102","1951":"58e66b8ead849bcf425a4f0f","1952":"58e811d18bb56c2d11873d56","1953":"58f11bb3f22385553d4024b2","1954":"58f11bba8bb56c2d11aa9261","1955":"58f4f8e40ed3020c3825cb24","1956":"58f71b778fcce56b2016c7a8","1957":"58f71c17bdf4acc11272f38e","1958":"58f71e3af22385553d559a44","1959":"58f85b7f881b89e1016a01d9","1960":"58f8e24b3e27cac331a93b17","1961":"58f8ee4308c00c092a9cbb2e","1962":"58f8eefd08c00c092a9cbeb2","1963":"58f8ef988fcce56b201ea8af","1964":"58f8f003881b89e1016cbf17","1965":"58f8fdbb881b89e1016d0bae","1966":"58f92b508fcce56b201fb2e3","1967":"58f92c1208c00c092a9dd4c4","1968":"58f92ff7f22385553d5ec514","1969":"58f92ffd12d2409935822435","1970":"58f93adbc1d3b5015404efec","1971":"58f93cb98e4b63533deafae3","1972":"58f94c33c1d3b50154052ee5","1973":"58f94c668bb56c2d11c988ea","1974":"58f94eb3c1d3b501540537e1","1975":"58f9f06fd32c6f2f0928bc21","1976":"58fa793708c00c092aa3234f","1977":"58fa795c8bb56c2d11ce8049","1978":"58fa796612d2409935874aa4","1979":"58fa798608c00c092aa32488","1980":"58fa83d58e4b63533df06652","1981":"58fb5dcf8e4b63533df30eaa","1982":"58fb5e3912d24099358a2488","1983":"58fdd48c881b89e1017df2f9","1984":"58fe0c33881b89e1017ef845","1985":"58fe1badc1d3b501541688ca","1986":"58fe36948fcce56b2031a2ce","1987":"58fe36ca08c00c092aafa87f","1988":"59009e168bb56c2d11e4f033","1989":"5901cab9881b89e1018ec89e","1990":"5901fd588fcce56b20415456","1991":"5902ef37c1d3b501542b2a1d","1992":"5902f107f22385553d849fc2","1993":"5902f10c587a245e2457ba83","1994":"5902f93a8bb56c2d11eeeec8","1995":"5904dd83f22385553d8bd338","1996":"5904e121881b89e1019aa45e","1997":"5905a8e8c1d3b5015434de88","1998":"5909d434c1d3b5015444cf1d","1999":"590a3d23d32c6f2f09666728","2000":"590a81c28fcce56b2060f2d3","2001":"590bba0e0dcaa48e672c10ee","2002":"590bbb2b9d90dc7a1c48c23a","2003":"590e04c6d1a7716a0a9c533a","2004":"590e04c8c89bb14b5ad830d8","2005":"590eb77d0a783b6c0a7185de","2006":"590ebaef5c89dc53618319a6","2007":"590f00aee2285d3b16376166","2008":"591175508a05641b1163ef6d","2009":"5911eb12c4d73f445a8cd0b2","2010":"5913ac719d90dc7a1c67e77b","2011":"5913ac77631b8e4e61c2dd66","2012":"5913accfac693c532adeeebf","2013":"59145f555c89dc53619a641a","2014":"5914a2dc92217cca5867c47a","2015":"5915d6119f4f4ab05bb9ab80","2016":"591a02918a05641b1185f53a","2017":"591a255292217cca587d03d3","2018":"591b849183cb5db0733af618","2019":"591c0e4e00efc2bb3e76fae1","2020":"591c78a15e34568d5e63f468","2021":"591cf7150a783b6c0aac6e53","2022":"591cfbb4631b8e4e61e89f6e","2023":"591d7a7892217cca588b5309","2024":"591d9c279f4f4ab05bd86746","2025":"591e1e97f3001cd34236a766","2026":"591e20b3eec422e415c7eb20","2027":"591e20c983cb5db0734679f9","2028":"591e2380c4d73f445abf32d8","2029":"591e24aac4d73f445abf35dd","2030":"591e2527631b8e4e61edca12","2031":"591ef333f3001cd34239b968","2032":"591ef33d33e9ee771cc2862e","2033":"59241de35e34568d5e81b29d","2034":"5925046d9f4f4ab05bf54419","2035":"592504b105e3326c67026246","2036":"592598b25e34568d5e880ea7","2037":"592648e305e3326c67087bf0","2038":"59264939eec422e415e800ff","2039":"59264953631b8e4e610e795e","2040":"592681d90a783b6c0ad298ae","2041":"5926c5445e34568d5e8d4585","2042":"5929de335e34568d5e98cb78","2043":"592d5d47fcbbe1891c5bc3f7","2044":"592d5d9e2b926f8a67a80bff","2045":"592d6e6d631b8e4e6128bb27","2046":"592f2234fa63ba2f769c133d","2047":"592f224c0a783b6c0af3bc96","2048":"5932bd846549436c7d1138e8","2049":"59377ce3f2dd2dba06781b70","2050":"5937aa8a6462d8493cea8c78","2051":"5938b880cf9c13503c64cca5","2052":"593d89ed02c480e67233b6df","2053":"593d8a1931f589c64f984950","2054":"593d8a2eca6d4ae80c02ef09","2055":"593d8b43f6a78eab483afa01","2056":"593d8cf6ca6d4ae80c02fae3","2057":"593d8d1a6462d8493c01008e","2058":"593ecbc1f31c8ced0c2b4f36","2059":"593f4c5ac59bd9c4640e0671","2060":"594514a5e531dbc905f1113b","2061":"59459281f31c8ced0c46f681","2062":"594a0db817a3066670885daf","2063":"594b33345bf0bef94ccec609","2064":"594b3345cf9c13503caf5ac8","2065":"594b334ae59e74be0aa3a373","2066":"594b335802c480e6726c4e11","2067":"594b340ccf9c13503caf5e1f","2068":"594d5476ad9c78184391d219","2069":"594dc7fabf7e6af22c6902f3","2070":"594dc819703e565c33393d21","2071":"594dc8203230e14f3aeb709d","2072":"594dc829c101bc4e3a150ffc","2073":"594dc84057a6e9f72ef22ba4","2074":"5951e21eceb5bef82eb4d0d4","2075":"5951e22cbf7e6af22c790a65","2076":"5951e3048dae42503159e6a3","2077":"5955076b8dae4250316818d4","2078":"5955b0ba703e565c335abfcd","2079":"5955b148329651f46e39749b","2080":"595dd59f6ae41d5d33beadf2","2081":"595e6c084bcd78af56828c85","2082":"595e720289aea4761d707462","2083":"595e8565bf7e6af22cb056e6","2084":"595eea9276a757f808e57cff","2085":"595f4768f5b3458e3020c9c2","2086":"595f47bf1c8697534afcb419","2087":"595f4af84bcd78af56862a7a","2088":"595fdb2e4bcd78af568912fc","2089":"5968973fc101bc4e3a840af8","2090":"59697da5bf7e6af22cdce433","2091":"596a6772c101bc4e3a8a9f53","2092":"596b12e889aea4761da242a5","2093":"596e915e0de4d2545e3efb84","2094":"597103cef5b3458e3067e01b","2095":"5971779a2723db8d5e305d45","2096":"597177f7bf7e6af22cfc26af","2097":"5971792cbc464729740e3226","2098":"59719cf6614889d475d65bbe","2099":"5971f2a2614889d475d7d2ea","2100":"597582b4f5b3458e307767ab","2101":"5975830cbc464729741c08e2","2102":"5975833af5b3458e30776997","2103":"59758379714ea96f7817883b","2104":"597583994bcd78af56dcebdc","2105":"5976534b76a757f80841b07e","2106":"597667e9714ea96f781b8493","2107":"59768a222723db8d5e42f058","2108":"59768a7e614889d475e88644","2109":"59775aa8bc4647297423e0a4","2110":"59775ac5f5b3458e307f2015","2111":"59775acf1c8697534a5b4221","2112":"59775ad92723db8d5e464164","2113":"59798175bc464729742c2d1f","2114":"597981ad76a757f8084e2921","2115":"59798a41c101bc4e3ac4a02e","2116":"59798a621c8697534a63e548","2117":"59798ac3f5b3458e3087b529","2118":"5979af1389aea4761ddaf95a","2119":"5979b02e89aea4761ddafd1f","2120":"5979b49fa7b406262d35abac","2121":"597a295a329651f46eca9338","2122":"597a298245fc670746d141bf","2123":"597a51ac614889d475f7b202","2124":"597a5378614889d475f7b875","2125":"597a5380329651f46ecb3265","2126":"597a53a176a757f808518bd1","2127":"597a53b945fc670746d1e40b","2128":"597a5482a7b406262d3839e4","2129":"597a548d2723db8d5e51e72e","2130":"597a5af9a7b406262d385072","2131":"597a5b7889aea4761dddac3f","2132":"59821374210ac269204a73a1","2133":"5983c6c74bcd78af5610a45f","2134":"5983c735f5b3458e30ab7b46","2135":"5983c75476a757f808723c83","2136":"5989cb28210ac26920649558","2137":"5989e395c101bc4e3afc5de9","2138":"598a2bc41c8697534a9d711b","2139":"598a491476a757f8088843da","2140":"598a4921614889d4752e6dea","2141":"598a49ab80d90ca024df61bc","2142":"598a49dcc101bc4e3afe059a","2143":"598a84892723db8d5e89108c","2144":"598a849d76a757f808890644","2145":"598a84d6329651f46e0206ef","2146":"598b1665c101bc4e3a00fa89","2147":"598f8118614889d4754154c8","2148":"598f8118210ac269207989f7","2149":"598f81472723db8d5e9ae642","2150":"59926c60a7b406262d8bf19b","2151":"59936dc676a757f808aa19d6","2152":"5993b848210ac26920897146","2153":"59a42f28bc46472974cf003d","2154":"59a5d9c476a757f808f84350","2155":"59a682ac210ac26920d7dfed","2156":"59a6c3599acddb2407e50bf2","2157":"59ad4100b16f26464203c43c","2158":"59add56bbac826f0547db723","2159":"59add5b9ee5c9a4c5f327c47","2160":"59b0093666c1c7c4771fda9f","2161":"59bab1167b7d98d30df5b334","2162":"59bab137bc4647297433a54f","2163":"59bbee1e1081499f1f36221f","2164":"59bfa0b4b59d55b8230de1cd","2165":"59bfe7b47b7d98d30d0de1e9","2166":"59c02d94614889d475141c93","2167":"59c02dff614889d475141e03","2168":"59c0c18c177fb9fe7edb511e","2169":"59c0c19f177fb9fe7edb5150","2170":"59c0f6c0614889d475176958","2171":"59c13836c101bc4e3ae6ee46","2172":"59c1391f7b7d98d30d14513c","2173":"59c13967210ac269204de33f","2174":"59c1397e177fb9fe7eddd286","2175":"59c25290bac826f054dd5bcc","2176":"59c2c765c101bc4e3aee5169","2177":"59c2d51d614889d475209486","2178":"59c2d5ed177fb9fe7ee59ed5","2179":"59c438fc7b7d98d30d2268fb","2180":"59c451da177fb9fe7eec82fe","2181":"59c8d0f0177fb9fe7efd1d19","2182":"59c9291b177fb9fe7eff00cc","2183":"59c939a1614889d47539dc49","2184":"59c96586177fb9fe7e0042c6","2185":"59ceecd4b59d55b82354c66b","2186":"59ceee9032fc8b7e4058e3a9","2187":"59d07115b20c642429aa73bb","2188":"59d422c1bbbf9f1a381c69a7","2189":"59d4a3ee210ac26920a63daa","2190":"59d5158f7f323fc375088204","2191":"59d515c8177fb9fe7e3b7d4f","2192":"59d51d3fbbbf9f1a38216ffa","2193":"59db68b0177fb9fe7e57684f","2194":"59db69c1177fb9fe7e576f64","2195":"59db6a3a3cb340a26101f1c3","2196":"59db6b58177fb9fe7e5778c9","2197":"59dbbc46b20c642429dfe0d1","2198":"59dbd8b001110b723196652a","2199":"59dc8f1dbac826f054573baf","2200":"59dcc810177fb9fe7e5e92b7","2201":"59dd0e9dbbbf9f1a38452d11","2202":"59dd0ea7f7299e8f53cee8d7","2203":"59dd0ec33cb340a2610a9744","2204":"59dd0ee1f7299e8f53ceea16","2205":"59dd10d2614889d4759a63b7","2206":"59dd10e1177fb9fe7e605ee8","2207":"59dd6c4001110b72319e904d","2208":"59ddce76b20c642429ea693d","2209":"59ddcf61f7299e8f53d281c9","2210":"59ddd075bac826f0545dced9","2211":"59ddfc0be44c43700a1cc0e0","2212":"59debec6bac826f054631d49","2213":"59deeceaf7299e8f53d88000","2214":"59defa7cbac826f05463ffce","2215":"59dfc755f7299e8f53dd4044","2216":"59e46add5c40c1ba79a75234","2217":"59e46ae65c40c1ba79a75291","2218":"59e47e71f7299e8f53f2344d","2219":"59e6a75501110b7231cbfdd6","2220":"59e6a842d6c36fca31650976","2221":"59e6a874f7299e8f53fe2ba0","2222":"59e73fe6f7299e8f530107f5","2223":"59e87be201110b7231d5846d","2224":"59e87c19e44c43700a50d1e6","2225":"59ed5ded5c40c1ba79d3bea5","2226":"59ed5f1bb20c6424293652a8","2227":"59f6bd27210ac2692049834d","2228":"59f8c10ab20c6424296f27c2","2229":"59f8c66c210ac26920544051","2230":"59f8c6865a1758ed0f71e7bc","2231":"59f8c997e44c43700a9f364d","2232":"59f8de724ff065ac189cc1ae","2233":"59f9afa35a1758ed0f760162","2234":"59f9afb1b20c64242973a23e","2235":"59f9afee5a1758ed0f760374","2236":"59f9aff5f7299e8f535af999","2237":"59f9affb614889d475280020","2238":"59f9b016e44c43700aa37d80","2239":"59f9b023d6c36fca31c1ae4c","2240":"59f9b081976e63937e12cd64","2241":"59fb93715a1758ed0f80019e","2242":"59fb938c976e63937e1d7959","2243":"59fb93a2976e63937e1d79de","2244":"5a01409386d308b755b89221","2245":"5a01ff6c614889d4754fc0ed","2246":"5a020183d6c36fca31ea09a9","2247":"5a020479df09362e67dce8dc","2248":"5a024e88df09362e67dea53a","2249":"5a025098b20c6424299e972c","2250":"5a026030df09362e67def5e7","2251":"5a026045b20c6424299edd81","2252":"5a02613de44c43700acdfd11","2253":"5a026ee7df09362e67df2e06","2254":"5a026f4032e080696e79f503","2255":"5a026f7932e080696e79f62a","2256":"5a026f82f7299e8f5385bbd2","2257":"5a02ceb6f7299e8f538784d0","2258":"5a02d03adf09362e67e10809","2259":"5a02d0c6d6c36fca31ee3de6","2260":"5a02d0e332e080696e7bd087","2261":"5a02d29d86d308b755c0ea42","2262":"5a039aa8e44c43700ad4c6e9","2263":"5a039b3d614889d47558daea","2264":"5a043b4be44c43700ad7afd6","2265":"5a0b9949505b630c05e38e7f","2266":"5a0bb62371ad3f8736e667c9","2267":"5a0bb685505b630c05e40b4a","2268":"5a0d3ae0ba39a53f1aa716f8","2269":"5a0dee49540c78242d113fc9","2270":"5a0dee5f71ad3f8736f2cc57","2271":"5a11fd8aba39a53f1abd7f0d","2272":"5a13c662df09362e673471dc","2273":"5a13c8d371ad3f87360ec026","2274":"5a13c8ff71ad3f87360ec108","2275":"5a13c9362837ee5106ac4fac","2276":"5a205e38232e79134df18a51","2277":"5a205e3cffa3e37919ddb551","2278":"5a25126bba39a53f1a1982dd","2279":"5a2560bf540c78242d81a8b4","2280":"5a2593a2cc1d527f6bedd399","2281":"5a272a0da2be46682865f82c","2282":"5a273f34232e79134d12efce","2283":"5a273f5dba39a53f1a25770a","2284":"5a27400dc65707ba2b186bfb","2285":"5a2761e3c65707ba2b18eaaf","2286":"5a2784d7ffa3e379190062e1","2287":"5a27a3d787680e6230d8d1e6","2288":"5a27a3f9ffa3e3791900fadd","2289":"5a282925ffa3e379190403ad","2290":"5a2b456cba39a53f1a3a85c1","2291":"5a2b4595232e79134d2849e9","2292":"5a2b4659a2be4668287b74e0","2293":"5a2b46e4ba39a53f1a3a8991","2294":"5a2b8fc2ba39a53f1a3b872e","2295":"5a2dfcc9540c78242dabe947","2296":"5a2eab84ffa3e37919237346","2297":"5a2fe346232e79134d3d9e9d","2298":"5a30738dcc1d527f6b248c8d","2299":"5a33bdb8ffa3e379193ea862","2300":"5a3468eaa2be466828a92bac","2301":"5a37f837a2be466828b82ee3","2302":"5a38b384232e79134d6875e7","2303":"5a3919020163b0281055e2b9","2304":"5a3919a80163b0281055e714","2305":"5a398494ffa3e3791959c529","2306":"5a3984a6ffa3e3791959c56d","2307":"5a3984da00d569114bc74f66","2308":"5a3ab15803838b2f2a1b3333","2309":"5a3ac2dcba39a53f1a84c584","2310":"5a3b2ede0163b02810607e0a","2311":"5a3c1827e43a7a150c90ff11","2312":"5a3df1245355812e570bbff1","2313":"5a3df1d15355812e570bc34f","2314":"5a3ea7260163b02810703c4b","2315":"5a3ea73ee43a7a150c9bf790","2316":"5a41dea7b48e8c35666803c0","2317":"5a41df6cba39a53f1aa2100a","2318":"5a4b395329ec6ac311ab164d","2319":"5a4b3959232e79134db6dfe4","2320":"5a4bd14dba39a53f1aca80a8","2321":"5a4c5c6f68d092bb62197853","2322":"5a4cfa6c29ec6ac311b3e8f9","2323":"5a4d3be403838b2f2a68d708","2324":"5a4d3ce95355812e574a9cf0","2325":"5a4dcb5368d092bb62208056","2326":"5a4dcb6568d092bb622080db","2327":"5a4dceb20163b02810adfa23","2328":"5a4dd433edd22308110e46f6","2329":"5a4dd5d384fb74b94036a119","2330":"5a4e029629ec6ac311b922aa","2331":"5a4e2ca65355812e574f27f8","2332":"5a53ba82290a1f4561641313","2333":"5a5406adb48e8c3566b7eb86","2334":"5a5406cd232e79134de137a8","2335":"5a547ece83152df26d4b3cf8","2336":"5a547eec83152df26d4b3dd7","2337":"5a54c72383152df26d4ce916","2338":"5a54d1e7ce68c3bc7498c16b","2339":"5a54e4c55a9ebe4f7566c301","2340":"5a5500a6b48e8c3566bd1c81","2341":"5a5521176117191e6146c41c","2342":"5a552b3183152df26d4f890d","2343":"5a552b6aba39a53f1af72e27","2344":"5a552c56232e79134de799df","2345":"5a552c8b232e79134de79a9d","2346":"5a552c936117191e6147056d","2347":"5a552cde232e79134de79cec","2348":"5a55c91a290a1f45616ec85f","2349":"5a5618696117191e614b9a22","2350":"5a561880ae53c15903ceed5f","2351":"5a562ef6290a1f45617103ea","2352":"5a5633e8ae53c15903cf9545","2353":"5a56370583152df26d54f3f2","2354":"5a566647d0514c785b14c164","2355":"5a572b53ce68c3bc74a4ba69","2356":"5a57bb11290a1f4561794049","2357":"5a57bb5cb48e8c3566cbb426","2358":"5a57c068ae53c15903d7e556","2359":"5a57c1fc5a9ebe4f757670af","2360":"5a57c47083152df26d5d2ff2","2361":"5a57c4ac290a1f456179795d","2362":"5a57c4b15a9ebe4f75767fea","2363":"5a57c4d483152df26d5d32d9","2364":"5a57c5e3290a1f4561797ea9","2365":"5a57c6bbd0514c785b1bd2cb","2366":"5a57c6dfae53c15903d808ca","2367":"5a57c70cae53c15903d809ac","2368":"5a57c74783152df26d5d40bd","2369":"5a57c7bace68c3bc74a8330f","2370":"5a57c7cad0514c785b1bda4c","2371":"5a57de0d61a861c927013c2b","2372":"5a5833ce6117191e615698d9","2373":"5a585d45290a1f45617c1958","2374":"5a586ac161a861c9270394fa","2375":"5a586ad083152df26d600fc7","2376":"5a586b0bba39a53f1a078a55","2377":"5a586b1cce68c3bc74aae91b","2378":"5a586da9ba39a53f1a079728","2379":"5a586e025a9ebe4f75798716","2380":"5a586e65b48e8c3566cec959","2381":"5a587a8bba39a53f1a07d38c","2382":"5a58905261a861c927045278","2383":"5a58aceece68c3bc74ac3e08","2384":"5a58addcae53c15903dc2e95","2385":"5a58af88ce68c3bc74ac4dbe","2386":"5a58b1ef1dcb91f17740d314","2387":"5a58c22f290a1f45617e3ade","2388":"5a58ee861dcb91f177423e55","2389":"5a5915d483152df26d63daee","2390":"5a5c550bae53c15903eb328d","2391":"5a5c658f290a1f45618cfe5b","2392":"5a5c65f96117191e61682c3d","2393":"5a5c668b290a1f45618d0308","2394":"5a5c78095ade18be39792ac5","2395":"5a5cd5b2517037a212ac2151","2396":"5a5d0e3eb48e8c3566e36688","2397":"5a5e1189517037a212b2a0fc","2398":"5a5e6649290a1f4561980900","2399":"5a5f14bd290a1f45619b5997","2400":"5a5f14d3290a1f45619b59ee","2401":"5a5f65f4290a1f45619d3b6f","2402":"5a5f99b51dcb91f1776193cb","2403":"5a5fdcde5ade18be398c3d31","2404":"5a5fdd8fae53c15903ff00a9","2405":"5a5fddebb48e8c3566f2ec50","2406":"5a5fdf3c517037a212bd2e81","2407":"5a5fdf96b48e8c3566f2f47b","2408":"5a5fdff06117191e617b8dc2","2409":"5a5fe1ca290a1f4561a041cb","2410":"5a5fe244ce68c3bc74ce8158","2411":"5a6090d01dcb91f17766adc8","2412":"5a6090e15a9ebe4f75a17083","2413":"5a60910db48e8c3566f68adc","2414":"5a6092f9ba39a53f1a2ea485","2415":"5a60db04b48e8c3566f889b8","2416":"5a61457b517037a212c532f5","2417":"5a6156576117191e6183e40c","2418":"5a6179f7ce68c3bc74d70d41","2419":"5a6198e35a9ebe4f75a74a3d","2420":"5a61999ce014122650638e5c","2421":"5a619d5e290a1f4561a9717d","2422":"5a61cae29cdc721e4f9f5c7c","2423":"5a62335c9cdc721e4fa1fd13","2424":"5a623432e01412265067622f","2425":"5a625f27290a1f4561ae1046","2426":"5a625f529cdc721e4fa3051e","2427":"5a625faee0141226506867d9","2428":"5a625fd1e01412265068687a","2429":"5a62601a290a1f4561ae158b","2430":"5a62dfd0ba39a53f1a3b118d","2431":"5a62e1345a9ebe4f75ae61eb","2432":"5a62e404ba39a53f1a3b1f1b","2433":"5a62e41b517037a212cd97b8","2434":"5a62e474517037a212cd9866","2435":"5a62f4195ade18be399ca5da","2436":"5a62f436e0141226506abed5","2437":"5a62f45eae53c159030f4b37","2438":"5a62f5075a9ebe4f75aea54a","2439":"5a62f98f290a1f4561b075fb","2440":"5a62f9ceba39a53f1a3b6a92","2441":"5a62fb13517037a212cdeb16","2442":"5a62fb345a9ebe4f75aebf3c","2443":"5a62fb4dba39a53f1a3b6eb2","2444":"5a62fb62e0141226506ad99f","2445":"5a62fb6fba39a53f1a3b70d7","2446":"5a62fb6fae53c159030f6456","2447":"5a62fb80517037a212cdec42","2448":"5a62fbb8ba39a53f1a3b725f","2449":"5a6321c16117191e618ce58d","2450":"5a6325ee6117191e618cf59c","2451":"5a6535f05ade18be39a663de","2452":"5a653659d9f895c360439cf5","2453":"5a658fda0ad3e04b1b50e685","2454":"5a65915cae53c159031a5d04","2455":"5a65917ce01412265075daa6","2456":"5a659185ce68c3bc74e98ae6","2457":"5a65918fae53c159031a5e12","2458":"5a65a71d5a9ebe4f75ba4fc9","2459":"5a65efabd9f895c360473a34","2460":"5a65f05698927d57451f59dc","2461":"5a66a61a6117191e619d9e84","2462":"5a66a7f2517037a212df7366","2463":"5a66a9190ad3e04b1b57582c","2464":"5a66ab63ae53c1590320ed34","2465":"5a66ddf75ade18be39af1d1b","2466":"5a66e52cce68c3bc74f0d62c","2467":"5a66e57bae53c1590321f49c","2468":"5a66e5cc6117191e619eb4a6","2469":"5a66e5d8ce68c3bc74f0da20","2470":"5a66e8590ad3e04b1b586e90","2471":"5a66ef11517037a212e0b26b","2472":"5a66efcd98927d574524bd25","2473":"5a66f06e517037a212e0b882","2474":"5a6703b4517037a212e12a1d","2475":"5a671f5d5a9ebe4f75c2bd31","2476":"5a67208f5ade18be39b08daf","2477":"5a6726875ade18be39b0af28","2478":"5a676d68517037a212e3e86f","2479":"5a6792d7c95f22546dd6cbd5","2480":"5a6792f2c95f22546dd6cca4","2481":"5a67ea8b517037a212e6a189","2482":"5a67f3c0ae53c15903282b14","2483":"5a67f3dae01412265083b8b1","2484":"5a67f3e0d9f895c3605281b1","2485":"5a67f5e35a9ebe4f75c7c186","2486":"5a67f8a60ad3e04b1b5e8dd5","2487":"5a680100ce68c3bc74f710d4","2488":"5a6802706117191e61a500fe","2489":"5a6802b05a9ebe4f75c7efb6","2490":"5a68068fce68c3bc74f727a1","2491":"5a6806c95a9ebe4f75c7ff60","2492":"5a6807225a9ebe4f75c80123","2493":"5a68073dae53c15903287803","2494":"5a6807bcce68c3bc74f72d43","2495":"5a6812ee0ad3e04b1b5eece0","2496":"5a68266b0ad3e04b1b5f48c9","2497":"5a6826cdd9f895c3605351d1","2498":"5a68276f517037a212e7a333","2499":"5a68286b5a9ebe4f75c89596","2500":"5a6840e45a9ebe4f75c91506","2501":"5a68505fce68c3bc74f8828c","2502":"5a689b84ce68c3bc74fa3f69","2503":"5a689d01c95f22546ddc34b1","2504":"5a68e9670ad3e04b1b63e6e1","2505":"5a6a82e798927d574538be41","2506":"5a6a83e698927d574538c1e4","2507":"5a6a84026117191e61b2f900","2508":"5a6acbcc494bd0f53027b32b","2509":"5a6fc8b86117191e61cc89dc","2510":"5a6fd9c3ac509d207d940e65","2511":"5a70186d40259f1a33c528c3","2512":"5a7018b847505419173fb2ed","2513":"5a7169726117191e61d591c1","2514":"5a7258bdce68c3bc742cd573","2515":"5a726e0147505419174de02f","2516":"5a72b745b3c4a0d376c77106","2517":"5a72d2d9b3c4a0d376c80489","2518":"5a72d323ce68c3bc742efc1b","2519":"5a72d3356117191e61ddde6c","2520":"5a72d3744a6b0dd32b75419e","2521":"5a72d37c98927d5745631175","2522":"5a72d5d26117191e61ddec3c","2523":"5a72d66b98927d5745631efd","2524":"5a740866ce68c3bc74357161","2525":"5a7414d86117191e61e49fb0","2526":"5a7414fa6117191e61e4a063","2527":"5a74154498927d574569b762","2528":"5a77c8446117191e61f54cbb","2529":"5a78b3617dcd63481f1fccbf","2530":"5a796afea3447aac754970ff","2531":"5a79724f36de78850cf8f84c","2532":"5a79785d4a6b0dd32b95c850","2533":"5a79f769f283b8e54629fa59","2534":"5a79fa1b7084124a3443e52e","2535":"5a79fa9a6117191e6101b8f6","2536":"5a79fab0f283b8e5462a1140","2537":"5a79fab57dcd63481f26eca6","2538":"5a79face4a6b0dd32b991701","2539":"5a7a01c9ce68c3bc7452addf","2540":"5a7a02b093be87284d83cdda","2541":"5a7a02bee217167e2c4e8eaa","2542":"5a7a02ddf283b8e5462a4440","2543":"5a7a02f593be87284d83cf27","2544":"5a7a2be8e217167e2c4f8cfd","2545":"5a7a2c046117191e6102ebc5","2546":"5a7a2cc37084124a34451bdd","2547":"5a7a2f0bce68c3bc7453bb5c","2548":"5a7aa47f7dcd63481f2a3a19","2549":"5a7abfa6b3c4a0d376f005a4","2550":"5a7abfd4b3c4a0d376f006b3","2551":"5a7ad18b7dcd63481f2b399d","2552":"5a7ad3e686ef1bb1417b895f","2553":"5a7ad5cab3c4a0d376f08801","2554":"5a7b344c86ef1bb1417df63c","2555":"5a7b5b7693be87284d8b56dd","2556":"5a7bf4fb93be87284d8e2f17","2557":"5a7bf556e217167e2c59334b","2558":"5a8134894a6b0dd32bbc539a","2559":"5a814d29ce68c3bc7475c50a","2560":"5a81690a7084124a3467cf79","2561":"5a820d80f283b8e54652a577","2562":"5a823ce5f283b8e546538e9b","2563":"5a823d4b93be87284dac8935","2564":"5a823d6418f388e626968abf","2565":"5a823d8cd74ee9f50db847c6","2566":"5a8253c7f283b8e54653efe5","2567":"5a82f0148c71e5e01d8d3ea8","2568":"5a830be7d74ee9f50dbc98bb","2569":"5a830e36d74ee9f50dbca8c1","2570":"5a830e9b18f388e6269b07a2","2571":"5a8311a9e217167e2c7c5ebb","2572":"5a831a0cb3c4a0d3761aac15","2573":"5a831a54ce68c3bc747ffec4","2574":"5a831b928c71e5e01d8e7c50","2575":"5a831bc14a6b0dd32bc77dac","2576":"5a831d25e217167e2c7cb30a","2577":"5a831d4db3c4a0d3761ac3b5","2578":"5a832214d74ee9f50dbd3b02","2579":"5a8322be8c71e5e01d8eb3aa","2580":"5a832881b3c4a0d3761b158f","2581":"5a8328dde217167e2c7d0267","2582":"5a8328fed74ee9f50dbd6a68","2583":"5a832f24e217167e2c7d2c7a","2584":"5a833e36ce68c3bc7480e6c4","2585":"5a833e4c18f388e6269c54d3","2586":"5a833ea84a6b0dd32bc87245","2587":"5a8340fae217167e2c7d9dbd","2588":"5a83514e93be87284db297b0","2589":"5a8368adf283b8e5465a56bf","2590":"5a8368f54a6b0dd32bc97801","2591":"5a8369d5f283b8e5465a5be1","2592":"5a85f279d74ee9f50dcd3c17","2593":"5a85f2817084124a348177a5","2594":"5a86253994627713603cc3e7","2595":"5a862542e91aaf146779081d","2596":"5a863c10d786ce546e6b579d","2597":"5a86ede8d786ce546e6fdf30","2598":"5a86fc73cc9e4b536ece52f5","2599":"5a8903b10202dc012e4ca934","2600":"5a8a64caa2194eb80d8169a0","2601":"5a8a650a888332ee3aa058f2","2602":"5a8b0eb18f1c77ef3a2a606a","2603":"5a8ba41b8f1c77ef3a2d3ff0","2604":"5a8ba4296f8b4b9946980da6","2605":"5a8ba613a2194eb80d892a8e","2606":"5a8c033d53c1dbb743519f60","2607":"5a8c038735dd17022ecc362e","2608":"5a8c5a6a35dd17022ece9d86","2609":"5a8c5ae9e4ff28713aa325b8","2610":"5a8c6226a2194eb80d8d9d33","2611":"5a8c7fc90202dc012e60886a","2612":"5a8d6eaf6f8b4b9946a223e3","2613":"5a8d807e53c1dbb7435a6036","2614":"5a8d9f6f888332ee3ab3514c","2615":"5a8d9f84e4ff28713aaa5f30","2616":"5a8dbaf8a2194eb80d95787f","2617":"5a8dbdfe0202dc012e67bbe1","2618":"5a8dcb1053c1dbb7435c4c86","2619":"5a8dcb288f1c77ef3a39c789","2620":"5a8e711ce4ff28713aaec880","2621":"5a8e86d8e4ff28713aaf48ae","2622":"5a8eaa4935dd17022edb9f12","2623":"5a8f36ce888332ee3abc7738","2624":"5a8f36d68f1c77ef3a41d2c5","2625":"5a8f36d835dd17022edf5bbe","2626":"5a8f370fa2194eb80d9e2f61","2627":"5a8f371d6fba1a703a8ac70d","2628":"5a8f87bbc3c5f8b90df330c5","2629":"5a904143c3c5f8b90df74494","2630":"5a90437ec3c5f8b90df7569b","2631":"5a9222478f1c77ef3a4fc03e","2632":"5a92227f6fba1a703a98bcb0","2633":"5a9222d46fba1a703a98bde1","2634":"5a92243253c1dbb743725275","2635":"5a92243cc3c5f8b90dfff684","2636":"5a922c3a6fba1a703a98e085","2637":"5a9296a0c3c5f8b90d01a7f7","2638":"5a9296f46f8b4b9946bc341f","2639":"5a932e556fba1a703a9d3cd5","2640":"5a932e9e0202dc012e8350a7","2641":"5a9330336f8b4b9946bf1164","2642":"5a9331770202dc012e835e3c","2643":"5a9334b96f8b4b9946bf2659","2644":"5a9334d153c1dbb74376e672","2645":"5a9334f1c3c5f8b90d04aba2","2646":"5a93356135dd17022ef220ae","2647":"5a933586888332ee3acf0f38","2648":"5a9335a235dd17022ef22245","2649":"5a93366a35dd17022ef224f6","2650":"5a9337206fba1a703a9d6628","2651":"5a9337328f1c77ef3a54639a","2652":"5a93374fc3c5f8b90d04b74e","2653":"5a93375153c1dbb74376f09f","2654":"5a93381b458cbde557c86971","2655":"5a933820c3c5f8b90d04bbf4","2656":"5a93668b458cbde557c92a6a","2657":"5a9366d06fba1a703a9e27fe","2658":"5a93673a6fba1a703a9e2961","2659":"5a936fcc0202dc012e845b8d","2660":"5a944d646fba1a703aa361a0","2661":"5a944da00202dc012e896ce3","2662":"5a944dab6fba1a703aa36358","2663":"5a944de9458cbde557ce7aac","2664":"5a944e156fba1a703aa3666b","2665":"5a944e3bc3c5f8b90d0abca1","2666":"5a944e566f8b4b9946c50a50","2667":"5a9454176f8b4b9946c531aa","2668":"5a94545e888332ee3ad52a5d","2669":"5a94546c8f1c77ef3a5a8915","2670":"5a9455c76f8b4b9946c53df5","2671":"5a94852d53c1dbb7437e6139","2672":"5a9488a38f1c77ef3a5bfeb7","2673":"5a94995be4ff28713ace9b92","2674":"5a94b06ec3c5f8b90d0d2f32","2675":"5a94b1188f1c77ef3a5cdbac","2676":"5a94b185c3c5f8b90d0d339b","2677":"5a94b1ab888332ee3ad76d64","2678":"5a94b1c4888332ee3ad76d98","2679":"5a94b1ff8f1c77ef3a5cdf4d","2680":"5a94b21d8f1c77ef3a5ce00b","2681":"5a94b2738f1c77ef3a5ce1ab","2682":"5a94b2a46f8b4b9946c7874b","2683":"5a94b2ef458cbde557d0ecba","2684":"5a94b31c53c1dbb7437f5680","2685":"5a94b3e26fba1a703aa5db98","2686":"5a94b41b8f1c77ef3a5ce888","2687":"5a94b433e4ff28713acf201f","2688":"5a94b43f6f8b4b9946c78f03","2689":"5a95ec7053c1dbb74385f7b3","2690":"5a95ec8d6fba1a703aacaaf4","2691":"5a95eca5e4ff28713ad5ef2b","2692":"5a95ecdd53c1dbb74385f930","2693":"5a95ed16c3c5f8b90d141265","2694":"5a965f420202dc012e94a20f","2695":"5a9660648f1c77ef3a65972a","2696":"5a967ea80202dc012e9542d0","2697":"5a967eb16f8b4b9946d0be69","2698":"5a96dd5ae4ff28713ada65f7","2699":"5a96ddf9c3c5f8b90d18aefb","2700":"5a96de63e4d1c63604a6d764","2701":"5a986ba753c1dbb74391f8ab","2702":"5a986bd6888332ee3aea45da","2703":"5a98b76e0202dc012ea051a3","2704":"5a9c1d9fe4d1c63604beb982","2705":"5a9c5db553c1dbb743a2ee87","2706":"5a9c5dcf8f1c77ef3a8122ff","2707":"5a9c5dd98f1c77ef3a812323","2708":"5a9cffede4d1c63604c26c42","2709":"5a9d01d553c1dbb743a57c26","2710":"5a9dcd788f1c77ef3a88502d","2711":"5a9e1fd26f8b4b9946f36bf7","2712":"5a9e88d98f1c77ef3a8b7fec","2713":"5a9e91af458cbde557006bf1","2714":"5a9e927453c1dbb743ad8973","2715":"5a9ea9ef458cbde55700feb5","2716":"5a9ee5366f8b4b9946f78c51","2717":"5a9ee581c3c5f8b90d3eb263","2718":"5a9ee591e4ff28713affbc93","2719":"5a9f870b888332ee3a0af1c6","2720":"5a9f8cfd6fba1a703ad98dcc","2721":"5a9f8e93c3c5f8b90d41b8ae","2722":"5a9f8f08f3f6d24c6847613f","2723":"5a9f8f27e4ff28713a02a569","2724":"5a9f8f4e0a1614b712ef5fc9","2725":"5a9f8f6335dd17022e2e56ae","2726":"5a9f8f6a0a1614b712ef60ab","2727":"5a9f8f9053c1dbb743b27e8a","2728":"5a9f8f98f3f6d24c68476376","2729":"5a9f8fe9e4ff28713a02a868","2730":"5a9f8ffff3f6d24c684764c2","2731":"5a9f90078f1c77ef3a909ce8","2732":"5a9f901d0a1614b712ef6434","2733":"5a9f90f5e4d1c63604cf7c73","2734":"5a9f9109f3f6d24c68476947","2735":"5a9f92518f1c77ef3a90ab17","2736":"5a9f9270458cbde557058dd5","2737":"5a9f927e458cbde557058e98","2738":"5a9f92f353c1dbb743b290fc","2739":"5a9f935d888332ee3a0b30d7","2740":"5aa00d470a1614b712f20c1c","2741":"5aa00dab53c1dbb743b522bd","2742":"5aa03c5ef3f6d24c684b31c8","2743":"5aa0a7a835dd17022e344583","2744":"5aa0a7e935dd17022e34462a","2745":"5aa1290a8f1c77ef3a98b411","2746":"5aa129f7e4d1c63604d7a639","2747":"5aa15afd8f1c77ef3a99db69","2748":"5aa164846fba1a703ae30969","2749":"5aa20734888332ee3a1764ab","2750":"5aa2073b0a1614b712fbbe41","2751":"5aa23181f3f6d24c68544c05","2752":"5aa231adc3c5f8b90d4eee11","2753":"5aa231d96f8b4b99460754d8","2754":"5aa231e2e4ff28713a0fac45","2755":"5aa232136fba1a703ae6c0e5","2756":"5aa232780a1614b712fc6799","2757":"5aa232a4888332ee3a180a26","2758":"5aa23787e4ff28713a0fc579","2759":"5aa241cd458cbde557131ca7","2760":"5aa242a96f8b4b994607a28a","2761":"5aa242cef3f6d24c6854a0a7","2762":"5aa2caaec3c5f8b90d524c15","2763":"5aa2cad0f3f6d24c68579ce7","2764":"5aa2ce4de4ff28713a12f1d2","2765":"5aa2d367e4ff28713a130dfd","2766":"5aa2e31735dd17022e3f2bc9","2767":"5aa2e32053c1dbb743c33fe5","2768":"5aa2e3520a1614b712003737","2769":"5aa32c716f8b4b99460c7c1d","2770":"5aa32cb835dd17022e407080","2771":"5aa32cc6458cbde55717fcf0","2772":"5aa32ce9c3c5f8b90d541527","2773":"5aa41778e4ff28713a1816c6","2774":"5aa4178353c1dbb743c7f392","2775":"5aa417f053c1dbb743c7f61a","2776":"5aa4569d8f1c77ef3aa715b1","2777":"5aa462cdc3c5f8b90d58cfc6","2778":"5aa463fee4d1c63604e619ce","2779":"5aa4641d888332ee3a219fe3","2780":"5aa47414f3f6d24c685e4239","2781":"5aa49778e4ff28713a19fa82","2782":"5aa4a9b7e4d1c63604e6f6ae","2783":"5aa4a9c98f1c77ef3aa827a7","2784":"5aa4a9e3458cbde5571da13c","2785":"5aa4ab7c6f8b4b994612173c","2786":"5aa4c9f00a1614b712075892","2787":"5aa52fa127c509a7744d7bfc","2788":"5aa5410cc3c5f8b90d5be960","2789":"5aa5a9a4f3f6d24c6862e24e","2790":"5aa5a9bee4d1c63604eaf4a2","2791":"5aa5aa34e4ff28713a1e3f86","2792":"5aa5aa3d458cbde55721c029","2793":"5aa5aeaac3c5f8b90d5dcca0","2794":"5aa5aebdc3c5f8b90d5dccc6","2795":"5aa61cf98f1c77ef3aadc2bd","2796":"5aa61e70458cbde557236ded","2797":"5aa689f28f1c77ef3ab00df7","2798":"5aa6af166f8b4b99461b024b","2799":"5aa726ba53c1dbb743d558f9","2800":"5aa73dc4458cbde5572986a3","2801":"5aa73e03e4d1c63604f27af2","2802":"5aa73e1be4d1c63604f27b3c","2803":"5aa73e82458cbde557298966","2804":"5aa73eb153c1dbb743d5b0f5","2805":"5aa73ed1c3c5f8b90d657e30","2806":"5aa7ba80458cbde5572bce9c","2807":"5aa7c58b27c509a774599410","2808":"5aa7d1596f8b4b99462076f1","2809":"5aa81f7535dd17022e56442a","2810":"5aa820c6e4ff28713a2ad75e","2811":"5aa903c7a60157d62fe6b1d0","2812":"5aa90d81e4d1c63604fb56b1","2813":"5aa940bfe4ff28713a3066af","2814":"5aa94130e4d1c63604fc7f17","2815":"5aa9415f0a1614b7121cc96c","2816":"5aa9417353c1dbb743dfca96","2817":"5aa941830a1614b7121cca08","2818":"5aa9433835dd17022e5bcbc0","2819":"5aa9fc5c27c509a7746479ec","2820":"5aaa13178f1c77ef3ac18cb1","2821":"5aaa32ca35dd17022e60106f","2822":"5aaa331ae4d1c6360400d3ce","2823":"5aaa332be4d1c6360400d451","2824":"5aaab9028f1c77ef3ac50d04","2825":"5aaab944f3f6d24c687bb71a","2826":"5aaace1d0a1614b7122474f7","2827":"5aaad46ae4d1c63604044cc1","2828":"5aaad50a35dd17022e639af0","2829":"5aab23dfa60157d62ff1579a","2830":"5aab2410bb1018b37aec8e20","2831":"5aab5feb27c509a7746b03d8","2832":"5aab725d6f8b4b9946322529","2833":"5aab9676e4ff28713a3b9dcb","2834":"5aac0484c3c5f8b90d7d7a54","2835":"5aac053f35dd17022e693baf","2836":"5aac1d498f1c77ef3acbb759","2837":"5aac1d5535dd17022e69c077","2838":"5aacec4d5f188ccc15c6a088","2839":"5aacec9fe4d1c636040d5a73","2840":"5aad6717458cbde55746ed6e","2841":"5aad672aa60157d62ffb1398","2842":"5aafb666f3f6d24c68901f1b","2843":"5aafbaad35dd17022e77b468","2844":"5aafe551bb1018b37a007727","2845":"5ab00846c3c5f8b90d8e01ee","2846":"5ab03585c3c5f8b90d8f04b3","2847":"5ab035ce35dd17022e7a7543","2848":"5ab0e13ac3c5f8b90d920230","2849":"5ab0fb59e4d1c636041e8d0e","2850":"5ab192f4e4d1c6360421e588","2851":"5ab1daa4bb1018b37a0a13cf","2852":"5ab2b050fa066c532557e9f8","2853":"5ab2b0595f188ccc15e09901","2854":"5ab327fd5f188ccc15e2821a","2855":"5ab32817458cbde557614a6b","2856":"5ab32876c574b1aa3e1beab7","2857":"5ab328baf3f6d24c68a136ea","2858":"5ab328c8fa066c532559db3c","2859":"5ab328ccc3c5f8b90d9d855d","2860":"5ab35c9e35dd17022e895ff6","2861":"5ab35cfbc3c5f8b90d9e46a9","2862":"5ab35d262b9dfdbc3a0c8412","2863":"5ab387f0a60157d62f1700a3","2864":"5ab3b6bebb1018b37a12bfc0","2865":"5ab4bea2fa066c5325611220","2866":"5ab4f12e5f188ccc15ea968e","2867":"5ab51c892b9dfdbc3a14bfb3","2868":"5ab534fee3d0b1ff2c5dd627","2869":"5ab8fd7d458cbde557793d3a","2870":"5ab907dbbb1018b37a2842c4","2871":"5aba6dcce3d0b1ff2c72ed64","2872":"5aba6e155f188ccc1501653b","2873":"5aba6e2df3f6d24c68c00769","2874":"5aba6e67458cbde55780415f","2875":"5aba6e82458cbde5578041be","2876":"5aba6ed7e4ff28713a7cd913","2877":"5aba7ad9bb1018b37a2f40a1","2878":"5aba86ba458cbde55780c311","2879":"5abab6c15f188ccc1502dd1b","2880":"5abb7b3cc4d0ae80070d8edf","2881":"5abb7b9be4ff28713a817cc0","2882":"5abb7bc1c574b1aa3e3fc999","2883":"5abb7bfdc4d0ae80070d91bb","2884":"5abbe7b65f188ccc15084eaf","2885":"5ac64568e3d0b1ff2ca54fdd","2886":"5acb033e1130fe3d36b83291","2887":"5acba9a4270d7d3708ac3c75","2888":"5acba9a7080a385053139415","2889":"5acba9d62b9dfdbc3a7140c2","2890":"5acbaa0227c509a774f3f1c4","2891":"5acbb9046bbe1d2739cb26bd","2892":"5acbb9215f188ccc1548d5bd","2893":"5acbb929080a38505313e67f","2894":"5acbb94adf3e0fb547bca30b","2895":"5acbd48a080a385053146d6e","2896":"5acbd4bddf3e0fb547bd2e45","2897":"5acc59575f188ccc154b6c8b","2898":"5acc79b9109bb04332a8132f","2899":"5acd61726d7e07082bdee6d7","2900":"5acd6afbdf3e0fb547c458ca","2901":"5ace7f401130fe3d36c93c92","2902":"5ad0f608df3e0fb547d4ec66","2903":"5ad0f62727c509a7740c6a3f","2904":"5ad0f670080a3850532c689f","2905":"5ad0f7155d7286b43a279b96","2906":"5ad0f7785f188ccc156174b5","2907":"5ad0f78f6d7e07082bf015a0","2908":"5ad0f7a8080a3850532c6e40","2909":"5ad0f7b71130fe3d36d4ec88","2910":"5ad0f7bedf3e0fb547d4f37a","2911":"5ad0f7cd1130fe3d36d4ed25","2912":"5ad0f7dc109bb04332bd45b2","2913":"5ad0f801df3e0fb547d4f4cf","2914":"5ad0f8187c3a01610ddd1428","2915":"5ad0f843080a3850532c70c3","2916":"5ad0f92e270d7d3708c4dfbc","2917":"5ad1088fdf3e0fb547d54ad5","2918":"5ad1089fdf3e0fb547d54b6f","2919":"5ad108ac080a3850532cc48f","2920":"5ad108e47c3a01610ddd6bf5","2921":"5ad1095c080a3850532cc964","2922":"5ad10986080a3850532cca6c","2923":"5ad1098f5f188ccc1561cdf5","2924":"5ad109af5f188ccc1561ce5b","2925":"5ad109ec2b9dfdbc3a8a7afa","2926":"5ad109f4109bb04332bd9cfc","2927":"5ad10a3b080a3850532ccd88","2928":"5ad10a4a6bbe1d2739e40357","2929":"5ad10acc109bb04332bda12a","2930":"5ad10ad9109bb04332bda16c","2931":"5ad10bc12b9dfdbc3a8a83da","2932":"5ad11b3e5d7286b43a285589","2933":"5ad11b5127c509a7740d227c","2934":"5ad11b651130fe3d36d5a140","2935":"5ad11b6a7c3a01610dddce35","2936":"5ad37d745f188ccc15699ead","2937":"5ad3e355109bb04332c6b975","2938":"5ad3e37e5d7286b43a312e9d","2939":"5ad455a327c509a7741780b0","2940":"5ad455b86bbe1d2739eed654","2941":"5ad4d0d15d7286b43a35389c","2942":"5ad4d1be15c9b0311401f375","2943":"5ad4da6e7c3a01610deacc87","2944":"5ad4ea766d7e07082bfe9cde","2945":"5ad4f7651130fe3d36e37245","2946":"5ad4f76b1130fe3d36e37256","2947":"5ad502e51130fe3d36e3af9f","2948":"5ad5a2286bbe1d2739f4c74f","2949":"5ad64bd25f188ccc1575d18f","2950":"5ad6a5817c3a01610df2cded","2951":"5ad6a5fa5f188ccc15774a68","2952":"5ad6bacd109bb04332d32290","2953":"5ad6bc166bbe1d2739f9ee3b","2954":"5ad6bc3727c509a77422b38e","2955":"5ad6c1c36d7e07082b06d735","2956":"5ad6f4ae7c3a01610df3ef24","2957":"5ad703177c3a01610df434a4","2958":"5ad7159715c9b031140c060d","2959":"5ad914cd5d7286b43a48e41c","2960":"5ad914ee6bbe1d2739050fce","2961":"5ad9151815c9b03114157981","2962":"5ad9e8a2109bb04332e1906c","2963":"5ade33832d0e228d7ba3d0bf","2964":"5ade33865f188ccc159691b6","2965":"5ade499662316e0505f098f3","2966":"5adea11f62316e0505f1def7","2967":"5adf16775f188ccc159a67f9","2968":"5adfa35015c9b03114309d36","2969":"5ae19041109bb04332020129","2970":"5ae1cce71130fe3d361c232a","2971":"5ae2681f5d7286b43a710561","2972":"5ae283af7c3a01610d262a4a","2973":"5ae283e05d7286b43a716069","2974":"5ae284e57c3a01610d262df6","2975":"5ae284eb62316e0505048655","2976":"5ae28d4162316e050504a2aa","2977":"5ae2909f62316e050504adc9","2978":"5ae2ecf2dad6fb186ff11355","2979":"5ae301db15c9b031144023b6","2980":"5ae3727e270d7d370812e021","2981":"5ae587a3109bb0433211ed68","2982":"5ae75b432b9dfdbc3ae5fe59","2983":"5ae7ec0b727e915b1040e099","2984":"5ae7ec1fdea1b95c10ef8b1b","2985":"5ae7ec3f727e915b1040e271","2986":"5ae7ec44dea1b95c10ef8dd9","2987":"5ae7ec7e727e915b1040e58e","2988":"5ae8c69f53ceca3604a3db47","2989":"5ae8dc7e6f9af87e0435cdab","2990":"5ae8dc9a00dc488804896742","2991":"5ae8dcad1eddba3d04c55e80","2992":"5ae8dd0740f24c430445c522","2993":"5ae8dd1f00dc48880489681b","2994":"5ae8e02d0a9c956f041b171d","2995":"5ae8e03b97e5506e048cfec7","2996":"5ae94da9b982f08504e8196a","2997":"5ae964f0b982f08504e86981","2998":"5ae967d9e2d30c2f045a0d4f","2999":"5ae967e31eddba3d04c6e784","3000":"5ae9f931f2d2d537045a1440","3001":"5aeab8bb5cf0b8300451a86d","3002":"5aeb2af459a0578004a0c769","3003":"5aeb2b075cf0b83004536a20","3004":"5aeb4eebdb299d4004cc1512","3005":"5aec723cf2d2d53704626f5b","3006":"5af3bb40bd10f34a68ee742d","3007":"5af3d4f8bd10f34a68eeb049","3008":"5af3d6901cfca775e1f93152","3009":"5af3f1545a1d895fae2b8831","3010":"5af5131852194a4a67d78312","3011":"5af92517e1cf621dba191cb9","3012":"5afc3f30a2d951363344f5e1","3013":"5afc67f05666c42eb6177505","3014":"5b02568cd245fe2eb7c7c9e7","3015":"5b03de77d245fe2eb7ccf2f8","3016":"5b03e0fae1cf621dba3b3407","3017":"5b042c095666c42eb62fadeb","3018":"5b04d9e05f3e6b40fad971d3","3019":"5b04da1eee623e2e41f6b6d0","3020":"5b04da3bb435f21fb8bcef23","3021":"5b0534cb2942532e42d59955","3022":"5b0534d56309af743d08a1fa","3023":"5b068fde2942532e42da6b03","3024":"5b075ce0ee623e2e41fff9cb","3025":"5b075d2d3815f70bffd7da33","3026":"5b077d4f16f6496124db8cc7","3027":"5b077d7793dc78791c8354b0","3028":"5b0781637ccd4f1a695c87d8","3029":"5b0781a016f6496124db9866","3030":"5b07e08fedd06f7d15e182a1","3031":"5b07e0a94eaffb692d54c32a","3032":"5b083f02361a950a6615cda6","3033":"5b083f41c712f56125315a9f","3034":"5b083f92c5750d377c11b1ed","3035":"5b084013a45f930a65d54b50","3036":"5b08404c6fcbaf377df9482c","3037":"5b084059c712f56125315d7f","3038":"5b0840f016f6496124de60d4","3039":"5b08419793dc78791c861adf","3040":"5b08424d4eaffb692d565482","3041":"5b084967160c567d16d98392","3042":"5b0bc205c712f561253a6421","3043":"5b0ca1ec4eaffb692d62678e","3044":"5b0ca205edd06f7d15ef2b2a","3045":"5b0ca22ca7abc8692ef0114c","3046":"5b0ca2a9a7abc8692ef012a6","3047":"5b0d9ecc99fa7f4c062b7384","3048":"5b0dadd393dc78791c95da00","3049":"5b0dade6edd06f7d15f2f66a","3050":"5b0db405ba1a351a68d3be52","3051":"5b0eb8af99fa7f4c062f5b30","3052":"5b0f0d94c712f561254624d6","3053":"5b103543b6eece791dcb5b86","3054":"5b10356193dc78791c9ea937","3055":"5b1035a9ba1a351a68dc89a3","3056":"5b1035ffe26c847ac8a82405","3057":"5b10363d160c567d16f20c07","3058":"5b109f924eaffb692d708c73","3059":"5b10a00193dc78791ca00e7e","3060":"5b10a009a7abc8692efe1721","3061":"5b152342b6eece791dd9cfbb","3062":"5b16fc18b6eece791de0dac8","3063":"5b170d00352b9e1a4b60740f","3064":"5b1718ce22a05f5e7103f7d4","3065":"5b221dbec277fb705dccf6cd","3066":"5b228a90cf3b245b2cfe805e","3067":"5b236861a0161836cb1d083a","3068":"5b23699532618e705ebc60e7","3069":"5b241aca37a2df7bed40494f","3070":"5b241af44fbf4449eb1a317b","3071":"5b2831d80168e70c08d0ee0e","3072":"5b283206ad21887018c5c6df","3073":"5b2847e659799e7017289b8e","3074":"5b2888f3960fcd4eb90b738a","3075":"5b2a86e6ce3b0f268d2d6915","3076":"5b2aa4617d3bca737af637b2","3077":"5b2b18435862c35f47b8caac","3078":"5b2b1caace3b0f268d338a97","3079":"5b2c0dfb7da8cd7c8c6192b8","3080":"5b2c54375862c35f47bcaac7","3081":"5b2c55f57da8cd7c8c622745","3082":"5b2c65bfd2abe466887e8f3a","3083":"5b2d4a9d7da8cd7c8c649d55","3084":"5b2fc0925862c35f47c40ccd","3085":"5b30173e479ca266897c02cf","3086":"5b302187479ca266897c13db","3087":"5b30d81659799e70173fe593","3088":"5b313ab2479ca266897eb9bf","3089":"5b319115960fcd4eb9233e64","3090":"5b31917f6ceffe4eba331291","3091":"5b31ce560168e70c08eedbd4","3092":"5b32bd22b9c2fb25570e08e9","3093":"5b333db6a288503b3de2e492","3094":"5b335a5f479ca2668983742f","3095":"5b33634d0168e70c08f2b116","3096":"5b3363d472b31d3691f7954a","3097":"5b346a53960fcd4eb929bd93","3098":"5b347ca4a288503b3de5da59","3099":"5b351e4ea288503b3de78105","3100":"5b3568c1960fcd4eb92c3b32","3101":"5b3569bf479ca26689887a71","3102":"5b356fa159799e70174aefb7","3103":"5b358a65960fcd4eb92c730d","3104":"5b35a903ce3b0f268d4cc254","3105":"5b3695e572b31d3691ff4937","3106":"5b376b20a99e1e52b70a936e","3107":"5b3a66053572e970c16fb3f2","3108":"5b3b31dd89db5e701c9d505e","3109":"5b3b92697b811a6d63cc0729","3110":"5b3bc3ecf16644066116afe7","3111":"5b461124bd92d80782a72945","3112":"5b4895c673026160f59d3568","3113":"5b4c56e81c0f906b145b04fa","3114":"5b4c572c1c0f906b145b06ba","3115":"5b4de2d3ecc1f82e2fbeab5f","3116":"5b4e0e3164990f3c000b5992","3117":"5b4e56da8578203ee73ad34e","3118":"5b4e57214b583a74a723c1b6","3119":"5b4e5744f046ba6aca5f4e74","3120":"5b508344cad358639d664ecd","3121":"5b50f7d4f10ffa0b489c2ef2","3122":"5b516903f477e4664aadbfde","3123":"5b519c899ddf5f4aadf87638","3124":"5b5228e2f9ffc4664bf02f19","3125":"5b5245bdc579673e6b8417e3","3126":"5b532d0df10ffa0b48a1b30f","3127":"5b53cb6bf10ffa0b48a3171d","3128":"5b53cc3163cf1636bde2e808","3129":"5b544b51f9ffc4664bf4699a","3130":"5b551400ee530e4aac8e9deb","3131":"5b551413f9ffc4664bf63802","3132":"5b558a0705e1cc3553046416","3133":"5b55b1a9f10ffa0b48a70dbb","3134":"5b58e0f9e5fc191d959d14d7","3135":"5b58e1c232d98c2ed2b53f7e","3136":"5b5a7737e5fc191d95a17651","3137":"5b5ac8a0bd17b961590811a4","3138":"5b5b9ba63e264c713846b7a5","3139":"5b5c514120d248394f5fc90b","3140":"5b5f483a17c942036b8385dd","3141":"5b5f496b33154658457d8dfb","3142":"5b5f58e617c942036b83b795","3143":"5b5f6a2f3cc39566073330d5","3144":"5b5f7dacd4527523f641950b","3145":"5b5f94f5bf754466067285e8","3146":"5b5f96c544812258444498e6","3147":"5b5f98d9c83d1230b1391c55","3148":"5b5f999820d248394f68c956","3149":"5b5f99fa12f1be713768f104","3150":"5b61c0b1defc9823f52ff961","3151":"5b61d3c7d4527523f649d591","3152":"5b61d4683e264c713858cbab","3153":"5b61d66b20d248394f709246","3154":"5b61e5fd966e803950378ee4","3155":"5b61ec8b44812258444cb3a4","3156":"5b61ec9aac380e3f3a14fb28","3157":"5b61ecadcb4d5b036cb22b68","3158":"5b61ed12c83d1230b1411d6e","3159":"5b61f79ccb4d5b036cb25258","3160":"5b6278675d1362758b1fb92f","3161":"5b641a8da9426c705d1eaa73","3162":"5b6898e604436a1ae624b128","3163":"5b69e1f7e9ab53770ca11b70","3164":"5b6cbf6d26e68560fdd3e2be","3165":"5b6dbcc65ec2bc174fde2f6f","3166":"5b747e8a937eee24232131d6","3167":"5b74909ce9b96f2c9812d951","3168":"5b7bf8b6f86b741b05a0d81b","3169":"5b7bf8deff445156161913c3","3170":"5b7c2544e5b40332abda7b01","3171":"5b7c27cad8d36815e56cf220","3172":"5b7c284fff445156161a1d95","3173":"5b7ed10e94f8164c178c6deb","3174":"5b7ee486c53ee54c189197b8","3175":"5b7ef2bbd8d36815e57d3b01","3176":"5b7ef39fd8d36815e57d403c","3177":"5b86fcd994f8164c17ba35bc","3178":"5b870cc24be56c5918b4023c","3179":"5b870ce894f8164c17ba8f9d","3180":"5b870f2358a3797aa3d51121","3181":"5b88405a4be56c5918bb1002","3182":"5b8ce62511227d711d0a06af","3183":"5b9180bcac25fd11b5eef38b","3184":"5b91abcccff55e5617ba3e9d","3185":"5b922ceb1d3a5711b6f8a977","3186":"5b97dbdfe6e309365e38f306","3187":"5b9aa1edb4990c30eeae4593","3188":"5b9ab16754587954f99a4d74","3189":"5b9ab170f08bc22dfb5161d6","3190":"5ba17288d655361f761c79de","3191":"5ba18235913ba7799b0e04af","3192":"5ba25426e5c2cc56adb1dc49","3193":"5ba39cdd0cfe7f30f1c13ee4","3194":"5ba3e242e6046343f38fa1f5","3195":"5ba85292b9531f2dfaafa3b3","3196":"5ba8f4aae5c2cc56add80890","3197":"5ba963d18196693171acb47e","3198":"5baa5048aedb375b9c44e9dd","3199":"5baa5080cdc50131724f7aee","3200":"5baaf3e556877c463a84e4c6","3201":"5babe9b84d320a463bfadb98","3202":"5babf89c41177e0bc7afec09","3203":"5babf8d0cdc50131725a74b5","3204":"5bac063eeba8e60bc64db451","3205":"5bb14bffc7bf7c366297933c","3206":"5bb263ff3844923661cbef3e","3207":"5bb3d68d435c2a518e40d237","3208":"5bb3d9646e5a401c2d08c5dd","3209":"5bb65525271506518db8b3b3","3210":"5bb6563f6e5a401c2d18838b","3211":"5bb6565a82893a2f3b9d1f81","3212":"5bb66a66435c2a518e50ee3a","3213":"5bb66b6a82893a2f3b9da49c","3214":"5bb674e282893a2f3b9de238","3215":"5bb6871c3844923661e5e9f6","3216":"5bb7cf3464cfc273f99fcf92","3217":"5bb7f15f1e23486b9394d65c","3218":"5bb7f18ac7bf7c3662c1367f","3219":"5bbb79281c100a4f294e12c5","3220":"5bbb8c793844923661043140","3221":"5bbc08f8c7bf7c3662da6fb1","3222":"5bbe5463c08b8b3067faaf47","3223":"5bbe6c8ac7bf7c3662ec38df","3224":"5bc75f13271506518d28e472","3225":"5bc75fc0ef4afc4f288bc0f8","3226":"5bc778e83844923661555b42","3227":"5bc855b064cfc273f9e66830","3228":"5bcee314600c5f6423f3a35b","3229":"5bcef311ae7be94016a11a96","3230":"5bcf0702435c2a518ef06a86","3231":"5bcf1aa982893a2f3b28d2fb","3232":"5bd73f96ef4afc4f28eef293","3233":"5bd866e6c7bf7c3662937907","3234":"5bda07690445e15fad022051","3235":"5bda0787076992347a960fc0","3236":"5bda078f076992347a960fc6","3237":"5bda07c3538a1c197152637c","3238":"5bda07d3b9c91919547eda5f","3239":"5bda2c380445e15fad031088","3240":"5bdaccce4775f53eb322de62","3241":"5bdaccf5cd2a6b5bdc7a229e","3242":"5bdb27656eb1e3597a943d8e","3243":"5bde0c9726be6b597963c5c9","3244":"5bde0f8725b9875faecbd100","3245":"5bded396d3442e1972890acb","3246":"5be2cccae8add80e63b51a15","3247":"5beb37e2d001b91720564b40","3248":"5beb3c713102f1452198577c","3249":"5bec656562866f74739b46bd","3250":"5bf39ca780e46b4266dc4345","3251":"5bf44faaa115c91ef7668b0a","3252":"5c05f04b8fa4333e39366843","3253":"5c092e681e86c3082336926a","3254":"5c09535e178d7860a1958675","3255":"5c097c014808192b03f69f01","3256":"5c12737f1e86c30823712265","3257":"5c12934826de6f0822cc4945","3258":"5c12936af4880a60a272ec76","3259":"5c129d30f992693c7a6bc908","3260":"5c129d681e86c30823724ee8","3261":"5c129d87f992693c7a6bcca9","3262":"5c12a710ae1ab5539edf3ccd","3263":"5c1308afae1ab5539ee1b707","3264":"5c132726039551387f950b46","3265":"5c13f990ca317a0e25c90220","3266":"5c13f99e72f31355cd566a59","3267":"5c13f9ad0a86bc6f8daa8526","3268":"5c13f9bbe806954a9a1aab7d","3269":"5c13f9d4b512ce0b9d8eefec","3270":"5c13f9f072f31355cd566c9d","3271":"5c1406b0ca317a0e25c94eef","3272":"5c1406b6392d8c6f8e6055b6","3273":"5c143925987052387ee8c705","3274":"5c1b6ba0dab2222ab3c2b922","3275":"5c1ba91141637902415c3f5a","3276":"5c1bce4341637902415d3d70","3277":"5c1beedac35a300247565542","3278":"5c1c8f1f5a0a8058beec07e9","3279":"5c1cc26392cf4d2242d15444","3280":"5c1d0525cac5bc2241c7e5a4","3281":"5c1d31c237975e7ca903e976","3282":"5c1f7d74babbc178b2c6ff6c","3283":"5c1fd6fe37975e7ca9132e2c","3284":"5c1fd7492863d8612b7b2c4d","3285":"5c23ece123323d58bd2c09aa","3286":"5c23ecfc23323d58bd2c09d4","3287":"5c2413a25064a51f837f0f8c","3288":"5c2413a85064a51f837f0f91","3289":"5c2c486dd945b968822fd4e1","3290":"5c2d0509db5b5c6883470aa9","3291":"5c2d05946649aa1f820d62fb","3292":"5c2d05a5babbc178b21911df","3293":"5c2faf168d31aa78b1493710","3294":"5c2faf25b8d2227918b24328","3295":"5c2fbfc6e6d89641ef8fd8ad","3296":"5c2fc0512863d8612bdb358f","3297":"5c40fb57f780a1521f2868ba","3298":"5c410edfc45b986d1179e303","3299":"5c48f26035350772cf7c4340","3300":"5c4902ab0721b912a5cacd1f","3301":"5c49b97df780a1521f5fc179","3302":"5c49b9840721b912a5cf4346","3303":"5c4a93821cb70a372a32f9ef","3304":"5c4a9388cb47ec30009abb43","3305":"5c4a93f9cb47ec30009abd35","3306":"5c4b6f6f78e1ed41038bd5d7","3307":"5c4b6f7441775971a082f7ef","3308":"5c4b791341775971a083410f","3309":"5c4b7b868aa5ca5abf3008cb","3310":"5c4c93eb975714406b4699d8","3311":"5c507631454aad4df7c0113b","3312":"5c5076677b68f941023a48ec","3313":"5c507d73ca428b064520078f","3314":"5c507e6c454aad4df7c04586","3315":"5c6adc81253c2b5ea332f678","3316":"5c6ae9bad1e3093ab540f56e","3317":"5c6b0336ecef85660bc91f98","3318":"5c6b035016e4682259c491bb","3319":"5c6bde9fe5eeec0d9b8f0f83","3320":"5c6c61b235c7a504227bafb2","3321":"5c6c61c09e430b308693973b","3322":"5c6c61e800aa630d9adbc43d","3323":"5c6d26d81f14630421ee6faf","3324":"5c6e489ab6c74f1e2e878b0c","3325":"5c6e48a0e5eeec0d9b9eaf20","3326":"5c6e87a21f14630421f77512","3327":"5c6eb641a7d733509da1e2b7","3328":"5c78a05035c0130753563796","3329":"5c78c22be1446a6ebe62c636","3330":"5c8412b51c597e5db6ae5bdf","3331":"5c841ce0ac408e119231ec81","3332":"5c911f74f3dbbd230c81b269","3333":"5c911fbb9d9cc8114ae8d1ce","3334":"5c914215fcaf7b5f73df6e1c","3335":"5c91426f8126720abc0d19d7","3336":"5c91466649fdaa0d81e07bba","3337":"5c9159b56a3d2e230df05c6d","3338":"5c916a7c9d9cc8114aeaedd6","3339":"5c92411a3dd817114920b4e1","3340":"5c926d702fb6800d805095f2","3341":"5c926dafa21ce51a20917382","3342":"5c93d83e49fdaa0d81f225c1","3343":"5c944d94dfc69a1454d42cac","3344":"5c9520bc2fb6800d8063702c","3345":"5c9520c20d719050574a86ff","3346":"5c95226ff3dbbd230c9d0d6a","3347":"5c990e238aa66959b66cfc26","3348":"5c990e50dfc69a1454f38d56","3349":"5c9943b95547f7744865628e","3350":"5c9943df0d71905057654042","3351":"5c9944399d9cc8114a1ed664","3352":"5c9a31ef81b15c5e4b8c9387","3353":"5c9a32078aa66959b6740a1f","3354":"5c9a32528126720abc47dae0","3355":"5c9a382ad0133e21e51a6fe6","3356":"5c9a4c305636de703de54dbb","3357":"5c9a4f010d719050576bba21","3358":"5c9a4f2436704f6eddd7ef58","3359":"5c9a4fd05c7a815f27d0a1a9","3360":"5c9a646281b15c5e4b8e05f0","3361":"5c9a64aee7341060cae76ced","3362":"5c9a64d38aa66959b6757e1e","3363":"5c9a64dee7341060cae76dd9","3364":"5c9a64ff81b15c5e4b8e09be","3365":"5c9a652981b15c5e4b8e0bd2","3366":"5c9a654f0d719050576c6902","3367":"5c9a657952c7a91455fcf944","3368":"5c9a69452fb6800d808593aa","3369":"5c9a695a40b32b4c4f9d0976","3370":"5c9a69621f74fc4d4ca05ac5","3371":"5c9a69690d719050576c8a9c","3372":"5c9a69712fb6800d80859442","3373":"5c9a69740d719050576c8bcf","3374":"5c9a697e0d719050576c8bef","3375":"5c9a699f8126720abc496f4a","3376":"5c9a69ba36704f6eddd8b3a1","3377":"5c9a69c2cf786a56c780f923","3378":"5c9a69ce81b15c5e4b8e3012","3379":"5c9a69f25636de703de6363c","3380":"5c9a69f440b32b4c4f9d0dd1","3381":"5c9a69fae820b6470b69ba2e","3382":"5c9a6a072fb6800d808597e2","3383":"5c9a6a2381b15c5e4b8e31c3","3384":"5c9a6a60e7341060cae79533","3385":"5c9a6a671f74fc4d4ca061f1","3386":"5c9a6a6e6a3d2e230d2bd818","3387":"5c9a6a978aa66959b675aa80","3388":"5c9a6aab82e11735c67c0550","3389":"5c9a6ab30d719050576c95c2","3390":"5c9a6ac68126720abc4977bd","3391":"5c9a6adb36704f6eddd8ba5d","3392":"5c9a6b135c7a815f27d16263","3393":"5c9a6b6a52c7a91455fd279a","3394":"5c9a6bd882e11735c67c101c","3395":"5c9a6be336704f6eddd8c410","3396":"5c9a6be552c7a91455fd2c64","3397":"5c9a6bed5c7a815f27d1672c","3398":"5c9a6bef5c7a815f27d16736","3399":"5c9ac5f5cf786a56c7837f51","3400":"5c9be9d81f98a87112aeddbb","3401":"5c9e57110b3b8749f4e37c9e","3402":"5c9e572db6711251984bd7df","3403":"5c9e57331f98a87112bfd6fe","3404":"5c9e57630b3b8749f4e37e8f","3405":"5ca4d25c0aad63501920cb5f","3406":"5ca4fd163ebbdc55b3571d69","3407":"5ca508c8f851ee043d57cb6e","3408":"5ca508e225686a7dc3cdeb23","3409":"5ca508ff0aad635019225101","3410":"5ca50913f851ee043d57cd2d","3411":"5ca5092431aec969e8495a72","3412":"5ca5092aa0790b29c9578e03","3413":"5ca5094631aec969e8495af2","3414":"5ca50999bd70a40d5fee6720","3415":"5ca509ac7ecbdc29caf4c654","3416":"5ca50b31b34ccd69e75d47e9","3417":"5ca50b4e5a83c30a46060cc2","3418":"5ca50b50016a930a455a064c","3419":"5ca50e81a84e0c501acf17d6","3420":"5ca6096d0aad63501928fce9","3421":"5ca6096e7ecbdc29cafb6b7c","3422":"5ca609a93ebbdc55b35e4b76","3423":"5ca60c2bc55bd14d3589f553","3424":"5ca628a431aec969e8501c3b","3425":"5ca628c731aec969e8501d52","3426":"5ca6290aa0790b29c95f1f0f","3427":"5ca6293e759abc043c66ca80","3428":"5ca62a2125686a7dc3d57638"},"time":{"0":"2015-05-23T00:37:03.643Z","1":"2015-05-23T01:35:35.876Z","2":"2015-05-23T03:04:58.626Z","3":"2015-05-23T03:05:59.997Z","4":"2015-05-23T03:07:02.755Z","5":"2015-05-23T03:13:47.338Z","6":"2015-05-23T03:20:37.819Z","7":"2015-05-23T03:20:54.616Z","8":"2015-05-23T03:21:30.852Z","9":"2015-05-23T03:23:21.237Z","10":"2015-05-23T03:23:47.904Z","11":"2015-05-23T03:57:53.884Z","12":"2015-05-23T03:58:12.860Z","13":"2015-05-23T03:58:16.571Z","14":"2015-05-23T04:52:02.669Z","15":"2015-05-24T01:09:01.436Z","16":"2015-05-24T02:13:33.164Z","17":"2015-05-27T16:57:07.901Z","18":"2015-05-27T16:57:31.353Z","19":"2015-05-27T16:57:55.814Z","20":"2015-05-27T16:58:21.674Z","21":"2015-05-27T18:34:32.375Z","22":"2015-05-27T18:34:36.947Z","23":"2015-05-27T18:34:51.573Z","24":"2015-05-27T18:50:24.017Z","25":"2015-05-27T18:50:38.923Z","26":"2015-05-27T18:50:48.298Z","27":"2015-05-27T19:04:17.674Z","28":"2015-05-27T19:20:24.453Z","29":"2015-05-27T19:27:00.572Z","30":"2015-05-27T19:27:12.216Z","31":"2015-05-27T19:36:21.759Z","32":"2015-05-27T19:43:00.171Z","33":"2015-05-27T19:44:42.897Z","34":"2015-05-27T19:46:27.639Z","35":"2015-05-27T19:48:07.538Z","36":"2015-05-27T19:48:48.828Z","37":"2015-05-27T19:49:21.280Z","38":"2015-05-27T19:49:33.240Z","39":"2015-05-27T19:51:24.550Z","40":"2015-05-27T19:52:15.708Z","41":"2015-05-27T19:52:56.170Z","42":"2015-05-27T19:57:40.587Z","43":"2015-05-27T19:58:28.653Z","44":"2015-05-27T19:59:23.492Z","45":"2015-05-27T19:59:54.845Z","46":"2015-05-27T20:04:48.722Z","47":"2015-05-27T20:05:12.415Z","48":"2015-05-27T20:08:19.873Z","49":"2015-05-27T20:08:31.505Z","50":"2015-05-27T20:08:38.688Z","51":"2015-05-27T20:08:45.809Z","52":"2015-05-27T20:08:51.683Z","53":"2015-05-27T20:09:32.378Z","54":"2015-05-27T20:11:09.677Z","55":"2015-05-27T20:11:25.956Z","56":"2015-05-28T06:26:33.528Z","57":"2015-05-28T17:06:15.828Z","58":"2015-05-28T17:07:50.635Z","59":"2015-05-28T17:46:15.029Z","60":"2015-05-28T18:25:16.063Z","61":"2015-06-03T11:22:32.523Z","62":"2015-06-03T11:26:07.433Z","63":"2015-06-03T11:29:55.680Z","64":"2015-06-03T13:57:25.742Z","65":"2015-06-03T18:56:58.294Z","66":"2015-06-03T18:57:23.996Z","67":"2015-06-03T19:10:10.204Z","68":"2015-06-03T21:12:56.374Z","69":"2015-06-06T11:22:56.257Z","70":"2015-06-06T11:23:03.720Z","71":"2015-06-06T11:23:18.778Z","72":"2015-06-06T16:48:26.512Z","73":"2015-06-08T07:56:43.536Z","74":"2015-06-08T21:11:38.595Z","75":"2015-06-09T02:28:57.765Z","76":"2015-06-09T05:17:35.623Z","77":"2015-06-11T18:30:51.946Z","78":"2015-06-12T15:26:17.849Z","79":"2015-06-12T16:26:32.912Z","80":"2015-06-12T16:43:42.398Z","81":"2015-06-12T17:49:54.161Z","82":"2015-06-12T20:26:41.856Z","83":"2015-06-15T18:00:18.316Z","84":"2015-06-15T18:01:06.439Z","85":"2015-06-15T18:07:56.070Z","86":"2015-06-15T18:07:58.099Z","87":"2015-06-15T19:05:43.853Z","88":"2015-06-16T07:29:57.790Z","89":"2015-06-16T18:16:17.595Z","90":"2015-06-16T18:20:41.496Z","91":"2015-06-16T20:00:23.695Z","92":"2015-06-16T20:33:24.903Z","93":"2015-06-16T20:48:19.721Z","94":"2015-06-17T16:21:42.451Z","95":"2015-06-17T16:22:11.935Z","96":"2015-06-17T16:25:30.907Z","97":"2015-06-17T16:26:31.987Z","98":"2015-06-17T17:02:15.488Z","99":"2015-06-17T18:57:41.746Z","100":"2015-06-17T19:36:38.616Z","101":"2015-06-17T21:13:44.592Z","102":"2015-06-17T21:14:29.716Z","103":"2015-06-17T21:16:48.467Z","104":"2015-06-17T21:18:47.619Z","105":"2015-06-17T21:18:50.128Z","106":"2015-06-17T21:18:53.366Z","107":"2015-06-17T21:38:01.492Z","108":"2015-06-17T21:38:24.749Z","109":"2015-06-17T21:49:43.177Z","110":"2015-06-18T12:47:31.839Z","111":"2015-06-18T14:01:48.644Z","112":"2015-06-18T14:02:37.952Z","113":"2015-06-18T14:05:24.136Z","114":"2015-06-18T15:45:33.114Z","115":"2015-06-18T15:45:50.472Z","116":"2015-06-18T15:47:12.426Z","117":"2015-06-18T15:47:22.307Z","118":"2015-06-18T16:01:47.811Z","119":"2015-06-18T16:01:58.527Z","120":"2015-06-18T16:47:14.306Z","121":"2015-06-18T16:49:34.991Z","122":"2015-06-18T17:04:09.690Z","123":"2015-06-18T22:58:55.578Z","124":"2015-06-18T23:00:12.120Z","125":"2015-06-18T23:04:21.360Z","126":"2015-06-18T23:05:04.814Z","127":"2015-06-20T19:12:47.771Z","128":"2015-06-22T17:34:56.060Z","129":"2015-06-22T18:05:59.413Z","130":"2015-06-22T18:26:29.825Z","131":"2015-06-22T18:47:27.011Z","132":"2015-06-22T21:36:44.827Z","133":"2015-06-23T00:10:48.348Z","134":"2015-06-23T00:32:10.706Z","135":"2015-06-24T22:32:56.310Z","136":"2015-06-25T00:09:03.880Z","137":"2015-06-25T18:59:01.635Z","138":"2015-06-25T21:28:02.142Z","139":"2015-06-25T21:36:01.974Z","140":"2015-06-25T22:47:15.701Z","141":"2015-06-29T22:18:02.976Z","142":"2015-07-02T21:30:09.092Z","143":"2015-07-06T18:41:20.078Z","144":"2015-07-06T18:52:20.288Z","145":"2015-07-06T19:47:21.348Z","146":"2015-07-06T19:51:12.996Z","147":"2015-07-07T01:15:30.237Z","148":"2015-07-07T04:12:53.159Z","149":"2015-07-09T11:03:08.735Z","150":"2015-07-09T16:57:58.254Z","151":"2015-07-09T17:06:18.567Z","152":"2015-07-09T17:14:18.941Z","153":"2015-07-09T17:18:34.240Z","154":"2015-07-09T17:33:01.641Z","155":"2015-07-10T01:20:10.572Z","156":"2015-07-10T01:20:11.966Z","157":"2015-07-10T07:33:59.085Z","158":"2015-07-10T08:25:18.588Z","159":"2015-07-10T11:38:36.351Z","160":"2015-07-11T23:10:26.710Z","161":"2015-07-12T08:13:27.727Z","162":"2015-07-13T15:55:51.201Z","163":"2015-07-15T16:02:29.774Z","164":"2015-07-16T02:21:19.241Z","165":"2015-07-16T02:37:47.132Z","166":"2015-07-16T02:40:06.152Z","167":"2015-07-16T02:46:04.679Z","168":"2015-07-16T10:25:56.720Z","169":"2015-07-16T16:08:39.711Z","170":"2015-07-16T18:27:44.058Z","171":"2015-07-16T18:30:11.300Z","172":"2015-07-16T21:59:42.639Z","173":"2015-07-17T03:20:00.984Z","174":"2015-07-17T04:01:05.543Z","175":"2015-07-17T04:53:14.350Z","176":"2015-07-17T11:21:46.378Z","177":"2015-07-17T11:37:20.302Z","178":"2015-07-17T19:36:39.468Z","179":"2015-07-17T19:38:30.131Z","180":"2015-07-20T20:05:25.361Z","181":"2015-07-21T22:11:23.265Z","182":"2015-07-22T00:30:50.737Z","183":"2015-07-23T15:06:12.388Z","184":"2015-07-23T16:46:33.484Z","185":"2015-07-23T17:10:15.933Z","186":"2015-07-23T18:46:50.697Z","187":"2015-07-23T18:53:58.092Z","188":"2015-07-23T19:01:35.201Z","189":"2015-07-23T19:04:37.113Z","190":"2015-07-23T22:27:19.839Z","191":"2015-07-27T18:23:42.087Z","192":"2015-07-28T16:40:15.642Z","193":"2015-07-29T14:16:15.554Z","194":"2015-07-29T21:44:01.383Z","195":"2015-07-29T22:52:14.834Z","196":"2015-07-30T19:53:21.875Z","197":"2015-07-30T20:28:38.710Z","198":"2015-07-30T21:30:41.387Z","199":"2015-07-30T21:36:02.952Z","200":"2015-07-30T21:37:57.002Z","201":"2015-07-30T21:38:10.081Z","202":"2015-07-30T21:49:17.525Z","203":"2015-07-31T00:17:27.306Z","204":"2015-08-01T06:23:46.159Z","205":"2015-08-02T19:22:18.405Z","206":"2015-08-02T21:06:34.281Z","207":"2015-08-03T23:56:26.832Z","208":"2015-08-04T03:31:36.033Z","209":"2015-08-04T09:23:58.052Z","210":"2015-08-04T09:25:22.125Z","211":"2015-08-06T18:45:16.371Z","212":"2015-08-06T18:45:50.359Z","213":"2015-08-06T20:45:01.490Z","214":"2015-08-07T00:23:40.356Z","215":"2015-08-07T01:53:27.172Z","216":"2015-08-07T18:19:36.627Z","217":"2015-08-18T01:08:12.918Z","218":"2015-08-18T01:08:45.347Z","219":"2015-08-19T17:56:33.203Z","220":"2015-08-19T21:07:17.809Z","221":"2015-08-19T21:07:39.495Z","222":"2015-08-27T16:20:32.873Z","223":"2015-08-27T16:39:46.179Z","224":"2015-08-27T16:39:56.856Z","225":"2015-08-27T16:40:31.482Z","226":"2015-08-27T17:45:49.010Z","227":"2015-08-27T17:48:03.928Z","228":"2015-08-27T17:49:38.014Z","229":"2015-08-27T18:05:19.161Z","230":"2015-08-27T18:45:34.925Z","231":"2015-08-27T19:02:48.392Z","232":"2015-08-27T19:24:23.813Z","233":"2015-08-27T19:25:39.964Z","234":"2015-08-27T19:27:08.009Z","235":"2015-08-27T19:27:59.695Z","236":"2015-08-27T19:28:07.069Z","237":"2015-08-27T19:28:27.066Z","238":"2015-08-27T19:29:31.831Z","239":"2015-08-27T19:30:14.450Z","240":"2015-08-27T19:31:31.953Z","241":"2015-08-27T19:33:43.343Z","242":"2015-08-27T19:34:37.990Z","243":"2015-08-27T19:34:50.677Z","244":"2015-08-27T19:35:33.122Z","245":"2015-08-27T19:36:21.853Z","246":"2015-08-27T19:37:05.187Z","247":"2015-08-27T19:37:40.590Z","248":"2015-08-27T19:38:12.033Z","249":"2015-08-27T19:38:33.049Z","250":"2015-08-27T19:38:51.903Z","251":"2015-08-27T19:39:21.484Z","252":"2015-08-27T19:39:49.343Z","253":"2015-08-27T19:40:09.261Z","254":"2015-08-27T19:40:53.830Z","255":"2015-08-27T20:53:19.035Z","256":"2015-08-27T20:57:50.943Z","257":"2015-08-27T22:42:52.946Z","258":"2015-08-27T22:51:27.323Z","259":"2015-08-27T23:33:19.122Z","260":"2015-08-27T23:33:20.079Z","261":"2015-08-27T23:34:03.729Z","262":"2015-08-27T23:34:42.007Z","263":"2015-08-27T23:34:44.052Z","264":"2015-08-27T23:35:51.806Z","265":"2015-08-27T23:38:45.274Z","266":"2015-08-27T23:40:27.048Z","267":"2015-08-28T19:25:33.782Z","268":"2015-08-28T19:28:28.217Z","269":"2015-08-28T19:58:30.299Z","270":"2015-08-28T20:18:05.994Z","271":"2015-09-02T16:13:53.817Z","272":"2015-09-02T18:18:08.862Z","273":"2015-09-02T18:46:07.686Z","274":"2015-09-02T19:25:52.729Z","275":"2015-09-02T19:26:01.467Z","276":"2015-09-02T19:26:07.165Z","277":"2015-09-02T19:27:15.805Z","278":"2015-09-02T22:06:43.975Z","279":"2015-09-02T22:07:35.601Z","280":"2015-09-02T22:08:40.384Z","281":"2015-09-02T22:15:29.029Z","282":"2015-09-02T22:18:49.204Z","283":"2015-09-02T22:25:38.554Z","284":"2015-09-02T22:34:29.925Z","285":"2015-09-02T22:35:17.849Z","286":"2015-09-02T22:45:16.069Z","287":"2015-09-02T22:45:22.048Z","288":"2015-09-02T22:46:50.403Z","289":"2015-09-02T22:48:42.715Z","290":"2015-09-02T22:55:00.850Z","291":"2015-09-02T22:56:05.182Z","292":"2015-09-02T22:57:58.224Z","293":"2015-09-02T22:58:09.870Z","294":"2015-09-02T22:59:26.292Z","295":"2015-09-02T23:00:54.736Z","296":"2015-09-02T23:04:23.392Z","297":"2015-09-02T23:04:48.160Z","298":"2015-09-02T23:05:47.021Z","299":"2015-09-02T23:07:07.691Z","300":"2015-09-02T23:09:20.855Z","301":"2015-09-02T23:17:08.699Z","302":"2015-09-02T23:18:49.001Z","303":"2015-09-02T23:22:26.152Z","304":"2015-09-02T23:22:52.086Z","305":"2015-09-02T23:24:16.126Z","306":"2015-09-02T23:27:06.435Z","307":"2015-09-02T23:34:47.219Z","308":"2015-09-02T23:35:34.472Z","309":"2015-09-02T23:36:53.241Z","310":"2015-09-03T00:44:22.628Z","311":"2015-09-03T16:00:51.201Z","312":"2015-09-03T19:13:54.290Z","313":"2015-09-03T19:14:06.453Z","314":"2015-09-04T00:00:12.643Z","315":"2015-09-04T19:27:14.769Z","316":"2015-09-04T23:37:33.365Z","317":"2015-09-08T19:20:42.314Z","318":"2015-09-08T20:09:58.089Z","319":"2015-09-08T20:17:23.474Z","320":"2015-09-10T17:21:36.830Z","321":"2015-09-24T21:32:34.098Z","322":"2015-09-24T21:32:53.831Z","323":"2015-09-24T21:43:59.214Z","324":"2015-09-24T21:44:40.192Z","325":"2015-09-24T21:57:23.705Z","326":"2015-09-24T22:30:00.895Z","327":"2015-09-28T19:01:00.953Z","328":"2015-09-28T19:02:32.136Z","329":"2015-09-28T22:24:10.843Z","330":"2015-09-28T22:40:31.363Z","331":"2015-09-28T22:42:14.215Z","332":"2015-09-28T22:42:27.965Z","333":"2015-09-28T22:47:17.067Z","334":"2015-09-28T22:47:47.401Z","335":"2015-09-28T22:49:06.647Z","336":"2015-09-28T22:49:16.514Z","337":"2015-09-28T22:50:37.472Z","338":"2015-09-28T22:50:48.615Z","339":"2015-09-28T22:50:56.022Z","340":"2015-09-28T22:51:33.153Z","341":"2015-09-28T23:08:52.173Z","342":"2015-09-29T00:46:11.469Z","343":"2015-09-29T01:09:38.194Z","344":"2015-09-29T04:49:55.988Z","345":"2015-09-29T07:22:29.091Z","346":"2015-09-29T17:38:30.627Z","347":"2015-09-29T17:48:29.603Z","348":"2015-09-29T17:55:55.062Z","349":"2015-09-29T19:57:40.084Z","350":"2015-09-29T19:58:32.359Z","351":"2015-09-29T20:24:27.770Z","352":"2015-09-29T20:25:48.851Z","353":"2015-09-29T22:14:54.702Z","354":"2015-09-30T01:20:39.899Z","355":"2015-09-30T16:46:43.643Z","356":"2015-09-30T18:07:26.306Z","357":"2015-09-30T19:02:29.534Z","358":"2015-09-30T19:10:47.476Z","359":"2015-09-30T19:14:47.357Z","360":"2015-10-01T23:52:04.688Z","361":"2015-10-02T01:06:12.737Z","362":"2015-10-02T01:33:38.122Z","363":"2015-10-02T01:40:06.185Z","364":"2015-10-02T01:45:11.048Z","365":"2015-10-02T17:20:53.898Z","366":"2015-10-05T05:31:51.853Z","367":"2015-10-05T10:48:02.325Z","368":"2015-10-05T16:57:00.173Z","369":"2015-10-05T17:29:14.016Z","370":"2015-10-05T18:57:52.463Z","371":"2015-10-05T21:54:41.339Z","372":"2015-10-05T22:05:33.427Z","373":"2015-10-05T22:45:18.793Z","374":"2015-10-08T22:43:37.658Z","375":"2015-10-08T22:44:05.508Z","376":"2015-10-08T22:57:09.701Z","377":"2015-10-08T23:56:14.280Z","378":"2015-10-09T10:36:02.494Z","379":"2015-10-09T10:37:01.696Z","380":"2015-10-09T23:59:53.143Z","381":"2015-10-10T00:22:04.323Z","382":"2015-10-10T00:22:16.948Z","383":"2015-10-10T00:31:28.497Z","384":"2015-10-10T00:38:31.364Z","385":"2015-10-10T01:26:12.478Z","386":"2015-10-10T01:26:19.102Z","387":"2015-10-10T06:31:14.518Z","388":"2015-10-10T11:44:49.663Z","389":"2015-10-10T11:45:45.829Z","390":"2015-10-10T13:54:26.658Z","391":"2015-10-10T13:57:57.830Z","392":"2015-10-10T18:02:58.246Z","393":"2015-10-10T18:03:06.007Z","394":"2015-10-11T05:58:55.575Z","395":"2015-10-11T05:59:07.884Z","396":"2015-10-11T06:00:05.878Z","397":"2015-10-11T06:09:02.353Z","398":"2015-10-11T06:31:43.918Z","399":"2015-10-11T07:13:35.766Z","400":"2015-10-11T07:13:48.305Z","401":"2015-10-11T07:14:06.700Z","402":"2015-10-11T07:14:34.062Z","403":"2015-10-11T07:15:05.137Z","404":"2015-10-11T07:15:10.483Z","405":"2015-10-11T08:03:52.270Z","406":"2015-10-11T08:04:05.379Z","407":"2015-10-11T09:22:15.113Z","408":"2015-10-11T15:51:49.766Z","409":"2015-10-12T11:47:55.914Z","410":"2015-10-12T11:49:00.818Z","411":"2015-10-12T17:22:52.814Z","412":"2015-10-12T17:41:57.333Z","413":"2015-10-13T00:14:30.354Z","414":"2015-10-13T00:14:50.867Z","415":"2015-10-13T03:38:31.500Z","416":"2015-10-13T04:17:31.644Z","417":"2015-10-13T17:18:45.939Z","418":"2015-10-13T18:24:54.561Z","419":"2015-10-14T05:13:16.603Z","420":"2015-10-14T17:09:36.463Z","421":"2015-10-14T21:02:30.339Z","422":"2015-10-14T21:02:37.185Z","423":"2015-10-14T21:02:46.707Z","424":"2015-10-14T21:03:49.757Z","425":"2015-10-14T21:27:41.942Z","426":"2015-10-14T23:08:34.400Z","427":"2015-10-14T23:16:03.488Z","428":"2015-10-14T23:19:40.642Z","429":"2015-10-14T23:22:24.142Z","430":"2015-10-14T23:59:13.685Z","431":"2015-10-15T00:28:32.882Z","432":"2015-10-15T00:31:21.228Z","433":"2015-10-15T00:31:51.970Z","434":"2015-10-15T17:40:40.508Z","435":"2015-10-17T19:27:45.136Z","436":"2015-10-17T19:28:18.973Z","437":"2015-10-17T19:30:20.514Z","438":"2015-10-20T04:30:08.756Z","439":"2015-10-20T14:01:26.904Z","440":"2015-10-20T14:17:04.770Z","441":"2015-10-20T18:01:58.876Z","442":"2015-10-26T19:00:41.179Z","443":"2015-10-26T19:16:59.230Z","444":"2015-10-26T19:21:51.657Z","445":"2015-10-26T19:22:28.175Z","446":"2015-10-26T19:23:33.624Z","447":"2015-10-26T19:24:29.286Z","448":"2015-10-26T19:28:10.824Z","449":"2015-10-26T19:37:12.842Z","450":"2015-10-26T20:56:46.900Z","451":"2015-10-26T20:57:02.799Z","452":"2015-10-26T20:57:50.206Z","453":"2015-10-26T21:22:06.790Z","454":"2015-10-26T21:22:32.396Z","455":"2015-10-26T22:03:30.825Z","456":"2015-10-26T22:12:24.731Z","457":"2015-10-27T21:20:30.641Z","458":"2015-10-27T21:39:27.005Z","459":"2015-10-27T22:11:24.199Z","460":"2015-10-27T23:00:00.561Z","461":"2015-10-27T23:00:34.910Z","462":"2015-10-27T23:01:36.221Z","463":"2015-10-27T23:01:57.171Z","464":"2015-10-27T23:19:44.250Z","465":"2015-10-27T23:21:37.937Z","466":"2015-10-27T23:28:37.259Z","467":"2015-10-27T23:29:01.082Z","468":"2015-10-27T23:30:37.800Z","469":"2015-10-27T23:31:33.137Z","470":"2015-10-27T23:32:15.244Z","471":"2015-10-27T23:32:57.822Z","472":"2015-10-27T23:33:22.360Z","473":"2015-10-27T23:34:44.783Z","474":"2015-10-27T23:35:14.925Z","475":"2015-10-27T23:35:20.187Z","476":"2015-10-27T23:36:01.388Z","477":"2015-10-27T23:36:02.915Z","478":"2015-10-27T23:36:39.854Z","479":"2015-10-27T23:37:36.291Z","480":"2015-10-27T23:38:13.422Z","481":"2015-10-27T23:38:51.191Z","482":"2015-10-27T23:39:31.410Z","483":"2015-10-27T23:39:33.678Z","484":"2015-10-27T23:39:40.834Z","485":"2015-10-27T23:39:51.005Z","486":"2015-10-27T23:40:09.800Z","487":"2015-10-27T23:40:13.122Z","488":"2015-10-27T23:41:40.012Z","489":"2015-10-27T23:41:55.646Z","490":"2015-10-27T23:42:18.405Z","491":"2015-10-27T23:43:33.854Z","492":"2015-10-27T23:44:12.999Z","493":"2015-10-27T23:47:03.005Z","494":"2015-10-27T23:48:49.852Z","495":"2015-10-27T23:50:30.457Z","496":"2015-10-27T23:51:25.907Z","497":"2015-10-27T23:51:37.458Z","498":"2015-10-27T23:52:16.687Z","499":"2015-10-27T23:54:45.780Z","500":"2015-10-27T23:55:41.768Z","501":"2015-10-27T23:56:10.597Z","502":"2015-10-27T23:57:27.401Z","503":"2015-10-28T00:00:01.210Z","504":"2015-10-28T00:00:23.895Z","505":"2015-10-28T00:00:32.532Z","506":"2015-10-28T00:01:18.957Z","507":"2015-10-28T00:01:52.923Z","508":"2015-10-28T00:05:13.898Z","509":"2015-10-28T00:07:47.156Z","510":"2015-10-28T00:08:00.657Z","511":"2015-10-28T00:08:18.570Z","512":"2015-10-28T00:09:40.625Z","513":"2015-10-28T00:44:04.144Z","514":"2015-10-28T00:44:05.636Z","515":"2015-10-28T00:44:28.190Z","516":"2015-10-28T00:58:19.800Z","517":"2015-10-28T21:46:40.915Z","518":"2015-10-28T21:54:15.614Z","519":"2015-10-28T21:58:06.122Z","520":"2015-10-28T22:24:39.774Z","521":"2015-10-28T22:25:14.064Z","522":"2015-10-28T22:27:26.612Z","523":"2015-10-28T22:27:54.484Z","524":"2015-10-28T22:28:33.957Z","525":"2015-10-28T22:28:49.610Z","526":"2015-10-28T22:29:52.085Z","527":"2015-10-28T22:30:16.576Z","528":"2015-10-28T22:30:40.042Z","529":"2015-10-28T22:31:13.654Z","530":"2015-10-28T22:32:00.271Z","531":"2015-10-28T22:32:12.437Z","532":"2015-10-28T22:33:07.188Z","533":"2015-10-28T22:33:14.937Z","534":"2015-10-28T22:33:35.436Z","535":"2015-10-28T22:34:25.730Z","536":"2015-10-28T22:34:32.351Z","537":"2015-10-28T22:34:47.465Z","538":"2015-10-28T22:34:52.994Z","539":"2015-10-28T22:35:05.914Z","540":"2015-10-28T22:35:22.828Z","541":"2015-10-28T22:35:42.975Z","542":"2015-10-28T22:37:39.547Z","543":"2015-10-28T22:38:11.056Z","544":"2015-10-28T22:38:48.820Z","545":"2015-10-28T22:46:18.297Z","546":"2015-10-28T22:46:40.859Z","547":"2015-10-28T22:46:52.022Z","548":"2015-10-28T22:47:40.926Z","549":"2015-10-28T22:47:53.213Z","550":"2015-10-28T22:48:10.087Z","551":"2015-10-28T22:48:57.915Z","552":"2015-10-28T22:49:58.876Z","553":"2015-10-28T23:00:17.812Z","554":"2015-10-28T23:52:38.203Z","555":"2015-10-29T02:15:50.100Z","556":"2015-10-29T02:16:46.196Z","557":"2015-10-29T02:20:00.406Z","558":"2015-10-29T02:30:13.072Z","559":"2015-10-29T02:38:35.247Z","560":"2015-10-29T02:39:36.641Z","561":"2015-10-29T06:20:20.658Z","562":"2015-10-29T17:07:41.299Z","563":"2015-10-29T18:03:47.640Z","564":"2015-10-29T18:25:43.700Z","565":"2015-10-29T18:49:55.759Z","566":"2015-10-29T18:50:05.869Z","567":"2015-10-29T18:52:07.678Z","568":"2015-10-29T23:01:35.071Z","569":"2015-10-29T23:02:24.044Z","570":"2015-10-29T23:02:34.632Z","571":"2015-10-29T23:02:57.531Z","572":"2015-10-29T23:04:19.280Z","573":"2015-10-29T23:09:12.411Z","574":"2015-10-29T23:09:31.043Z","575":"2015-10-29T23:09:43.867Z","576":"2015-10-29T23:09:45.191Z","577":"2015-10-29T23:10:51.724Z","578":"2015-10-29T23:12:01.564Z","579":"2015-10-29T23:12:06.269Z","580":"2015-10-29T23:12:33.948Z","581":"2015-10-29T23:12:38.406Z","582":"2015-10-29T23:13:13.570Z","583":"2015-10-29T23:14:20.625Z","584":"2015-10-29T23:14:36.884Z","585":"2015-10-29T23:18:46.874Z","586":"2015-10-29T23:20:10.099Z","587":"2015-10-29T23:20:46.270Z","588":"2015-10-29T23:21:26.787Z","589":"2015-10-29T23:23:54.200Z","590":"2015-10-29T23:24:44.805Z","591":"2015-10-29T23:24:46.552Z","592":"2015-10-29T23:35:44.037Z","593":"2015-10-29T23:41:43.646Z","594":"2015-10-29T23:42:26.080Z","595":"2015-10-30T00:05:52.518Z","596":"2015-10-30T00:05:54.777Z","597":"2015-10-30T01:16:32.067Z","598":"2015-10-30T01:45:49.817Z","599":"2015-10-30T02:05:12.443Z","600":"2015-10-30T02:06:33.537Z","601":"2015-10-30T02:07:05.785Z","602":"2015-10-30T02:07:23.905Z","603":"2015-10-30T02:09:07.888Z","604":"2015-10-30T02:09:46.881Z","605":"2015-10-30T02:10:58.805Z","606":"2015-10-30T02:19:27.394Z","607":"2015-10-30T02:20:44.676Z","608":"2015-10-30T02:21:12.164Z","609":"2015-10-30T02:21:48.282Z","610":"2015-10-30T16:06:31.617Z","611":"2015-10-30T17:55:21.414Z","612":"2015-10-30T20:54:02.616Z","613":"2015-10-30T20:55:14.679Z","614":"2015-10-30T21:20:51.423Z","615":"2015-10-30T21:34:35.609Z","616":"2015-10-30T21:49:34.278Z","617":"2015-10-30T21:52:08.899Z","618":"2015-10-30T23:00:33.726Z","619":"2015-10-30T23:31:22.399Z","620":"2015-10-31T11:23:24.205Z","621":"2015-10-31T11:24:13.773Z","622":"2015-10-31T11:24:42.635Z","623":"2015-10-31T11:24:52.509Z","624":"2015-10-31T16:28:07.626Z","625":"2015-11-02T11:44:44.361Z","626":"2015-11-02T16:01:58.669Z","627":"2015-11-02T21:45:35.138Z","628":"2015-11-02T21:46:18.309Z","629":"2015-11-02T21:47:31.289Z","630":"2015-11-02T21:49:16.144Z","631":"2015-11-02T21:49:42.370Z","632":"2015-11-02T21:50:03.158Z","633":"2015-11-02T21:50:18.702Z","634":"2015-11-02T21:50:24.687Z","635":"2015-11-02T21:50:50.853Z","636":"2015-11-02T21:51:04.514Z","637":"2015-11-02T21:51:45.069Z","638":"2015-11-02T21:52:15.655Z","639":"2015-11-02T21:52:50.240Z","640":"2015-11-02T21:53:30.486Z","641":"2015-11-02T21:54:55.243Z","642":"2015-11-02T21:55:19.379Z","643":"2015-11-02T21:55:47.762Z","644":"2015-11-02T21:56:25.034Z","645":"2015-11-02T21:56:32.486Z","646":"2015-11-02T21:56:40.568Z","647":"2015-11-02T21:57:06.549Z","648":"2015-11-02T21:58:15.128Z","649":"2015-11-02T21:58:29.631Z","650":"2015-11-02T21:59:25.657Z","651":"2015-11-02T22:11:00.744Z","652":"2015-11-02T23:29:23.175Z","653":"2015-11-02T23:29:24.002Z","654":"2015-11-03T18:35:52.652Z","655":"2015-11-03T18:36:30.451Z","656":"2015-11-03T19:08:56.634Z","657":"2015-11-03T19:09:03.049Z","658":"2015-11-03T19:16:04.114Z","659":"2015-11-03T19:17:53.971Z","660":"2015-11-03T19:32:32.150Z","661":"2015-11-03T23:18:29.029Z","662":"2015-11-05T12:47:58.065Z","663":"2015-11-05T12:48:17.597Z","664":"2015-11-05T12:48:46.072Z","665":"2015-11-05T18:57:23.467Z","666":"2015-11-05T19:02:17.127Z","667":"2015-11-06T04:47:25.339Z","668":"2015-11-06T04:47:29.848Z","669":"2015-11-06T04:48:50.267Z","670":"2015-11-06T04:56:31.633Z","671":"2015-11-06T05:05:05.182Z","672":"2015-11-06T07:26:52.057Z","673":"2015-11-06T08:09:01.563Z","674":"2015-11-08T08:14:45.617Z","675":"2015-11-08T08:14:56.448Z","676":"2015-11-08T08:15:19.159Z","677":"2015-11-08T08:15:23.565Z","678":"2015-11-08T08:15:27.103Z","679":"2015-11-08T08:15:31.537Z","680":"2015-11-08T08:15:37.001Z","681":"2015-11-08T08:15:43.436Z","682":"2015-11-08T08:15:49.463Z","683":"2015-11-08T08:16:05.532Z","684":"2015-11-08T08:16:08.744Z","685":"2015-11-08T08:16:12.367Z","686":"2015-11-08T08:17:19.815Z","687":"2015-11-09T20:34:30.232Z","688":"2015-11-09T20:35:39.742Z","689":"2015-11-09T20:45:31.951Z","690":"2015-11-09T20:46:05.828Z","691":"2015-11-09T20:46:23.946Z","692":"2015-11-09T20:46:35.008Z","693":"2015-11-09T20:46:41.257Z","694":"2015-11-09T20:49:25.083Z","695":"2015-11-09T21:00:25.058Z","696":"2015-11-09T21:45:13.317Z","697":"2015-11-09T21:46:48.836Z","698":"2015-11-09T21:48:41.173Z","699":"2015-11-09T21:49:01.396Z","700":"2015-11-09T21:52:53.785Z","701":"2015-11-09T21:55:53.793Z","702":"2015-11-09T21:56:35.620Z","703":"2015-11-09T22:32:19.024Z","704":"2015-11-10T00:57:53.974Z","705":"2015-11-10T00:58:30.981Z","706":"2015-11-10T02:23:10.803Z","707":"2015-11-10T13:29:10.287Z","708":"2015-11-10T13:46:06.384Z","709":"2015-11-11T04:48:21.338Z","710":"2015-11-11T05:00:44.313Z","711":"2015-11-11T15:45:08.698Z","712":"2015-11-12T01:27:27.736Z","713":"2015-11-12T23:46:14.152Z","714":"2015-11-13T05:32:10.687Z","715":"2015-11-13T05:32:27.230Z","716":"2015-11-13T06:30:00.755Z","717":"2015-11-13T06:30:24.773Z","718":"2015-11-13T16:51:15.902Z","719":"2015-11-15T17:44:04.679Z","720":"2015-11-15T20:57:47.493Z","721":"2015-11-15T20:58:20.525Z","722":"2015-11-15T20:58:54.796Z","723":"2015-11-15T20:59:12.339Z","724":"2015-11-15T21:00:22.075Z","725":"2015-11-15T21:00:24.502Z","726":"2015-11-15T21:00:37.405Z","727":"2015-11-15T21:00:53.690Z","728":"2015-11-15T21:03:50.592Z","729":"2015-11-15T21:06:08.523Z","730":"2015-11-15T21:07:08.607Z","731":"2015-11-15T21:09:05.224Z","732":"2015-11-17T17:48:23.759Z","733":"2015-11-17T18:33:55.197Z","734":"2015-11-17T20:23:20.227Z","735":"2015-11-17T23:52:46.100Z","736":"2015-11-17T23:57:54.711Z","737":"2015-11-18T00:10:12.265Z","738":"2015-11-18T00:11:05.857Z","739":"2015-11-18T00:17:08.097Z","740":"2015-11-18T22:19:01.109Z","741":"2015-11-18T22:20:21.186Z","742":"2015-11-19T01:18:36.225Z","743":"2015-11-19T01:31:49.053Z","744":"2015-11-19T04:09:20.508Z","745":"2015-11-20T00:33:54.607Z","746":"2015-11-20T00:34:24.871Z","747":"2015-11-20T00:34:30.981Z","748":"2015-11-20T00:34:43.039Z","749":"2015-11-20T00:35:16.529Z","750":"2015-11-20T00:35:31.991Z","751":"2015-11-20T00:36:52.638Z","752":"2015-11-20T00:37:28.176Z","753":"2015-11-20T08:52:28.836Z","754":"2015-11-20T18:40:47.074Z","755":"2015-11-20T18:42:28.148Z","756":"2015-11-20T18:44:15.637Z","757":"2015-11-21T19:33:10.589Z","758":"2015-11-21T19:35:01.859Z","759":"2015-11-21T22:15:35.766Z","760":"2015-11-23T19:44:45.842Z","761":"2015-11-23T19:44:54.954Z","762":"2015-11-23T19:45:13.556Z","763":"2015-11-23T19:45:56.483Z","764":"2015-11-23T19:46:20.434Z","765":"2015-11-23T19:48:49.560Z","766":"2015-11-23T19:50:02.281Z","767":"2015-11-23T20:55:16.173Z","768":"2015-11-23T21:15:11.032Z","769":"2015-11-23T23:45:59.314Z","770":"2015-11-24T00:22:16.611Z","771":"2015-11-24T00:29:18.768Z","772":"2015-11-24T00:30:12.074Z","773":"2015-11-24T00:42:00.640Z","774":"2015-11-25T15:17:07.681Z","775":"2015-11-25T19:44:56.813Z","776":"2015-11-25T23:57:17.096Z","777":"2015-11-27T00:24:11.341Z","778":"2015-11-27T00:24:38.534Z","779":"2015-11-27T00:42:43.701Z","780":"2015-11-27T00:46:26.399Z","781":"2015-11-27T20:30:40.092Z","782":"2015-11-27T22:03:00.364Z","783":"2015-11-27T22:04:31.631Z","784":"2015-11-27T22:11:28.699Z","785":"2015-11-27T22:26:40.079Z","786":"2015-11-27T22:30:42.622Z","787":"2015-11-27T22:33:42.077Z","788":"2015-12-03T20:19:32.174Z","789":"2015-12-03T20:20:07.432Z","790":"2015-12-04T16:44:18.370Z","791":"2015-12-07T16:12:01.446Z","792":"2015-12-07T17:47:40.363Z","793":"2015-12-07T17:48:09.613Z","794":"2015-12-07T17:48:59.115Z","795":"2015-12-07T17:50:59.347Z","796":"2015-12-07T22:53:55.211Z","797":"2015-12-08T10:07:38.716Z","798":"2015-12-08T10:07:51.033Z","799":"2015-12-08T10:08:04.118Z","800":"2015-12-08T17:56:37.217Z","801":"2015-12-08T19:31:09.005Z","802":"2015-12-10T00:42:08.926Z","803":"2015-12-10T00:44:40.233Z","804":"2015-12-10T00:45:17.352Z","805":"2015-12-23T17:56:51.218Z","806":"2015-12-23T17:57:07.563Z","807":"2015-12-23T17:57:44.178Z","808":"2015-12-23T19:43:49.958Z","809":"2015-12-24T01:05:20.937Z","810":"2016-01-06T17:16:25.372Z","811":"2016-01-06T23:37:51.826Z","812":"2016-01-07T00:02:02.562Z","813":"2016-01-07T11:06:39.164Z","814":"2016-01-07T21:01:58.325Z","815":"2016-01-07T21:11:58.866Z","816":"2016-01-08T08:07:18.592Z","817":"2016-01-08T10:52:55.051Z","818":"2016-01-08T18:03:10.157Z","819":"2016-01-08T20:10:10.888Z","820":"2016-01-14T01:04:20.789Z","821":"2016-01-18T06:06:44.913Z","822":"2016-01-18T07:13:29.082Z","823":"2016-01-18T07:13:39.680Z","824":"2016-01-18T10:10:39.397Z","825":"2016-01-18T10:11:56.758Z","826":"2016-01-18T17:14:46.650Z","827":"2016-01-18T17:15:28.214Z","828":"2016-01-18T19:57:08.176Z","829":"2016-01-18T22:26:36.245Z","830":"2016-01-19T19:28:50.947Z","831":"2016-01-19T19:44:46.603Z","832":"2016-01-19T20:11:30.895Z","833":"2016-01-20T17:59:05.680Z","834":"2016-01-20T19:58:18.100Z","835":"2016-01-21T13:06:27.396Z","836":"2016-01-26T03:24:47.072Z","837":"2016-01-26T03:25:11.072Z","838":"2016-01-26T03:28:42.595Z","839":"2016-01-26T03:29:07.083Z","840":"2016-01-26T03:33:20.222Z","841":"2016-01-26T03:33:44.140Z","842":"2016-01-26T03:34:10.751Z","843":"2016-01-26T03:35:56.254Z","844":"2016-01-26T03:36:15.755Z","845":"2016-01-26T03:36:49.417Z","846":"2016-01-26T03:37:28.966Z","847":"2016-01-26T03:38:06.019Z","848":"2016-01-26T03:38:08.373Z","849":"2016-01-26T03:38:28.940Z","850":"2016-01-26T03:38:37.832Z","851":"2016-01-26T03:38:47.364Z","852":"2016-01-26T03:39:13.684Z","853":"2016-01-26T03:39:52.078Z","854":"2016-01-26T03:40:09.165Z","855":"2016-01-26T03:41:18.697Z","856":"2016-01-26T03:44:49.974Z","857":"2016-01-26T03:45:43.026Z","858":"2016-01-26T03:46:12.607Z","859":"2016-01-26T03:47:48.484Z","860":"2016-01-26T03:53:25.179Z","861":"2016-01-26T03:53:44.167Z","862":"2016-01-26T03:54:47.977Z","863":"2016-01-26T03:56:08.726Z","864":"2016-01-26T04:03:13.095Z","865":"2016-01-26T04:18:49.908Z","866":"2016-01-26T06:02:38.672Z","867":"2016-01-26T06:02:48.556Z","868":"2016-01-26T06:04:16.741Z","869":"2016-01-26T06:07:35.483Z","870":"2016-01-26T06:10:43.647Z","871":"2016-01-26T06:13:25.097Z","872":"2016-01-26T06:13:36.884Z","873":"2016-01-26T07:21:30.099Z","874":"2016-01-26T07:58:12.420Z","875":"2016-01-26T07:58:30.372Z","876":"2016-01-26T19:32:48.422Z","877":"2016-01-26T19:43:32.560Z","878":"2016-01-26T19:43:52.675Z","879":"2016-01-26T23:42:58.813Z","880":"2016-01-26T23:44:09.251Z","881":"2016-01-27T02:04:36.980Z","882":"2016-01-27T02:04:54.896Z","883":"2016-01-27T03:12:00.455Z","884":"2016-01-27T03:20:52.877Z","885":"2016-01-27T03:21:04.173Z","886":"2016-01-27T03:27:38.071Z","887":"2016-01-27T03:56:29.708Z","888":"2016-01-27T03:57:46.387Z","889":"2016-01-27T11:21:54.826Z","890":"2016-01-27T19:07:11.883Z","891":"2016-01-28T02:31:48.811Z","892":"2016-01-28T06:20:01.085Z","893":"2016-01-28T06:29:38.724Z","894":"2016-01-28T06:31:01.388Z","895":"2016-01-28T06:32:56.347Z","896":"2016-01-28T13:58:01.185Z","897":"2016-01-28T13:58:19.434Z","898":"2016-01-29T05:59:45.323Z","899":"2016-01-29T17:39:33.961Z","900":"2016-01-29T17:50:43.467Z","901":"2016-01-29T21:12:47.059Z","902":"2016-01-29T21:17:37.482Z","903":"2016-01-29T21:18:31.022Z","904":"2016-01-30T11:49:32.889Z","905":"2016-01-31T23:10:34.705Z","906":"2016-01-31T23:11:57.081Z","907":"2016-01-31T23:13:28.881Z","908":"2016-01-31T23:19:34.551Z","909":"2016-01-31T23:19:46.552Z","910":"2016-01-31T23:22:18.894Z","911":"2016-01-31T23:25:00.038Z","912":"2016-02-01T17:30:49.179Z","913":"2016-02-01T23:33:00.942Z","914":"2016-02-01T23:33:26.466Z","915":"2016-02-02T17:13:04.806Z","916":"2016-02-02T17:14:21.849Z","917":"2016-02-02T17:18:38.303Z","918":"2016-02-02T17:19:16.813Z","919":"2016-02-02T17:21:55.457Z","920":"2016-02-02T17:29:43.170Z","921":"2016-02-02T17:52:51.612Z","922":"2016-02-02T21:46:44.902Z","923":"2016-02-02T21:47:17.497Z","924":"2016-02-02T21:47:22.371Z","925":"2016-02-02T22:04:47.514Z","926":"2016-02-02T22:05:25.339Z","927":"2016-02-03T03:09:41.038Z","928":"2016-02-03T03:12:58.205Z","929":"2016-02-03T03:29:22.817Z","930":"2016-02-03T10:54:59.897Z","931":"2016-02-03T11:59:19.242Z","932":"2016-02-03T12:09:20.426Z","933":"2016-02-03T19:06:36.225Z","934":"2016-02-03T20:24:28.512Z","935":"2016-02-03T20:30:01.621Z","936":"2016-02-03T20:32:54.349Z","937":"2016-02-03T22:24:00.849Z","938":"2016-02-03T22:25:53.699Z","939":"2016-02-03T22:49:45.796Z","940":"2016-02-04T00:55:39.433Z","941":"2016-02-04T10:51:02.379Z","942":"2016-02-04T21:03:17.602Z","943":"2016-02-04T21:06:46.595Z","944":"2016-02-04T21:13:46.541Z","945":"2016-02-05T00:31:35.083Z","946":"2016-02-05T10:33:54.203Z","947":"2016-02-05T11:02:51.426Z","948":"2016-02-05T21:40:51.233Z","949":"2016-02-05T21:56:39.335Z","950":"2016-02-05T22:11:03.238Z","951":"2016-02-05T23:39:11.437Z","952":"2016-02-06T02:04:41.028Z","953":"2016-02-09T20:58:42.165Z","954":"2016-02-09T20:59:45.352Z","955":"2016-02-09T21:00:48.061Z","956":"2016-02-09T21:02:24.609Z","957":"2016-02-09T21:02:45.636Z","958":"2016-02-09T21:03:38.383Z","959":"2016-02-09T21:05:14.907Z","960":"2016-02-09T22:05:27.968Z","961":"2016-02-09T22:24:28.257Z","962":"2016-02-09T22:47:59.681Z","963":"2016-02-09T22:48:47.268Z","964":"2016-02-09T22:49:53.548Z","965":"2016-02-09T22:50:58.726Z","966":"2016-02-09T22:52:22.085Z","967":"2016-02-09T22:52:45.840Z","968":"2016-02-09T22:52:49.481Z","969":"2016-02-09T22:53:01.814Z","970":"2016-02-09T22:54:10.899Z","971":"2016-02-09T22:54:34.943Z","972":"2016-02-11T18:46:13.060Z","973":"2016-02-11T18:46:42.777Z","974":"2016-02-11T19:06:21.206Z","975":"2016-02-11T19:09:15.670Z","976":"2016-02-11T19:10:30.582Z","977":"2016-02-11T20:39:07.710Z","978":"2016-02-11T21:22:50.180Z","979":"2016-02-16T16:34:24.874Z","980":"2016-02-18T06:15:17.739Z","981":"2016-02-18T08:11:13.412Z","982":"2016-02-18T08:17:53.021Z","983":"2016-02-18T08:18:02.437Z","984":"2016-02-18T08:20:36.946Z","985":"2016-02-18T08:41:31.810Z","986":"2016-02-18T08:42:00.846Z","987":"2016-02-18T08:42:15.163Z","988":"2016-02-18T10:41:11.508Z","989":"2016-02-18T19:39:50.604Z","990":"2016-02-19T09:29:54.840Z","991":"2016-02-19T09:30:24.796Z","992":"2016-02-19T10:36:36.084Z","993":"2016-02-19T10:38:14.313Z","994":"2016-02-19T18:32:02.428Z","995":"2016-02-19T18:32:50.216Z","996":"2016-02-19T18:35:49.905Z","997":"2016-02-22T05:47:56.237Z","998":"2016-02-22T06:23:35.304Z","999":"2016-02-22T11:58:15.596Z","1000":"2016-02-22T11:58:32.124Z","1001":"2016-02-22T23:02:59.994Z","1002":"2016-02-23T01:17:49.595Z","1003":"2016-02-23T01:33:54.660Z","1004":"2016-02-24T18:47:50.320Z","1005":"2016-02-24T18:47:58.331Z","1006":"2016-02-24T18:49:19.718Z","1007":"2016-02-24T18:50:06.957Z","1008":"2016-02-24T18:54:16.924Z","1009":"2016-02-24T19:08:41.786Z","1010":"2016-02-24T19:36:10.705Z","1011":"2016-02-25T00:27:55.684Z","1012":"2016-02-25T08:01:55.734Z","1013":"2016-02-25T08:02:02.464Z","1014":"2016-03-01T00:51:07.981Z","1015":"2016-03-01T00:56:03.578Z","1016":"2016-03-01T01:01:30.207Z","1017":"2016-03-01T01:01:49.321Z","1018":"2016-03-01T06:41:00.901Z","1019":"2016-03-01T06:41:28.100Z","1020":"2016-03-01T06:41:31.659Z","1021":"2016-03-01T06:45:26.548Z","1022":"2016-03-01T06:51:47.153Z","1023":"2016-03-01T06:51:54.520Z","1024":"2016-03-01T06:53:25.990Z","1025":"2016-03-01T06:54:03.406Z","1026":"2016-03-01T06:54:27.903Z","1027":"2016-03-01T07:27:48.702Z","1028":"2016-03-01T12:38:23.397Z","1029":"2016-03-01T21:03:26.552Z","1030":"2016-03-07T18:42:51.095Z","1031":"2016-03-07T18:43:28.573Z","1032":"2016-03-07T19:31:26.025Z","1033":"2016-03-07T19:34:13.657Z","1034":"2016-03-07T19:48:09.809Z","1035":"2016-03-07T20:58:28.120Z","1036":"2016-03-07T21:21:16.698Z","1037":"2016-03-07T21:22:00.396Z","1038":"2016-03-07T21:28:22.911Z","1039":"2016-03-07T21:28:24.582Z","1040":"2016-03-07T21:28:50.966Z","1041":"2016-03-07T21:29:04.160Z","1042":"2016-03-07T21:29:15.909Z","1043":"2016-03-07T21:29:43.180Z","1044":"2016-03-07T21:30:40.328Z","1045":"2016-03-08T15:22:56.933Z","1046":"2016-03-08T15:23:11.960Z","1047":"2016-03-08T15:45:44.998Z","1048":"2016-03-08T15:46:57.847Z","1049":"2016-03-08T15:48:35.107Z","1050":"2016-03-08T15:49:01.969Z","1051":"2016-03-08T15:49:30.477Z","1052":"2016-03-08T15:49:40.482Z","1053":"2016-03-08T15:50:15.200Z","1054":"2016-03-08T15:50:49.598Z","1055":"2016-03-08T15:50:52.116Z","1056":"2016-03-08T15:51:04.637Z","1057":"2016-03-08T15:52:04.844Z","1058":"2016-03-08T15:52:30.630Z","1059":"2016-03-08T15:52:40.217Z","1060":"2016-03-08T15:53:11.859Z","1061":"2016-03-08T15:53:15.057Z","1062":"2016-03-08T15:54:12.361Z","1063":"2016-03-08T15:55:10.629Z","1064":"2016-03-08T15:55:20.345Z","1065":"2016-03-08T15:55:53.384Z","1066":"2016-03-08T15:56:18.864Z","1067":"2016-03-08T15:56:29.789Z","1068":"2016-03-08T15:56:46.995Z","1069":"2016-03-08T15:56:56.423Z","1070":"2016-03-08T15:57:10.505Z","1071":"2016-03-08T15:57:23.873Z","1072":"2016-03-08T15:57:54.734Z","1073":"2016-03-08T15:58:29.909Z","1074":"2016-03-08T16:00:03.498Z","1075":"2016-03-08T19:22:49.910Z","1076":"2016-03-09T05:05:21.945Z","1077":"2016-03-09T06:07:04.544Z","1078":"2016-03-09T06:08:27.681Z","1079":"2016-03-09T15:01:32.208Z","1080":"2016-03-09T18:49:36.349Z","1081":"2016-03-09T19:26:28.359Z","1082":"2016-03-09T19:47:40.646Z","1083":"2016-03-09T19:49:37.623Z","1084":"2016-03-09T20:03:59.172Z","1085":"2016-03-10T09:27:29.516Z","1086":"2016-03-10T09:44:45.215Z","1087":"2016-03-10T09:50:53.520Z","1088":"2016-03-10T09:57:13.450Z","1089":"2016-03-10T10:21:02.747Z","1090":"2016-03-10T10:22:29.515Z","1091":"2016-03-10T10:23:02.178Z","1092":"2016-03-10T11:13:21.211Z","1093":"2016-03-10T11:26:35.361Z","1094":"2016-03-10T12:01:54.086Z","1095":"2016-03-10T13:07:17.967Z","1096":"2016-03-10T15:59:03.265Z","1097":"2016-03-11T03:41:57.474Z","1098":"2016-03-11T03:44:17.510Z","1099":"2016-03-11T18:59:05.937Z","1100":"2016-03-11T18:59:07.499Z","1101":"2016-03-11T18:59:34.642Z","1102":"2016-03-11T18:59:52.856Z","1103":"2016-03-11T18:59:56.440Z","1104":"2016-03-11T19:00:04.546Z","1105":"2016-03-11T19:13:12.289Z","1106":"2016-03-11T19:14:25.702Z","1107":"2016-03-11T19:15:23.817Z","1108":"2016-03-11T19:15:37.273Z","1109":"2016-03-11T19:17:36.999Z","1110":"2016-03-11T19:19:13.651Z","1111":"2016-03-11T19:19:34.382Z","1112":"2016-03-11T19:20:25.588Z","1113":"2016-03-11T20:15:14.143Z","1114":"2016-03-11T20:16:39.528Z","1115":"2016-03-11T20:34:42.464Z","1116":"2016-03-11T20:35:25.736Z","1117":"2016-03-11T20:47:41.702Z","1118":"2016-03-11T20:48:04.441Z","1119":"2016-03-11T20:48:06.920Z","1120":"2016-03-11T20:48:19.636Z","1121":"2016-03-11T20:48:32.727Z","1122":"2016-03-11T20:48:45.902Z","1123":"2016-03-11T20:48:47.160Z","1124":"2016-03-11T20:49:34.528Z","1125":"2016-03-11T20:50:03.948Z","1126":"2016-03-11T20:50:57.294Z","1127":"2016-03-11T20:51:46.874Z","1128":"2016-03-11T20:54:44.823Z","1129":"2016-03-12T19:46:48.121Z","1130":"2016-03-14T10:32:16.237Z","1131":"2016-03-14T20:54:27.298Z","1132":"2016-03-14T20:57:02.450Z","1133":"2016-03-14T20:57:17.322Z","1134":"2016-03-15T06:57:35.679Z","1135":"2016-03-16T07:14:02.598Z","1136":"2016-03-16T16:56:03.176Z","1137":"2016-03-17T00:05:36.473Z","1138":"2016-03-17T00:47:08.479Z","1139":"2016-03-17T00:47:28.843Z","1140":"2016-03-17T00:47:38.170Z","1141":"2016-03-17T00:53:44.907Z","1142":"2016-03-17T00:54:03.009Z","1143":"2016-03-17T00:54:26.114Z","1144":"2016-03-17T05:52:26.993Z","1145":"2016-03-17T05:52:56.090Z","1146":"2016-03-17T17:22:11.190Z","1147":"2016-03-17T18:48:35.650Z","1148":"2016-03-17T18:48:48.380Z","1149":"2016-03-17T18:50:11.686Z","1150":"2016-03-17T18:54:23.726Z","1151":"2016-03-17T20:17:11.566Z","1152":"2016-03-17T20:17:25.470Z","1153":"2016-03-17T20:18:36.027Z","1154":"2016-03-17T20:20:06.805Z","1155":"2016-03-17T20:34:33.850Z","1156":"2016-03-17T20:37:06.876Z","1157":"2016-03-17T21:36:36.829Z","1158":"2016-03-17T21:37:10.047Z","1159":"2016-03-17T21:37:51.133Z","1160":"2016-03-17T21:38:06.912Z","1161":"2016-03-17T21:38:38.245Z","1162":"2016-03-17T21:38:39.306Z","1163":"2016-03-17T21:38:50.834Z","1164":"2016-03-17T21:38:52.028Z","1165":"2016-03-17T21:38:58.125Z","1166":"2016-03-17T21:40:06.973Z","1167":"2016-03-17T21:40:35.122Z","1168":"2016-03-17T21:41:00.087Z","1169":"2016-03-17T21:41:13.436Z","1170":"2016-03-17T21:41:18.773Z","1171":"2016-03-17T21:41:29.354Z","1172":"2016-03-17T21:41:35.772Z","1173":"2016-03-17T21:41:40.360Z","1174":"2016-03-17T21:41:52.595Z","1175":"2016-03-17T21:42:14.734Z","1176":"2016-03-17T21:42:29.912Z","1177":"2016-03-18T00:04:53.784Z","1178":"2016-03-18T00:05:12.797Z","1179":"2016-03-18T00:05:44.941Z","1180":"2016-03-18T22:02:03.536Z","1181":"2016-03-20T06:36:54.510Z","1182":"2016-03-20T06:37:34.506Z","1183":"2016-03-20T06:40:12.758Z","1184":"2016-03-20T06:42:21.834Z","1185":"2016-03-20T06:44:00.149Z","1186":"2016-03-20T06:45:09.865Z","1187":"2016-03-20T06:45:33.041Z","1188":"2016-03-20T06:46:40.485Z","1189":"2016-03-20T06:47:04.740Z","1190":"2016-03-20T06:48:05.927Z","1191":"2016-03-20T06:48:33.819Z","1192":"2016-03-20T06:48:56.540Z","1193":"2016-03-20T06:49:03.585Z","1194":"2016-03-20T06:50:26.431Z","1195":"2016-03-20T06:51:09.381Z","1196":"2016-03-21T08:01:47.212Z","1197":"2016-03-21T13:27:41.920Z","1198":"2016-03-21T17:16:06.709Z","1199":"2016-03-21T18:41:34.048Z","1200":"2016-03-22T04:26:18.318Z","1201":"2016-03-22T04:29:09.510Z","1202":"2016-03-22T04:30:02.125Z","1203":"2016-03-22T04:33:02.502Z","1204":"2016-03-22T04:33:43.068Z","1205":"2016-03-22T04:42:16.217Z","1206":"2016-03-22T04:54:02.614Z","1207":"2016-03-22T04:54:31.458Z","1208":"2016-03-22T04:54:53.737Z","1209":"2016-03-23T00:46:28.408Z","1210":"2016-03-23T00:46:46.999Z","1211":"2016-03-23T00:49:53.286Z","1212":"2016-03-23T00:50:56.918Z","1213":"2016-03-23T01:08:44.464Z","1214":"2016-03-23T01:09:25.561Z","1215":"2016-03-23T01:09:56.042Z","1216":"2016-03-23T01:10:28.862Z","1217":"2016-03-23T01:59:30.954Z","1218":"2016-03-23T02:00:19.702Z","1219":"2016-03-23T02:06:32.373Z","1220":"2016-03-23T02:13:43.046Z","1221":"2016-03-23T02:17:33.824Z","1222":"2016-03-23T02:18:12.745Z","1223":"2016-03-23T02:21:26.650Z","1224":"2016-03-23T02:22:35.762Z","1225":"2016-03-23T02:22:57.955Z","1226":"2016-03-23T02:23:18.355Z","1227":"2016-03-23T02:23:23.188Z","1228":"2016-03-23T02:24:07.134Z","1229":"2016-03-23T02:26:29.349Z","1230":"2016-03-23T02:27:52.495Z","1231":"2016-03-23T02:28:12.790Z","1232":"2016-03-23T02:30:42.789Z","1233":"2016-03-23T03:56:43.823Z","1234":"2016-03-23T03:57:39.347Z","1235":"2016-03-23T03:58:01.463Z","1236":"2016-03-23T03:58:46.713Z","1237":"2016-03-23T03:59:13.257Z","1238":"2016-03-23T04:00:59.143Z","1239":"2016-03-23T04:01:18.339Z","1240":"2016-03-23T04:01:27.354Z","1241":"2016-03-23T04:02:19.554Z","1242":"2016-03-23T04:02:22.108Z","1243":"2016-03-23T04:03:29.042Z","1244":"2016-03-23T04:06:31.826Z","1245":"2016-03-23T04:08:52.212Z","1246":"2016-03-23T04:11:52.879Z","1247":"2016-03-23T04:12:40.696Z","1248":"2016-03-23T04:16:32.601Z","1249":"2016-03-23T04:17:32.936Z","1250":"2016-03-23T04:35:50.753Z","1251":"2016-03-23T04:39:38.638Z","1252":"2016-03-23T17:57:36.271Z","1253":"2016-03-23T18:01:59.364Z","1254":"2016-03-23T18:02:11.197Z","1255":"2016-03-24T02:46:49.198Z","1256":"2016-03-24T03:01:32.896Z","1257":"2016-03-24T16:00:21.562Z","1258":"2016-03-25T18:50:54.435Z","1259":"2016-03-25T18:50:55.204Z","1260":"2016-03-25T18:51:39.554Z","1261":"2016-03-25T18:52:01.130Z","1262":"2016-03-25T18:52:16.375Z","1263":"2016-03-25T18:52:41.388Z","1264":"2016-03-26T08:27:47.828Z","1265":"2016-03-26T08:27:48.698Z","1266":"2016-03-26T08:28:12.791Z","1267":"2016-03-26T09:14:13.243Z","1268":"2016-03-26T09:14:15.188Z","1269":"2016-03-26T09:14:23.730Z","1270":"2016-03-26T09:14:35.371Z","1271":"2016-03-26T09:30:17.252Z","1272":"2016-03-26T09:30:29.632Z","1273":"2016-03-26T09:48:50.058Z","1274":"2016-03-26T09:49:17.021Z","1275":"2016-03-28T04:00:18.581Z","1276":"2016-03-28T11:50:30.804Z","1277":"2016-03-28T11:50:56.075Z","1278":"2016-03-28T11:51:09.492Z","1279":"2016-03-28T19:42:23.431Z","1280":"2016-03-28T19:44:57.125Z","1281":"2016-03-28T19:50:52.624Z","1282":"2016-03-29T06:46:30.144Z","1283":"2016-03-29T06:47:53.647Z","1284":"2016-03-29T06:48:21.764Z","1285":"2016-03-29T06:50:03.581Z","1286":"2016-03-29T07:18:58.304Z","1287":"2016-03-29T07:19:23.269Z","1288":"2016-03-29T09:06:50.034Z","1289":"2016-03-30T16:11:41.318Z","1290":"2016-03-30T16:16:59.469Z","1291":"2016-03-31T03:25:32.793Z","1292":"2016-03-31T03:46:28.896Z","1293":"2016-03-31T05:14:16.966Z","1294":"2016-03-31T05:14:32.626Z","1295":"2016-03-31T13:00:21.277Z","1296":"2016-03-31T15:06:44.104Z","1297":"2016-03-31T15:07:53.126Z","1298":"2016-03-31T15:47:51.797Z","1299":"2016-03-31T16:46:49.114Z","1300":"2016-03-31T17:29:13.441Z","1301":"2016-03-31T17:29:17.714Z","1302":"2016-03-31T23:17:49.925Z","1303":"2016-04-01T00:36:59.845Z","1304":"2016-04-01T00:37:31.894Z","1305":"2016-04-01T00:37:45.877Z","1306":"2016-04-01T00:39:22.619Z","1307":"2016-04-01T00:40:20.601Z","1308":"2016-04-01T07:43:43.384Z","1309":"2016-04-01T15:56:59.560Z","1310":"2016-04-01T16:02:11.171Z","1311":"2016-04-01T19:19:32.200Z","1312":"2016-04-01T19:48:12.514Z","1313":"2016-04-01T19:48:17.563Z","1314":"2016-04-01T19:52:32.762Z","1315":"2016-04-01T19:52:36.771Z","1316":"2016-04-01T19:54:25.782Z","1317":"2016-04-01T19:55:50.882Z","1318":"2016-04-01T20:11:07.852Z","1319":"2016-04-01T20:13:08.925Z","1320":"2016-04-01T20:16:52.745Z","1321":"2016-04-01T20:21:56.756Z","1322":"2016-04-01T20:22:20.570Z","1323":"2016-04-01T20:22:30.057Z","1324":"2016-04-01T20:24:03.446Z","1325":"2016-04-01T20:24:32.259Z","1326":"2016-04-01T20:27:22.818Z","1327":"2016-04-01T20:31:57.102Z","1328":"2016-04-01T20:32:13.387Z","1329":"2016-04-01T20:32:37.881Z","1330":"2016-04-01T20:33:28.198Z","1331":"2016-04-01T20:33:43.058Z","1332":"2016-04-01T20:33:54.498Z","1333":"2016-04-01T20:34:51.359Z","1334":"2016-04-01T20:35:18.784Z","1335":"2016-04-01T20:35:54.001Z","1336":"2016-04-01T20:52:19.055Z","1337":"2016-04-01T20:52:53.118Z","1338":"2016-04-01T20:53:09.385Z","1339":"2016-04-01T20:59:03.852Z","1340":"2016-04-01T20:59:18.837Z","1341":"2016-04-01T22:09:22.545Z","1342":"2016-04-01T22:16:56.136Z","1343":"2016-04-01T22:21:37.260Z","1344":"2016-04-01T22:22:23.815Z","1345":"2016-04-02T00:03:27.305Z","1346":"2016-04-02T00:13:16.577Z","1347":"2016-04-02T00:13:41.912Z","1348":"2016-04-02T04:43:19.383Z","1349":"2016-04-02T13:15:58.831Z","1350":"2016-04-02T13:16:06.828Z","1351":"2016-04-02T13:16:53.101Z","1352":"2016-04-02T13:21:56.323Z","1353":"2016-04-05T22:28:37.901Z","1354":"2016-04-06T17:16:50.595Z","1355":"2016-04-06T17:19:20.735Z","1356":"2016-04-06T17:22:29.970Z","1357":"2016-04-06T17:24:11.011Z","1358":"2016-04-06T17:24:12.060Z","1359":"2016-04-06T17:24:59.295Z","1360":"2016-04-06T17:25:04.704Z","1361":"2016-04-06T17:25:26.401Z","1362":"2016-04-06T17:25:40.146Z","1363":"2016-04-06T17:25:47.535Z","1364":"2016-04-06T17:26:04.392Z","1365":"2016-04-06T17:30:30.879Z","1366":"2016-04-06T17:31:37.527Z","1367":"2016-04-06T17:36:58.011Z","1368":"2016-04-06T17:37:12.262Z","1369":"2016-04-06T17:37:31.403Z","1370":"2016-04-06T17:37:58.993Z","1371":"2016-04-06T17:38:12.630Z","1372":"2016-04-06T17:38:30.120Z","1373":"2016-04-06T17:38:53.686Z","1374":"2016-04-06T17:43:36.077Z","1375":"2016-04-07T00:33:29.624Z","1376":"2016-04-07T00:42:28.385Z","1377":"2016-04-07T00:53:07.469Z","1378":"2016-04-07T00:53:51.662Z","1379":"2016-04-07T05:55:09.586Z","1380":"2016-04-07T07:13:09.696Z","1381":"2016-04-07T07:16:18.777Z","1382":"2016-04-07T07:17:05.615Z","1383":"2016-04-07T07:17:08.956Z","1384":"2016-04-07T07:17:24.969Z","1385":"2016-04-07T14:31:03.665Z","1386":"2016-04-08T01:44:23.825Z","1387":"2016-04-08T01:44:45.096Z","1388":"2016-04-08T01:45:05.816Z","1389":"2016-04-08T01:45:21.743Z","1390":"2016-04-08T05:48:22.659Z","1391":"2016-04-08T18:20:20.507Z","1392":"2016-04-08T23:26:19.090Z","1393":"2016-04-08T23:28:24.290Z","1394":"2016-04-11T20:13:11.638Z","1395":"2016-04-12T14:08:27.286Z","1396":"2016-04-12T15:23:50.283Z","1397":"2016-04-12T19:04:09.982Z","1398":"2016-04-13T15:50:08.983Z","1399":"2016-04-13T16:44:01.783Z","1400":"2016-04-13T16:46:06.040Z","1401":"2016-04-13T17:05:58.557Z","1402":"2016-04-13T17:08:23.149Z","1403":"2016-04-13T17:09:26.278Z","1404":"2016-04-13T17:11:35.137Z","1405":"2016-04-13T17:11:57.635Z","1406":"2016-04-13T17:12:23.062Z","1407":"2016-04-13T17:15:37.604Z","1408":"2016-04-13T17:16:00.293Z","1409":"2016-04-13T17:16:26.141Z","1410":"2016-04-13T17:18:25.082Z","1411":"2016-04-13T18:11:53.892Z","1412":"2016-04-13T19:12:29.985Z","1413":"2016-04-13T20:22:42.848Z","1414":"2016-04-13T21:08:46.649Z","1415":"2016-04-13T21:09:02.706Z","1416":"2016-04-14T16:05:36.343Z","1417":"2016-04-14T21:42:41.453Z","1418":"2016-04-14T21:54:19.584Z","1419":"2016-04-14T23:20:50.313Z","1420":"2016-04-14T23:23:59.008Z","1421":"2016-04-18T15:47:21.131Z","1422":"2016-04-18T19:35:45.765Z","1423":"2016-04-18T22:37:26.187Z","1424":"2016-04-18T22:47:09.938Z","1425":"2016-04-19T10:57:45.529Z","1426":"2016-04-20T02:12:52.242Z","1427":"2016-04-22T15:09:13.229Z","1428":"2016-04-22T17:36:07.992Z","1429":"2016-04-22T17:43:45.728Z","1430":"2016-04-22T17:44:12.344Z","1431":"2016-04-22T17:50:27.285Z","1432":"2016-04-22T18:14:41.506Z","1433":"2016-04-22T18:18:26.268Z","1434":"2016-04-22T18:24:41.319Z","1435":"2016-04-22T21:29:53.144Z","1436":"2016-04-23T15:30:52.539Z","1437":"2016-04-23T15:58:39.581Z","1438":"2016-04-25T19:06:58.979Z","1439":"2016-04-25T20:04:23.113Z","1440":"2016-04-25T20:52:40.780Z","1441":"2016-04-25T20:53:50.581Z","1442":"2016-04-25T22:58:26.582Z","1443":"2016-04-26T20:34:04.167Z","1444":"2016-04-27T03:04:47.224Z","1445":"2016-04-27T03:17:24.209Z","1446":"2016-04-27T15:21:30.494Z","1447":"2016-04-29T03:28:27.857Z","1448":"2016-04-29T03:29:38.242Z","1449":"2016-04-29T11:27:48.433Z","1450":"2016-04-29T21:42:02.928Z","1451":"2016-05-01T02:15:34.158Z","1452":"2016-05-01T16:24:26.256Z","1453":"2016-05-01T20:23:25.254Z","1454":"2016-05-02T18:30:35.883Z","1455":"2016-05-02T18:31:44.432Z","1456":"2016-05-02T18:32:41.340Z","1457":"2016-05-02T19:09:27.790Z","1458":"2016-05-02T20:27:50.993Z","1459":"2016-05-04T12:52:10.366Z","1460":"2016-05-04T12:52:49.544Z","1461":"2016-05-04T12:55:06.231Z","1462":"2016-05-04T14:21:32.417Z","1463":"2016-05-05T16:51:40.502Z","1464":"2016-05-05T16:57:32.623Z","1465":"2016-05-05T16:59:16.409Z","1466":"2016-05-05T20:35:27.664Z","1467":"2016-05-05T20:36:34.992Z","1468":"2016-05-05T21:22:03.248Z","1469":"2016-05-06T13:25:45.029Z","1470":"2016-05-07T02:28:41.032Z","1471":"2016-05-07T02:29:14.804Z","1472":"2016-05-07T02:35:46.143Z","1473":"2016-05-07T02:36:26.286Z","1474":"2016-05-07T02:37:13.510Z","1475":"2016-05-07T02:41:47.697Z","1476":"2016-05-07T02:43:12.330Z","1477":"2016-05-07T03:10:25.272Z","1478":"2016-05-07T03:14:32.777Z","1479":"2016-05-09T02:52:55.741Z","1480":"2016-05-09T02:57:45.983Z","1481":"2016-05-09T03:07:44.297Z","1482":"2016-05-09T03:09:29.101Z","1483":"2016-05-09T03:12:51.828Z","1484":"2016-05-09T03:23:41.619Z","1485":"2016-05-09T03:25:03.882Z","1486":"2016-05-10T05:16:38.782Z","1487":"2016-05-10T05:18:04.167Z","1488":"2016-05-10T05:18:31.628Z","1489":"2016-05-10T11:42:28.172Z","1490":"2016-05-10T13:20:05.573Z","1491":"2016-05-10T17:45:04.759Z","1492":"2016-05-10T17:45:22.418Z","1493":"2016-05-10T17:48:29.881Z","1494":"2016-05-10T18:52:12.536Z","1495":"2016-05-11T01:19:58.630Z","1496":"2016-05-11T04:13:13.655Z","1497":"2016-05-11T04:23:41.276Z","1498":"2016-05-15T22:51:57.603Z","1499":"2016-05-15T22:53:03.183Z","1500":"2016-05-15T22:54:30.317Z","1501":"2016-05-15T22:54:32.928Z","1502":"2016-05-17T15:34:17.133Z","1503":"2016-05-17T15:34:48.453Z","1504":"2016-05-18T14:33:03.026Z","1505":"2016-05-19T16:55:49.216Z","1506":"2016-05-19T16:59:21.352Z","1507":"2016-05-19T19:41:21.805Z","1508":"2016-05-19T19:42:15.451Z","1509":"2016-05-19T19:42:52.292Z","1510":"2016-05-22T20:03:38.635Z","1511":"2016-05-22T20:04:21.202Z","1512":"2016-05-22T23:57:07.788Z","1513":"2016-05-23T06:43:48.667Z","1514":"2016-05-23T20:38:02.542Z","1515":"2016-05-23T20:38:26.109Z","1516":"2016-05-23T22:47:38.969Z","1517":"2016-05-23T22:47:43.013Z","1518":"2016-05-23T22:58:28.033Z","1519":"2016-05-24T07:13:52.519Z","1520":"2016-05-25T09:38:03.084Z","1521":"2016-05-25T09:49:11.975Z","1522":"2016-05-25T09:52:17.098Z","1523":"2016-05-25T09:53:32.958Z","1524":"2016-05-25T10:11:51.516Z","1525":"2016-05-25T10:11:53.277Z","1526":"2016-05-25T15:37:44.114Z","1527":"2016-05-25T15:38:52.605Z","1528":"2016-05-25T15:40:54.163Z","1529":"2016-05-25T17:20:49.715Z","1530":"2016-05-25T17:22:25.021Z","1531":"2016-05-25T18:06:01.239Z","1532":"2016-05-25T18:19:40.237Z","1533":"2016-05-26T12:53:19.118Z","1534":"2016-05-26T17:32:23.326Z","1535":"2016-05-26T17:34:31.876Z","1536":"2016-05-26T17:36:01.416Z","1537":"2016-05-26T17:36:01.752Z","1538":"2016-05-26T17:36:11.823Z","1539":"2016-05-26T20:49:03.875Z","1540":"2016-05-27T15:41:39.894Z","1541":"2016-05-27T23:06:15.009Z","1542":"2016-05-27T23:07:45.394Z","1543":"2016-05-28T16:12:55.357Z","1544":"2016-05-30T12:53:38.460Z","1545":"2016-05-30T16:32:57.601Z","1546":"2016-05-30T17:35:50.761Z","1547":"2016-05-31T15:02:57.021Z","1548":"2016-05-31T17:44:45.824Z","1549":"2016-06-01T10:05:43.360Z","1550":"2016-06-01T10:06:31.884Z","1551":"2016-06-01T10:07:36.664Z","1552":"2016-06-01T23:09:08.760Z","1553":"2016-06-01T23:11:15.702Z","1554":"2016-06-01T23:11:22.040Z","1555":"2016-06-01T23:13:04.677Z","1556":"2016-06-02T04:27:12.155Z","1557":"2016-06-02T11:20:46.305Z","1558":"2016-06-02T12:35:45.870Z","1559":"2016-06-02T12:36:04.084Z","1560":"2016-06-02T12:36:43.698Z","1561":"2016-06-02T12:37:51.969Z","1562":"2016-06-02T19:35:16.108Z","1563":"2016-06-03T12:40:51.328Z","1564":"2016-06-03T13:55:23.536Z","1565":"2016-06-05T16:51:05.528Z","1566":"2016-06-06T13:01:22.404Z","1567":"2016-06-06T18:04:40.020Z","1568":"2016-06-07T15:57:37.708Z","1569":"2016-06-07T15:59:42.506Z","1570":"2016-06-07T16:00:13.068Z","1571":"2016-06-08T03:38:55.442Z","1572":"2016-06-08T17:24:08.666Z","1573":"2016-06-10T13:25:50.366Z","1574":"2016-06-10T13:29:20.033Z","1575":"2016-06-10T13:52:12.237Z","1576":"2016-06-10T16:45:02.256Z","1577":"2016-06-10T16:47:24.209Z","1578":"2016-06-11T05:41:24.094Z","1579":"2016-06-11T05:52:59.610Z","1580":"2016-06-11T13:30:33.443Z","1581":"2016-06-11T16:54:18.827Z","1582":"2016-06-11T16:55:59.401Z","1583":"2016-06-11T16:57:09.736Z","1584":"2016-06-11T17:05:36.246Z","1585":"2016-06-11T17:07:17.093Z","1586":"2016-06-11T17:12:41.420Z","1587":"2016-06-11T17:28:48.908Z","1588":"2016-06-11T21:45:59.154Z","1589":"2016-06-11T21:50:51.864Z","1590":"2016-06-11T21:54:19.584Z","1591":"2016-06-11T23:01:19.549Z","1592":"2016-06-13T05:43:45.417Z","1593":"2016-06-13T05:46:07.131Z","1594":"2016-06-15T20:21:57.547Z","1595":"2016-06-15T20:22:44.545Z","1596":"2016-06-15T20:22:54.108Z","1597":"2016-06-16T19:59:26.537Z","1598":"2016-06-16T20:15:41.674Z","1599":"2016-06-16T20:16:07.620Z","1600":"2016-06-18T20:41:48.180Z","1601":"2016-06-19T00:47:10.351Z","1602":"2016-06-20T14:32:50.137Z","1603":"2016-06-20T16:01:45.697Z","1604":"2016-06-20T16:02:21.420Z","1605":"2016-06-20T16:56:39.471Z","1606":"2016-06-22T05:50:07.088Z","1607":"2016-06-22T05:50:30.396Z","1608":"2016-06-22T16:36:04.125Z","1609":"2016-06-22T16:51:06.149Z","1610":"2016-06-23T00:24:31.231Z","1611":"2016-06-23T20:25:31.557Z","1612":"2016-06-23T21:32:57.336Z","1613":"2016-06-23T23:55:37.210Z","1614":"2016-06-29T16:17:52.536Z","1615":"2016-06-29T16:18:33.515Z","1616":"2016-06-29T16:19:15.679Z","1617":"2016-07-01T16:45:47.487Z","1618":"2016-07-01T18:25:47.095Z","1619":"2016-07-02T19:50:49.936Z","1620":"2016-07-02T19:51:26.090Z","1621":"2016-07-03T02:17:34.092Z","1622":"2016-07-03T17:35:06.645Z","1623":"2016-07-03T21:40:04.713Z","1624":"2016-07-04T17:34:21.088Z","1625":"2016-07-04T17:35:26.952Z","1626":"2016-07-04T17:43:04.549Z","1627":"2016-07-08T00:20:22.481Z","1628":"2016-07-08T23:37:13.152Z","1629":"2016-07-09T00:43:21.433Z","1630":"2016-07-09T02:43:27.628Z","1631":"2016-07-11T16:30:20.126Z","1632":"2016-07-12T00:34:47.256Z","1633":"2016-07-12T22:53:19.968Z","1634":"2016-07-12T23:54:57.481Z","1635":"2016-07-13T15:56:33.434Z","1636":"2016-07-14T08:26:40.708Z","1637":"2016-07-14T08:33:03.214Z","1638":"2016-07-16T22:23:49.509Z","1639":"2016-07-19T14:32:54.465Z","1640":"2016-07-19T14:33:57.111Z","1641":"2016-07-19T14:34:21.807Z","1642":"2016-07-19T14:40:07.401Z","1643":"2016-07-19T14:44:48.307Z","1644":"2016-07-19T14:44:56.290Z","1645":"2016-07-19T14:45:58.749Z","1646":"2016-07-19T14:46:11.018Z","1647":"2016-07-19T14:46:13.657Z","1648":"2016-07-19T14:46:36.857Z","1649":"2016-07-19T14:47:23.347Z","1650":"2016-07-19T14:47:54.844Z","1651":"2016-07-21T03:07:31.167Z","1652":"2016-07-21T14:51:44.493Z","1653":"2016-07-21T14:55:50.723Z","1654":"2016-07-24T17:41:26.235Z","1655":"2016-07-24T17:41:53.350Z","1656":"2016-07-28T14:28:12.607Z","1657":"2016-07-28T14:32:28.532Z","1658":"2016-07-28T14:33:04.819Z","1659":"2016-07-28T14:37:40.855Z","1660":"2016-07-28T15:23:57.287Z","1661":"2016-07-28T15:44:14.929Z","1662":"2016-07-28T16:01:00.053Z","1663":"2016-07-28T16:03:20.995Z","1664":"2016-07-28T22:25:43.495Z","1665":"2016-07-28T22:26:09.039Z","1666":"2016-07-28T22:26:49.120Z","1667":"2016-07-29T08:28:13.218Z","1668":"2016-07-29T09:26:23.619Z","1669":"2016-07-29T10:12:53.733Z","1670":"2016-07-29T10:14:05.651Z","1671":"2016-07-29T10:14:28.027Z","1672":"2016-07-29T10:14:56.882Z","1673":"2016-07-29T10:15:18.422Z","1674":"2016-08-02T14:25:31.035Z","1675":"2016-08-02T16:25:50.304Z","1676":"2016-08-03T02:27:09.213Z","1677":"2016-08-03T03:51:07.613Z","1678":"2016-08-03T03:51:49.717Z","1679":"2016-08-04T09:09:45.901Z","1680":"2016-08-04T09:10:03.350Z","1681":"2016-08-04T09:10:29.907Z","1682":"2016-08-04T15:50:38.780Z","1683":"2016-08-04T15:53:05.128Z","1684":"2016-08-04T16:40:25.663Z","1685":"2016-08-04T19:20:24.427Z","1686":"2016-08-05T10:09:23.780Z","1687":"2016-08-05T10:09:31.575Z","1688":"2016-08-05T10:10:29.578Z","1689":"2016-08-05T10:10:48.233Z","1690":"2016-08-10T02:12:18.783Z","1691":"2016-08-10T02:12:59.803Z","1692":"2016-08-10T02:27:31.476Z","1693":"2016-08-10T02:41:23.843Z","1694":"2016-08-10T07:06:00.976Z","1695":"2016-08-10T17:11:38.743Z","1696":"2016-08-10T17:11:52.500Z","1697":"2016-08-10T17:12:33.562Z","1698":"2016-08-10T17:12:40.888Z","1699":"2016-08-17T21:55:40.719Z","1700":"2016-08-18T05:52:13.511Z","1701":"2016-08-18T18:46:42.298Z","1702":"2016-08-18T18:47:22.936Z","1703":"2016-08-18T19:19:04.674Z","1704":"2016-09-19T03:21:00.005Z","1705":"2016-09-19T18:04:31.143Z","1706":"2016-09-19T18:06:07.489Z","1707":"2016-09-19T18:06:23.092Z","1708":"2016-09-19T18:07:49.118Z","1709":"2016-09-19T22:37:46.822Z","1710":"2016-09-21T05:49:41.726Z","1711":"2016-09-21T07:58:30.032Z","1712":"2016-09-28T15:47:08.550Z","1713":"2016-09-28T15:49:36.978Z","1714":"2016-09-30T22:55:44.677Z","1715":"2016-09-30T22:55:47.656Z","1716":"2016-09-30T22:56:18.654Z","1717":"2016-10-01T17:10:27.267Z","1718":"2016-10-01T17:10:52.069Z","1719":"2016-10-03T13:14:01.654Z","1720":"2016-10-03T13:14:09.856Z","1721":"2016-10-03T13:26:35.413Z","1722":"2016-10-03T13:28:44.912Z","1723":"2016-10-03T13:47:28.890Z","1724":"2016-10-03T17:53:28.421Z","1725":"2016-10-03T17:54:27.780Z","1726":"2016-10-06T11:50:59.806Z","1727":"2016-10-12T06:45:10.154Z","1728":"2016-10-12T06:49:45.397Z","1729":"2016-10-12T07:15:54.039Z","1730":"2016-10-12T07:16:55.274Z","1731":"2016-10-12T07:17:53.125Z","1732":"2016-10-12T07:18:05.327Z","1733":"2016-10-12T21:36:43.110Z","1734":"2016-10-17T02:31:43.700Z","1735":"2016-10-19T20:17:05.998Z","1736":"2016-10-19T21:34:21.430Z","1737":"2016-10-19T21:34:30.323Z","1738":"2016-10-20T18:41:25.565Z","1739":"2016-10-21T14:15:01.293Z","1740":"2016-10-22T04:20:45.417Z","1741":"2016-10-22T04:30:06.489Z","1742":"2016-10-22T18:23:04.979Z","1743":"2016-10-22T19:33:32.674Z","1744":"2016-10-24T09:01:10.099Z","1745":"2016-10-24T16:23:27.148Z","1746":"2016-10-25T17:38:07.499Z","1747":"2016-10-25T17:39:06.016Z","1748":"2016-10-25T17:40:29.654Z","1749":"2016-10-25T17:41:29.061Z","1750":"2016-10-25T17:42:16.276Z","1751":"2016-10-25T17:48:48.933Z","1752":"2016-10-25T18:49:25.828Z","1753":"2016-10-25T19:00:45.399Z","1754":"2016-10-25T19:00:54.483Z","1755":"2016-10-25T19:02:09.796Z","1756":"2016-10-25T20:05:40.513Z","1757":"2016-10-25T20:54:41.786Z","1758":"2016-10-25T20:56:08.552Z","1759":"2016-10-25T21:34:51.528Z","1760":"2016-10-26T09:09:29.277Z","1761":"2016-10-26T15:39:19.008Z","1762":"2016-10-26T15:39:34.635Z","1763":"2016-10-28T03:15:11.804Z","1764":"2016-10-30T05:18:04.379Z","1765":"2016-10-30T09:28:08.998Z","1766":"2016-11-02T15:30:48.801Z","1767":"2016-11-03T21:56:15.392Z","1768":"2016-11-04T16:42:16.201Z","1769":"2016-11-04T16:43:29.617Z","1770":"2016-11-05T06:16:03.374Z","1771":"2016-11-09T00:01:34.701Z","1772":"2016-11-09T00:01:43.378Z","1773":"2016-11-09T00:02:07.086Z","1774":"2016-11-09T00:02:58.468Z","1775":"2016-11-12T22:42:06.408Z","1776":"2016-11-12T22:42:15.508Z","1777":"2016-11-13T16:40:08.343Z","1778":"2016-11-17T16:10:19.166Z","1779":"2016-11-17T16:10:29.815Z","1780":"2016-11-17T16:11:45.813Z","1781":"2016-11-17T16:13:41.711Z","1782":"2016-11-17T16:14:35.311Z","1783":"2016-11-17T16:17:30.206Z","1784":"2016-11-22T08:31:44.575Z","1785":"2016-11-22T19:51:12.262Z","1786":"2016-11-22T19:51:29.360Z","1787":"2016-11-22T19:52:00.602Z","1788":"2016-11-22T20:44:25.847Z","1789":"2016-11-30T15:27:58.899Z","1790":"2016-11-30T15:28:05.798Z","1791":"2016-12-01T04:52:48.892Z","1792":"2016-12-02T07:03:37.503Z","1793":"2016-12-02T07:04:58.988Z","1794":"2016-12-02T08:00:09.312Z","1795":"2016-12-02T08:02:00.406Z","1796":"2016-12-02T08:28:17.694Z","1797":"2016-12-02T08:28:21.011Z","1798":"2016-12-02T08:28:26.752Z","1799":"2016-12-02T14:41:04.434Z","1800":"2016-12-07T00:43:37.822Z","1801":"2016-12-07T00:44:35.963Z","1802":"2016-12-07T00:46:14.991Z","1803":"2016-12-07T00:53:11.892Z","1804":"2016-12-07T00:55:31.751Z","1805":"2016-12-07T00:56:33.704Z","1806":"2016-12-07T08:09:51.743Z","1807":"2016-12-07T21:44:11.231Z","1808":"2016-12-07T21:45:20.970Z","1809":"2016-12-18T20:31:49.649Z","1810":"2016-12-19T15:11:51.979Z","1811":"2016-12-20T05:07:46.789Z","1812":"2016-12-20T09:00:37.933Z","1813":"2016-12-20T09:07:28.376Z","1814":"2016-12-20T13:49:20.540Z","1815":"2016-12-20T13:51:06.991Z","1816":"2016-12-22T13:25:52.520Z","1817":"2016-12-23T03:44:58.547Z","1818":"2016-12-23T19:15:23.624Z","1819":"2016-12-23T19:16:28.038Z","1820":"2016-12-23T19:16:51.507Z","1821":"2016-12-23T19:30:24.240Z","1822":"2016-12-23T19:32:18.047Z","1823":"2016-12-23T19:40:00.710Z","1824":"2016-12-23T20:26:51.834Z","1825":"2016-12-25T01:52:03.289Z","1826":"2016-12-29T16:00:12.994Z","1827":"2016-12-29T16:00:27.453Z","1828":"2016-12-29T16:02:21.538Z","1829":"2016-12-29T16:05:28.724Z","1830":"2017-01-01T05:59:13.126Z","1831":"2017-01-02T06:10:28.158Z","1832":"2017-01-02T22:18:41.751Z","1833":"2017-01-04T02:15:41.550Z","1834":"2017-01-04T02:17:16.225Z","1835":"2017-01-04T02:18:01.762Z","1836":"2017-01-04T02:20:13.010Z","1837":"2017-01-04T02:20:32.814Z","1838":"2017-01-04T07:54:43.698Z","1839":"2017-01-04T07:55:14.417Z","1840":"2017-01-04T07:55:43.946Z","1841":"2017-01-04T09:36:29.496Z","1842":"2017-01-04T09:37:03.693Z","1843":"2017-01-04T09:37:09.500Z","1844":"2017-01-04T09:37:38.869Z","1845":"2017-01-04T09:52:24.457Z","1846":"2017-01-04T09:53:41.248Z","1847":"2017-01-09T08:51:49.450Z","1848":"2017-01-09T09:04:09.416Z","1849":"2017-01-09T09:06:57.543Z","1850":"2017-01-09T20:02:38.646Z","1851":"2017-01-09T20:04:46.500Z","1852":"2017-01-11T09:38:36.178Z","1853":"2017-01-12T01:10:18.213Z","1854":"2017-01-12T01:10:52.125Z","1855":"2017-01-12T01:13:00.471Z","1856":"2017-01-12T01:55:17.421Z","1857":"2017-01-12T23:19:59.863Z","1858":"2017-01-13T02:18:06.490Z","1859":"2017-01-13T03:14:25.652Z","1860":"2017-01-17T00:16:55.039Z","1861":"2017-01-17T00:17:58.777Z","1862":"2017-01-18T16:48:11.555Z","1863":"2017-01-19T14:52:26.299Z","1864":"2017-02-14T21:40:09.282Z","1865":"2017-02-14T21:40:31.464Z","1866":"2017-02-14T23:56:18.768Z","1867":"2017-02-15T18:52:38.817Z","1868":"2017-02-15T18:53:08.768Z","1869":"2017-02-15T18:53:33.844Z","1870":"2017-02-15T18:54:05.846Z","1871":"2017-02-15T20:00:46.631Z","1872":"2017-02-15T20:00:53.291Z","1873":"2017-02-15T20:01:09.796Z","1874":"2017-02-15T20:01:11.130Z","1875":"2017-02-15T20:01:28.051Z","1876":"2017-02-15T20:01:49.935Z","1877":"2017-02-15T20:01:54.038Z","1878":"2017-02-15T22:53:33.249Z","1879":"2017-02-15T23:31:38.738Z","1880":"2017-02-16T06:43:34.741Z","1881":"2017-02-16T06:52:55.426Z","1882":"2017-02-23T08:21:59.330Z","1883":"2017-02-26T04:00:39.112Z","1884":"2017-02-26T04:00:41.689Z","1885":"2017-02-28T02:43:03.851Z","1886":"2017-02-28T02:46:07.333Z","1887":"2017-02-28T02:51:23.297Z","1888":"2017-02-28T02:52:34.960Z","1889":"2017-02-28T06:16:42.129Z","1890":"2017-03-01T01:38:13.345Z","1891":"2017-03-01T01:40:50.701Z","1892":"2017-03-01T08:07:57.673Z","1893":"2017-03-01T08:08:07.997Z","1894":"2017-03-03T00:11:33.160Z","1895":"2017-03-03T02:50:33.347Z","1896":"2017-03-03T02:52:44.790Z","1897":"2017-03-03T02:53:41.521Z","1898":"2017-03-03T06:54:01.210Z","1899":"2017-03-03T09:43:18.772Z","1900":"2017-03-05T06:21:53.880Z","1901":"2017-03-05T07:21:45.856Z","1902":"2017-03-05T11:17:31.604Z","1903":"2017-03-08T06:16:31.191Z","1904":"2017-03-09T02:04:59.790Z","1905":"2017-03-10T00:47:36.355Z","1906":"2017-03-10T00:48:12.234Z","1907":"2017-03-10T00:51:36.445Z","1908":"2017-03-10T07:19:02.534Z","1909":"2017-03-13T03:27:04.209Z","1910":"2017-03-13T03:34:17.300Z","1911":"2017-03-14T17:25:56.359Z","1912":"2017-03-15T11:26:50.828Z","1913":"2017-03-15T13:04:52.485Z","1914":"2017-03-16T00:53:09.693Z","1915":"2017-03-16T00:58:13.669Z","1916":"2017-03-16T01:06:03.917Z","1917":"2017-03-16T17:08:07.027Z","1918":"2017-03-16T17:08:39.386Z","1919":"2017-03-17T10:08:15.333Z","1920":"2017-03-18T12:58:57.238Z","1921":"2017-03-18T20:01:24.705Z","1922":"2017-03-20T00:39:36.761Z","1923":"2017-03-20T05:18:39.391Z","1924":"2017-03-20T05:19:31.475Z","1925":"2017-03-22T09:39:21.825Z","1926":"2017-03-22T09:39:38.879Z","1927":"2017-03-22T09:43:35.745Z","1928":"2017-03-22T09:43:36.652Z","1929":"2017-03-22T09:43:51.385Z","1930":"2017-03-22T09:48:43.751Z","1931":"2017-03-22T11:04:57.203Z","1932":"2017-03-22T12:02:26.108Z","1933":"2017-03-23T12:51:24.598Z","1934":"2017-03-28T16:55:42.378Z","1935":"2017-03-28T18:07:25.940Z","1936":"2017-03-28T18:23:59.187Z","1937":"2017-03-28T19:36:13.714Z","1938":"2017-03-31T02:02:33.785Z","1939":"2017-03-31T02:04:48.430Z","1940":"2017-03-31T02:06:35.654Z","1941":"2017-03-31T02:06:53.144Z","1942":"2017-03-31T04:12:09.891Z","1943":"2017-03-31T08:24:06.608Z","1944":"2017-03-31T08:26:10.919Z","1945":"2017-03-31T08:41:13.647Z","1946":"2017-03-31T09:25:18.594Z","1947":"2017-03-31T19:52:06.767Z","1948":"2017-04-03T21:38:04.106Z","1949":"2017-04-04T14:57:57.756Z","1950":"2017-04-06T16:06:41.426Z","1951":"2017-04-06T16:23:42.730Z","1952":"2017-04-07T22:25:21.555Z","1953":"2017-04-14T18:57:55.160Z","1954":"2017-04-14T18:58:02.398Z","1955":"2017-04-17T17:18:28.452Z","1956":"2017-04-19T08:10:31.607Z","1957":"2017-04-19T08:13:11.339Z","1958":"2017-04-19T08:22:18.273Z","1959":"2017-04-20T06:55:59.164Z","1960":"2017-04-20T16:31:07.432Z","1961":"2017-04-20T17:22:11.191Z","1962":"2017-04-20T17:25:17.018Z","1963":"2017-04-20T17:27:52.514Z","1964":"2017-04-20T17:29:39.234Z","1965":"2017-04-20T18:28:11.077Z","1966":"2017-04-20T21:42:40.197Z","1967":"2017-04-20T21:45:54.291Z","1968":"2017-04-20T22:02:31.914Z","1969":"2017-04-20T22:02:37.364Z","1970":"2017-04-20T22:48:59.743Z","1971":"2017-04-20T22:56:57.153Z","1972":"2017-04-21T00:02:59.329Z","1973":"2017-04-21T00:03:50.861Z","1974":"2017-04-21T00:13:39.783Z","1975":"2017-04-21T11:43:43.264Z","1976":"2017-04-21T21:27:19.170Z","1977":"2017-04-21T21:27:56.397Z","1978":"2017-04-21T21:28:06.156Z","1979":"2017-04-21T21:28:38.572Z","1980":"2017-04-21T22:12:37.831Z","1981":"2017-04-22T13:42:39.095Z","1982":"2017-04-22T13:44:25.567Z","1983":"2017-04-24T10:33:48.376Z","1984":"2017-04-24T14:31:15.821Z","1985":"2017-04-24T15:37:17.418Z","1986":"2017-04-24T17:32:04.272Z","1987":"2017-04-24T17:32:58.274Z","1988":"2017-04-26T13:18:14.211Z","1989":"2017-04-27T10:40:57.724Z","1990":"2017-04-27T14:16:56.216Z","1991":"2017-04-28T07:28:55.026Z","1992":"2017-04-28T07:36:39.946Z","1993":"2017-04-28T07:36:44.350Z","1994":"2017-04-28T08:11:38.843Z","1995":"2017-04-29T18:37:55.519Z","1996":"2017-04-29T18:53:21.493Z","1997":"2017-04-30T09:05:44.160Z","1998":"2017-05-03T12:59:32.849Z","1999":"2017-05-03T20:27:15.907Z","2000":"2017-05-04T01:20:02.685Z","2001":"2017-05-04T23:32:30.907Z","2002":"2017-05-04T23:37:15.898Z","2003":"2017-05-06T17:15:50.607Z","2004":"2017-05-06T17:15:52.466Z","2005":"2017-05-07T05:58:21.879Z","2006":"2017-05-07T06:13:03.726Z","2007":"2017-05-07T11:10:38.496Z","2008":"2017-05-09T07:52:48.831Z","2009":"2017-05-09T16:15:14.152Z","2010":"2017-05-11T00:12:33.273Z","2011":"2017-05-11T00:12:39.597Z","2012":"2017-05-11T00:14:07.052Z","2013":"2017-05-11T12:55:49.908Z","2014":"2017-05-11T17:43:56.896Z","2015":"2017-05-12T15:34:41.951Z","2016":"2017-05-15T19:33:37.722Z","2017":"2017-05-15T22:01:54.032Z","2018":"2017-05-16T23:00:33.779Z","2019":"2017-05-17T08:48:14.574Z","2020":"2017-05-17T16:21:53.020Z","2021":"2017-05-18T01:21:25.678Z","2022":"2017-05-18T01:41:08.484Z","2023":"2017-05-18T10:42:00.571Z","2024":"2017-05-18T13:05:43.499Z","2025":"2017-05-18T22:22:15.777Z","2026":"2017-05-18T22:31:15.877Z","2027":"2017-05-18T22:31:37.417Z","2028":"2017-05-18T22:43:12.426Z","2029":"2017-05-18T22:48:10.415Z","2030":"2017-05-18T22:50:15.135Z","2031":"2017-05-19T13:29:23.844Z","2032":"2017-05-19T13:29:33.848Z","2033":"2017-05-23T11:32:51.186Z","2034":"2017-05-24T03:56:29.455Z","2035":"2017-05-24T03:57:37.808Z","2036":"2017-05-24T14:29:06.150Z","2037":"2017-05-25T03:00:51.293Z","2038":"2017-05-25T03:02:17.509Z","2039":"2017-05-25T03:02:43.059Z","2040":"2017-05-25T07:03:53.295Z","2041":"2017-05-25T11:51:32.819Z","2042":"2017-05-27T20:14:43.980Z","2043":"2017-05-30T11:53:43.645Z","2044":"2017-05-30T11:55:10.896Z","2045":"2017-05-30T13:06:53.141Z","2046":"2017-05-31T20:06:12.352Z","2047":"2017-05-31T20:06:36.072Z","2048":"2017-06-03T13:45:40.762Z","2049":"2017-06-07T04:11:15.143Z","2050":"2017-06-07T07:26:02.261Z","2051":"2017-06-08T02:37:52.369Z","2052":"2017-06-11T18:20:29.795Z","2053":"2017-06-11T18:21:13.092Z","2054":"2017-06-11T18:21:34.747Z","2055":"2017-06-11T18:26:11.954Z","2056":"2017-06-11T18:33:26.725Z","2057":"2017-06-11T18:34:02.216Z","2058":"2017-06-12T17:13:37.742Z","2059":"2017-06-13T02:22:18.673Z","2060":"2017-06-17T11:38:13.893Z","2061":"2017-06-17T20:35:13.737Z","2062":"2017-06-21T06:10:00.056Z","2063":"2017-06-22T03:02:12.380Z","2064":"2017-06-22T03:02:29.117Z","2065":"2017-06-22T03:02:34.943Z","2066":"2017-06-22T03:02:48.617Z","2067":"2017-06-22T03:05:48.479Z","2068":"2017-06-23T17:48:38.881Z","2069":"2017-06-24T02:01:30.954Z","2070":"2017-06-24T02:02:01.129Z","2071":"2017-06-24T02:02:08.136Z","2072":"2017-06-24T02:02:17.103Z","2073":"2017-06-24T02:02:40.173Z","2074":"2017-06-27T04:42:06.122Z","2075":"2017-06-27T04:42:20.282Z","2076":"2017-06-27T04:45:56.095Z","2077":"2017-06-29T13:58:03.938Z","2078":"2017-06-30T02:00:26.463Z","2079":"2017-06-30T02:02:48.150Z","2080":"2017-07-06T06:15:59.322Z","2081":"2017-07-06T16:57:44.251Z","2082":"2017-07-06T17:23:14.888Z","2083":"2017-07-06T18:45:57.029Z","2084":"2017-07-07T01:57:37.999Z","2085":"2017-07-07T08:33:44.469Z","2086":"2017-07-07T08:35:11.101Z","2087":"2017-07-07T08:48:56.413Z","2088":"2017-07-07T19:04:14.391Z","2089":"2017-07-14T10:04:47.617Z","2090":"2017-07-15T02:27:49.311Z","2091":"2017-07-15T19:05:22.318Z","2092":"2017-07-16T07:16:56.992Z","2093":"2017-07-18T22:53:18.900Z","2094":"2017-07-20T19:26:06.751Z","2095":"2017-07-21T03:40:10.294Z","2096":"2017-07-21T03:41:43.945Z","2097":"2017-07-21T03:46:52.095Z","2098":"2017-07-21T06:19:34.504Z","2099":"2017-07-21T12:25:06.656Z","2100":"2017-07-24T05:16:36.230Z","2101":"2017-07-24T05:18:04.208Z","2102":"2017-07-24T05:18:50.706Z","2103":"2017-07-24T05:19:53.593Z","2104":"2017-07-24T05:20:25.094Z","2105":"2017-07-24T20:06:35.138Z","2106":"2017-07-24T21:34:33.036Z","2107":"2017-07-25T00:00:34.562Z","2108":"2017-07-25T00:02:06.079Z","2109":"2017-07-25T14:50:16.737Z","2110":"2017-07-25T14:50:45.103Z","2111":"2017-07-25T14:50:55.210Z","2112":"2017-07-25T14:51:05.624Z","2113":"2017-07-27T06:00:21.651Z","2114":"2017-07-27T06:01:17.289Z","2115":"2017-07-27T06:37:53.818Z","2116":"2017-07-27T06:38:26.898Z","2117":"2017-07-27T06:40:03.160Z","2118":"2017-07-27T09:14:59.955Z","2119":"2017-07-27T09:19:42.498Z","2120":"2017-07-27T09:38:39.618Z","2121":"2017-07-27T17:56:42.579Z","2122":"2017-07-27T17:57:22.253Z","2123":"2017-07-27T20:48:44.802Z","2124":"2017-07-27T20:56:24.521Z","2125":"2017-07-27T20:56:32.481Z","2126":"2017-07-27T20:57:05.351Z","2127":"2017-07-27T20:57:29.670Z","2128":"2017-07-27T21:00:50.820Z","2129":"2017-07-27T21:01:01.582Z","2130":"2017-07-27T21:28:25.040Z","2131":"2017-07-27T21:30:32.119Z","2132":"2017-08-02T18:01:24.233Z","2133":"2017-08-04T00:58:47.196Z","2134":"2017-08-04T01:00:37.844Z","2135":"2017-08-04T01:01:08.583Z","2136":"2017-08-08T14:31:04.697Z","2137":"2017-08-08T16:15:17.463Z","2138":"2017-08-08T21:23:16.945Z","2139":"2017-08-08T23:28:20.506Z","2140":"2017-08-08T23:28:33.239Z","2141":"2017-08-08T23:30:51.850Z","2142":"2017-08-08T23:31:40.168Z","2143":"2017-08-09T03:42:01.476Z","2144":"2017-08-09T03:42:21.284Z","2145":"2017-08-09T03:43:18.905Z","2146":"2017-08-09T14:04:21.200Z","2147":"2017-08-12T22:28:40.231Z","2148":"2017-08-12T22:28:40.333Z","2149":"2017-08-12T22:29:27.238Z","2150":"2017-08-15T03:37:04.763Z","2151":"2017-08-15T21:55:18.890Z","2152":"2017-08-16T03:13:12.608Z","2153":"2017-08-28T14:56:40.114Z","2154":"2017-08-29T21:16:52.297Z","2155":"2017-08-30T09:17:32.158Z","2156":"2017-08-30T13:53:29.737Z","2157":"2017-09-04T12:03:12.449Z","2158":"2017-09-04T22:36:27.060Z","2159":"2017-09-04T22:37:45.387Z","2160":"2017-09-06T14:41:58.598Z","2161":"2017-09-14T16:40:54.349Z","2162":"2017-09-14T16:41:27.328Z","2163":"2017-09-15T15:13:34.690Z","2164":"2017-09-18T10:32:20.233Z","2165":"2017-09-18T15:35:16.335Z","2166":"2017-09-18T20:33:24.387Z","2167":"2017-09-18T20:35:11.633Z","2168":"2017-09-19T07:04:44.625Z","2169":"2017-09-19T07:05:03.864Z","2170":"2017-09-19T10:51:44.029Z","2171":"2017-09-19T15:31:02.555Z","2172":"2017-09-19T15:34:55.466Z","2173":"2017-09-19T15:36:07.874Z","2174":"2017-09-19T15:36:30.447Z","2175":"2017-09-20T11:35:44.500Z","2176":"2017-09-20T19:54:13.237Z","2177":"2017-09-20T20:52:45.550Z","2178":"2017-09-20T20:56:13.448Z","2179":"2017-09-21T22:11:08.009Z","2180":"2017-09-21T23:57:14.945Z","2181":"2017-09-25T09:48:32.911Z","2182":"2017-09-25T16:04:43.532Z","2183":"2017-09-25T17:15:13.072Z","2184":"2017-09-25T20:22:30.069Z","2185":"2017-09-30T01:01:08.276Z","2186":"2017-09-30T01:08:32.691Z","2187":"2017-10-01T04:37:41.976Z","2188":"2017-10-03T23:52:33.297Z","2189":"2017-10-04T09:03:42.467Z","2190":"2017-10-04T17:08:31.645Z","2191":"2017-10-04T17:09:28.071Z","2192":"2017-10-04T17:41:19.066Z","2193":"2017-10-09T12:16:48.592Z","2194":"2017-10-09T12:21:21.761Z","2195":"2017-10-09T12:23:22.563Z","2196":"2017-10-09T12:28:08.123Z","2197":"2017-10-09T18:13:26.515Z","2198":"2017-10-09T20:14:40.504Z","2199":"2017-10-10T09:13:01.168Z","2200":"2017-10-10T13:16:00.408Z","2201":"2017-10-10T18:17:01.955Z","2202":"2017-10-10T18:17:11.285Z","2203":"2017-10-10T18:17:39.123Z","2204":"2017-10-10T18:18:09.133Z","2205":"2017-10-10T18:26:26.867Z","2206":"2017-10-10T18:26:41.169Z","2207":"2017-10-11T00:56:32.438Z","2208":"2017-10-11T07:55:34.136Z","2209":"2017-10-11T07:59:29.015Z","2210":"2017-10-11T08:04:05.872Z","2211":"2017-10-11T11:10:03.551Z","2212":"2017-10-12T01:00:54.269Z","2213":"2017-10-12T04:17:46.706Z","2214":"2017-10-12T05:15:40.557Z","2215":"2017-10-12T19:49:41.892Z","2216":"2017-10-16T08:16:29.140Z","2217":"2017-10-16T08:16:38.482Z","2218":"2017-10-16T09:40:01.071Z","2219":"2017-10-18T00:59:01.567Z","2220":"2017-10-18T01:02:58.359Z","2221":"2017-10-18T01:03:48.531Z","2222":"2017-10-18T11:49:58.193Z","2223":"2017-10-19T10:18:10.348Z","2224":"2017-10-19T10:19:05.105Z","2225":"2017-10-23T03:11:41.408Z","2226":"2017-10-23T03:16:43.836Z","2227":"2017-10-30T05:48:23.809Z","2228":"2017-10-31T18:29:30.127Z","2229":"2017-10-31T18:52:28.461Z","2230":"2017-10-31T18:52:54.258Z","2231":"2017-10-31T19:05:59.541Z","2232":"2017-10-31T20:34:58.112Z","2233":"2017-11-01T11:27:31.228Z","2234":"2017-11-01T11:27:45.703Z","2235":"2017-11-01T11:28:46.217Z","2236":"2017-11-01T11:28:53.598Z","2237":"2017-11-01T11:28:59.642Z","2238":"2017-11-01T11:29:26.943Z","2239":"2017-11-01T11:29:39.147Z","2240":"2017-11-01T11:31:13.466Z","2241":"2017-11-02T21:51:45.375Z","2242":"2017-11-02T21:52:12.381Z","2243":"2017-11-02T21:52:34.073Z","2244":"2017-11-07T05:11:47.177Z","2245":"2017-11-07T18:46:04.856Z","2246":"2017-11-07T18:54:59.994Z","2247":"2017-11-07T19:07:37.276Z","2248":"2017-11-08T00:23:36.171Z","2249":"2017-11-08T00:32:24.351Z","2250":"2017-11-08T01:38:56.118Z","2251":"2017-11-08T01:39:17.742Z","2252":"2017-11-08T01:43:25.802Z","2253":"2017-11-08T02:41:43.806Z","2254":"2017-11-08T02:43:12.795Z","2255":"2017-11-08T02:44:09.816Z","2256":"2017-11-08T02:44:18.564Z","2257":"2017-11-08T09:30:30.556Z","2258":"2017-11-08T09:36:58.878Z","2259":"2017-11-08T09:39:18.165Z","2260":"2017-11-08T09:39:47.155Z","2261":"2017-11-08T09:47:09.402Z","2262":"2017-11-09T00:00:40.505Z","2263":"2017-11-09T00:03:09.827Z","2264":"2017-11-09T11:26:03.993Z","2265":"2017-11-15T01:32:57.776Z","2266":"2017-11-15T03:36:03.086Z","2267":"2017-11-15T03:37:41.600Z","2268":"2017-11-16T07:14:40.585Z","2269":"2017-11-16T20:00:09.193Z","2270":"2017-11-16T20:00:31.035Z","2271":"2017-11-19T21:54:18.194Z","2272":"2017-11-21T06:23:30.055Z","2273":"2017-11-21T06:33:55.093Z","2274":"2017-11-21T06:34:39.108Z","2275":"2017-11-21T06:35:34.378Z","2276":"2017-11-30T19:38:32.512Z","2277":"2017-11-30T19:38:36.633Z","2278":"2017-12-04T09:16:27.974Z","2279":"2017-12-04T14:50:39.811Z","2280":"2017-12-04T18:27:46.678Z","2281":"2017-12-05T23:21:49.149Z","2282":"2017-12-06T00:52:04.240Z","2283":"2017-12-06T00:52:45.396Z","2284":"2017-12-06T00:55:41.870Z","2285":"2017-12-06T03:20:03.543Z","2286":"2017-12-06T05:49:11.546Z","2287":"2017-12-06T08:01:27.384Z","2288":"2017-12-06T08:02:01.687Z","2289":"2017-12-06T17:30:13.268Z","2290":"2017-12-09T02:07:40.089Z","2291":"2017-12-09T02:08:21.757Z","2292":"2017-12-09T02:11:37.217Z","2293":"2017-12-09T02:13:56.084Z","2294":"2017-12-09T07:24:50.332Z","2295":"2017-12-11T03:34:33.742Z","2296":"2017-12-11T16:00:04.329Z","2297":"2017-12-12T14:10:14.565Z","2298":"2017-12-13T00:25:49.347Z","2299":"2017-12-15T12:19:04.918Z","2300":"2017-12-16T00:29:30.737Z","2301":"2017-12-18T17:17:43.828Z","2302":"2017-12-19T06:36:52.067Z","2303":"2017-12-19T13:49:54.940Z","2304":"2017-12-19T13:52:40.098Z","2305":"2017-12-19T21:28:52.118Z","2306":"2017-12-19T21:29:10.858Z","2307":"2017-12-19T21:30:02.420Z","2308":"2017-12-20T18:52:08.746Z","2309":"2017-12-20T20:06:52.127Z","2310":"2017-12-21T03:47:42.784Z","2311":"2017-12-21T20:23:03.697Z","2312":"2017-12-23T06:01:08.083Z","2313":"2017-12-23T06:04:01.598Z","2314":"2017-12-23T18:57:42.165Z","2315":"2017-12-23T18:58:06.785Z","2316":"2017-12-26T05:31:19.157Z","2317":"2017-12-26T05:34:36.355Z","2318":"2018-01-02T07:48:35.466Z","2319":"2018-01-02T07:48:41.221Z","2320":"2018-01-02T18:37:01.057Z","2321":"2018-01-03T04:30:39.748Z","2322":"2018-01-03T15:44:44.432Z","2323":"2018-01-03T20:24:04.745Z","2324":"2018-01-03T20:28:25.140Z","2325":"2018-01-04T06:36:03.209Z","2326":"2018-01-04T06:36:21.419Z","2327":"2018-01-04T06:50:26.263Z","2328":"2018-01-04T07:13:55.114Z","2329":"2018-01-04T07:20:51.727Z","2330":"2018-01-04T10:31:50.941Z","2331":"2018-01-04T13:31:18.787Z","2332":"2018-01-08T18:37:54.780Z","2333":"2018-01-09T00:02:53.121Z","2334":"2018-01-09T00:03:25.351Z","2335":"2018-01-09T08:35:26.132Z","2336":"2018-01-09T08:35:56.655Z","2337":"2018-01-09T13:44:03.100Z","2338":"2018-01-09T14:29:59.329Z","2339":"2018-01-09T15:50:29.374Z","2340":"2018-01-09T17:49:26.263Z","2341":"2018-01-09T20:07:51.740Z","2342":"2018-01-09T20:50:57.074Z","2343":"2018-01-09T20:51:54.488Z","2344":"2018-01-09T20:55:50.827Z","2345":"2018-01-09T20:56:43.744Z","2346":"2018-01-09T20:56:51.809Z","2347":"2018-01-09T20:58:06.516Z","2348":"2018-01-10T08:04:42.852Z","2349":"2018-01-10T13:43:05.329Z","2350":"2018-01-10T13:43:28.483Z","2351":"2018-01-10T15:19:18.414Z","2352":"2018-01-10T15:40:24.663Z","2353":"2018-01-10T15:53:41.718Z","2354":"2018-01-10T19:15:19.522Z","2355":"2018-01-11T09:16:03.791Z","2356":"2018-01-11T19:29:21.692Z","2357":"2018-01-11T19:30:36.400Z","2358":"2018-01-11T19:52:08.915Z","2359":"2018-01-11T19:58:52.980Z","2360":"2018-01-11T20:09:20.980Z","2361":"2018-01-11T20:10:20.469Z","2362":"2018-01-11T20:10:25.357Z","2363":"2018-01-11T20:11:00.102Z","2364":"2018-01-11T20:15:31.005Z","2365":"2018-01-11T20:19:07.085Z","2366":"2018-01-11T20:19:43.746Z","2367":"2018-01-11T20:20:28.119Z","2368":"2018-01-11T20:21:27.494Z","2369":"2018-01-11T20:23:22.602Z","2370":"2018-01-11T20:23:38.707Z","2371":"2018-01-11T21:58:37.035Z","2372":"2018-01-12T04:04:30.420Z","2373":"2018-01-12T07:01:25.552Z","2374":"2018-01-12T07:58:57.495Z","2375":"2018-01-12T07:59:12.418Z","2376":"2018-01-12T08:00:11.377Z","2377":"2018-01-12T08:00:28.058Z","2378":"2018-01-12T08:11:21.559Z","2379":"2018-01-12T08:12:50.433Z","2380":"2018-01-12T08:14:29.742Z","2381":"2018-01-12T09:06:19.021Z","2382":"2018-01-12T10:39:14.967Z","2383":"2018-01-12T12:41:18.220Z","2384":"2018-01-12T12:45:16.576Z","2385":"2018-01-12T12:52:24.042Z","2386":"2018-01-12T13:02:39.524Z","2387":"2018-01-12T14:11:59.875Z","2388":"2018-01-12T17:21:10.659Z","2389":"2018-01-12T20:08:52.876Z","2390":"2018-01-15T07:15:23.450Z","2391":"2018-01-15T08:25:51.065Z","2392":"2018-01-15T08:27:37.545Z","2393":"2018-01-15T08:30:03.739Z","2394":"2018-01-15T09:44:41.927Z","2395":"2018-01-15T16:24:18.980Z","2396":"2018-01-15T20:25:34.704Z","2397":"2018-01-16T14:51:53.261Z","2398":"2018-01-16T20:53:29.288Z","2399":"2018-01-17T09:17:49.793Z","2400":"2018-01-17T09:18:11.735Z","2401":"2018-01-17T15:04:20.794Z","2402":"2018-01-17T18:45:09.625Z","2403":"2018-01-17T23:31:42.728Z","2404":"2018-01-17T23:34:39.599Z","2405":"2018-01-17T23:36:11.043Z","2406":"2018-01-17T23:41:48.829Z","2407":"2018-01-17T23:43:18.279Z","2408":"2018-01-17T23:44:48.907Z","2409":"2018-01-17T23:52:42.418Z","2410":"2018-01-17T23:54:44.157Z","2411":"2018-01-18T12:19:28.976Z","2412":"2018-01-18T12:19:45.270Z","2413":"2018-01-18T12:20:29.124Z","2414":"2018-01-18T12:28:41.265Z","2415":"2018-01-18T17:36:04.578Z","2416":"2018-01-19T01:10:19.872Z","2417":"2018-01-19T02:22:15.748Z","2418":"2018-01-19T04:54:15.632Z","2419":"2018-01-19T07:06:11.894Z","2420":"2018-01-19T07:09:16.305Z","2421":"2018-01-19T07:25:18.495Z","2422":"2018-01-19T10:39:30.537Z","2423":"2018-01-19T18:05:16.872Z","2424":"2018-01-19T18:08:50.955Z","2425":"2018-01-19T21:12:07.056Z","2426":"2018-01-19T21:12:50.020Z","2427":"2018-01-19T21:14:22.539Z","2428":"2018-01-19T21:14:57.833Z","2429":"2018-01-19T21:16:10.455Z","2430":"2018-01-20T06:21:04.016Z","2431":"2018-01-20T06:27:00.241Z","2432":"2018-01-20T06:39:00.289Z","2433":"2018-01-20T06:39:23.688Z","2434":"2018-01-20T06:40:52.726Z","2435":"2018-01-20T07:47:37.581Z","2436":"2018-01-20T07:48:06.085Z","2437":"2018-01-20T07:48:46.514Z","2438":"2018-01-20T07:51:35.095Z","2439":"2018-01-20T08:10:55.836Z","2440":"2018-01-20T08:11:58.230Z","2441":"2018-01-20T08:17:23.686Z","2442":"2018-01-20T08:17:56.603Z","2443":"2018-01-20T08:18:21.544Z","2444":"2018-01-20T08:18:42.701Z","2445":"2018-01-20T08:18:55.676Z","2446":"2018-01-20T08:18:55.786Z","2447":"2018-01-20T08:19:12.188Z","2448":"2018-01-20T08:20:08.974Z","2449":"2018-01-20T11:02:25.080Z","2450":"2018-01-20T11:20:14.761Z","2451":"2018-01-22T00:53:04.422Z","2452":"2018-01-22T00:54:49.939Z","2453":"2018-01-22T07:16:42.457Z","2454":"2018-01-22T07:23:08.428Z","2455":"2018-01-22T07:23:40.769Z","2456":"2018-01-22T07:23:49.833Z","2457":"2018-01-22T07:23:59.072Z","2458":"2018-01-22T08:55:57.538Z","2459":"2018-01-22T14:05:31.493Z","2460":"2018-01-22T14:08:22.854Z","2461":"2018-01-23T03:03:54.248Z","2462":"2018-01-23T03:11:46.865Z","2463":"2018-01-23T03:16:41.414Z","2464":"2018-01-23T03:26:27.283Z","2465":"2018-01-23T07:02:15.281Z","2466":"2018-01-23T07:33:00.660Z","2467":"2018-01-23T07:34:19.245Z","2468":"2018-01-23T07:35:40.574Z","2469":"2018-01-23T07:35:52.483Z","2470":"2018-01-23T07:46:33.069Z","2471":"2018-01-23T08:15:13.421Z","2472":"2018-01-23T08:18:21.004Z","2473":"2018-01-23T08:21:02.011Z","2474":"2018-01-23T09:43:16.961Z","2475":"2018-01-23T11:41:17.529Z","2476":"2018-01-23T11:46:23.633Z","2477":"2018-01-23T12:11:51.137Z","2478":"2018-01-23T17:14:16.921Z","2479":"2018-01-23T19:53:59.778Z","2480":"2018-01-23T19:54:26.845Z","2481":"2018-01-24T02:08:11.932Z","2482":"2018-01-24T02:47:28.053Z","2483":"2018-01-24T02:47:54.507Z","2484":"2018-01-24T02:48:00.908Z","2485":"2018-01-24T02:56:35.813Z","2486":"2018-01-24T03:08:22.834Z","2487":"2018-01-24T03:44:00.965Z","2488":"2018-01-24T03:50:08.731Z","2489":"2018-01-24T03:51:12.547Z","2490":"2018-01-24T04:07:43.460Z","2491":"2018-01-24T04:08:41.456Z","2492":"2018-01-24T04:10:10.364Z","2493":"2018-01-24T04:10:37.330Z","2494":"2018-01-24T04:12:44.623Z","2495":"2018-01-24T05:00:30.647Z","2496":"2018-01-24T06:23:39.910Z","2497":"2018-01-24T06:25:17.032Z","2498":"2018-01-24T06:27:59.132Z","2499":"2018-01-24T06:32:11.899Z","2500":"2018-01-24T08:16:36.833Z","2501":"2018-01-24T09:22:39.520Z","2502":"2018-01-24T14:43:16.371Z","2503":"2018-01-24T14:49:37.515Z","2504":"2018-01-24T20:15:35.600Z","2505":"2018-01-26T01:22:47.801Z","2506":"2018-01-26T01:27:02.900Z","2507":"2018-01-26T01:27:30.270Z","2508":"2018-01-26T06:33:48.712Z","2509":"2018-01-30T01:22:00.632Z","2510":"2018-01-30T02:34:43.527Z","2511":"2018-01-30T07:02:05.254Z","2512":"2018-01-30T07:03:20.008Z","2513":"2018-01-31T07:00:02.090Z","2514":"2018-02-01T00:01:01.812Z","2515":"2018-02-01T01:31:45.146Z","2516":"2018-02-01T06:44:21.636Z","2517":"2018-02-01T08:42:01.386Z","2518":"2018-02-01T08:43:15.109Z","2519":"2018-02-01T08:43:33.817Z","2520":"2018-02-01T08:44:36.704Z","2521":"2018-02-01T08:44:44.952Z","2522":"2018-02-01T08:54:42.438Z","2523":"2018-02-01T08:57:15.612Z","2524":"2018-02-02T06:42:46.838Z","2525":"2018-02-02T07:35:52.389Z","2526":"2018-02-02T07:36:26.761Z","2527":"2018-02-02T07:37:40.618Z","2528":"2018-02-05T02:58:12.098Z","2529":"2018-02-05T19:41:21.360Z","2530":"2018-02-06T08:44:46.868Z","2531":"2018-02-06T09:15:59.650Z","2532":"2018-02-06T09:41:49.924Z","2533":"2018-02-06T18:43:53.820Z","2534":"2018-02-06T18:55:23.919Z","2535":"2018-02-06T18:57:30.025Z","2536":"2018-02-06T18:57:52.806Z","2537":"2018-02-06T18:57:57.332Z","2538":"2018-02-06T18:58:22.728Z","2539":"2018-02-06T19:28:09.670Z","2540":"2018-02-06T19:32:00.731Z","2541":"2018-02-06T19:32:14.495Z","2542":"2018-02-06T19:32:45.342Z","2543":"2018-02-06T19:33:09.555Z","2544":"2018-02-06T22:27:52.020Z","2545":"2018-02-06T22:28:20.187Z","2546":"2018-02-06T22:31:31.499Z","2547":"2018-02-06T22:41:15.745Z","2548":"2018-02-07T07:02:23.908Z","2549":"2018-02-07T08:58:14.244Z","2550":"2018-02-07T08:59:00.033Z","2551":"2018-02-07T10:14:35.541Z","2552":"2018-02-07T10:24:38.067Z","2553":"2018-02-07T10:32:42.093Z","2554":"2018-02-07T17:15:56.041Z","2555":"2018-02-07T20:03:02.959Z","2556":"2018-02-08T06:58:03.685Z","2557":"2018-02-08T06:59:34.077Z","2558":"2018-02-12T06:30:33.188Z","2559":"2018-02-12T08:15:37.310Z","2560":"2018-02-12T10:14:34.082Z","2561":"2018-02-12T21:56:16.051Z","2562":"2018-02-13T01:18:29.285Z","2563":"2018-02-13T01:20:11.869Z","2564":"2018-02-13T01:20:36.443Z","2565":"2018-02-13T01:21:16.218Z","2566":"2018-02-13T02:56:07.489Z","2567":"2018-02-13T14:03:00.898Z","2568":"2018-02-13T16:01:43.414Z","2569":"2018-02-13T16:11:34.705Z","2570":"2018-02-13T16:13:15.675Z","2571":"2018-02-13T16:26:17.430Z","2572":"2018-02-13T17:02:04.359Z","2573":"2018-02-13T17:03:16.069Z","2574":"2018-02-13T17:08:34.611Z","2575":"2018-02-13T17:09:21.938Z","2576":"2018-02-13T17:15:17.152Z","2577":"2018-02-13T17:15:57.427Z","2578":"2018-02-13T17:36:20.259Z","2579":"2018-02-13T17:39:10.418Z","2580":"2018-02-13T18:03:45.789Z","2581":"2018-02-13T18:05:17.378Z","2582":"2018-02-13T18:05:50.233Z","2583":"2018-02-13T18:32:04.180Z","2584":"2018-02-13T19:36:22.848Z","2585":"2018-02-13T19:36:44.644Z","2586":"2018-02-13T19:38:16.785Z","2587":"2018-02-13T19:48:10.223Z","2588":"2018-02-13T20:57:50.091Z","2589":"2018-02-13T22:37:33.311Z","2590":"2018-02-13T22:38:45.787Z","2591":"2018-02-13T22:42:29.304Z","2592":"2018-02-15T20:50:01.319Z","2593":"2018-02-15T20:50:09.282Z","2594":"2018-02-16T00:26:33.900Z","2595":"2018-02-16T00:26:42.354Z","2596":"2018-02-16T02:04:00.718Z","2597":"2018-02-16T14:42:48.886Z","2598":"2018-02-16T15:44:51.199Z","2599":"2018-02-18T04:40:17.480Z","2600":"2018-02-19T05:46:50.668Z","2601":"2018-02-19T05:47:54.207Z","2602":"2018-02-19T17:51:45.804Z","2603":"2018-02-20T04:29:15.415Z","2604":"2018-02-20T04:29:29.893Z","2605":"2018-02-20T04:37:39.403Z","2606":"2018-02-20T11:15:09.954Z","2607":"2018-02-20T11:16:23.837Z","2608":"2018-02-20T17:27:06.786Z","2609":"2018-02-20T17:29:13.106Z","2610":"2018-02-20T18:00:06.224Z","2611":"2018-02-20T20:06:33.030Z","2612":"2018-02-21T13:05:51.102Z","2613":"2018-02-21T14:21:50.359Z","2614":"2018-02-21T16:33:51.375Z","2615":"2018-02-21T16:34:12.092Z","2616":"2018-02-21T18:31:20.748Z","2617":"2018-02-21T18:44:14.780Z","2618":"2018-02-21T19:40:00.405Z","2619":"2018-02-21T19:40:24.094Z","2620":"2018-02-22T07:28:28.048Z","2621":"2018-02-22T09:01:12.911Z","2622":"2018-02-22T11:32:25.347Z","2623":"2018-02-22T21:31:58.213Z","2624":"2018-02-22T21:32:06.518Z","2625":"2018-02-22T21:32:08.892Z","2626":"2018-02-22T21:33:03.167Z","2627":"2018-02-22T21:33:17.848Z","2628":"2018-02-23T03:17:15.216Z","2629":"2018-02-23T16:28:51.654Z","2630":"2018-02-23T16:38:22.721Z","2631":"2018-02-25T02:41:11.503Z","2632":"2018-02-25T02:42:07.035Z","2633":"2018-02-25T02:43:32.960Z","2634":"2018-02-25T02:49:22.122Z","2635":"2018-02-25T02:49:32.027Z","2636":"2018-02-25T03:23:38.733Z","2637":"2018-02-25T10:57:36.388Z","2638":"2018-02-25T10:59:00.123Z","2639":"2018-02-25T21:44:53.620Z","2640":"2018-02-25T21:46:06.447Z","2641":"2018-02-25T21:52:51.475Z","2642":"2018-02-25T21:58:15.244Z","2643":"2018-02-25T22:12:09.288Z","2644":"2018-02-25T22:12:33.091Z","2645":"2018-02-25T22:13:05.016Z","2646":"2018-02-25T22:14:57.589Z","2647":"2018-02-25T22:15:34.471Z","2648":"2018-02-25T22:16:02.073Z","2649":"2018-02-25T22:19:22.773Z","2650":"2018-02-25T22:22:24.574Z","2651":"2018-02-25T22:22:42.033Z","2652":"2018-02-25T22:23:11.964Z","2653":"2018-02-25T22:23:13.712Z","2654":"2018-02-25T22:26:35.119Z","2655":"2018-02-25T22:26:40.245Z","2656":"2018-02-26T01:44:43.993Z","2657":"2018-02-26T01:45:52.835Z","2658":"2018-02-26T01:47:38.759Z","2659":"2018-02-26T02:24:12.086Z","2660":"2018-02-26T18:09:40.238Z","2661":"2018-02-26T18:10:40.157Z","2662":"2018-02-26T18:10:51.273Z","2663":"2018-02-26T18:11:53.732Z","2664":"2018-02-26T18:12:37.768Z","2665":"2018-02-26T18:13:15.669Z","2666":"2018-02-26T18:13:42.769Z","2667":"2018-02-26T18:38:15.254Z","2668":"2018-02-26T18:39:26.195Z","2669":"2018-02-26T18:39:40.229Z","2670":"2018-02-26T18:45:27.877Z","2671":"2018-02-26T22:07:41.271Z","2672":"2018-02-26T22:22:27.530Z","2673":"2018-02-26T23:33:47.791Z","2674":"2018-02-27T01:12:14.073Z","2675":"2018-02-27T01:15:04.371Z","2676":"2018-02-27T01:16:53.918Z","2677":"2018-02-27T01:17:31.418Z","2678":"2018-02-27T01:17:56.264Z","2679":"2018-02-27T01:18:55.926Z","2680":"2018-02-27T01:19:24.999Z","2681":"2018-02-27T01:20:51.809Z","2682":"2018-02-27T01:21:40.627Z","2683":"2018-02-27T01:22:55.841Z","2684":"2018-02-27T01:23:40.425Z","2685":"2018-02-27T01:26:58.045Z","2686":"2018-02-27T01:27:55.000Z","2687":"2018-02-27T01:28:19.889Z","2688":"2018-02-27T01:28:31.080Z","2689":"2018-02-27T23:40:32.726Z","2690":"2018-02-27T23:41:01.827Z","2691":"2018-02-27T23:41:25.557Z","2692":"2018-02-27T23:42:21.998Z","2693":"2018-02-27T23:43:18.936Z","2694":"2018-02-28T07:50:26.077Z","2695":"2018-02-28T07:55:16.525Z","2696":"2018-02-28T10:04:24.412Z","2697":"2018-02-28T10:04:33.203Z","2698":"2018-02-28T16:48:26.606Z","2699":"2018-02-28T16:51:05.888Z","2700":"2018-02-28T16:52:51.047Z","2701":"2018-03-01T21:07:51.796Z","2702":"2018-03-01T21:08:38.307Z","2703":"2018-03-02T02:31:10.441Z","2704":"2018-03-04T16:23:59.826Z","2705":"2018-03-04T20:57:25.420Z","2706":"2018-03-04T20:57:51.329Z","2707":"2018-03-04T20:58:01.459Z","2708":"2018-03-05T08:29:33.853Z","2709":"2018-03-05T08:37:41.574Z","2710":"2018-03-05T23:06:32.157Z","2711":"2018-03-06T04:57:54.719Z","2712":"2018-03-06T12:26:01.515Z","2713":"2018-03-06T13:03:43.513Z","2714":"2018-03-06T13:07:00.211Z","2715":"2018-03-06T14:47:11.358Z","2716":"2018-03-06T19:00:06.429Z","2717":"2018-03-06T19:01:21.318Z","2718":"2018-03-06T19:01:37.537Z","2719":"2018-03-07T06:30:35.001Z","2720":"2018-03-07T06:55:57.382Z","2721":"2018-03-07T07:02:43.984Z","2722":"2018-03-07T07:04:40.163Z","2723":"2018-03-07T07:05:11.464Z","2724":"2018-03-07T07:05:50.276Z","2725":"2018-03-07T07:06:11.945Z","2726":"2018-03-07T07:06:18.716Z","2727":"2018-03-07T07:06:56.793Z","2728":"2018-03-07T07:07:04.889Z","2729":"2018-03-07T07:08:25.245Z","2730":"2018-03-07T07:08:47.546Z","2731":"2018-03-07T07:08:55.333Z","2732":"2018-03-07T07:09:17.967Z","2733":"2018-03-07T07:12:53.102Z","2734":"2018-03-07T07:13:13.603Z","2735":"2018-03-07T07:18:41.933Z","2736":"2018-03-07T07:19:12.105Z","2737":"2018-03-07T07:19:26.331Z","2738":"2018-03-07T07:21:23.276Z","2739":"2018-03-07T07:23:09.489Z","2740":"2018-03-07T16:03:19.411Z","2741":"2018-03-07T16:04:59.323Z","2742":"2018-03-07T19:24:14.517Z","2743":"2018-03-08T03:02:00.112Z","2744":"2018-03-08T03:03:05.185Z","2745":"2018-03-08T12:14:02.257Z","2746":"2018-03-08T12:17:59.800Z","2747":"2018-03-08T15:47:09.615Z","2748":"2018-03-08T16:27:48.520Z","2749":"2018-03-09T04:01:56.033Z","2750":"2018-03-09T04:02:03.010Z","2751":"2018-03-09T07:02:25.517Z","2752":"2018-03-09T07:03:09.317Z","2753":"2018-03-09T07:03:53.968Z","2754":"2018-03-09T07:04:02.608Z","2755":"2018-03-09T07:04:51.287Z","2756":"2018-03-09T07:06:32.668Z","2757":"2018-03-09T07:07:16.783Z","2758":"2018-03-09T07:28:07.046Z","2759":"2018-03-09T08:11:57.022Z","2760":"2018-03-09T08:15:37.344Z","2761":"2018-03-09T08:16:14.516Z","2762":"2018-03-09T17:55:58.549Z","2763":"2018-03-09T17:56:32.876Z","2764":"2018-03-09T18:11:25.966Z","2765":"2018-03-09T18:33:11.754Z","2766":"2018-03-09T19:40:07.667Z","2767":"2018-03-09T19:40:16.986Z","2768":"2018-03-09T19:41:06.152Z","2769":"2018-03-10T00:53:05.227Z","2770":"2018-03-10T00:54:16.231Z","2771":"2018-03-10T00:54:30.487Z","2772":"2018-03-10T00:55:05.413Z","2773":"2018-03-10T17:35:52.007Z","2774":"2018-03-10T17:36:03.881Z","2775":"2018-03-10T17:37:52.386Z","2776":"2018-03-10T22:05:17.573Z","2777":"2018-03-10T22:57:17.559Z","2778":"2018-03-10T23:02:22.177Z","2779":"2018-03-10T23:02:53.267Z","2780":"2018-03-11T00:11:00.936Z","2781":"2018-03-11T02:42:00.069Z","2782":"2018-03-11T03:59:51.189Z","2783":"2018-03-11T04:00:09.901Z","2784":"2018-03-11T04:00:35.248Z","2785":"2018-03-11T04:07:24.656Z","2786":"2018-03-11T06:17:20.899Z","2787":"2018-03-11T13:31:13.577Z","2788":"2018-03-11T14:45:32.436Z","2789":"2018-03-11T22:11:48.496Z","2790":"2018-03-11T22:12:14.364Z","2791":"2018-03-11T22:14:12.825Z","2792":"2018-03-11T22:14:21.391Z","2793":"2018-03-11T22:33:14.694Z","2794":"2018-03-11T22:33:33.586Z","2795":"2018-03-12T06:23:53.004Z","2796":"2018-03-12T06:30:08.794Z","2797":"2018-03-12T14:08:50.289Z","2798":"2018-03-12T16:47:18.634Z","2799":"2018-03-13T01:17:46.438Z","2800":"2018-03-13T02:56:04.722Z","2801":"2018-03-13T02:57:07.427Z","2802":"2018-03-13T02:57:31.522Z","2803":"2018-03-13T02:59:14.756Z","2804":"2018-03-13T03:00:01.560Z","2805":"2018-03-13T03:00:33.245Z","2806":"2018-03-13T11:48:16.325Z","2807":"2018-03-13T12:35:23.667Z","2808":"2018-03-13T13:25:45.510Z","2809":"2018-03-13T18:59:01.567Z","2810":"2018-03-13T19:04:38.951Z","2811":"2018-03-14T11:13:11.917Z","2812":"2018-03-14T11:54:41.886Z","2813":"2018-03-14T15:33:19.880Z","2814":"2018-03-14T15:35:12.540Z","2815":"2018-03-14T15:35:59.012Z","2816":"2018-03-14T15:36:19.740Z","2817":"2018-03-14T15:36:35.810Z","2818":"2018-03-14T15:43:52.261Z","2819":"2018-03-15T04:53:48.631Z","2820":"2018-03-15T06:30:47.066Z","2821":"2018-03-15T08:46:02.660Z","2822":"2018-03-15T08:47:22.049Z","2823":"2018-03-15T08:47:39.623Z","2824":"2018-03-15T18:18:42.620Z","2825":"2018-03-15T18:19:48.414Z","2826":"2018-03-15T19:48:45.584Z","2827":"2018-03-15T20:15:38.779Z","2828":"2018-03-15T20:18:18.949Z","2829":"2018-03-16T01:54:39.390Z","2830":"2018-03-16T01:55:28.573Z","2831":"2018-03-16T06:10:50.990Z","2832":"2018-03-16T07:29:33.541Z","2833":"2018-03-16T10:03:34.619Z","2834":"2018-03-16T17:53:08.922Z","2835":"2018-03-16T17:56:15.244Z","2836":"2018-03-16T19:38:49.960Z","2837":"2018-03-16T19:39:01.349Z","2838":"2018-03-17T10:22:05.142Z","2839":"2018-03-17T10:23:27.291Z","2840":"2018-03-17T19:05:59.152Z","2841":"2018-03-17T19:06:18.510Z","2842":"2018-03-19T13:08:54.771Z","2843":"2018-03-19T13:27:09.077Z","2844":"2018-03-19T16:29:05.261Z","2845":"2018-03-19T18:58:14.817Z","2846":"2018-03-19T22:11:17.911Z","2847":"2018-03-19T22:12:30.615Z","2848":"2018-03-20T10:23:54.140Z","2849":"2018-03-20T12:15:21.236Z","2850":"2018-03-20T23:02:12.681Z","2851":"2018-03-21T04:08:04.494Z","2852":"2018-03-21T19:19:44.988Z","2853":"2018-03-21T19:19:53.567Z","2854":"2018-03-22T03:50:21.787Z","2855":"2018-03-22T03:50:47.177Z","2856":"2018-03-22T03:52:22.206Z","2857":"2018-03-22T03:53:30.678Z","2858":"2018-03-22T03:53:44.246Z","2859":"2018-03-22T03:53:48.847Z","2860":"2018-03-22T07:34:54.914Z","2861":"2018-03-22T07:36:27.834Z","2862":"2018-03-22T07:37:10.538Z","2863":"2018-03-22T10:39:44.250Z","2864":"2018-03-22T13:59:26.195Z","2865":"2018-03-23T08:45:22.472Z","2866":"2018-03-23T12:21:02.559Z","2867":"2018-03-23T15:26:01.670Z","2868":"2018-03-23T17:10:22.464Z","2869":"2018-03-26T14:02:37.713Z","2870":"2018-03-26T14:46:51.248Z","2871":"2018-03-27T16:14:04.658Z","2872":"2018-03-27T16:15:17.120Z","2873":"2018-03-27T16:15:41.996Z","2874":"2018-03-27T16:16:39.421Z","2875":"2018-03-27T16:17:06.846Z","2876":"2018-03-27T16:18:31.567Z","2877":"2018-03-27T17:09:45.757Z","2878":"2018-03-27T18:00:26.656Z","2879":"2018-03-27T21:25:21.319Z","2880":"2018-03-28T11:23:40.364Z","2881":"2018-03-28T11:25:15.038Z","2882":"2018-03-28T11:25:53.883Z","2883":"2018-03-28T11:26:53.097Z","2884":"2018-03-28T19:06:30.983Z","2885":"2018-04-05T15:48:56.439Z","2886":"2018-04-09T06:07:58.426Z","2887":"2018-04-09T17:57:56.442Z","2888":"2018-04-09T17:57:59.899Z","2889":"2018-04-09T17:58:46.282Z","2890":"2018-04-09T17:59:30.529Z","2891":"2018-04-09T19:03:32.106Z","2892":"2018-04-09T19:04:01.897Z","2893":"2018-04-09T19:04:09.289Z","2894":"2018-04-09T19:04:42.766Z","2895":"2018-04-09T21:00:58.543Z","2896":"2018-04-09T21:01:49.706Z","2897":"2018-04-10T06:27:35.831Z","2898":"2018-04-10T08:45:45.192Z","2899":"2018-04-11T01:14:26.937Z","2900":"2018-04-11T01:55:07.471Z","2901":"2018-04-11T21:33:52.510Z","2902":"2018-04-13T18:25:12.464Z","2903":"2018-04-13T18:25:43.356Z","2904":"2018-04-13T18:26:56.218Z","2905":"2018-04-13T18:29:41.070Z","2906":"2018-04-13T18:31:20.992Z","2907":"2018-04-13T18:31:43.648Z","2908":"2018-04-13T18:32:08.325Z","2909":"2018-04-13T18:32:23.437Z","2910":"2018-04-13T18:32:30.921Z","2911":"2018-04-13T18:32:45.534Z","2912":"2018-04-13T18:33:00.454Z","2913":"2018-04-13T18:33:37.742Z","2914":"2018-04-13T18:34:00.680Z","2915":"2018-04-13T18:34:43.873Z","2916":"2018-04-13T18:38:38.244Z","2917":"2018-04-13T19:44:15.580Z","2918":"2018-04-13T19:44:31.277Z","2919":"2018-04-13T19:44:43.999Z","2920":"2018-04-13T19:45:40.032Z","2921":"2018-04-13T19:47:40.284Z","2922":"2018-04-13T19:48:22.726Z","2923":"2018-04-13T19:48:31.764Z","2924":"2018-04-13T19:49:03.892Z","2925":"2018-04-13T19:50:04.191Z","2926":"2018-04-13T19:50:12.819Z","2927":"2018-04-13T19:51:23.818Z","2928":"2018-04-13T19:51:38.976Z","2929":"2018-04-13T19:53:48.235Z","2930":"2018-04-13T19:54:01.113Z","2931":"2018-04-13T19:57:53.046Z","2932":"2018-04-13T21:03:58.515Z","2933":"2018-04-13T21:04:17.517Z","2934":"2018-04-13T21:04:37.830Z","2935":"2018-04-13T21:04:42.219Z","2936":"2018-04-15T16:27:32.405Z","2937":"2018-04-15T23:42:13.588Z","2938":"2018-04-15T23:42:54.901Z","2939":"2018-04-16T07:49:55.900Z","2940":"2018-04-16T07:50:16.203Z","2941":"2018-04-16T16:35:29.000Z","2942":"2018-04-16T16:39:26.492Z","2943":"2018-04-16T17:16:30.438Z","2944":"2018-04-16T18:24:54.419Z","2945":"2018-04-16T19:20:05.194Z","2946":"2018-04-16T19:20:11.706Z","2947":"2018-04-16T20:09:09.167Z","2948":"2018-04-17T07:28:40.255Z","2949":"2018-04-17T19:32:34.825Z","2950":"2018-04-18T01:55:13.737Z","2951":"2018-04-18T01:57:14.645Z","2952":"2018-04-18T03:26:05.567Z","2953":"2018-04-18T03:31:34.300Z","2954":"2018-04-18T03:32:07.949Z","2955":"2018-04-18T03:55:47.431Z","2956":"2018-04-18T07:33:02.091Z","2957":"2018-04-18T08:34:31.699Z","2958":"2018-04-18T09:53:27.333Z","2959":"2018-04-19T22:14:37.320Z","2960":"2018-04-19T22:15:10.153Z","2961":"2018-04-19T22:15:52.475Z","2962":"2018-04-20T13:18:26.836Z","2963":"2018-04-23T19:26:59.609Z","2964":"2018-04-23T19:27:02.149Z","2965":"2018-04-23T21:01:09.996Z","2966":"2018-04-24T03:14:39.367Z","2967":"2018-04-24T11:35:19.445Z","2968":"2018-04-24T21:36:16.512Z","2969":"2018-04-26T08:39:29.817Z","2970":"2018-04-26T12:58:15.857Z","2971":"2018-04-27T00:00:31.181Z","2972":"2018-04-27T01:58:07.022Z","2973":"2018-04-27T01:58:56.202Z","2974":"2018-04-27T02:03:17.371Z","2975":"2018-04-27T02:03:23.141Z","2976":"2018-04-27T02:38:57.556Z","2977":"2018-04-27T02:53:19.134Z","2978":"2018-04-27T09:27:14.359Z","2979":"2018-04-27T10:56:27.904Z","2980":"2018-04-27T18:57:02.664Z","2981":"2018-04-29T08:51:47.314Z","2982":"2018-04-30T18:06:59.214Z","2983":"2018-05-01T04:24:43.578Z","2984":"2018-05-01T04:25:03.484Z","2985":"2018-05-01T04:25:35.340Z","2986":"2018-05-01T04:25:40.708Z","2987":"2018-05-01T04:26:38.713Z","2988":"2018-05-01T19:57:19.483Z","2989":"2018-05-01T21:30:38.685Z","2990":"2018-05-01T21:31:06.886Z","2991":"2018-05-01T21:31:25.327Z","2992":"2018-05-01T21:32:55.480Z","2993":"2018-05-01T21:33:19.560Z","2994":"2018-05-01T21:46:21.975Z","2995":"2018-05-01T21:46:35.787Z","2996":"2018-05-02T05:33:29.390Z","2997":"2018-05-02T07:12:48.302Z","2998":"2018-05-02T07:25:13.103Z","2999":"2018-05-02T07:25:23.627Z","3000":"2018-05-02T17:45:21.523Z","3001":"2018-05-03T07:22:35.735Z","3002":"2018-05-03T15:29:56.707Z","3003":"2018-05-03T15:30:15.481Z","3004":"2018-05-03T18:03:23.376Z","3005":"2018-05-04T14:46:20.777Z","3006":"2018-05-10T03:23:44.061Z","3007":"2018-05-10T05:13:28.235Z","3008":"2018-05-10T05:20:16.105Z","3009":"2018-05-10T07:14:28.188Z","3010":"2018-05-11T03:50:48.554Z","3011":"2018-05-14T05:56:39.813Z","3012":"2018-05-16T14:24:48.819Z","3013":"2018-05-16T17:18:40.938Z","3014":"2018-05-21T05:18:04.037Z","3015":"2018-05-22T09:10:15.294Z","3016":"2018-05-22T09:20:57.999Z","3017":"2018-05-22T14:41:13.043Z","3018":"2018-05-23T03:02:56.425Z","3019":"2018-05-23T03:03:58.069Z","3020":"2018-05-23T03:04:27.343Z","3021":"2018-05-23T09:30:51.496Z","3022":"2018-05-23T09:31:01.698Z","3023":"2018-05-24T10:11:42.022Z","3024":"2018-05-25T00:46:24.150Z","3025":"2018-05-25T00:47:41.954Z","3026":"2018-05-25T03:04:47.491Z","3027":"2018-05-25T03:05:27.687Z","3028":"2018-05-25T03:22:11.456Z","3029":"2018-05-25T03:23:12.738Z","3030":"2018-05-25T10:08:15.649Z","3031":"2018-05-25T10:08:41.087Z","3032":"2018-05-25T16:51:14.088Z","3033":"2018-05-25T16:52:17.338Z","3034":"2018-05-25T16:53:38.429Z","3035":"2018-05-25T16:55:47.856Z","3036":"2018-05-25T16:56:44.413Z","3037":"2018-05-25T16:56:57.656Z","3038":"2018-05-25T16:59:28.229Z","3039":"2018-05-25T17:02:15.996Z","3040":"2018-05-25T17:05:17.413Z","3041":"2018-05-25T17:35:35.942Z","3042":"2018-05-28T08:47:01.062Z","3043":"2018-05-29T00:42:20.795Z","3044":"2018-05-29T00:42:45.544Z","3045":"2018-05-29T00:43:24.830Z","3046":"2018-05-29T00:45:29.340Z","3047":"2018-05-29T18:41:16.675Z","3048":"2018-05-29T19:45:23.380Z","3049":"2018-05-29T19:45:42.857Z","3050":"2018-05-29T20:11:49.645Z","3051":"2018-05-30T14:43:59.903Z","3052":"2018-05-30T20:46:12.969Z","3053":"2018-05-31T17:47:47.612Z","3054":"2018-05-31T17:48:17.393Z","3055":"2018-05-31T17:49:29.805Z","3056":"2018-05-31T17:50:55.076Z","3057":"2018-05-31T17:51:57.930Z","3058":"2018-06-01T01:21:22.311Z","3059":"2018-06-01T01:23:13.771Z","3060":"2018-06-01T01:23:21.712Z","3061":"2018-06-04T11:32:18.531Z","3062":"2018-06-05T21:09:44.892Z","3063":"2018-06-05T22:21:52.360Z","3064":"2018-06-05T23:12:14.638Z","3065":"2018-06-14T07:48:14.144Z","3066":"2018-06-14T15:32:32.024Z","3067":"2018-06-15T07:18:57.267Z","3068":"2018-06-15T07:24:05.920Z","3069":"2018-06-15T20:00:10.435Z","3070":"2018-06-15T20:00:52.602Z","3071":"2018-06-18T22:27:36.404Z","3072":"2018-06-18T22:28:22.863Z","3073":"2018-06-19T00:01:42.224Z","3074":"2018-06-19T04:39:15.913Z","3075":"2018-06-20T16:55:02.807Z","3076":"2018-06-20T19:00:49.861Z","3077":"2018-06-21T03:15:15.791Z","3078":"2018-06-21T03:34:02.618Z","3079":"2018-06-21T20:43:39.858Z","3080":"2018-06-22T01:43:19.554Z","3081":"2018-06-22T01:50:45.352Z","3082":"2018-06-22T02:58:07.285Z","3083":"2018-06-22T19:14:37.803Z","3084":"2018-06-24T16:02:26.534Z","3085":"2018-06-24T22:12:14.095Z","3086":"2018-06-24T22:56:07.427Z","3087":"2018-06-25T11:55:02.532Z","3088":"2018-06-25T18:55:46.608Z","3089":"2018-06-26T01:04:21.014Z","3090":"2018-06-26T01:06:07.064Z","3091":"2018-06-26T05:25:42.729Z","3092":"2018-06-26T22:24:34.095Z","3093":"2018-06-27T07:33:10.026Z","3094":"2018-06-27T09:35:27.098Z","3095":"2018-06-27T10:13:33.441Z","3096":"2018-06-27T10:15:48.073Z","3097":"2018-06-28T04:55:47.042Z","3098":"2018-06-28T06:13:56.513Z","3099":"2018-06-28T17:43:42.077Z","3100":"2018-06-28T23:01:21.057Z","3101":"2018-06-28T23:05:35.833Z","3102":"2018-06-28T23:30:41.924Z","3103":"2018-06-29T01:24:53.467Z","3104":"2018-06-29T03:35:31.029Z","3105":"2018-06-29T20:26:13.636Z","3106":"2018-06-30T11:36:00.534Z","3107":"2018-07-02T17:51:01.126Z","3108":"2018-07-03T08:20:45.795Z","3109":"2018-07-03T15:12:41.106Z","3110":"2018-07-03T18:43:56.529Z","3111":"2018-07-11T14:16:04.698Z","3112":"2018-07-13T12:06:30.530Z","3113":"2018-07-16T08:27:20.517Z","3114":"2018-07-16T08:28:28.525Z","3115":"2018-07-17T12:36:35.786Z","3116":"2018-07-17T15:41:37.256Z","3117":"2018-07-17T20:51:38.206Z","3118":"2018-07-17T20:52:49.868Z","3119":"2018-07-17T20:53:24.480Z","3120":"2018-07-19T12:25:40.157Z","3121":"2018-07-19T20:43:00.081Z","3122":"2018-07-20T04:45:55.031Z","3123":"2018-07-20T08:25:45.510Z","3124":"2018-07-20T18:24:34.969Z","3125":"2018-07-20T20:27:41.692Z","3126":"2018-07-21T12:54:37.102Z","3127":"2018-07-22T00:10:19.251Z","3128":"2018-07-22T00:13:37.492Z","3129":"2018-07-22T09:16:01.818Z","3130":"2018-07-22T23:32:16.369Z","3131":"2018-07-22T23:32:35.216Z","3132":"2018-07-23T07:55:51.343Z","3133":"2018-07-23T10:44:57.025Z","3134":"2018-07-25T20:43:37.794Z","3135":"2018-07-25T20:46:58.295Z","3136":"2018-07-27T01:36:55.800Z","3137":"2018-07-27T07:24:16.873Z","3138":"2018-07-27T22:24:38.123Z","3139":"2018-07-28T11:19:29.519Z","3140":"2018-07-30T17:17:46.971Z","3141":"2018-07-30T17:22:51.708Z","3142":"2018-07-30T18:28:54.372Z","3143":"2018-07-30T19:42:39.470Z","3144":"2018-07-30T21:05:48.430Z","3145":"2018-07-30T22:45:09.059Z","3146":"2018-07-30T22:52:53.465Z","3147":"2018-07-30T23:01:45.612Z","3148":"2018-07-30T23:04:56.018Z","3149":"2018-07-30T23:06:33.999Z","3150":"2018-08-01T14:16:17.237Z","3151":"2018-08-01T15:37:43.009Z","3152":"2018-08-01T15:40:24.450Z","3153":"2018-08-01T15:48:59.417Z","3154":"2018-08-01T16:55:25.019Z","3155":"2018-08-01T17:23:23.181Z","3156":"2018-08-01T17:23:38.588Z","3157":"2018-08-01T17:23:57.040Z","3158":"2018-08-01T17:25:38.157Z","3159":"2018-08-01T18:10:36.333Z","3160":"2018-08-02T03:20:07.173Z","3161":"2018-08-03T09:04:13.221Z","3162":"2018-08-06T18:52:22.068Z","3163":"2018-08-07T18:16:23.011Z","3164":"2018-08-09T22:25:49.460Z","3165":"2018-08-10T16:26:46.765Z","3166":"2018-08-15T19:27:06.626Z","3167":"2018-08-15T20:44:12.310Z","3168":"2018-08-21T11:34:14.384Z","3169":"2018-08-21T11:34:54.899Z","3170":"2018-08-21T14:44:20.730Z","3171":"2018-08-21T14:55:06.770Z","3172":"2018-08-21T14:57:19.047Z","3173":"2018-08-23T15:21:50.157Z","3174":"2018-08-23T16:44:54.393Z","3175":"2018-08-23T17:45:31.564Z","3176":"2018-08-23T17:49:19.278Z","3177":"2018-08-29T20:06:49.381Z","3178":"2018-08-29T21:14:42.083Z","3179":"2018-08-29T21:15:20.422Z","3180":"2018-08-29T21:24:51.732Z","3181":"2018-08-30T19:07:06.340Z","3182":"2018-09-03T07:43:33.571Z","3183":"2018-09-06T19:32:12.257Z","3184":"2018-09-06T22:35:56.764Z","3185":"2018-09-07T07:46:51.957Z","3186":"2018-09-11T15:14:39.748Z","3187":"2018-09-13T17:44:13.858Z","3188":"2018-09-13T18:50:15.474Z","3189":"2018-09-13T18:50:24.000Z","3190":"2018-09-18T21:47:52.287Z","3191":"2018-09-18T22:54:45.753Z","3192":"2018-09-19T13:50:30.026Z","3193":"2018-09-20T13:13:01.165Z","3194":"2018-09-20T18:09:06.469Z","3195":"2018-09-24T02:57:22.877Z","3196":"2018-09-24T14:28:58.690Z","3197":"2018-09-24T22:23:13.200Z","3198":"2018-09-25T15:12:08.435Z","3199":"2018-09-25T15:13:04.261Z","3200":"2018-09-26T02:50:13.701Z","3201":"2018-09-26T20:19:04.477Z","3202":"2018-09-26T21:22:36.369Z","3203":"2018-09-26T21:23:28.847Z","3204":"2018-09-26T22:20:46.688Z","3205":"2018-09-30T22:19:43.517Z","3206":"2018-10-01T18:14:23.230Z","3207":"2018-10-02T20:35:25.812Z","3208":"2018-10-02T20:47:32.892Z","3209":"2018-10-04T18:00:05.819Z","3210":"2018-10-04T18:04:47.245Z","3211":"2018-10-04T18:05:14.365Z","3212":"2018-10-04T19:30:46.388Z","3213":"2018-10-04T19:35:06.634Z","3214":"2018-10-04T20:15:30.820Z","3215":"2018-10-04T21:33:16.314Z","3216":"2018-10-05T20:53:08.991Z","3217":"2018-10-05T23:18:55.050Z","3218":"2018-10-05T23:19:38.184Z","3219":"2018-10-08T15:35:04.952Z","3220":"2018-10-08T16:57:29.877Z","3221":"2018-10-09T01:48:40.107Z","3222":"2018-10-10T19:34:59.607Z","3223":"2018-10-10T21:18:02.040Z","3224":"2018-10-17T16:10:59.200Z","3225":"2018-10-17T16:13:52.179Z","3226":"2018-10-17T18:01:12.232Z","3227":"2018-10-18T09:43:12.082Z","3228":"2018-10-23T09:00:04.077Z","3229":"2018-10-23T10:08:17.776Z","3230":"2018-10-23T11:33:22.121Z","3231":"2018-10-23T12:57:13.758Z","3232":"2018-10-29T17:12:54.216Z","3233":"2018-10-30T14:12:54.833Z","3234":"2018-10-31T19:50:01.803Z","3235":"2018-10-31T19:50:31.923Z","3236":"2018-10-31T19:50:39.678Z","3237":"2018-10-31T19:51:31.964Z","3238":"2018-10-31T19:51:47.436Z","3239":"2018-10-31T22:27:04.435Z","3240":"2018-11-01T09:52:14.657Z","3241":"2018-11-01T09:52:53.219Z","3242":"2018-11-01T16:18:45.953Z","3243":"2018-11-03T21:01:11.113Z","3244":"2018-11-03T21:13:43.504Z","3245":"2018-11-04T11:10:14.605Z","3246":"2018-11-07T11:30:18.168Z","3247":"2018-11-13T20:45:22.818Z","3248":"2018-11-13T21:04:49.201Z","3249":"2018-11-14T18:11:49.724Z","3250":"2018-11-20T05:33:27.625Z","3251":"2018-11-20T18:17:14.655Z","3252":"2018-12-04T03:11:07.771Z","3253":"2018-12-06T14:12:56.711Z","3254":"2018-12-06T16:50:38.546Z","3255":"2018-12-06T19:44:01.182Z","3256":"2018-12-13T14:58:07.015Z","3257":"2018-12-13T17:13:44.773Z","3258":"2018-12-13T17:14:18.064Z","3259":"2018-12-13T17:56:00.857Z","3260":"2018-12-13T17:56:56.397Z","3261":"2018-12-13T17:57:27.668Z","3262":"2018-12-13T18:38:08.055Z","3263":"2018-12-14T01:34:39.450Z","3264":"2018-12-14T03:44:38.013Z","3265":"2018-12-14T18:42:24.295Z","3266":"2018-12-14T18:42:38.048Z","3267":"2018-12-14T18:42:53.387Z","3268":"2018-12-14T18:43:07.041Z","3269":"2018-12-14T18:43:32.227Z","3270":"2018-12-14T18:44:00.566Z","3271":"2018-12-14T19:38:24.442Z","3272":"2018-12-14T19:38:30.431Z","3273":"2018-12-14T23:13:41.439Z","3274":"2018-12-20T10:14:56.761Z","3275":"2018-12-20T14:37:05.674Z","3276":"2018-12-20T17:15:47.846Z","3277":"2018-12-20T19:34:50.773Z","3278":"2018-12-21T06:58:39.054Z","3279":"2018-12-21T10:37:23.806Z","3280":"2018-12-21T15:22:13.050Z","3281":"2018-12-21T18:32:34.410Z","3282":"2018-12-23T12:20:04.998Z","3283":"2018-12-23T18:42:06.164Z","3284":"2018-12-23T18:43:21.776Z","3285":"2018-12-26T21:04:33.912Z","3286":"2018-12-26T21:05:00.742Z","3287":"2018-12-26T23:49:54.682Z","3288":"2018-12-26T23:50:00.761Z","3289":"2019-01-02T05:13:17.756Z","3290":"2019-01-02T18:38:01.818Z","3291":"2019-01-02T18:40:20.642Z","3292":"2019-01-02T18:40:37.758Z","3293":"2019-01-04T19:08:06.446Z","3294":"2019-01-04T19:08:21.757Z","3295":"2019-01-04T20:19:18.571Z","3296":"2019-01-04T20:21:37.837Z","3297":"2019-01-17T22:01:59.123Z","3298":"2019-01-17T23:25:19.205Z","3299":"2019-01-23T23:01:52.396Z","3300":"2019-01-24T00:11:23.922Z","3301":"2019-01-24T13:11:25.102Z","3302":"2019-01-24T13:11:32.483Z","3303":"2019-01-25T04:41:38.091Z","3304":"2019-01-25T04:41:44.874Z","3305":"2019-01-25T04:43:37.311Z","3306":"2019-01-25T20:19:59.024Z","3307":"2019-01-25T20:20:04.360Z","3308":"2019-01-25T21:01:07.616Z","3309":"2019-01-25T21:11:34.245Z","3310":"2019-01-26T17:07:55.518Z","3311":"2019-01-29T15:50:09.407Z","3312":"2019-01-29T15:51:03.344Z","3313":"2019-01-29T16:21:07.048Z","3314":"2019-01-29T16:25:16.205Z","3315":"2019-02-18T16:25:37.125Z","3316":"2019-02-18T17:22:02.081Z","3317":"2019-02-18T19:10:46.996Z","3318":"2019-02-18T19:11:12.248Z","3319":"2019-02-19T10:46:55.621Z","3320":"2019-02-19T20:06:10.577Z","3321":"2019-02-19T20:06:24.678Z","3322":"2019-02-19T20:07:04.788Z","3323":"2019-02-20T10:07:20.577Z","3324":"2019-02-21T06:43:38.412Z","3325":"2019-02-21T06:43:44.293Z","3326":"2019-02-21T11:12:34.029Z","3327":"2019-02-21T14:31:29.317Z","3328":"2019-03-01T03:00:32.950Z","3329":"2019-03-01T05:24:59.594Z","3330":"2019-03-09T19:23:33.907Z","3331":"2019-03-09T20:06:56.868Z","3332":"2019-03-19T16:57:24.143Z","3333":"2019-03-19T16:58:35.670Z","3334":"2019-03-19T19:25:09.891Z","3335":"2019-03-19T19:26:39.912Z","3336":"2019-03-19T19:43:34.797Z","3337":"2019-03-19T21:05:57.700Z","3338":"2019-03-19T22:17:32.483Z","3339":"2019-03-20T13:33:14.818Z","3340":"2019-03-20T16:42:24.361Z","3341":"2019-03-20T16:43:27.451Z","3342":"2019-03-21T18:30:22.549Z","3343":"2019-03-22T02:51:00.654Z","3344":"2019-03-22T17:51:56.306Z","3345":"2019-03-22T17:52:02.979Z","3346":"2019-03-22T17:59:11.110Z","3347":"2019-03-25T17:21:39.082Z","3348":"2019-03-25T17:22:24.492Z","3349":"2019-03-25T21:10:17.064Z","3350":"2019-03-25T21:10:55.641Z","3351":"2019-03-25T21:12:25.014Z","3352":"2019-03-26T14:06:39.554Z","3353":"2019-03-26T14:07:03.626Z","3354":"2019-03-26T14:08:18.718Z","3355":"2019-03-26T14:32:30.421Z","3356":"2019-03-26T15:58:40.119Z","3357":"2019-03-26T16:10:41.554Z","3358":"2019-03-26T16:11:16.689Z","3359":"2019-03-26T16:14:08.155Z","3360":"2019-03-26T17:41:54.964Z","3361":"2019-03-26T17:43:10.232Z","3362":"2019-03-26T17:43:47.460Z","3363":"2019-03-26T17:43:58.342Z","3364":"2019-03-26T17:44:31.848Z","3365":"2019-03-26T17:45:13.536Z","3366":"2019-03-26T17:45:51.656Z","3367":"2019-03-26T17:46:33.137Z","3368":"2019-03-26T18:02:45.435Z","3369":"2019-03-26T18:03:06.960Z","3370":"2019-03-26T18:03:14.453Z","3371":"2019-03-26T18:03:21.805Z","3372":"2019-03-26T18:03:29.547Z","3373":"2019-03-26T18:03:32.093Z","3374":"2019-03-26T18:03:42.378Z","3375":"2019-03-26T18:04:15.622Z","3376":"2019-03-26T18:04:42.634Z","3377":"2019-03-26T18:04:50.082Z","3378":"2019-03-26T18:05:02.500Z","3379":"2019-03-26T18:05:38.491Z","3380":"2019-03-26T18:05:40.059Z","3381":"2019-03-26T18:05:46.406Z","3382":"2019-03-26T18:05:59.816Z","3383":"2019-03-26T18:06:27.725Z","3384":"2019-03-26T18:07:28.480Z","3385":"2019-03-26T18:07:35.028Z","3386":"2019-03-26T18:07:42.579Z","3387":"2019-03-26T18:08:23.301Z","3388":"2019-03-26T18:08:43.633Z","3389":"2019-03-26T18:08:51.861Z","3390":"2019-03-26T18:09:10.329Z","3391":"2019-03-26T18:09:31.402Z","3392":"2019-03-26T18:10:27.751Z","3393":"2019-03-26T18:11:54.242Z","3394":"2019-03-26T18:13:44.320Z","3395":"2019-03-26T18:13:55.883Z","3396":"2019-03-26T18:13:57.117Z","3397":"2019-03-26T18:14:05.167Z","3398":"2019-03-26T18:14:07.709Z","3399":"2019-03-27T00:38:13.885Z","3400":"2019-03-27T21:23:36.162Z","3401":"2019-03-29T17:34:09.931Z","3402":"2019-03-29T17:34:37.284Z","3403":"2019-03-29T17:34:43.601Z","3404":"2019-03-29T17:35:31.161Z","3405":"2019-04-03T15:33:48.431Z","3406":"2019-04-03T18:36:06.991Z","3407":"2019-04-03T19:26:00.496Z","3408":"2019-04-03T19:26:26.836Z","3409":"2019-04-03T19:26:55.080Z","3410":"2019-04-03T19:27:15.584Z","3411":"2019-04-03T19:27:32.187Z","3412":"2019-04-03T19:27:38.582Z","3413":"2019-04-03T19:28:06.330Z","3414":"2019-04-03T19:29:29.078Z","3415":"2019-04-03T19:29:48.435Z","3416":"2019-04-03T19:36:17.820Z","3417":"2019-04-03T19:36:46.904Z","3418":"2019-04-03T19:36:48.083Z","3419":"2019-04-03T19:50:25.849Z","3420":"2019-04-04T13:41:01.652Z","3421":"2019-04-04T13:41:02.909Z","3422":"2019-04-04T13:42:01.695Z","3423":"2019-04-04T13:52:43.148Z","3424":"2019-04-04T15:54:12.896Z","3425":"2019-04-04T15:54:47.079Z","3426":"2019-04-04T15:55:54.940Z","3427":"2019-04-04T15:56:46.860Z","3428":"2019-04-04T16:00:33.764Z"},"user":{"0":"vchollati","1":"lo5","2":"vchollati","3":"vchollati","4":"vchollati","5":"mmalohlava","6":"vchollati","7":"vchollati","8":"mmalohlava","9":"vchollati","10":"mmalohlava","11":"vchollati","12":"vchollati","13":"vchollati","14":"mmalohlava","15":"chrinide","16":"mmalohlava","17":"andrewcstewart","18":"andrewcstewart","19":"andrewcstewart","20":"andrewcstewart","21":"amywang718","22":"amywang718","23":"amywang718","24":"andrewcstewart","25":"andrewcstewart","26":"andrewcstewart","27":"amywang718","28":"andrewcstewart","29":"andrewcstewart","30":"andrewcstewart","31":"lo5","32":"lo5","33":"andrewcstewart","34":"andrewcstewart","35":"lo5","36":"andrewcstewart","37":"andrewcstewart","38":"andrewcstewart","39":"lo5","40":"lo5","41":"lo5","42":"andrewcstewart","43":"andrewcstewart","44":"andrewcstewart","45":"andrewcstewart","46":"lo5","47":"lo5","48":"andrewcstewart","49":"lo5","50":"andrewcstewart","51":"lo5","52":"andrewcstewart","53":"lo5","54":"andrewcstewart","55":"andrewcstewart","56":"mihaisecasiu","57":"amywang718","58":"lo5","59":"andrewcstewart","60":"mmalohlava","61":"chrinide","62":"chrinide","63":"chrinide","64":"petro-rudenko","65":"mmalohlava","66":"mmalohlava","67":"petro-rudenko","68":"bghill","69":"zgmming","70":"zgmming","71":"zgmming","72":"mmalohlava","73":"chrinide","74":"bghill","75":"vchollati","76":"chrinide","77":"binga","78":"hvanhovell","79":"mmalohlava","80":"mmalohlava","81":"hvanhovell","82":"mmalohlava","83":"geponce","84":"lo5","85":"mmalohlava","86":"maxschloemer0xdata","87":"rpeck","88":"pcchong","89":"rpeck","90":"geponce","91":"bghill","92":"geponce","93":"bghill","94":"geponce","95":"geponce","96":"geponce","97":"geponce","98":"geponce","99":"bghill","100":"geponce","101":"rpeck","102":"rpeck","103":"geponce","104":"rpeck","105":"rpeck","106":"rpeck","107":"geponce","108":"geponce","109":"geponce","110":"mihaisecasiu","111":"geponce","112":"geponce","113":"geponce","114":"geponce","115":"geponce","116":"geponce","117":"geponce","118":"andrewcstewart","119":"andrewcstewart","120":"mihaisecasiu","121":"mihaisecasiu","122":"andrewcstewart","123":"rpeck","124":"rpeck","125":"rpeck","126":"rpeck","127":"geponce","128":"bghill","129":"geponce","130":"bghill","131":"bghill","132":"bghill","133":"geponce","134":"bghill","135":"andrewcstewart","136":"rpeck","137":"geponce","138":"bghill","139":"bghill","140":"geponce","141":"andrewcstewart","142":"bghill","143":"geponce","144":"geponce","145":"bghill","146":"bghill","147":"geponce","148":"Sam7","149":"petro-rudenko","150":"bghill","151":"bghill","152":"bghill","153":"petro-rudenko","154":"bghill","155":"Sam7","156":"Sam7","157":"mmalohlava","158":"petro-rudenko","159":"mmalohlava","160":"aglagla","161":"aglagla","162":"petro-rudenko","163":"petro-rudenko","164":"bghill","165":"bghill","166":"bghill","167":"bghill","168":"petro-rudenko","169":"geponce","170":"bghill","171":"bghill","172":"kryton","173":"bghill","174":"bghill","175":"bghill","176":"petro-rudenko","177":"petro-rudenko","178":"bghill","179":"bghill","180":"geponce","181":"amywang718","182":"geponce","183":"petro-rudenko","184":"petro-rudenko","185":"geponce","186":"bghill","187":"bghill","188":"bghill","189":"bghill","190":"geponce","191":"bghill","192":"petro-rudenko","193":"petro-rudenko","194":"mmalohlava","195":"mmalohlava","196":"davemssavage","197":"davemssavage","198":"rpeck","199":"rpeck","200":"rpeck","201":"rpeck","202":"davemssavage","203":"rpeck","204":"Sam7","205":"rpeck","206":"Sam7","207":"rpeck","208":"Sam7","209":"jvullo","210":"jvullo","211":"rpeck","212":"rpeck","213":"mmalohlava","214":"Sam7","215":"mmalohlava","216":"mmalohlava","217":"christophergutierrez","218":"christophergutierrez","219":"mmalohlava","220":"christophergutierrez","221":"christophergutierrez","222":"geponce","223":"geponce","224":"geponce","225":"geponce","226":"bghill","227":"geponce","228":"bghill","229":"geponce","230":"davidljung","231":"bghill","232":"davidljung","233":"davidljung","234":"bghill","235":"bghill","236":"davidljung","237":"davidljung","238":"davidljung","239":"davidljung","240":"davidljung","241":"bghill","242":"bghill","243":"davidljung","244":"davidljung","245":"bghill","246":"davidljung","247":"davidljung","248":"bghill","249":"bghill","250":"davidljung","251":"davidljung","252":"bghill","253":"bghill","254":"bghill","255":"davidljung","256":"bghill","257":"geponce","258":"bghill","259":"geponce","260":"geponce","261":"geponce","262":"geponce","263":"geponce","264":"geponce","265":"bghill","266":"bghill","267":"geponce","268":"bghill","269":"geponce","270":"bghill","271":"geponce","272":"r3tex","273":"rpeck","274":"bghill","275":"bghill","276":"bghill","277":"bghill","278":"geponce","279":"geponce","280":"geponce","281":"geponce","282":"bghill","283":"geponce","284":"bghill","285":"geponce","286":"geponce","287":"geponce","288":"geponce","289":"geponce","290":"geponce","291":"bghill","292":"geponce","293":"geponce","294":"bghill","295":"bghill","296":"geponce","297":"geponce","298":"geponce","299":"bghill","300":"geponce","301":"bghill","302":"bghill","303":"geponce","304":"bghill","305":"geponce","306":"bghill","307":"geponce","308":"bghill","309":"bghill","310":"bghill","311":"geponce","312":"geponce","313":"geponce","314":"bghill","315":"mongoose54","316":"ledell","317":"gdequeiroz","318":"bghill","319":"gdequeiroz","320":"lo5","321":"gdequeiroz","322":"gdequeiroz","323":"gdequeiroz","324":"bghill","325":"gdequeiroz","326":"bghill","327":"gdequeiroz","328":"gdequeiroz","329":"bghill","330":"jagatsingh","331":"jagatsingh","332":"jagatsingh","333":"bghill","334":"jagatsingh","335":"bghill","336":"bghill","337":"bghill","338":"jagatsingh","339":"jagatsingh","340":"bghill","341":"bghill","342":"haty1","343":"bghill","344":"haty1","345":"jagatsingh","346":"mmalohlava","347":"mmalohlava","348":"mmalohlava","349":"geponce","350":"geponce","351":"bghill","352":"bghill","353":"mmalohlava","354":"geponce","355":"geponce","356":"mmalohlava","357":"geponce","358":"geponce","359":"geponce","360":"jagatsingh","361":"mmalohlava","362":"toddniven","363":"mmalohlava","364":"jagatsingh","365":"mmalohlava","366":"jagatsingh","367":"jagatsingh","368":"mmalohlava","369":"mmalohlava","370":"mmalohlava","371":"jagatsingh","372":"mmalohlava","373":"haty1","374":"gdequeiroz","375":"gdequeiroz","376":"gdequeiroz","377":"mmalohlava","378":"toddniven","379":"toddniven","380":"jagatsingh","381":"mmalohlava","382":"mmalohlava","383":"jagatsingh","384":"toddniven","385":"mmalohlava","386":"mmalohlava","387":"bawongfai","388":"bawongfai","389":"jagatsingh","390":"bawongfai","391":"bawongfai","392":"jagatsingh","393":"jagatsingh","394":"ledell","395":"ledell","396":"ledell","397":"jagatsingh","398":"bawongfai","399":"ledell","400":"ledell","401":"ledell","402":"ledell","403":"ledell","404":"ledell","405":"jagatsingh","406":"jagatsingh","407":"ledell","408":"bawongfai","409":"bawongfai","410":"bawongfai","411":"mmalohlava","412":"mmalohlava","413":"bawongfai","414":"mmalohlava","415":"toddniven","416":"bawongfai","417":"mmalohlava","418":"bghill","419":"bawongfai","420":"mmalohlava","421":"santy2509","422":"santy2509","423":"santy2509","424":"santy2509","425":"gdequeiroz","426":"gdequeiroz","427":"ledell","428":"jessica0xdata","429":"gdequeiroz","430":"bawongfai","431":"bghill","432":"gdequeiroz","433":"bghill","434":"mmalohlava","435":"r3tex","436":"r3tex","437":"r3tex","438":"jagatsingh","439":"MNXT7","440":"MNXT7","441":"mmalohlava","442":"geponce","443":"geponce","444":"bghill","445":"bghill","446":"bghill","447":"geponce","448":"geponce","449":"geponce","450":"gdequeiroz","451":"gdequeiroz","452":"gdequeiroz","453":"ledell","454":"ledell","455":"gdequeiroz","456":"gdequeiroz","457":"geponce","458":"bghill","459":"geponce","460":"bghill","461":"geponce","462":"bghill","463":"bghill","464":"geponce","465":"bghill","466":"geponce","467":"geponce","468":"bghill","469":"geponce","470":"bghill","471":"bghill","472":"bghill","473":"geponce","474":"geponce","475":"bghill","476":"bghill","477":"geponce","478":"geponce","479":"bghill","480":"bghill","481":"bghill","482":"geponce","483":"geponce","484":"geponce","485":"geponce","486":"geponce","487":"bghill","488":"geponce","489":"bghill","490":"bghill","491":"bghill","492":"geponce","493":"geponce","494":"geponce","495":"bghill","496":"bghill","497":"geponce","498":"geponce","499":"bghill","500":"bghill","501":"bghill","502":"geponce","503":"geponce","504":"bghill","505":"geponce","506":"bghill","507":"bghill","508":"geponce","509":"bghill","510":"geponce","511":"geponce","512":"bghill","513":"geponce","514":"geponce","515":"geponce","516":"jagatsingh","517":"geponce","518":"bghill","519":"bghill","520":"geponce","521":"bghill","522":"geponce","523":"geponce","524":"geponce","525":"geponce","526":"bghill","527":"bghill","528":"bghill","529":"bghill","530":"geponce","531":"bghill","532":"geponce","533":"bghill","534":"bghill","535":"bghill","536":"geponce","537":"bghill","538":"geponce","539":"geponce","540":"bghill","541":"bghill","542":"geponce","543":"geponce","544":"bghill","545":"geponce","546":"bghill","547":"geponce","548":"geponce","549":"geponce","550":"bghill","551":"bghill","552":"geponce","553":"ledell","554":"geponce","555":"jagatsingh","556":"bghill","557":"jagatsingh","558":"bghill","559":"bghill","560":"bghill","561":"jagatsingh","562":"geponce","563":"bghill","564":"bghill","565":"geponce","566":"geponce","567":"bghill","568":"geponce","569":"geponce","570":"geponce","571":"geponce","572":"bghill","573":"geponce","574":"geponce","575":"bghill","576":"geponce","577":"geponce","578":"bghill","579":"geponce","580":"bghill","581":"geponce","582":"geponce","583":"bghill","584":"geponce","585":"bghill","586":"geponce","587":"bghill","588":"geponce","589":"bghill","590":"geponce","591":"bghill","592":"geponce","593":"bghill","594":"bghill","595":"geponce","596":"geponce","597":"bghill","598":"gdequeiroz","599":"bghill","600":"gdequeiroz","601":"gdequeiroz","602":"bghill","603":"gdequeiroz","604":"bghill","605":"gdequeiroz","606":"bghill","607":"bghill","608":"gdequeiroz","609":"bghill","610":"alexshires","611":"bghill","612":"geponce","613":"geponce","614":"bghill","615":"geponce","616":"bghill","617":"bghill","618":"geponce","619":"bghill","620":"alexshires","621":"alexshires","622":"alexshires","623":"alexshires","624":"bghill","625":"alexshires","626":"geponce","627":"geponce","628":"geponce","629":"bghill","630":"geponce","631":"geponce","632":"geponce","633":"bghill","634":"geponce","635":"geponce","636":"geponce","637":"geponce","638":"geponce","639":"geponce","640":"bghill","641":"geponce","642":"geponce","643":"geponce","644":"geponce","645":"geponce","646":"geponce","647":"bghill","648":"bghill","649":"geponce","650":"geponce","651":"bghill","652":"geponce","653":"geponce","654":"geponce","655":"geponce","656":"geponce","657":"geponce","658":"bghill","659":"geponce","660":"geponce","661":"bghill","662":"chrinide","663":"chrinide","664":"chrinide","665":"bghill","666":"bghill","667":"chrinide","668":"chrinide","669":"chrinide","670":"bghill","671":"chrinide","672":"bghill","673":"bghill","674":"HackToHell","675":"HackToHell","676":"HackToHell","677":"HackToHell","678":"HackToHell","679":"HackToHell","680":"HackToHell","681":"HackToHell","682":"HackToHell","683":"HackToHell","684":"HackToHell","685":"HackToHell","686":"HackToHell","687":"geponce","688":"geponce","689":"jagatsingh","690":"geponce","691":"geponce","692":"geponce","693":"jagatsingh","694":"toddniven","695":"geponce","696":"jagatsingh","697":"jagatsingh","698":"bghill","699":"jagatsingh","700":"toddniven","701":"jagatsingh","702":"jagatsingh","703":"bghill","704":"bawongfai","705":"bawongfai","706":"bghill","707":"bawongfai","708":"bawongfai","709":"hack-r","710":"hack-r","711":"bghill","712":"hack-r","713":"ledell","714":"geponce","715":"geponce","716":"jagatsingh","717":"jagatsingh","718":"geponce","719":"Compy","720":"ledell","721":"Compy","722":"Compy","723":"ledell","724":"ledell","725":"Compy","726":"ledell","727":"ledell","728":"Compy","729":"ledell","730":"Compy","731":"ledell","732":"geponce","733":"bghill","734":"geponce","735":"geponce","736":"geponce","737":"bghill","738":"bghill","739":"geponce","740":"ledell","741":"ledell","742":"geponce","743":"ledell","744":"geponce","745":"asa88","746":"asa88","747":"asa88","748":"asa88","749":"asa88","750":"asa88","751":"asa88","752":"asa88","753":"jakubhava","754":"geponce","755":"asa88","756":"geponce","757":"ledell","758":"ledell","759":"geponce","760":"scottstanfield","761":"bghill","762":"bghill","763":"scottstanfield","764":"scottstanfield","765":"bghill","766":"scottstanfield","767":"scottstanfield","768":"ledell","769":"scottstanfield","770":"ledell","771":"ledell","772":"scottstanfield","773":"ledell","774":"kprybol","775":"gdequeiroz","776":"jagatsingh","777":"jagatsingh","778":"bghill","779":"bghill","780":"bghill","781":"geoHeil","782":"bghill","783":"geoHeil","784":"bghill","785":"geoHeil","786":"bghill","787":"geoHeil","788":"asa88","789":"asa88","790":"kzr-soze","791":"geponce","792":"mmalohlava","793":"mmalohlava","794":"mmalohlava","795":"mmalohlava","796":"lucasvfventura","797":"javadba","798":"javadba","799":"javadba","800":"mmalohlava","801":"javadba","802":"ledell","803":"ledell","804":"ledell","805":"cauldnz","806":"cauldnz","807":"cauldnz","808":"ledell","809":"cauldnz","810":"binga","811":"ledell","812":"ledell","813":"vijaykiran","814":"ledell","815":"ledell","816":"vijaykiran","817":"vijaykiran","818":"mmalohlava","819":"ledell","820":"toddniven","821":"joostshao","822":"ledell","823":"ledell","824":"joostshao","825":"joostshao","826":"ledell","827":"ledell","828":"toddniven","829":"ledell","830":"mmalohlava","831":"toddniven","832":"toddniven","833":"mmalohlava","834":"toddniven","835":"vijaykiran","836":"joostshao","837":"bghill","838":"joostshao","839":"joostshao","840":"bghill","841":"bghill","842":"bghill","843":"joostshao","844":"joostshao","845":"joostshao","846":"bghill","847":"joostshao","848":"bghill","849":"joostshao","850":"joostshao","851":"bghill","852":"bghill","853":"joostshao","854":"bghill","855":"joostshao","856":"joostshao","857":"bghill","858":"bghill","859":"bghill","860":"joostshao","861":"joostshao","862":"bghill","863":"joostshao","864":"bghill","865":"joostshao","866":"joostshao","867":"joostshao","868":"bghill","869":"joostshao","870":"bghill","871":"joostshao","872":"bghill","873":"joostshao","874":"joostshao","875":"joostshao","876":"pelatimtt","877":"pelatimtt","878":"pelatimtt","879":"ledell","880":"ledell","881":"joostshao","882":"joostshao","883":"bghill","884":"joostshao","885":"joostshao","886":"bghill","887":"joostshao","888":"bghill","889":"njss","890":"bghill","891":"joostshao","892":"joostshao","893":"bghill","894":"bghill","895":"joostshao","896":"njss","897":"njss","898":"ZhongBaby","899":"lucasvfventura","900":"lucasvfventura","901":"bghill","902":"bghill","903":"bghill","904":"lucasvfventura","905":"scottstanfield","906":"scottstanfield","907":"scottstanfield","908":"scottstanfield","909":"scottstanfield","910":"scottstanfield","911":"scottstanfield","912":"lucasvfventura","913":"ledell","914":"ledell","915":"lucasvfventura","916":"scottstanfield","917":"lucasvfventura","918":"scottstanfield","919":"lucasvfventura","920":"lucasvfventura","921":"scottstanfield","922":"bghill","923":"scottstanfield","924":"scottstanfield","925":"bghill","926":"bghill","927":"scottstanfield","928":"scottstanfield","929":"bghill","930":"AlexanderModestov","931":"lucasvfventura","932":"lucasvfventura","933":"scottstanfield","934":"bghill","935":"bghill","936":"bghill","937":"lucasvfventura","938":"bghill","939":"lucasvfventura","940":"bghill","941":"lucasvfventura","942":"bghill","943":"bghill","944":"bghill","945":"bghill","946":"njss","947":"lucasvfventura","948":"lucasvfventura","949":"bghill","950":"bghill","951":"lucasvfventura","952":"bghill","953":"cauldnz","954":"bghill","955":"cauldnz","956":"bghill","957":"cauldnz","958":"cauldnz","959":"cauldnz","960":"ledell","961":"bghill","962":"cauldnz","963":"bghill","964":"cauldnz","965":"cauldnz","966":"bghill","967":"cauldnz","968":"cauldnz","969":"cauldnz","970":"bghill","971":"cauldnz","972":"scottstanfield","973":"scottstanfield","974":"scottstanfield","975":"scottstanfield","976":"scottstanfield","977":"bghill","978":"scottstanfield","979":"lucasvfventura","980":"ledell","981":"joostshao","982":"huajinghua","983":"huajinghua","984":"huajinghua","985":"joostshao","986":"joostshao","987":"joostshao","988":"lucasvfventura","989":"EngrStudent","990":"joostshao","991":"joostshao","992":"joostshao","993":"joostshao","994":"mmalohlava","995":"mmalohlava","996":"mmalohlava","997":"joostshao","998":"joostshao","999":"alexshires","1000":"alexshires","1001":"scottstanfield","1002":"joostshao","1003":"joostshao","1004":"geponce","1005":"geponce","1006":"geponce","1007":"geponce","1008":"geponce","1009":"geponce","1010":"geponce","1011":"geponce","1012":"joostshao","1013":"joostshao","1014":"kirilligum","1015":"kirilligum","1016":"kirilligum","1017":"kirilligum","1018":"ledell","1019":"ledell","1020":"ledell","1021":"ledell","1022":"ledell","1023":"ledell","1024":"ledell","1025":"ledell","1026":"ledell","1027":"ledell","1028":"lucasvfventura","1029":"ledell","1030":"scottstanfield","1031":"scottstanfield","1032":"scottstanfield","1033":"scottstanfield","1034":"scottstanfield","1035":"scottstanfield","1036":"ledell","1037":"ledell","1038":"ledell","1039":"scottstanfield","1040":"ledell","1041":"scottstanfield","1042":"scottstanfield","1043":"ledell","1044":"scottstanfield","1045":"qspencer","1046":"qspencer","1047":"scottstanfield","1048":"scottstanfield","1049":"qspencer","1050":"scottstanfield","1051":"scottstanfield","1052":"scottstanfield","1053":"scottstanfield","1054":"qspencer","1055":"scottstanfield","1056":"scottstanfield","1057":"scottstanfield","1058":"scottstanfield","1059":"qspencer","1060":"qspencer","1061":"scottstanfield","1062":"scottstanfield","1063":"qspencer","1064":"scottstanfield","1065":"scottstanfield","1066":"qspencer","1067":"scottstanfield","1068":"qspencer","1069":"scottstanfield","1070":"scottstanfield","1071":"scottstanfield","1072":"scottstanfield","1073":"scottstanfield","1074":"qspencer","1075":"qspencer","1076":"scottstanfield","1077":"ledell","1078":"ledell","1079":"qspencer","1080":"lucasvfventura","1081":"ledell","1082":"ledell","1083":"ledell","1084":"lucasvfventura","1085":"AlexanderModestov","1086":"petro-rudenko","1087":"AlexanderModestov","1088":"AlexanderModestov","1089":"AlexanderModestov","1090":"petro-rudenko","1091":"AlexanderModestov","1092":"AlexanderModestov","1093":"AlexanderModestov","1094":"AlexanderModestov","1095":"petro-rudenko","1096":"qspencer","1097":"ledell","1098":"ledell","1099":"geponce","1100":"geponce","1101":"geponce","1102":"ledell","1103":"geponce","1104":"geponce","1105":"ledell","1106":"geponce","1107":"ledell","1108":"geponce","1109":"ledell","1110":"geponce","1111":"ledell","1112":"geponce","1113":"geponce","1114":"geponce","1115":"ledell","1116":"ledell","1117":"geponce","1118":"ledell","1119":"geponce","1120":"geponce","1121":"ledell","1122":"ledell","1123":"geponce","1124":"geponce","1125":"ledell","1126":"geponce","1127":"geponce","1128":"geponce","1129":"ledell","1130":"r3tex","1131":"ledell","1132":"ledell","1133":"ledell","1134":"r3tex","1135":"NitinKumar94","1136":"ledell","1137":"ying-w","1138":"ledell","1139":"ledell","1140":"ledell","1141":"ying-w","1142":"ying-w","1143":"ying-w","1144":"ledell","1145":"ledell","1146":"ying-w","1147":"ledell","1148":"ledell","1149":"ledell","1150":"ledell","1151":"ying-w","1152":"ying-w","1153":"ying-w","1154":"ying-w","1155":"ledell","1156":"ledell","1157":"ying-w","1158":"ying-w","1159":"ledell","1160":"ledell","1161":"ying-w","1162":"ledell","1163":"ledell","1164":"ying-w","1165":"ying-w","1166":"ledell","1167":"ying-w","1168":"ying-w","1169":"ledell","1170":"ledell","1171":"ledell","1172":"ying-w","1173":"ying-w","1174":"ying-w","1175":"ledell","1176":"ledell","1177":"ying-w","1178":"ying-w","1179":"ying-w","1180":"mmalohlava","1181":"signedbit","1182":"ledell","1183":"signedbit","1184":"ledell","1185":"ledell","1186":"ledell","1187":"ledell","1188":"ledell","1189":"signedbit","1190":"ledell","1191":"ledell","1192":"signedbit","1193":"ledell","1194":"signedbit","1195":"ledell","1196":"miladf2","1197":"mmalohlava","1198":"miladf2","1199":"ledell","1200":"miladf2","1201":"ledell","1202":"miladf2","1203":"ledell","1204":"ledell","1205":"miladf2","1206":"ledell","1207":"miladf2","1208":"ledell","1209":"ying-w","1210":"ying-w","1211":"ying-w","1212":"ying-w","1213":"ledell","1214":"ledell","1215":"ledell","1216":"ledell","1217":"signedbit","1218":"ledell","1219":"signedbit","1220":"ledell","1221":"signedbit","1222":"ledell","1223":"signedbit","1224":"ledell","1225":"ledell","1226":"ledell","1227":"signedbit","1228":"ledell","1229":"signedbit","1230":"ledell","1231":"ledell","1232":"signedbit","1233":"ledell","1234":"signedbit","1235":"ledell","1236":"signedbit","1237":"ledell","1238":"signedbit","1239":"signedbit","1240":"ledell","1241":"ledell","1242":"ledell","1243":"signedbit","1244":"ledell","1245":"ledell","1246":"signedbit","1247":"ledell","1248":"signedbit","1249":"ledell","1250":"signedbit","1251":"signedbit","1252":"ying-w","1253":"ledell","1254":"ledell","1255":"Lana777","1256":"ledell","1257":"Lana777","1258":"agaddale","1259":"agaddale","1260":"ledell","1261":"agaddale","1262":"ledell","1263":"agaddale","1264":"djvulee","1265":"djvulee","1266":"djvulee","1267":"djvulee","1268":"djvulee","1269":"djvulee","1270":"djvulee","1271":"djvulee","1272":"djvulee","1273":"agaddale","1274":"agaddale","1275":"ledell","1276":"djvulee","1277":"djvulee","1278":"djvulee","1279":"ledell","1280":"ledell","1281":"ledell","1282":"agaddale","1283":"ledell","1284":"ledell","1285":"agaddale","1286":"ledell","1287":"ledell","1288":"agaddale","1289":"geponce","1290":"geponce","1291":"mattdowle","1292":"djvulee","1293":"djvulee","1294":"djvulee","1295":"AlexanderModestov","1296":"cauldnz","1297":"cauldnz","1298":"djvulee","1299":"geponce","1300":"geponce","1301":"geponce","1302":"ledell","1303":"geponce","1304":"geponce","1305":"ledell","1306":"geponce","1307":"ledell","1308":"mattdowle","1309":"geponce","1310":"geponce","1311":"mattdowle","1312":"mattdowle","1313":"geponce","1314":"mattdowle","1315":"geponce","1316":"geponce","1317":"mattdowle","1318":"geponce","1319":"geponce","1320":"geponce","1321":"ledell","1322":"ledell","1323":"ledell","1324":"ledell","1325":"ledell","1326":"geponce","1327":"ledell","1328":"ledell","1329":"ledell","1330":"geponce","1331":"geponce","1332":"geponce","1333":"geponce","1334":"geponce","1335":"geponce","1336":"ledell","1337":"ledell","1338":"mattdowle","1339":"scottstanfield","1340":"scottstanfield","1341":"geponce","1342":"ledell","1343":"mattdowle","1344":"mattdowle","1345":"geponce","1346":"ledell","1347":"ledell","1348":"mattdowle","1349":"agaddale","1350":"agaddale","1351":"agaddale","1352":"agaddale","1353":"ck37","1354":"geponce","1355":"geponce","1356":"geponce","1357":"geponce","1358":"scottstanfield","1359":"ck37","1360":"scottstanfield","1361":"scottstanfield","1362":"geponce","1363":"ck37","1364":"scottstanfield","1365":"geponce","1366":"ck37","1367":"scottstanfield","1368":"scottstanfield","1369":"scottstanfield","1370":"ck37","1371":"scottstanfield","1372":"ck37","1373":"scottstanfield","1374":"scottstanfield","1375":"ck37","1376":"ck37","1377":"ck37","1378":"ck37","1379":"agaddale","1380":"ck37","1381":"agaddale","1382":"ck37","1383":"ck37","1384":"agaddale","1385":"cliffclick","1386":"ledell","1387":"ledell","1388":"ledell","1389":"ledell","1390":"scottstanfield","1391":"ledell","1392":"scottstanfield","1393":"scottstanfield","1394":"scottstanfield","1395":"varunpa83","1396":"scottstanfield","1397":"petro-rudenko","1398":"rajshah4","1399":"petro-rudenko","1400":"rajshah4","1401":"vmarchen","1402":"petro-rudenko","1403":"vmarchen","1404":"ledell","1405":"petro-rudenko","1406":"rajshah4","1407":"cliffclick","1408":"vmarchen","1409":"ledell","1410":"ledell","1411":"mmalohlava","1412":"petro-rudenko","1413":"mmalohlava","1414":"ledell","1415":"ledell","1416":"cliffclick","1417":"gbrock16","1418":"gbrock16","1419":"mattdowle","1420":"mattdowle","1421":"vmarchen","1422":"ledell","1423":"cliffclick","1424":"cliffclick","1425":"AlexanderModestov","1426":"ledell","1427":"yongjiaw","1428":"mmalohlava","1429":"ledell","1430":"ledell","1431":"ledell","1432":"yongjiaw","1433":"yongjiaw","1434":"ledell","1435":"yongjiaw","1436":"yongjiaw","1437":"yongjiaw","1438":"vmarchen","1439":"vmarchen","1440":"ledell","1441":"vmarchen","1442":"mmalohlava","1443":"vmarchen","1444":"ledell","1445":"ledell","1446":"hamuchiwa","1447":"ledell","1448":"ledell","1449":"vijaykiran","1450":"cliffclick","1451":"bgallmeister","1452":"cliffclick","1453":"bgallmeister","1454":"scottstanfield","1455":"scottstanfield","1456":"scottstanfield","1457":"scottstanfield","1458":"lilloraffa","1459":"geoffreya","1460":"geoffreya","1461":"geoffreya","1462":"Lana777","1463":"koertkuipers","1464":"koertkuipers","1465":"koertkuipers","1466":"mnorayr","1467":"mnorayr","1468":"neallwebster","1469":"hamuchiwa","1470":"ledell","1471":"ledell","1472":"ledell","1473":"ledell","1474":"ledell","1475":"ledell","1476":"ledell","1477":"ledell","1478":"ledell","1479":"cauldnz","1480":"cauldnz","1481":"ledell","1482":"ledell","1483":"ledell","1484":"ledell","1485":"ledell","1486":"cauldnz","1487":"cauldnz","1488":"cauldnz","1489":"AlexanderModestov","1490":"kamiKAZIK","1491":"ledell","1492":"ledell","1493":"ledell","1494":"mdymczyk","1495":"cauldnz","1496":"ledell","1497":"ledell","1498":"cauldnz","1499":"cauldnz","1500":"cauldnz","1501":"cauldnz","1502":"ledell","1503":"ledell","1504":"gitdek","1505":"miladf2","1506":"miladf2","1507":"ledell","1508":"ledell","1509":"ledell","1510":"michaelr524","1511":"michaelr524","1512":"ledell","1513":"michaelr524","1514":"cliffclick","1515":"cliffclick","1516":"miladf2","1517":"miladf2","1518":"miladf2","1519":"michaelr524","1520":"michaelr524","1521":"michaelr524","1522":"michaelr524","1523":"michaelr524","1524":"michaelr524","1525":"michaelr524","1526":"michaelr524","1527":"mdymczyk","1528":"michaelr524","1529":"switzer","1530":"switzer","1531":"mdymczyk","1532":"switzer","1533":"petro-rudenko","1534":"miladf2","1535":"petro-rudenko","1536":"petro-rudenko","1537":"miladf2","1538":"petro-rudenko","1539":"toddniven","1540":"petro-rudenko","1541":"ledell","1542":"ledell","1543":"cliffclick","1544":"ledell","1545":"arnocandel","1546":"ledell","1547":"petro-rudenko","1548":"petro-rudenko","1549":"petro-rudenko","1550":"petro-rudenko","1551":"petro-rudenko","1552":"ledell","1553":"ledell","1554":"ledell","1555":"ledell","1556":"gbrock16","1557":"ledell","1558":"geoffreya","1559":"geoffreya","1560":"geoffreya","1561":"geoffreya","1562":"ledell","1563":"yarenty","1564":"bgallmeister","1565":"cliffclick","1566":"geoffreya","1567":"ledell","1568":"calvertj","1569":"calvertj","1570":"calvertj","1571":"cauldnz","1572":"ledell","1573":"geoffreya","1574":"geoffreya","1575":"geoffreya","1576":"tanselmi","1577":"geoffreya","1578":"SggGupta","1579":"SggGupta","1580":"jangorecki","1581":"mmalohlava","1582":"jangorecki","1583":"mmalohlava","1584":"jangorecki","1585":"mmalohlava","1586":"jangorecki","1587":"jangorecki","1588":"ledell","1589":"ledell","1590":"ledell","1591":"jangorecki","1592":"SggGupta","1593":"SggGupta","1594":"ying-w","1595":"ying-w","1596":"ying-w","1597":"ledell","1598":"ledell","1599":"ledell","1600":"cauldnz","1601":"toddniven","1602":"cliffclick","1603":"srisatish","1604":"srisatish","1605":"asa88","1606":"ledell","1607":"ledell","1608":"cliffclick","1609":"cliffclick","1610":"jangorecki","1611":"ledell","1612":"jangorecki","1613":"ledell","1614":"BenjamWhite","1615":"BenjamWhite","1616":"BenjamWhite","1617":"txr150430","1618":"txr150430","1619":"ledell","1620":"ledell","1621":"txr150430","1622":"cliffclick","1623":"jangorecki","1624":"cliffclick","1625":"cliffclick","1626":"jangorecki","1627":"bghill","1628":"ledell","1629":"bghill","1630":"mlazarew_twitter","1631":"bghill","1632":"ledell","1633":"bghill","1634":"ledell","1635":"MarcinKosinski","1636":"MarcinKosinski","1637":"mdymczyk","1638":"jangorecki","1639":"sauravp","1640":"sauravp","1641":"sauravp","1642":"mdymczyk","1643":"sauravp","1644":"sauravp","1645":"mdymczyk","1646":"sauravp","1647":"mdymczyk","1648":"mdymczyk","1649":"sauravp","1650":"mdymczyk","1651":"mdymczyk","1652":"sauravp","1653":"mdymczyk","1654":"AlexExplorer","1655":"AlexExplorer","1656":"pelatimtt","1657":"sauravp","1658":"sauravp","1659":"pelatimtt","1660":"pelatimtt","1661":"sauravp","1662":"Hassanbenlebsir","1663":"Hassanbenlebsir","1664":"ledell","1665":"ledell","1666":"ledell","1667":"pelatimtt","1668":"mdymczyk","1669":"pelatimtt","1670":"pelatimtt","1671":"pelatimtt","1672":"mdymczyk","1673":"mdymczyk","1674":"sauravp","1675":"rajshah4","1676":"ledell","1677":"sauravp","1678":"sauravp","1679":"mdymczyk","1680":"mdymczyk","1681":"mdymczyk","1682":"sauravp","1683":"yarenty","1684":"mdymczyk","1685":"yarenty","1686":"mdymczyk","1687":"mdymczyk","1688":"yarenty","1689":"mdymczyk","1690":"spennihana","1691":"spennihana","1692":"spennihana","1693":"spennihana","1694":"mdymczyk","1695":"spennihana","1696":"spennihana","1697":"spennihana","1698":"spennihana","1699":"spennihana","1700":"ledell","1701":"spennihana","1702":"spennihana","1703":"ledell","1704":"jagatsingh","1705":"mmalohlava","1706":"mmalohlava","1707":"mmalohlava","1708":"mmalohlava","1709":"jagatsingh","1710":"pelatimtt","1711":"petro-rudenko","1712":"2020testuser","1713":"pelatimtt","1714":"ledell","1715":"ledell","1716":"ledell","1717":"AnkitAggarwalPEC","1718":"AnkitAggarwalPEC","1719":"r3tex","1720":"r3tex","1721":"r3tex","1722":"r3tex","1723":"r3tex","1724":"ledell","1725":"ledell","1726":"ggauravuee","1727":"pelatimtt","1728":"mdymczyk","1729":"pelatimtt","1730":"pelatimtt","1731":"pelatimtt","1732":"mdymczyk","1733":"lucasvfventura","1734":"ledell","1735":"sauravp","1736":"sauravp","1737":"sauravp","1738":"alextorar_twitter","1739":"Shantanuprak_twitter","1740":"ledell","1741":"ledell","1742":"arita37","1743":"alextorar_twitter","1744":"abossenbroek","1745":"deepak_s_rawat_twitter","1746":"ledell","1747":"ledell","1748":"ledell","1749":"ledell","1750":"ledell","1751":"ledell","1752":"deepak_s_rawat_twitter","1753":"ledell","1754":"ledell","1755":"deepak_s_rawat_twitter","1756":"ledell","1757":"abossenbroek","1758":"abossenbroek","1759":"abossenbroek","1760":"dongxuzhao","1761":"ledell","1762":"ledell","1763":"dongxuzhao","1764":"alextorar_twitter","1765":"AnkurRaj","1766":"pelatimtt","1767":"switzer","1768":"ck37","1769":"ck37","1770":"ledell","1771":"radek1st","1772":"radek1st","1773":"radek1st","1774":"radek1st","1775":"ledell","1776":"ledell","1777":"buoyantair","1778":"sauravp","1779":"sauravp","1780":"sauravp","1781":"sauravp","1782":"sauravp","1783":"sauravp","1784":"adityabhatia52","1785":"ledell","1786":"ledell","1787":"ledell","1788":"ledell","1789":"FRosner","1790":"FRosner","1791":"MartinPark","1792":"jeffwong-nflx","1793":"jeffwong-nflx","1794":"jeffwong-nflx","1795":"jeffwong-nflx","1796":"FRosner","1797":"FRosner","1798":"FRosner","1799":"rezaAdie","1800":"ledell","1801":"ledell","1802":"ledell","1803":"ledell","1804":"ledell","1805":"ledell","1806":"FRosner","1807":"ledell","1808":"ledell","1809":"pgensler","1810":"rezaAdie","1811":"Ij888","1812":"michalkurka","1813":"michalkurka","1814":"rezaAdie","1815":"rezaAdie","1816":"dkincaid","1817":"dkincaid","1818":"ledell","1819":"ledell","1820":"ledell","1821":"ledell","1822":"ledell","1823":"micahstubbs","1824":"dkincaid","1825":"ledell","1826":"rendi7936","1827":"rendi7936","1828":"rendi7936","1829":"rendi7936","1830":"ledell","1831":"rendi7936","1832":"rendi7936","1833":"ledell","1834":"ledell","1835":"ledell","1836":"ledell","1837":"ledell","1838":"quertenmont","1839":"quertenmont","1840":"quertenmont","1841":"mdymczyk","1842":"quertenmont","1843":"quertenmont","1844":"quertenmont","1845":"mdymczyk","1846":"quertenmont","1847":"WangAllen","1848":"mdymczyk","1849":"WangAllen","1850":"spennihana","1851":"spennihana","1852":"bithw1","1853":"ledell","1854":"ledell","1855":"ledell","1856":"Ij888","1857":"ledell","1858":"Ij888","1859":"bithw1","1860":"ledell","1861":"ledell","1862":"yarenty","1863":"nogj","1864":"burkaygur","1865":"burkaygur","1866":"ledell","1867":"burkaygur","1868":"burkaygur","1869":"burkaygur","1870":"burkaygur","1871":"burkaygur","1872":"burkaygur","1873":"burkaygur","1874":"burkaygur","1875":"burkaygur","1876":"burkaygur","1877":"burkaygur","1878":"geoffreya","1879":"geoffreya","1880":"ledell","1881":"ledell","1882":"xiuxiuxiaodi","1883":"ledell","1884":"ledell","1885":"xiuxiuxiaodi","1886":"xiuxiuxiaodi","1887":"xiuxiuxiaodi","1888":"xiuxiuxiaodi","1889":"ledell","1890":"xiuxiuxiaodi","1891":"xiuxiuxiaodi","1892":"xiuxiuxiaodi","1893":"xiuxiuxiaodi","1894":"ledell","1895":"xiuxiuxiaodi","1896":"xiuxiuxiaodi","1897":"xiuxiuxiaodi","1898":"ledell","1899":"xiuxiuxiaodi","1900":"jangorecki","1901":"ledell","1902":"jangorecki","1903":"cauldnz","1904":"WangAllen","1905":"ledell","1906":"ledell","1907":"ledell","1908":"cauldnz","1909":"WangAllen","1910":"WangAllen","1911":"rudnyt_twitter","1912":"petro-rudenko","1913":"rudnyt_twitter","1914":"ledell","1915":"ledell","1916":"ledell","1917":"michalkurka","1918":"michalkurka","1919":"r3tex","1920":"WangAllen","1921":"michalkurka","1922":"ledell","1923":"ledell","1924":"ledell","1925":"WangAllen","1926":"deepak_s_rawat_twitter","1927":"WangAllen","1928":"WangAllen","1929":"WangAllen","1930":"deepak_s_rawat_twitter","1931":"petro-rudenko","1932":"deepak_s_rawat_twitter","1933":"retroam","1934":"mathemage","1935":"michalkurka","1936":"mathemage","1937":"mathemage","1938":"ledell","1939":"ledell","1940":"ledell","1941":"ledell","1942":"retroam","1943":"mathemage","1944":"mathemage","1945":"mathemage","1946":"mathemage","1947":"spennihana","1948":"AnkurRaj","1949":"mmalohlava","1950":"jpotts18","1951":"jpotts18","1952":"ledell","1953":"geponce","1954":"geponce","1955":"geponce","1956":"bettopper","1957":"bettopper","1958":"bettopper","1959":"ledell","1960":"geponce","1961":"tomasnykodym","1962":"tomasnykodym","1963":"tomasnykodym","1964":"tomasnykodym","1965":"mmalohlava","1966":"ledell","1967":"ledell","1968":"ledell","1969":"ledell","1970":"geponce","1971":"ggauravuee","1972":"ledell","1973":"ledell","1974":"ledell","1975":"ggauravuee","1976":"geponce","1977":"geponce","1978":"geponce","1979":"geponce","1980":"ggauravuee","1981":"bettopper","1982":"bettopper","1983":"dietzc","1984":"mmalohlava","1985":"dietzc","1986":"tomasnykodym","1987":"tomasnykodym","1988":"bettopper","1989":"ganeshkrishnan1","1990":"ganeshkrishnan1","1991":"ledell","1992":"ledell","1993":"ledell","1994":"ganeshkrishnan1","1995":"ledell","1996":"mdymczyk","1997":"ganeshkrishnan1","1998":"rendi7936","1999":"FlyElephant-M31","2000":"ck37","2001":"ledell","2002":"ledell","2003":"pandravada","2004":"pandravada","2005":"mohanr","2006":"mohanr","2007":"mohanr","2008":"mohanr","2009":"cauldnz","2010":"ledell","2011":"ledell","2012":"ledell","2013":"yarenty","2014":"ledell","2015":"ledell","2016":"matanster","2017":"ledell","2018":"kevinykuo","2019":"ArunLakhotia","2020":"dietzc","2021":"mmalohlava","2022":"mmalohlava","2023":"mohanr","2024":"atroiano","2025":"ledell","2026":"ledell","2027":"ledell","2028":"ledell","2029":"ledell","2030":"ledell","2031":"atroiano","2032":"atroiano","2033":"yalcinyenigun_twitter","2034":"ledell","2035":"ledell","2036":"yalcinyenigun_twitter","2037":"ledell","2038":"ledell","2039":"ledell","2040":"yalcinyenigun_twitter","2041":"atroiano","2042":"ledell","2043":"bettopper","2044":"bettopper","2045":"yalcinyenigun_twitter","2046":"ledell","2047":"ledell","2048":"WangAllen","2049":"ledell","2050":"WangAllen","2051":"kevinykuo","2052":"dietzc","2053":"dietzc","2054":"dietzc","2055":"dietzc","2056":"dietzc","2057":"dietzc","2058":"michalkurka","2059":"dietzc","2060":"defoye","2061":"dietzc","2062":"ArunLakhotia","2063":"dietzc","2064":"dietzc","2065":"dietzc","2066":"dietzc","2067":"dietzc","2068":"michalkurka","2069":"dietzc","2070":"dietzc","2071":"dietzc","2072":"dietzc","2073":"dietzc","2074":"ledell","2075":"ledell","2076":"ledell","2077":"ozgemeva","2078":"ledell","2079":"ledell","2080":"nimesh-mittal","2081":"michalkurka","2082":"nimesh-mittal","2083":"michalkurka","2084":"nimesh-mittal","2085":"matanster","2086":"matanster","2087":"matanster","2088":"dietzc","2089":"r_mohan_twitter","2090":"j2k850_twitter","2091":"ledell","2092":"r_mohan_twitter","2093":"ggauravuee","2094":"szilard0","2095":"ledell","2096":"ledell","2097":"ledell","2098":"szilard0","2099":"daas-ankur-shukla","2100":"ledell","2101":"ledell","2102":"ledell","2103":"ledell","2104":"ledell","2105":"daas-ankur-shukla","2106":"bwv988","2107":"bwv988","2108":"bwv988","2109":"bwv988","2110":"bwv988","2111":"bwv988","2112":"bwv988","2113":"ledell","2114":"ledell","2115":"ledell","2116":"ledell","2117":"ledell","2118":"bwv988","2119":"bwv988","2120":"bwv988","2121":"ledell","2122":"ledell","2123":"bwv988","2124":"ledell","2125":"bwv988","2126":"bwv988","2127":"ledell","2128":"bwv988","2129":"bwv988","2130":"ledell","2131":"bwv988","2132":"alextorar_twitter","2133":"rohan-kekatpure","2134":"rohan-kekatpure","2135":"rohan-kekatpure","2136":"0biwanken0bi","2137":"michalkurka","2138":"ggauravuee","2139":"ledell","2140":"ledell","2141":"ledell","2142":"ledell","2143":"ledell","2144":"ledell","2145":"ledell","2146":"ggauravuee","2147":"alextorar_twitter","2148":"Ahsaan-566","2149":"Ahsaan-566","2150":"ledell","2151":"Ahsaan-566","2152":"ledell","2153":"jrivers96","2154":"ledell","2155":"mbaddar1","2156":"zhenyiy","2157":"robhawkins","2158":"ledell","2159":"ledell","2160":"swordbeta","2161":"yarenty","2162":"yarenty","2163":"mbaddar1","2164":"SimonSchmid","2165":"michalkurka","2166":"mmalohlava","2167":"mmalohlava","2168":"ksbg","2169":"ksbg","2170":"SimonSchmid","2171":"saltcake00_twitter","2172":"saltcake00_twitter","2173":"saltcake00_twitter","2174":"saltcake00_twitter","2175":"yarenty","2176":"ggauravuee","2177":"ledell","2178":"ledell","2179":"ledell","2180":"michalkurka","2181":"Pscheidl","2182":"michalkurka","2183":"Pscheidl","2184":"mmalohlava","2185":"allenjack","2186":"ledell","2187":"mdymczyk","2188":"allenjack","2189":"SimonSchmid","2190":"Aakash282","2191":"Aakash282","2192":"mdymczyk","2193":"ledell","2194":"ledell","2195":"ledell","2196":"ledell","2197":"michalkurka","2198":"SimonSchmid","2199":"pqrth","2200":"hutaohutc","2201":"ledell","2202":"ledell","2203":"ledell","2204":"ledell","2205":"ledell","2206":"ledell","2207":"hutaohutc","2208":"ledell","2209":"pqrth","2210":"hutaohutc","2211":"ledell","2212":"hutaohutc","2213":"mmalohlava","2214":"pqrth","2215":"Aakash282","2216":"velconia","2217":"velconia","2218":"JohnnyWallker","2219":"ledell","2220":"ledell","2221":"ledell","2222":"JohnnyWallker","2223":"jerbome","2224":"jerbome","2225":"ledell","2226":"ledell","2227":"pgensler","2228":"pgensler","2229":"ledell","2230":"ledell","2231":"pgensler","2232":"ledell","2233":"zenix","2234":"zenix","2235":"zenix","2236":"zenix","2237":"zenix","2238":"zenix","2239":"zenix","2240":"zenix","2241":"ledell","2242":"ledell","2243":"ledell","2244":"ArunLakhotia","2245":"ledell","2246":"bettopper","2247":"bettopper","2248":"ledell","2249":"ledell","2250":"bettopper","2251":"bettopper","2252":"bettopper","2253":"ledell","2254":"ledell","2255":"ledell","2256":"ledell","2257":"bettopper","2258":"bettopper","2259":"bettopper","2260":"bettopper","2261":"bettopper","2262":"ledell","2263":"ledell","2264":"bettopper","2265":"Aakash282","2266":"ledell","2267":"ledell","2268":"ali8zake","2269":"spennihana","2270":"spennihana","2271":"ledell","2272":"sooraj2189","2273":"ledell","2274":"ledell","2275":"ledell","2276":"burkaygur","2277":"burkaygur","2278":"ledell","2279":"mbaddar1","2280":"ggauravuee","2281":"AntonPolishko_twitter","2282":"ledell","2283":"ledell","2284":"ledell","2285":"AntonPolishko_twitter","2286":"mohit-shrma","2287":"ledell","2288":"ledell","2289":"mohit-shrma","2290":"ledell","2291":"ledell","2292":"ledell","2293":"ledell","2294":"mohit-shrma","2295":"ledell","2296":"rcercos","2297":"ArunLakhotia","2298":"ledell","2299":"sooraj2189","2300":"ledell","2301":"dkincaid","2302":"ledell","2303":"dkincaid","2304":"dkincaid","2305":"ledell","2306":"ledell","2307":"dkincaid","2308":"syam3526","2309":"ledell","2310":"syam3526","2311":"dkincaid","2312":"ledell","2313":"ledell","2314":"dkincaid","2315":"dkincaid","2316":"sivassk14","2317":"sivassk14","2318":"bravekjh","2319":"bravekjh","2320":"tjowers95","2321":"ledell","2322":"gediminaszylius","2323":"michalkurka","2324":"michalkurka","2325":"sooraj2189","2326":"sooraj2189","2327":"syam3526","2328":"syam3526","2329":"sooraj2189","2330":"gediminaszylius","2331":"COA1IMB","2332":"cdagnino","2333":"ledell","2334":"ledell","2335":"syam3526","2336":"syam3526","2337":"gediminaszylius","2338":"geislefc","2339":"SimonSchmid","2340":"cdagnino","2341":"cdagnino","2342":"ledell","2343":"ledell","2344":"ledell","2345":"ledell","2346":"ledell","2347":"ledell","2348":"gediminaszylius","2349":"cdagnino","2350":"cdagnino","2351":"cdagnino","2352":"gediminaszylius","2353":"ggauravuee","2354":"cdagnino","2355":"gediminaszylius","2356":"ledell","2357":"ledell","2358":"ggauravuee","2359":"ggauravuee","2360":"ledell","2361":"ledell","2362":"ledell","2363":"ledell","2364":"ggauravuee","2365":"ledell","2366":"cdagnino","2367":"ledell","2368":"cdagnino","2369":"ledell","2370":"ledell","2371":"ggauravuee","2372":"redtrades","2373":"gediminaszylius","2374":"ledell","2375":"ledell","2376":"ledell","2377":"ledell","2378":"ledell","2379":"ledell","2380":"ledell","2381":"gediminaszylius","2382":"gediminaszylius","2383":"cdagnino","2384":"gediminaszylius","2385":"gediminaszylius","2386":"cdagnino","2387":"gediminaszylius","2388":"michalkurka","2389":"ledell","2390":"gediminaszylius","2391":"schwannden","2392":"schwannden","2393":"schwannden","2394":"schwannden","2395":"cdagnino","2396":"ledell","2397":"ggauravuee","2398":"ledell","2399":"ggauravuee","2400":"ggauravuee","2401":"gediminaszylius","2402":"ledell","2403":"tmcfl","2404":"tmcfl","2405":"ledell","2406":"tmcfl","2407":"tmcfl","2408":"tmcfl","2409":"tmcfl","2410":"tmcfl","2411":"sjsdfg","2412":"sjsdfg","2413":"sjsdfg","2414":"sjsdfg","2415":"ggauravuee","2416":"sjsdfg","2417":"sjsdfg","2418":"mohit-shrma","2419":"mmalohlava","2420":"mmalohlava","2421":"mmalohlava","2422":"gediminaszylius","2423":"mmalohlava","2424":"mmalohlava","2425":"ledell","2426":"ledell","2427":"ledell","2428":"ledell","2429":"ledell","2430":"sjsdfg","2431":"sjsdfg","2432":"sjsdfg","2433":"sjsdfg","2434":"sjsdfg","2435":"ledell","2436":"ledell","2437":"ledell","2438":"ledell","2439":"sjsdfg","2440":"ledell","2441":"sjsdfg","2442":"ledell","2443":"ledell","2444":"sjsdfg","2445":"ledell","2446":"sjsdfg","2447":"ledell","2448":"sjsdfg","2449":"sjsdfg","2450":"sjsdfg","2451":"sjsdfg","2452":"sjsdfg","2453":"gediminaszylius","2454":"ledell","2455":"ledell","2456":"ledell","2457":"ledell","2458":"sjsdfg","2459":"gediminaszylius","2460":"gediminaszylius","2461":"schwannden","2462":"ledell","2463":"schwannden","2464":"ledell","2465":"schwannden","2466":"ledell","2467":"ledell","2468":"ledell","2469":"ledell","2470":"ledell","2471":"schwannden","2472":"schwannden","2473":"schwannden","2474":"schwannden","2475":"sjsdfg","2476":"schwannden","2477":"sjsdfg","2478":"ggauravuee","2479":"ledell","2480":"ledell","2481":"schwannden","2482":"ledell","2483":"ledell","2484":"ledell","2485":"ledell","2486":"ledell","2487":"schwannden","2488":"ledell","2489":"schwannden","2490":"ledell","2491":"ledell","2492":"ledell","2493":"ledell","2494":"ledell","2495":"schwannden","2496":"schwannden","2497":"ledell","2498":"ledell","2499":"schwannden","2500":"gediminaszylius","2501":"gediminaszylius","2502":"gediminaszylius","2503":"gediminaszylius","2504":"cdagnino","2505":"ledell","2506":"ledell","2507":"ledell","2508":"gediminaszylius","2509":"ledell","2510":"michalkurka","2511":"gediminaszylius","2512":"gediminaszylius","2513":"aruncapiot","2514":"ledell","2515":"sjsdfg","2516":"ledell","2517":"sjsdfg","2518":"sjsdfg","2519":"sjsdfg","2520":"sjsdfg","2521":"sjsdfg","2522":"sjsdfg","2523":"sjsdfg","2524":"ledell","2525":"sjsdfg","2526":"sjsdfg","2527":"sjsdfg","2528":"sjsdfg","2529":"michalkurka","2530":"schwannden","2531":"sjsdfg","2532":"sjsdfg","2533":"schwannden","2534":"ledell","2535":"schwannden","2536":"ledell","2537":"ledell","2538":"ledell","2539":"schwannden","2540":"ledell","2541":"ledell","2542":"ledell","2543":"schwannden","2544":"ledell","2545":"ledell","2546":"ledell","2547":"ledell","2548":"schwannden","2549":"sjsdfg","2550":"sjsdfg","2551":"schwannden","2552":"schwannden","2553":"WitJakuczun","2554":"ledell","2555":"WitJakuczun","2556":"sjsdfg","2557":"sjsdfg","2558":"aruncapiot","2559":"schwannden","2560":"aruncapiot","2561":"dkincaid","2562":"michalkurka","2563":"michalkurka","2564":"michalkurka","2565":"dkincaid","2566":"schwannden","2567":"pcejrowski","2568":"dkincaid","2569":"dkincaid","2570":"dkincaid","2571":"dkincaid","2572":"michalkurka","2573":"dkincaid","2574":"michalkurka","2575":"dkincaid","2576":"michalkurka","2577":"michalkurka","2578":"dkincaid","2579":"dkincaid","2580":"michalkurka","2581":"michalkurka","2582":"dkincaid","2583":"dkincaid","2584":"michalkurka","2585":"dkincaid","2586":"michalkurka","2587":"dkincaid","2588":"michalkurka","2589":"ledell","2590":"ledell","2591":"ledell","2592":"stealthman13","2593":"stealthman13","2594":"michalkurka","2595":"michalkurka","2596":"michalkurka","2597":"stealthman13","2598":"stealthman13","2599":"luisdelatorre012","2600":"ledell","2601":"ledell","2602":"NkululekoThangelane","2603":"ledell","2604":"ledell","2605":"ledell","2606":"NkululekoThangelane","2607":"NkululekoThangelane","2608":"ledell","2609":"NkululekoThangelane","2610":"ggauravuee","2611":"ledell","2612":"thirdeye802","2613":"gediminaszylius","2614":"ledell","2615":"ledell","2616":"NkululekoThangelane","2617":"NkululekoThangelane","2618":"ledell","2619":"ledell","2620":"gediminaszylius","2621":"NkululekoThangelane","2622":"schwannden","2623":"ledell","2624":"ledell","2625":"ledell","2626":"ledell","2627":"ledell","2628":"schwannden","2629":"rcercos","2630":"rcercos","2631":"ledell","2632":"ledell","2633":"ledell","2634":"ledell","2635":"ledell","2636":"dkincaid","2637":"WitJakuczun","2638":"NkululekoThangelane","2639":"ledell","2640":"ledell","2641":"logancwilson17_twitter","2642":"logancwilson17_twitter","2643":"ledell","2644":"ledell","2645":"ledell","2646":"logancwilson17_twitter","2647":"ledell","2648":"ledell","2649":"logancwilson17_twitter","2650":"ledell","2651":"ledell","2652":"ledell","2653":"ledell","2654":"ledell","2655":"ledell","2656":"ledell","2657":"ledell","2658":"ledell","2659":"terrytangyuan","2660":"Aakash282","2661":"Aakash282","2662":"Aakash282","2663":"Aakash282","2664":"Aakash282","2665":"Aakash282","2666":"Aakash282","2667":"Aakash282","2668":"Aakash282","2669":"Aakash282","2670":"Aakash282","2671":"ledell","2672":"Aakash282","2673":"ledell","2674":"Aakash282","2675":"ledell","2676":"Aakash282","2677":"ledell","2678":"ledell","2679":"Aakash282","2680":"ledell","2681":"Aakash282","2682":"ledell","2683":"ledell","2684":"ledell","2685":"Aakash282","2686":"Aakash282","2687":"ledell","2688":"ledell","2689":"Aakash282","2690":"Aakash282","2691":"Aakash282","2692":"Aakash282","2693":"Aakash282","2694":"wreathcrystal_twitter","2695":"wreathcrystal_twitter","2696":"NkululekoThangelane","2697":"NkululekoThangelane","2698":"rcercos","2699":"NkululekoThangelane","2700":"NkululekoThangelane","2701":"ledell","2702":"ledell","2703":"ledell","2704":"NkululekoThangelane","2705":"ledell","2706":"ledell","2707":"ledell","2708":"NkululekoThangelane","2709":"NkululekoThangelane","2710":"ledell","2711":"t1nuswillemse_twitter","2712":"thirdeye802","2713":"NkululekoThangelane","2714":"thirdeye802","2715":"pcejrowski","2716":"ledell","2717":"ledell","2718":"ledell","2719":"schwannden","2720":"schwannden","2721":"ledell","2722":"schwannden","2723":"ledell","2724":"ledell","2725":"schwannden","2726":"schwannden","2727":"ledell","2728":"ledell","2729":"schwannden","2730":"ledell","2731":"schwannden","2732":"ledell","2733":"ledell","2734":"ledell","2735":"schwannden","2736":"ledell","2737":"ledell","2738":"schwannden","2739":"ledell","2740":"michalkurka","2741":"michalkurka","2742":"ledell","2743":"schwannden","2744":"schwannden","2745":"DanGolding","2746":"DanGolding","2747":"DanGolding","2748":"DanGolding","2749":"ledell","2750":"ledell","2751":"schwannden","2752":"schwannden","2753":"ledell","2754":"ledell","2755":"ledell","2756":"schwannden","2757":"ledell","2758":"schwannden","2759":"NkululekoThangelane","2760":"NkululekoThangelane","2761":"NkululekoThangelane","2762":"ledell","2763":"ledell","2764":"NkululekoThangelane","2765":"DanGolding","2766":"ledell","2767":"ledell","2768":"ledell","2769":"DanGolding","2770":"DanGolding","2771":"DanGolding","2772":"DanGolding","2773":"BardiaAfshin","2774":"BardiaAfshin","2775":"BardiaAfshin","2776":"ledell","2777":"ledell","2778":"ledell","2779":"ledell","2780":"DanGolding","2781":"schwannden","2782":"ledell","2783":"ledell","2784":"ledell","2785":"ledell","2786":"schwannden","2787":"r50206v","2788":"schwannden","2789":"ledell","2790":"ledell","2791":"ledell","2792":"ledell","2793":"ledell","2794":"ledell","2795":"r50206v","2796":"r50206v","2797":"stealthman13","2798":"stealthman13","2799":"schwannden","2800":"ledell","2801":"ledell","2802":"ledell","2803":"ledell","2804":"ledell","2805":"ledell","2806":"schwannden","2807":"thirdeye802","2808":"stealthman13","2809":"ledell","2810":"ledell","2811":"schwannden","2812":"thirdeye802","2813":"ledell","2814":"ledell","2815":"ledell","2816":"ledell","2817":"ledell","2818":"thirdeye802","2819":"ledell","2820":"thirdeye802","2821":"fjcarton","2822":"fjcarton","2823":"fjcarton","2824":"ledell","2825":"ledell","2826":"r50206v","2827":"ledell","2828":"ledell","2829":"ledell","2830":"ledell","2831":"r50206v","2832":"schwannden","2833":"fjcarton","2834":"ledell","2835":"ledell","2836":"ledell","2837":"ledell","2838":"fjcarton","2839":"fjcarton","2840":"ledell","2841":"ledell","2842":"pcejrowski","2843":"DanGolding","2844":"ddawley","2845":"ggauravuee","2846":"ledell","2847":"ledell","2848":"pcejrowski","2849":"fjcarton","2850":"ledell","2851":"schwannden","2852":"stealthman13","2853":"stealthman13","2854":"ledell","2855":"ledell","2856":"ledell","2857":"ledell","2858":"ledell","2859":"ledell","2860":"fjcarton","2861":"fjcarton","2862":"DanGolding","2863":"schwannden","2864":"stealthman13","2865":"thirdeye802","2866":"fjcarton","2867":"fjcarton","2868":"rcercos","2869":"constantinembufung","2870":"rcercos","2871":"ledell","2872":"ledell","2873":"ledell","2874":"ledell","2875":"ledell","2876":"ledell","2877":"ggauravuee","2878":"ledell","2879":"ggauravuee","2880":"fjcarton","2881":"fjcarton","2882":"fjcarton","2883":"fjcarton","2884":"ledell","2885":"thirdeye802","2886":"ledell","2887":"DanGolding","2888":"DanGolding","2889":"DanGolding","2890":"DanGolding","2891":"ledell","2892":"ledell","2893":"ledell","2894":"ledell","2895":"dietzc","2896":"dietzc","2897":"siim-romanov","2898":"DanGolding","2899":"ledell","2900":"ledell","2901":"ggauravuee","2902":"ledell","2903":"ledell","2904":"ggauravuee","2905":"stealthman13","2906":"ledell","2907":"ledell","2908":"ledell","2909":"stealthman13","2910":"ledell","2911":"stealthman13","2912":"ledell","2913":"ledell","2914":"stealthman13","2915":"ledell","2916":"ledell","2917":"michalkurka","2918":"stealthman13","2919":"stealthman13","2920":"michalkurka","2921":"stealthman13","2922":"michalkurka","2923":"stealthman13","2924":"michalkurka","2925":"stealthman13","2926":"stealthman13","2927":"michalkurka","2928":"michalkurka","2929":"stealthman13","2930":"stealthman13","2931":"stealthman13","2932":"michalkurka","2933":"stealthman13","2934":"michalkurka","2935":"michalkurka","2936":"dietzc","2937":"spennihana","2938":"spennihana","2939":"spennihana","2940":"spennihana","2941":"michalkurka","2942":"michalkurka","2943":"michalkurka","2944":"michalkurka","2945":"dietzc","2946":"dietzc","2947":"michalkurka","2948":"schwannden","2949":"ggauravuee","2950":"ledell","2951":"ledell","2952":"r50206v","2953":"ledell","2954":"ledell","2955":"r50206v","2956":"schwannden","2957":"schwannden","2958":"schwannden","2959":"ledell","2960":"ledell","2961":"ledell","2962":"lucav76","2963":"mathankumarts","2964":"mathankumarts","2965":"michalkurka","2966":"t1nuswillemse_twitter","2967":"mathankumarts","2968":"JoeIsTheBest","2969":"pcejrowski","2970":"schildjo","2971":"mrdbourke","2972":"michalkurka","2973":"michalkurka","2974":"michalkurka","2975":"michalkurka","2976":"mrdbourke","2977":"ggauravuee","2978":"pcejrowski","2979":"mathankumarts","2980":"ggauravuee","2981":"schildjo","2982":"rcercos","2983":"ledell","2984":"ledell","2985":"ledell","2986":"ledell","2987":"ledell","2988":"ggauravuee","2989":"xyedabz","2990":"xyedabz","2991":"xyedabz","2992":"xyedabz","2993":"xyedabz","2994":"ledell","2995":"ledell","2996":"xyedabz","2997":"r50206v","2998":"schwannden","2999":"schwannden","3000":"ggauravuee","3001":"r50206v","3002":"dangchienhsgs","3003":"dangchienhsgs","3004":"ggauravuee","3005":"fjcarton","3006":"JulioBarros","3007":"cranella","3008":"cranella","3009":"cranella","3010":"ggauravuee","3011":"cranella","3012":"rezacsedu","3013":"rezacsedu","3014":"Alec007","3015":"pedrorijo91","3016":"pedrorijo91","3017":"schildjo","3018":"Chandrak1907_twitter","3019":"Chandrak1907_twitter","3020":"Chandrak1907_twitter","3021":"schildjo","3022":"schildjo","3023":"fjcarton","3024":"ledell","3025":"ledell","3026":"ggauravuee","3027":"ggauravuee","3028":"cranella","3029":"cranella","3030":"andyxf1029","3031":"andyxf1029","3032":"ledell","3033":"ledell","3034":"cranella","3035":"ledell","3036":"cranella","3037":"schildjo","3038":"ledell","3039":"cranella","3040":"ledell","3041":"cranella","3042":"schildjo","3043":"ledell","3044":"ledell","3045":"ledell","3046":"ledell","3047":"schildjo","3048":"alextorresa4_twitter","3049":"alextorresa4_twitter","3050":"schildjo","3051":"ggauravuee","3052":"ggauravuee","3053":"developeralgo8888","3054":"developeralgo8888","3055":"developeralgo8888","3056":"developeralgo8888","3057":"developeralgo8888","3058":"ledell","3059":"ledell","3060":"ledell","3061":"schildjo","3062":"dkincaid","3063":"laurendiperna","3064":"dkincaid","3065":"FrancisLiang","3066":"michalkurka","3067":"FrancisLiang","3068":"FrancisLiang","3069":"michalkurka","3070":"michalkurka","3071":"saidhiraj","3072":"saidhiraj","3073":"ledell","3074":"snbhanja","3075":"michalkurka","3076":"LuizGG","3077":"FrancisLiang","3078":"laurendiperna","3079":"laurendiperna","3080":"FrancisLiang","3081":"laurendiperna","3082":"FrancisLiang","3083":"laurendiperna","3084":"Tarrahi_gitlab","3085":"michalkurka","3086":"Tarrahi_gitlab","3087":"thirdeye802","3088":"laurendiperna","3089":"michalkurka","3090":"michalkurka","3091":"thirdeye802","3092":"laurendiperna","3093":"arnabbiswas1","3094":"dietzc","3095":"pcejrowski","3096":"pcejrowski","3097":"ledell","3098":"vincealdrin","3099":"dkincaid","3100":"laurendiperna","3101":"dkincaid","3102":"laurendiperna","3103":"laurendiperna","3104":"arnabbiswas1","3105":"pcejrowski","3106":"breakanalysis","3107":"laurendiperna","3108":"pcejrowski","3109":"laurendiperna","3110":"laurendiperna","3111":"schildjo","3112":"arnabbiswas1","3113":"breakanalysis","3114":"breakanalysis","3115":"aruncapiot","3116":"ggauravuee","3117":"ledell","3118":"ledell","3119":"ledell","3120":"arnabbiswas1","3121":"ledell","3122":"cranella","3123":"arnabbiswas1","3124":"ggauravuee","3125":"PerformanceGenetics","3126":"schildjo","3127":"ledell","3128":"ledell","3129":"schildjo","3130":"ledell","3131":"ledell","3132":"schildjo","3133":"schildjo","3134":"ggauravuee","3135":"ggauravuee","3136":"cranella","3137":"cranella","3138":"laurendiperna","3139":"schildjo","3140":"ggauravuee","3141":"ggauravuee","3142":"michalkurka","3143":"laurendiperna","3144":"ggauravuee","3145":"cranella","3146":"michalkurka","3147":"michalkurka","3148":"Pscheidl","3149":"Pscheidl","3150":"arnabbiswas1","3151":"michalkurka","3152":"michalkurka","3153":"gkouro_twitter","3154":"michalkurka","3155":"michalkurka","3156":"michalkurka","3157":"michalkurka","3158":"Pscheidl","3159":"gkouro_twitter","3160":"cranella","3161":"arnabbiswas1","3162":"ggauravuee","3163":"angela0xdata","3164":"ggauravuee","3165":"michalkurka","3166":"ggauravuee","3167":"laurendiperna","3168":"gafr","3169":"gafr","3170":"laurendiperna","3171":"gafr","3172":"gafr","3173":"thirdeye802","3174":"laurendiperna","3175":"thirdeye802","3176":"thirdeye802","3177":"SimonSchmid","3178":"michalkurka","3179":"michalkurka","3180":"SimonSchmid","3181":"SimonSchmid","3182":"dietzc","3183":"michalkurka","3184":"michalkurka","3185":"dietzc","3186":"SimonSchmid","3187":"dparkar","3188":"laurendiperna","3189":"dparkar","3190":"dparkar","3191":"laurendiperna","3192":"ledell","3193":"gokl","3194":"laurendiperna","3195":"legalizenet","3196":"SimonSchmid","3197":"legalizenet","3198":"laurendiperna","3199":"laurendiperna","3200":"ggauravuee","3201":"legalizenet","3202":"laurendiperna","3203":"laurendiperna","3204":"ledell","3205":"SimonSchmid","3206":"laurendiperna","3207":"ggauravuee","3208":"ggauravuee","3209":"valkyrias_gitlab","3210":"valkyrias_gitlab","3211":"valkyrias_gitlab","3212":"michalkurka","3213":"michalkurka","3214":"valkyrias_gitlab","3215":"michalkurka","3216":"ggauravuee","3217":"michalkurka","3218":"michalkurka","3219":"bobknight79","3220":"michalkurka","3221":"bobknight79","3222":"ggauravuee","3223":"michalkurka","3224":"DanGolding","3225":"DanGolding","3226":"laurendiperna","3227":"DanGolding","3228":"gokl","3229":"Pscheidl","3230":"gokl","3231":"gokl","3232":"NkululekoThangelane","3233":"bilcus","3234":"valkyrias_gitlab","3235":"valkyrias_gitlab","3236":"valkyrias_gitlab","3237":"valkyrias_gitlab","3238":"valkyrias_gitlab","3239":"michalkurka","3240":"NkululekoThangelane","3241":"NkululekoThangelane","3242":"valkyrias_gitlab","3243":"Pscheidl","3244":"Pscheidl","3245":"bilcus","3246":"DanGolding","3247":"colettace","3248":"colettace","3249":"hassaanseeker","3250":"SimonSchmid","3251":"pkozelka","3252":"ledell","3253":"mmejdoubi","3254":"laurendiperna","3255":"mmejdoubi","3256":"timdunn22","3257":"laurendiperna","3258":"timdunn22","3259":"timdunn22","3260":"timdunn22","3261":"timdunn22","3262":"laurendiperna","3263":"timdunn22","3264":"laurendiperna","3265":"jbentleyEG","3266":"jbentleyEG","3267":"jbentleyEG","3268":"jbentleyEG","3269":"jbentleyEG","3270":"jbentleyEG","3271":"jbentleyEG","3272":"jbentleyEG","3273":"jbentleyEG","3274":"Bioninbo","3275":"Bioninbo","3276":"ledell","3277":"michalkurka","3278":"ledell","3279":"Bioninbo","3280":"Bioninbo","3281":"timdunn22","3282":"mmejdoubi","3283":"ledell","3284":"ledell","3285":"jbentleyEG","3286":"jbentleyEG","3287":"jbentleyEG","3288":"jbentleyEG","3289":"schwannden","3290":"jbentleyEG","3291":"jbentleyEG","3292":"jbentleyEG","3293":"rwatts3","3294":"rwatts3","3295":"michalkurka","3296":"michalkurka","3297":"zhenyiy","3298":"ledell","3299":"lukasz-gosiewski","3300":"gponce-ars","3301":"ledell","3302":"ledell","3303":"gponce-ars","3304":"gponce-ars","3305":"gponce-ars","3306":"ledell","3307":"ledell","3308":"gponce-ars","3309":"gponce-ars","3310":"lukasz-gosiewski","3311":"jbentleyEG","3312":"jbentleyEG","3313":"jbentleyEG","3314":"jbentleyEG","3315":"gkourogiorgas","3316":"iamjarvo","3317":"ledell","3318":"ledell","3319":"gkourogiorgas","3320":"ledell","3321":"ledell","3322":"ledell","3323":"gkourogiorgas","3324":"ledell","3325":"ledell","3326":"gkourogiorgas","3327":"pjtuxe","3328":"gponce-ars","3329":"gponce-ars","3330":"gkourogiorgas","3331":"gkourogiorgas","3332":"valkyrias_gitlab","3333":"valkyrias_gitlab","3334":"michalkurka","3335":"michalkurka","3336":"valkyrias_gitlab","3337":"michalkurka","3338":"michalkurka","3339":"valkyrias_gitlab","3340":"michalkurka","3341":"michalkurka","3342":"dollarHome","3343":"billyli200465","3344":"dollarHome","3345":"dollarHome","3346":"dollarHome","3347":"valkyrias_gitlab","3348":"valkyrias_gitlab","3349":"michalkurka","3350":"michalkurka","3351":"michalkurka","3352":"valkyrias_gitlab","3353":"valkyrias_gitlab","3354":"valkyrias_gitlab","3355":"valkyrias_gitlab","3356":"michalkurka","3357":"valkyrias_gitlab","3358":"valkyrias_gitlab","3359":"valkyrias_gitlab","3360":"michalkurka","3361":"michalkurka","3362":"michalkurka","3363":"valkyrias_gitlab","3364":"valkyrias_gitlab","3365":"michalkurka","3366":"valkyrias_gitlab","3367":"valkyrias_gitlab","3368":"michalkurka","3369":"michalkurka","3370":"valkyrias_gitlab","3371":"valkyrias_gitlab","3372":"valkyrias_gitlab","3373":"michalkurka","3374":"valkyrias_gitlab","3375":"michalkurka","3376":"valkyrias_gitlab","3377":"valkyrias_gitlab","3378":"michalkurka","3379":"valkyrias_gitlab","3380":"michalkurka","3381":"valkyrias_gitlab","3382":"michalkurka","3383":"valkyrias_gitlab","3384":"valkyrias_gitlab","3385":"michalkurka","3386":"valkyrias_gitlab","3387":"michalkurka","3388":"valkyrias_gitlab","3389":"michalkurka","3390":"michalkurka","3391":"michalkurka","3392":"valkyrias_gitlab","3393":"valkyrias_gitlab","3394":"michalkurka","3395":"michalkurka","3396":"valkyrias_gitlab","3397":"valkyrias_gitlab","3398":"michalkurka","3399":"dollarHome","3400":"dollarHome","3401":"jbentleyEG","3402":"jbentleyEG","3403":"jbentleyEG","3404":"jbentleyEG","3405":"jbentleyEG","3406":"dollarHome","3407":"michalkurka","3408":"michalkurka","3409":"jbentleyEG","3410":"jbentleyEG","3411":"jbentleyEG","3412":"michalkurka","3413":"michalkurka","3414":"michalkurka","3415":"jbentleyEG","3416":"michalkurka","3417":"jbentleyEG","3418":"jbentleyEG","3419":"michalkurka","3420":"valkyrias_gitlab","3421":"valkyrias_gitlab","3422":"valkyrias_gitlab","3423":"valkyrias_gitlab","3424":"michalkurka","3425":"michalkurka","3426":"michalkurka","3427":"michalkurka","3428":"michalkurka"},"message.1":{"0":"Anyone using h2o from Python?","1":"Sure. Have you tried the python bindings that ship with h2o? ","2":"I actually installed h2o with pip, using the link mentioned on h2o website. I'm having issues starting h2o from inside python. Works okay if I start the cluster from commandline and then connect from python but h2o.init() fails to start the cluster. Tried both h2o.init() and h2o.init(start_h2o=True).","3":"No instance found at ip and port: localhost:54321. Trying to start local jar...\\n\\n\\n---------------------------------------------------------------------------\\nTypeError                                 Traceback (most recent call last)\\n<ipython-input-2-e7cfdc50af66> in <module>()\\n----> 1 h2o.init()\\n\\nC:\\\\Anaconda\\\\lib\\\\site-packages\\\\h2o\\\\h2o.pyc in init(ip, port, size, start_h2o, enable_assertions, license, max_mem_size_GB, min_mem_size_GB, ice_root, strict_version_check)\\n    449   :return: None\\n    450   \\\\\\\\n--> 451   H2OConnection(ip=ip, port=port,start_h2o=start_h2o,enable_assertions=enable_assertions,license=license,max_mem_size_GB=max_mem_size_GB,min_mem_size_GB=min_mem_size_GB,ice_root=ice_root,strict_version_check=strict_version_check)\\n    452   return None\\n    453 \\n\\nC:\\\\Anaconda\\\\lib\\\\site-packages\\\\h2o\\\\connection.pyc in __init__(self, ip, port, size, start_h2o, enable_assertions, license, max_mem_size_GB, min_mem_size_GB, ice_root, strict_version_check)\\n     76           if not ice_root:\\n     77             ice_root = tempfile.mkdtemp()\\n---> 78           cld = self._start_local_h2o_jar(max_mem_size_GB, min_mem_size_GB, enable_assertions, license, ice_root)\\n     79         else:\\n     80           print \\No jar file found. Could not start local instance.\\\\n\\nC:\\\\Anaconda\\\\lib\\\\site-packages\\\\h2o\\\\connection.pyc in _start_local_h2o_jar(self, mmax, mmin, ea, license, ice)\\n    164       raise ValueError(\\`ice_root` must be specified\\)\\n    165 \\n--> 166     stdout = open(H2OConnection._tmp_file(\\stdout\\), 'w')\\n    167     stderr = open(H2OConnection._tmp_file(\\stderr\\), 'w')\\n    168 \\n\\nC:\\\\Anaconda\\\\lib\\\\site-packages\\\\h2o\\\\connection.pyc in _tmp_file(type)\\n    272   def _tmp_file(type):\\n    273     if sys.platform == \\win32\\:\\n--> 274       usr = re.sub(\\[^A-Za-z0-9]\\ \\_\\ os.getenv(\\USERNMAME\\))\\n    275     else:\\n    276       usr = re.sub(\\[^A-Za-z0-9]\\ \\_\\ os.getenv(\\USER\\))\\n\\nC:\\\\Anaconda\\\\lib\\\\re.pyc in sub(pattern, repl, string, count, flags)\\n    149     a callable, it's passed the match object and must return\\n    150     a replacement string to be used.\\\\\\\\n--> 151     return _compile(pattern, flags).sub(repl, string, count)\\n    152 \\n    153 def subn(pattern, repl, string, count=0, flags=0):\\n\\nTypeError: expected string or buffer","4":"[![blob](https:\/\/files.gitter.im\/h2oai\/h2o-3\/3Yqv\/thumb\/blob.png)](https:\/\/files.gitter.im\/h2oai\/h2o-3\/3Yqv\/blob)","5":"Hi, can you please try to type \\n```\\nimport os\\nos.getenv(\\USERNAME\\). \\n```\\n\\nIt is bug in our code, i just would like to verify the behavior on your site.","6":"Returns 'User'","7":"I fixed it by changing the return statement","8":"Oki, thank you, it is stupid typo on our side, sorry for that. I push fix to the master, but release will be ready later during weekend","9":"not a problem, fixed it at my end as well :)","10":"perfect! thank you for trying h2o! :-)","11":"fixed another small bug, sent PR.","12":"Thanks for making it opensource ","13":":D","14":"cool! thanks a lot for PR","15":"very perfect project, I really love it","16":"Thank you! ","17":"Hi there.  Im wondering if there's a mismatch between some example code im following and the version of h2o Im using with R...","18":"Im trying to do\\n```\\ntrain <- as.h2o(localH2O, object = df)\\n```","19":"h2o appears to be assigning its own col names to the resulting object","20":"whereas the example code im following along with seems to be subsetting the object with the assumption that the column names match the original dataframe","21":"Hey Andrew, as.h2o would save the df object temporarily and then upload it into H2O. Sounds like when during the upload we detected no headers.","22":"Which example were you following?","23":"Or what's the df object?","24":"@amywang718 Adding the headers=TRUE option did the trick.","25":"Just strange because it didn't seem necessary in a prior example I had seen.","26":"Thanks.","27":"Hey Andrew, if it's not specified H2O's parser will try to detect whether the first column is part of the data or not. Looks like this version and this dataset it detected the first column is part of the data.","28":"Yeah I got the hang of it now :)  Awesome software!","29":"Hm.. so I realize this question is surely covered in the documentation, but I'm kinda curious for a more interactive answer: what's the experience like for implementing new algorithms into h2o?  ","30":"Is h2o limited to java based implementations?","31":"Sure. Take a look at Cliff\\u2019s blog posts here: http:\/\/h2o.ai\/blog\/2014\/16\/Hacking\/Algos\/","32":"If you want to dig deeper into some of the performance characteristics to be aware of while implementing new algorithms, look at http:\/\/h2o.ai\/blog\/2014\/02\/kv-store-memory-analytics\/ and http:\/\/h2o.ai\/blog\/2014\/05\/kv-store-memory-analytics-part-2-2\/","33":"Thanks","34":"Pretty good overview, but I'm wondering if its imaginable to implement an algo in another language... perhaps by wrapping with the necessary Java dressings making a call to some kind of process container?","35":"Well, ultimately it has to run in the JVM. So are you talking about another JVM language, or something else?","36":"something else","37":"but, even sticking within the JVM could open possibilities it seems..","38":"so perhaps something like Clojure or Scala?","39":"Sure, that should be possible. There\\u2019s Sparkling Water, which is built in Scala, but that\\u2019s more of a H2O-Spark integration project. ","40":"Which language would you want to write the algos in, if I may ask?","41":"Or are you looking at some kind of DSL, or surface-syntax-to-Java transformation?","42":"More curious about what options exist than anything","43":"Python is my usual go to","44":"But even jumping into something like Groovy would be nice","45":"as for DSLs.. what about a DSL that lives in the JVM?","46":"Currently all of the algos are implemented in Java. This is because the implementors know what the Java translates to during runtime, and consequently have better guarantees about how the algo will perform. A DSL or high level surface-syntax would be elegant, but we haven\\u2019t built any yet. @mmalohlava has more ideas on this. ","47":"He\\u2019s the DSL expert :-)","48":"I don't know a ton about h2o yet but it seems that one of the main ingredients here is use of this kv-store ?","49":"Yes","50":"and I assume that would then bound any algo implementations?","51":"Yes","52":"(ie, any implementations must use that kv-store)","53":"Correct. It\\u2019s a distributed kv-store. The algos work on that. ","54":"Hm.. I wonder if you could potentially use something like docker to encapsulate the algorithm implementation","55":"allowing the implementation in any language so long as it interfaces with the kv-store","56":"Hello everyone, I'm using the python api. Is there a way to save the models using the api? I can see that I can download a model's POJO file but how can I recreate the model from the POJO file in python without retraining it? Thank you!","57":"@mihaisecasiu At the moment we haven't yet implemented save\/restore model in H2O-3.0 yet, it's a pending jira: https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-1164?jql=text%20~%20%22save%20model%22 . Once it has been implemented we'll put in the R and Python bindings. ","58":"@mihaisecasiu Save and restore is not implemented yet. There\\u2019s a ticket for that: https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-787\\n@andrewcstewart I would suppose the api calls across that boundary would be prohibitively expensive for this to be a practical strategy.","59":"@lo5 Yeah, I suspect you're right.","60":"@andrewcstewart regarding DSL - right now at JVM level we expose Java API, and simple Scala API from data frames.  For example of using Java API i would point you to github tests (for example, https:\/\/github.com\/h2oai\/h2o-3\/blob\/master\/h2o-algos\/src\/test\/java\/hex\/tree\/gbm\/GBMTest.java), for Scala API you can visit Sparkling Water project using H2O API (look here: https:\/\/github.com\/h2oai\/sparkling-water\/blob\/master\/examples\/scripts\/chicagoCrimeSmallShell.script.scala)","61":"Hi H2Oer,","62":"I have found that in H2O Classic, when one column is mixed int or real numbers with string, than H2O can not identify the string, only get blank values. But H2O 3.0 can identify mixed type columns.","63":"if one set the column to ENUM, then H2) 3 can identify the mixed type","64":"Hi everyone. I have a question regarding sparkling water. Any reason why it collects column domain on a spark side, not at h2o - where it should be faster:\\nhttp:\/\/i.imgur.com\/8ngv2Sl.png","65":"Hey Petro, right now if Spark DataFrame\/RDD contains a string field, it does not contain information about arity of column, so i collect this information in advance in Spark and then decide if i should create H2O String-column or Enum-column.\\n\\nHowever, you are right - perhaps better strategy would be to transfer column directly to H2O and do post-processing (switching column type to enum) in H2O. \\n\\n","66":"Let me create H2O ticket for this and solve it later. \\n\\nIs it blocking you?","67":"Not so much, but it neglects performance winning for small models compared to spark's mllib implementation. ","68":"@chrinide Yes, in H2O Classic, the parser reads all the data and tries to guess the column type.  In H2O-3, the parser reads a subset and makes a type guess for each column.  In Flow, you will see these guesses and can change the column types as you like and the parser should obey the new column types.  Similar effects can be done in R and Python.","69":"hi guys, it seems the H2O 3.0 not work well with R","70":"prostate.dl = h2o.deeplearning(x = 3:9, training_frame = prostate.hex, autoencoder = TRUE,\\n                               hidden = c(10, 10), epochs = 5)\\n","71":"ERROR: Unexpected HTTP Status code: 412 Precondition Failed (url = http:\/\/localhost:54321\/3\/Rapids)\\n\\nwater.exceptions.H2OIllegalArgumentException\\n [1] \\water.api.RapidsHandler.exec(RapidsHandler.java:132)\\           \\n [2] \\sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\\    \\n [3] \\sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\\    \\n [4] \\sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\\\\n [5] \\java.lang.reflect.Method.invoke(Unknown Source)\\                \\n [6] \\water.api.Handler.handle(Handler.java:56)\\                      \\n [7] \\water.api.RequestServer.handle(RequestServer.java:673)\\         \\n [8] \\water.api.RequestServer.serve(RequestServer.java:610)\\          \\n [9] \\water.NanoHTTPD$HTTPSession.run(NanoHTTPD.java:438)\\            \\n[10] \\java.lang.Thread.run(Unknown Source)\\                           \\n\\nError in .h2o.doSafeREST(conn = conn, urlSuffix = page, parms = .params,  : \\n  factor requires a single column\\n","72":"Hello @zgmming, can you specify your H2O version? Was it 3.0.0.12?","73":"Hi H2Oer, it is now GLRM model Available under Python API & WebUI? I saw that it is available under R API? ","74":"@chrinide I believe GLRM is still under testing.  As such we haven't ported it to the other interfaces yet.","75":"Is it possible to run sparkling water on windows (on pyspark)?","76":"@bghill Thanks for your information.","77":"Hello, I am interested to use h2o algorithms (like RF\/GBM) to perform a classification task on a dataset loaded in Spark. Scala is on my \\to-learn\\ list but at this point of time, I would like to use R. Is it possible to write R code that calls h2o algorithms on data in spark?","78":"Hello, is it possible to filter a H2OFrame  using the scala\/sparkling water? Or do I have to do this in Spark?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ","79":"@binga yes, you can connect from R to running H2O\/Sparkling water cluster and run algos, analyze data, or do feature munging. See docs.h2o.ai \\n\\nAlso you can look at some example in Sparkling Water:\\n\\n  - Prepare data\/models in Spark\/Sparkling Water and use them from R https:\/\/github.com\/h2oai\/sparkling-water\/blob\/master\/examples\/meetups\/Meetup20150326.md\\n  - Analysis on airline data, making a regression model in Sparkling Water, and producing residuals plot in R. See code https:\/\/github.com\/h2oai\/sparkling-water\/blob\/master\/examples\/meetups\/Meetup20150203.md\\n","80":"@hvanhovell yes:\\n  - column filtering is easy, just remove columns which you do not need, or create a new H2OFrame from selected columns (probably there is no H2OFrame accessor right now, but you can create a new Frame - Frame(String[] names, Vec[] vec) and then make H2OFrame wrapper around it (new H2OFrame(frame))\\n\\n  - row filtering is little bit harder. There are two ways: \\n    - create an additional binary vector holding 1\/0 for in\/out the sample, and during your computation you have to take into account the created vector. This solution is quite cheap, since you do not duplicate data, just create one simple vector in one data walk.\\n    -  create a new frame with filtered rows - this is harder tasks, since you have to copy data - look at #deepSlice call on Frame (H2OFrame)","81":"@mmalohlava  It concerns row filtering. I have added a binary Vec to my dataframe, now how do i make deeplearning or some other algo ignore the rows with a '1' value for the binary vec? I suppose I need to use the deepslice approach?","82":"@vchollati yes, but there is no explicit Windows script right now. \\n\\nHowever, you can go Spark way (`spark-shell`, `spark-submit`) and specify cmd line parameter `--jars` to point to sparkling water fat jar (should be in directory `assembly\/build\/libs\/`)","83":"Regarding H20-Flow-3, Any idea on why do I get the message \\Exception in thread \\NanoHTTPD Session\\ java.lang.OutOfMemoryError: Requested array size exceeds VM limit\\n        at java.util.Arrays.copyOf(Arrays.java:2367)\\ when I try to \\Download POJO\\ ?\\n","84":"@geponce: @paragsanghavi replied to you on google groups","85":"@srisatish for Spark packages: $SPARK_HOME\/bin\/spark-shell --packages ai.h2o:sparkling-water-core_2.10:1.3.3","86":" - Spark 1.3.1 Hadoop 2.4 from https:\/\/spark.apache.org\/downloads.html- direct link: http:\/\/d3kbcqa49mib13.cloudfront.net\/spark-1.3.1-bin-hadoop2.4.tgz\\n - Sparkling Water 1.3.4 (can probably change during weekend) http:\/\/h2o-release.s3.amazonaws.com\/sparkling-water\/rel-1.3\/4\/index.html (the backup version is Sparkling Water 1.3.1 from http:\/\/h2o-release.s3.amazonaws.com\/sparkling-water\/rel-1.3\/1\/index.html)\\n\\n - Demo scripts are located in the downloaded Sparkling Water zip file under examples\/scripts folder or here: https:\/\/github.com\/h2oai\/sparkling-water\/tree\/rel-1.3\/examples\/scripts\\n  \\n We have several applications which can be run from Sparkling shell:\\n   -  Craigslist application ( craigslistJobTitles.scala)- based on job description it predicts job category (e.g., \\labor\\ \\eduction\\ ...)\\n   -  Chicago crime ( chicagoCrimeSmallShell.script.scala) - predicts probability of arrest for given crime + some nice graphs in flow explaining crimes in Chicago\\n   - Ham or Spam ( mlconf_2015_hamSpam.script.scala) - for a given message predicts if it is spam or normal message (ham)\\n   - CitiBike demo ( strata2015_demo.scala) - predicts number of bikes at given stations and hour\\n\\nTo run them, please launch Sparkling Shell: bin\/sparkling-shell -i examples\/scripts\/craigslistJobTitles.scala\\n\\nThere are also several standalone applications (Spark guys call them self-contained applications) corresponding to scripts listed above,\\nHOWEVER one app is fresh new: Craigslist Streaming Application (it builds a model, and then open a Spark stream and classifies incoming events).\\n\\nTo run it:\\n   1. window: bin\/run-example.sh CraigslistJobTitlesStreamingApp\\n   2. window: nc -lk 9999\\n\\nwait for 1. window build a model and then send job descriptions from the 2nd window. Window #1 will show you predicted job category for events you send via 2nd window\\n","87":"I'm planning on adding a minimalist, fully transparent, opt-out telemetry system to H2O 3, to help us  find and fix problems in the software.  I've begin a new thread in the Google Group here: https:\/\/groups.google.com\/forum\/#!topic\/h2ostream\/C8B6bHP2Q4A\\n\\nOf course, you're welcome to discuss it here as well.  :-)","88":"I want to use this project in Eclipse.Who have done this?","89":"@pcchong : sorry for the delayed response.  We've had a few internal developers do H2O development in Eclipse in the past, but they've all moved to IntelliJ.  @bghill was looking at Eclipse yesterday, and the Eclipse syntax checker  was giving errors on some fairly advanced type parameter usage, which works fine in both javac and IntelliJ.  Looks like an Eclipse bug.  We'll be tracking that down and will get back to you.","90":"@rpeck @paragsanghavi  Hi,  So,  is the size of a H2O model an issue regarding the process of downloading POJO and the resulting predict vector from H2O Flow server?   Is there anyway to get rid of this limitation within the JVM set up?","91":"@pcchong I've just sent an email with screenshots of each step.  I'll put them together as a blog post, but for now, the directions I emailed you should help you get it running in the latest Eclipse.","92":"@paragsanghavi  The water meter only works in Linux, right?  Mac OS ?","93":"@geponce Correct.  The water meter will only show you the performance of the H2O server if it is running on Linux.","94":"[![blob](https:\/\/files.gitter.im\/h2oai\/h2o-3\/qNcF\/thumb\/blob.png)](https:\/\/files.gitter.im\/h2oai\/h2o-3\/qNcF\/blob)","95":"@paragsanghavi @bghill @rpeck  ","96":"@bghill @paragsanghavi @rpeck  ~ 13 hrs (DRF, 66M rows training data and 11M rows for validation data, 400 Trees, Depth 20, 12 predictors (most of the columns are real, I  reduced the size of my  tables by reducing the precision to 3 using \\format(myDataTable, digits=3)\\   ","97":"@bghill @paragsanghavi @rpeck Server specs:  Dell R710, 2 Xeon processors with 16 Cores and 290 GB Ram  ","98":"@paragsanghavi @bghill @rpeck  How to run h2o.saveModel in R ? Documentation in R (June 14, 2015) has a difference in the parameters between the example and the specification of h2o.saveModel(...) ? Should I still use ... save_cv = TRUE, force = TRUE... ?","99":"@geponce You shouldn't have to use those two parameters.  force= TRUE only overwrites the file if you try to save the file twice to the same name.  I think save_cv isn't in the current version, and I don't think it would apply to your model anyways.","100":"@bghill @paragsanghavi @rpeck Is the newest version of h2o.randomForest only intended for use on classification ?","101":"No, random forest works for binary and multinomial classification and for regression.  In H2O 3 the type of the response column determines whether you get classification or regression.  If your response column is a categorical (aka an enum) you can convert it to numerical before training to get regression.  This is true of all the algos.","102":"Folks got confused sometimes by the automatic conversion in H2O 2, so we made it more explicit \/ user controlled in H2O 3.","103":"@rpeck  Thanks... I just got confused while reading current documentation where it says: \\H2O supports a number of standard statistical models, such as GLM, K-means, and Random Forest\\nclassification. \\","104":"Ah, I'll see that that gets fixed.","105":"Thank you!","106":"@geponce, that seems like an unexpectedly long training time for that size of data.  We really need to dig into the details with you.  Is it possible to send us the dataset to profile in-house?  Also, if your number of categorical levels you will likely get better speed and less overfitting by reducing nbins_cats.","107":"@rpeck sure... I'll zip the data... ","108":"@rpeck any email address I can use to send a link ","109":"@rpeck I only have three ENUM variables with 2 to 3 levels ","110":"Hello, when I do a prediction using the python api for any model ( binomial  or bernoulli distribution) I get a frame with 3 columns , the first is NaN and the second ones seem to be probabity for the two classes I'm trying to predict. Shouldn't I be getting the actual class in the first column? I thought it would be fine to just assume that if the number in the column 2 is higher than 0.5 then the predicted class would be 1 but if I do this and I compute a confusion matrix using something like sklearn confusion_matrix I get slightly different numbers than what I get using the model's build in confusion matrix. Then I find ( for the glm ) the threshold parameter which the documentation says it's the \\decision threshold for label-generation\\ but I don't know how to read it from the model so that I can get the right classes from the prediction.  ","111":"[![blob](https:\/\/files.gitter.im\/h2oai\/h2o-3\/GCp0\/thumb\/blob.png)](https:\/\/files.gitter.im\/h2oai\/h2o-3\/GCp0\/blob)","112":"@rpeck @bghill @paragsanghavi  it took ~ 8 hrs to run predict over ~ 600 M rows","113":"@rpeck @bghill @paragsanghavi  I reduced precision of real columns to 3 digits for all my data tables.","114":"I got the following error when I tried to convert the predictions vector into a data.frame @paragsanghavi @bghill  ","115":"[![blob](https:\/\/files.gitter.im\/h2oai\/h2o-3\/tXDM\/thumb\/blob.png)](https:\/\/files.gitter.im\/h2oai\/h2o-3\/tXDM\/blob)","116":"@paragsanghavi @bghill I prefer to use data.table instead of dataframe, but I also got this: ","117":"[![blob](https:\/\/files.gitter.im\/h2oai\/h2o-3\/qCu0\/thumb\/blob.png)](https:\/\/files.gitter.im\/h2oai\/h2o-3\/qCu0\/blob)","118":"Anyone ever see this? (not sure if should report a bug)","119":"```\\n> localH2O = h2o.init()\\nSuccessfully connected to http:\/\/127.0.0.1:54321\/ \\n\\n\\nERROR: Unexpected HTTP Status code: 404 Not Found (url = http:\/\/127.0.0.1:54321\/3\/Cloud?skip_ticks=true)\\n\\nError in fromJSON(rv$payload) : unexpected character '<'\\n```","120":"Ok, back with a bit more information, it seems i had some issues converting from my h2o frame to numpy but now that fixed that I can see that the prediction column in the prediction frame is always 1 and I can see why this happened because I looked in the POJO at the score0 method and it seems that the threshold for converting the probabilityies to classes is 0 so of course the class is always 1  ","121":"ah btw this seems to only happen in glm ","122":"(btw, with above error, I can reach the h2o web service just fine in the browser)","123":"@mihaisecasiu I'll ping Tomas the GLM guy to take a look at the issue.  Feel free to file JIRA tickets for these things.  I go through every day or two and triage the tickets.","124":"@andrewcstewart That sure looks like a bug to me.  The binding is trying to get cloud status to see if it's ok.  In your case (and in most cases) it is, so you're good to go, but it's probably not detecting cloud failures correctly.","125":"@mihaisecasiu https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-1459","126":"@andrewcstewart https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-1460","127":"@bghill Did you get a chance to take a look to the data? ","128":"@geponce I'm playing with the data currently.  I'll let you know what I find.","129":"@bghill Thanks... Is there anyway to visualize  tree-diagrams out of DRF-h2o models,  just an excerpt?","130":"Not currently.  There is a desire to do it.  We have had that as a request by others.  We are adding visualizations as a part of the H2O Flow (the web UI) development.","131":"@geponce For giggles I'm also running Deep Learning on the data (I already ran GBM and GLM with defaults just to see where they land). From the logs you sent, I see that your 400 tree model gave a MSE of 0.028679 on the validation data.  So that is the score to beat.  Of course, with rerunning the 400 tree RF model, I am mostly trying to get a sense of whether the generated model could be trimmed down in size.  But if I can stumble upon a faster more accurate model, that could be fun.","132":"@geponce Still waiting on the RF tree construction.  While playing with different model types, I did find I can build a GBM model that gets a validation MSE of 0.0259 in less than an hour.  This was on 32 cores shared with other jobs and 60G of memory (I probably didn't need it all, but I was trying lots of different model types).  I went with the defaults except for 150 tress, and a max_depth of 15.  The resulting model is also smaller (31MB) and so should be faster for scoring.  ","133":"@bghill Do you think that one of the variables (ENUM) with a lot of 0's can be causing the timing and object size ? I don't remember where I read something related to this in the h2o documentation... ","134":"@geponce Not in this case.  Your categorical columns only have two values in each (zeros aside).  The slow down you are referring to can happen for large numbers of categories and category bins.  In your case, the nbins_cats variable may say 1024, but it actually shrinks to fit your data.","135":"Can h2o's deep learning library be used in a semisupervised context","136":"@andrewcstewart: @arnocandel is the person to ask.  He's overseas right now, so it might be a bit before he can get back to you.","137":"@bghill Regarding the data set I sent you,  would you suggest to use GBM instead of DRF?  However, GBM it is more prone to overfit  than RF, right? And also can have trouble with noisy data?  ","138":"@geponce While that can happen with GBM in some cases, your current data looks pretty good as far as this is concerned.  66M training with 11M validation is lots of data.   For smaller data sets you would need cross validation to prevent over fit (as well as playing with learning rates and other parameters).  When I made the GBM model, it seemed to get even slightly better results on the validation data.  You should see the sign of overfitting in the MSE for the validation being poorer than for the validation. ","139":"@geponce Are you concerned with noise in the data or the training classification?  The criticisms I have read of boosting methods and noise have only been in regard to classification noise.  ","140":"@bghill I also got slightly better results on the val data with DRF.   I'm just trying to get more familiarized with the GBM algo before I give it a try and just was reading something on the drawbacks for GBM and saw the issue related to noisy data, I might missed the part where it makes reference to classification noise. ","141":"I keep getting `Unknown parameter: n_folds` while trying to run h2o.deeplearning (h2o v3.0)  Is the documentation not in sync with the function definitions ?","142":"@andrewcstewart Hi Andrew, cross-validation didn't make it into the current release of H2Ov3.0.  It is coming in the next couple of weeks.  Your are correct that it seems to have slipped through into the documentation.","143":"@bghill  In one of your last comments regarding the overfitting issuess you said: \\...You should see the sign of overfitting in the MSE for the validation being poorer than for the validation.\\  You meant the sign in the MSE for the validation being poorer than for the \\training\\ right? ","144":"@bghill  Any clue on why it takes so long to run the DRF on the data that I sent you? ","145":"@geponce Correct.  It should show up in the difference between the validation and training MSEs.","146":"@geponce Random Forests are inherently slow, and you've built a really big forest.  I'm still looking to see if we can optimize this model, but I am waiting on fixes being done by others first before I can get an answer.","147":"@bghill @rpeck Is ROC only used to evaluate quality and correctness of classification models or can also be used for Regression? Let's say DRF, which has the dual purpose(Regression\/Classification). ","148":"I'd like to build a .net (c#) library to connect to the h2o REST API, but I can't seem to find the JSON schema definition. Can anyone help?","149":"Hi, started local h20 with -Xmx8g and uploaded 2Gb file. Getframesummary fails with OOM:\\n```\\nfrom \/192.168.1.115:54321; by class water.fvec.RollupStats$ComputeRollupsTask; class java.lang.OutOfMemoryError: Java heap space (water.DException.DistributedException)\\n  water.fvec.RollupStats$Histo.map(RollupStats.java:314)\\n  water.MRTask.compute2(MRTask.java:638)\\n  water.MRTask.compute2(MRTask.java:599)\\n  water.H2O$H2OCountedCompleter.compute(H2O.java:698)\\n  jsr166y.CountedCompleter.exec(CountedCompleter.java:429)\\n  jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\\n  jsr166y.ForkJoinPool$WorkQueue.pollAndExecAll(ForkJoinPool.java:914)\\n  jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:979)\\n  jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1477)\\n  jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\\n```","150":"@geponce Sorry for the delay.  ROC curves can also be used to evaluate regressions.","151":"@Sam7 I believe this is what you are looking for: http:\/\/h2o-release.s3.amazonaws.com\/h2o\/rel-shannon\/26\/docs-website\/h2o-docs\/index.html#schema-reference  correct?","152":"@petro-rudenko That shouldn't happen.  Does it happen reliably, or did garbage collection get delayed too long in single run?  I'm working on reducing the memory footprint during parsing.  Does this data set have an categorical columns with extremely large category counts?  That is another item that currently uses more memory than it needs.  I've written a fix for that, but it is still in testing.  ","153":"Yep it's criteo dataset that has high cardinality for categorical columns","154":"@petro-rudenko  Ok, I'll try to play with that a bit later today.","155":"@bghill  thanks for responding :) I was actually looking for the json schema. I actually found it by looking at the python  scripts.","156":"http:\/\/localhost:54321\/3\/Metadata\/schemas","157":"@petro-rudenko can you specify your java version? Java7 or Java8?","158":"@mmalohlava ```java version \\1.8.0_45\\\\nJava(TM) SE Runtime Environment (build 1.8.0_45-b14)\\nJava HotSpot(TM) 64-Bit Server VM (build 25.45-b02, mixed mode)\\n```","159":"oki, thanks a lot!","160":"Sorry to plug me here with something that isn't probably relevant to the current h2o-3 trunk. I have a local test spark 1.4, scala 2.11 env. When I run sparkling water sparkling-shell, the --jars with the assembly are added : \\n````\\n15\/07\/12 00:52:18 INFO SparkContext: Added JAR file:\/sparkling-water\/assembly\/build\/libs\/sparkling-water-assembly-0.2.17-SNAPSHOT-all.jar at http:\/\/192.168.1.6:50586\/jars\/sparkling-water-assembly-0.2.17-SNAPSHOT-all.jar with timestamp 1436655138712\\n```\\nBut ...\\n```\\nscala> import org.apache.spark.h2o._\\n<console>:20: error: object h2o is not a member of package org.apache.spark\\n       import org.apache.spark.h2o._\\n```\\nAny ideas ?  Sorry if too obvious. Thanks.","161":"It seems an issue with spark 1.4 spark-shell not adding the jars passed in --jars. Must use SparkContext.addJar() instead.","162":"Hi is there a way to convert a string frame to enum? E.g. i have a categorical columns in spark that are strings (e.g. \\cat1\\ \\cat2\\ etc.) - i've transformed to h2oframe and trying to call:\\n```scala\\ndataFrame.colToEnum(Array(colName))\\n```\\nAnd get Operation not allowed on string vector.","163":"Hi trying to play with 11gb criteo dataset on h2o cluster (launched on yarn 50 nodes cluster). It fails at parse phase: http:\/\/pix.toile-libre.org\/upload\/original\/1436976089.png\\n\\nIn logs i see only:\\n```\\n07-15 15:57:19.017 10.50.225.155:54321   1218   FJ-0-15   INFO: Canceled job $03010a32e19b32d4ffffffff$_b9a7dc85176438f5283f1f71ca3243fa(Parse) was cancelled again\\n```\\n\\nWhere can i get more information why it fails?","164":"@petro-rudenko  I think we may need to add that.  In native H2O you only get a string column if you ask for it or if your column is >= 95% unique values it is guessed to be strings.  In either case, the need to switch back to enum is unlikely.  I hadn't considered data coming in from Spark.  I'll open a JIRA ticket for that.","165":"@petro-rudenko Only 50 nodes, why so few?  ;)  I can't think of any failure mode that should cause a cancel, but I'll go through the code to see if I am forgetting something.  That is really weird.  It looks like ingestion of the file went quickly (yay!).  After ingestion (which hits 100%) there are 4 actions that happen after that.  Categories are collected across nodes and unified, the data is compressed, the unified category domains are distributed to each node, and finally basic summary stats are calculated over the data.  Each of these actions gets reported in the spot that says \\CANCELLED\\ in your screen view.  Any idea which was the last one to occur?  If you couldn't see you can also get it in the logs.  In the image above, your \\Select Log File Type:\\ is set to \\info\\. Try \\trace\\.  You'll get more details.","166":"@petro-rudenko Where is the 11G Criteo dataset?  I see larger ones and smaller ones.  I'd like to play with it.","167":"A note on parsing.  Several improvements are on their way.  Faster categorical unification is almost done.  This will vastly improve the memory consumption during the parse of datasets with extremely large categorical sets.  The current method is fine for most datasets, but I've come up with hostile test cases where I'd like to see better performance.  All parsing should benefit from it.  Next up is another memory\/speed improvement that will do compression as parsing occurs instead of as a post processing step.  After that I've got a few new formats that I will work on supporting.","168":"@bghill here's a dataset from original kaggle challenge: https:\/\/s3-eu-west-1.amazonaws.com\/criteo-labs\/dac.tar.gz - mine dataset is almost similar, but with few other columns (not important ones)","169":"@bghill Getting back to my issue with DRF and the size of the resulting object model and the time is taking to run the DRF model and the prediction task... You suggested to run GBM as an alternative, but if I'm more interested on reducing variance, DRF is my best option, right? Since GBM is more on the bias reduction... Also, I'm wondering how GBM can be faster than DRF, if GBM, intrinsically, has to run one tree at the time... right? while DRF can take advantage of the parallelization of trees... ","170":"@petro-rudenko Thanks, downloading it now.","171":"@geponce Let me see if I can get the person who implemented our GBM and DRF to answer","172":"i was watching Venkatesh Ramanathan's video, and I was wondering if he released the code\/data to the public","173":"@geponce The guy who implemented them doesn't have a Gitter account yet.  In short, yes, DRF would likely be better at reducing variance.  As far as speed, there are a number of ways to parallelize tree building.  Our DRF is currently designed for situations where all the data doesn't fit into the memory of a single node.  In the past we have had other RF implementations to use for smaller datasets.  We are looking at how we want to move forward for improving the performance.","174":"@petro-rudenko It seems that the 17th column has over 10 million unique values.  That is above H2O's current limit on categories for a single column.  If you set that column type to string, the parse should work.  I've got three things to do here.  One is to figure out why your job reported as cancelled and not failed.  The other is to see why the error message didn't propagate.  Finally, I already have a JIRA ticket for this, but I need to report which column it is that blew the categorical limit.  ","175":"@petro-rudenko Looking at the data, the 18th column has 2.2M categories, the 26th has 8.4M categories, the 30th has 5.5M, and the 36th has 7M.  Any algorithm that does categorical expansion will have some serious problems with these columns.","176":"Hey guys. Is 120GB data generated or it's original data? from here: \\nhttps:\/\/github.com\/h2oai\/h2o-2\/wiki\/Hacking-Airline-DataSet-with-H2O\\n","177":"@bghill we're using spark's freqItem (count-sketch), to get most frequent items, all other encode as a special category. Winning solution for criteo used similar approach:\\n![](http:\/\/pix.toile-libre.org\/upload\/original\/1437132967.png)","178":"@petro-rudenko The 120GB data is the base dataset repeated 10 times over.  It is mainly for looking at scaling and speed.","179":"@petro-rudenko Good to hear.  Just wanted to make sure.  With such a wide variety of skill levels around, it is sometimes important to warn folks not to try the impossible.","180":"Is there anyway to get the **range** of values of a prediction object (H2OFrame) in R ?  I got this:  **dt.predictions <- h2o.predict(md, dt.main.hex)** and then **dt.predictions2 <- data.table(dt.predictions)**. However, **class(dt.predictions2$V1)** is still a H2OFrame and not a vector, I guess the only option is to save it as CSV and then reload it, right?","181":"@geponce At the moment we can convert a H2OFrame to a data.frame which you can in turn make into a data.table. To convert a H2OFrame to data.frame just run ```dt.predictions2 <- as.data.frame(dt.predictions)```. However if you just want the range of the frame you can run ```min(dt.predictions$predict)``` and ```max(dt.predictions$predict)```.","182":"@amywang718 Thanks Amy...  Interesting, first time that I see a data.table inheriting data frame that doesn't work","183":"Hi i have several questions:\\n1) How many columns does h2o supports? What's the overhead per column? The problem is when i transfer from spark dataframe of sparse vector of size 200000 it puts down all h2o cluster.\\n2) How does word2vec in h2o works? Does it accepts a single column of type string or multiple columns? Here's a script i'm running:\\n```scala\\nval fr = h2oContext.asH2OFrame(data)\\n    val word2VecParams = new Word2VecParameters()\\n    word2VecParams._minWordFreq = 10\\n    word2VecParams._train = fr\\n    val word2VecModel = new Word2Vec(word2VecParams).trainModel().get()\\n    val vec = word2VecModel.score(fr, $(labelCol))\\n```\\n\\nand get ``` No Model Metrics for Word2Vec.```. I want to transform categorical string to a single vector and run GLM on it. Thanks","184":"get cluster stucked, even though getCloud shows all instances are green. In log see next:\\n```07-23 16:38:48.911 10.50.225.6:54321     12887  FJ-123-1  ERRR: Possibly broken network, can not send ack through, got 600 resends.```\\nCluster is under vpn on yarn though sparkling-water.  Yarn and spark show all nodes healthy also. What could cause it?","185":"@bghill Should I try the new H2O release (DRF) for the data set I sent you before? ","186":"@petro-rudenko 1) We don\\u2019t have a set limit on columns. We\\u2019ve had customers successfully use column counts above 10K.  While our current design is set to scale on row count,  we are constantly pushing to make things more efficient to handle higher column counts.  For 100K+ sparse columns we still need to implement internal storage that takes greater advantage of the sparsity.","187":"2) Word2Vec is still underdevelopment, and not ready for production use.  We don\\u2019t expose it in the REST API.  I forgot that it can be seen through Sparkling Water.","188":"@petro-rudenko Our current underlying network infrastructure relies mostly on UDP with an additional reliability layer.  In the past, it has given us speed advantages.  We have now twice systems whose routers are repeatedly blocking specific UDP packets (for unknown reasons).  This effectively killed any resend from getting through.   We\\u2019ve are testing moving completely to TCP currently.","189":"@geponce The current release has the underlying infrastructure needed to stream out extremely large models, but the actual streaming has not been added.  I hope to add it in the next couple of weeks.","190":"@bghill Do you think precision of the float variables could be the main issue related to the size of the H2O object? I guess we discussed this, just wondering how Java is handling the numeric precision... if you change the values from float to integer in the data set I sent do you think that would significantly reduce the size of the H2O object model ?","191":"@geponce I don\\u2019t think that it would.  There are likely to be just as many if statements.","192":"Hi, DRFModel for regression makes a predict column of type integer, not double:\\n```scala\\nval drf = new DRF(rfParams)\\nval rfModel = drf.trainModel.get\\nrfModel._output.nclasses() == 1 \/\/regression\\nrfModel.score(frame).vec(\\predict\\).isInt == true \/\/Should be double\\n```","193":"Hi, how does categorical variables encode in H2O DL model? One hot encoding or something different?","194":"Hi Petro, one-hot encoding","195":"@petro-rudenko regarding DRF `isInt()` issue - can you give us more details? i created simple regression DRF model, call `modelFinal.score(f).vec(\\predict\\).isInt()` and it returns `false`.","196":"I'm investigating h2o and interested in extending some of the build in models, I found this article: http:\/\/h2o.ai\/blog\/2014\/11\/Hacking\/Algo\/KMeans\/ and I'm just wondering if this is still the way to go in the 3.0 release branch? If not any pointers to differences would be appreciated","197":"Specifically I've been digging in the code and it seems like the Schema class is loading models via Reflections, wondering if there are any downsides to building the new models in a separate project and including in the classpath vs building a custom version of h2o? I noticed some comments around hadoop classloading issues, anyone tried this approach and have any feedback?","198":"@davemssavage: The blog post was written for H2O 3, but it's somewhat out of date.  It's being updated, but probably won't be in time for what you want to do.  I'm happy to help here or on h2ostream.\\n\\nIf you want to extend an existing algo I'd do just that, on a fork.  If you want to contribute back your changes you can send us a pull request.\\n\\nYou can create brand new algos and register them via the mechanism that's in H2O.registerExtensions().  Currently your extension will need to be in either the water or hex package to be discovered.  We will loosen this soon (sooner if it's very important to you).\\n\\nH2O.registerExtensions() discovers all subclaasses of AbstractRegister and calls them.  The built-in ones are hex.api.Register and water.api.Register.  You'll see that these register algos and resource roots, respectively.  Use the former as a model of how to register your new algo.","199":"If you're enhancing an existing algo and have new parameters you'll need to add them to the appropriate ModelParametersSchema class.  If you're creating a new algo it's best to begin with an existing one: copy and rename all the classes as appropriate.  You'll find a bunch: the ModelBuilder, the Model.Parameters, the Model (containing the model state), and the ModelOutput.  For each of these there's a Schema which provides stability for the REST API.  Normally all you need in the Schemas are the fields; the rest will happen through reflection magic.","200":"Doing just these should make your algo Just Work (tm) via Flow.  If you want it accessible through R and\/or Python you will need to tweak the bindings.  We don't currently have a nice extension mechanism for those, so if you don't push your changes back to master you'll need to track and merge changes yourself.","201":"Let me know if you have any questions!","202":"@rpeck thanks for getting back to me, at the moment I'm experimenting, I'll try out your suggestions and get back if I have any problems","203":"Excellent!","204":"Does anyone know of a h2o REST API wrapper for .net?","205":"Currently I have Java classes for all the payloads, generated as part of the build process.  I'm working on and off on generated endpoint proxies and hope to have that done in the next few weeks.\\n\\nIt should be trivial to generate .NET classes for the payloads if you send me some examples of what the syntax would be in .NET.  Have you had a look at the Java classes which are in the bindings jar file?","206":"Thanks @rpeck for the response. I've had a look at those and easily modified the py script to spit out a c# syntax. It doesn't seem to be generating the endpoint classes though. Just the models.","207":"Yes, I haven't finished the endpoint proxy generation yet, sorry.\\n\\nIf you would like to contribute back your C# class generation we'd love to incorporate it into the build.  Just send us a pull request for your branch.\\n\\nI'll let you know when I have proxy generation complete for Java Retrofit.  It might be a week or two, since other priorities are more pressing.","208":"@rpeck  done: https:\/\/github.com\/h2oai\/h2o-3\/pull\/25","209":"With h20 flow when building a model (say a DRF), is there an option to randomly do a 90\/10 split for the training_frame & validation_frame  ? ","210":"Ah - SplitFrame achieves this. ","211":"@Sam7: THANKS!","212":"@mmalohlava: can you pull Sam's C# bindings once we've cut simons-5?  Thanks!","213":"@rpeck sure, i am just curious - @Sam7 is there any repository for C# artifacts similar to Maven central?","214":"@mmalohlava yes. it's https:\/\/www.nuget.org\/ once @rpeck get's around to creating a script for the endpoints I'm happy to create a nuget package.","215":"@Sam7 cool! thanks for that - when we are ready i will plug it into our release pipeline","216":"One more note: https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-1851 for tracking C# building and publishing","217":"Is there a way we can score a file and pass an ID through? e.g. record_id, var1, var2... -> record_id, predicted 1","218":"right now we just assume same order","219":"@christophergutierrez  can you explain your usecase in more details? you can do something like this:\\n```java\\nVec recordId = validFrame.vec(\\record_id\\);\\nFrame prediction = model.score(validFrame)\\nprediction.add(\\recordId\\ recordId)\\n```\\n\\nNow prediction frame contains prediction itself and additional column with input \\record_id\\.\\n\\nWill this work for you?\\n\\n","220":"I think so. Basically, when we score a file using the compiled pojo, we'd want to know which score goes with which record. e.g. Suppose the record_id was a social security number and we  scored a file with many people (using social security number as a key). Without depending on the file order, we'd like to know what person (social security number) got what score.","221":"if you're passing the record_id through that should work ","222":"@bghill  I'm trying again the DRF model with the newest H2O version... Any idea why I got this error while I was running h2o.randomForest? \\n|========   4%\\nError in .h2o.doSafeREST(conn = conn, h2oRestApiVersion = h2oRestApiVersion,  :\\nUnexpected CURL error: couldn't connect to host\\nTiming stopped at: 15.101 0.614 1032.699\\nAlso, if I check the web app and click on \\getJobs\\ is says Running in the status column...\\n\\n\\nThanks,\\nGuillermo ","223":"[![blob](https:\/\/files.gitter.im\/h2oai\/h2o-3\/4ZMa\/thumb\/blob.png)](https:\/\/files.gitter.im\/h2oai\/h2o-3\/4ZMa\/blob)","224":"@bghill The job continues working: \\n\\n","225":"@bghill Should I leave it running?  I was working within R-session","226":"@geponce Yes.  If the web app reports things are still running, then I would.  Sometimes the R just doesn\\u2019t get a response fast enough and it believes the H2O server may have died.","227":"@bghill Thanks Brandon... Yesterday I got a 6 hours run time with a DRF training with the latest H2O version for a very similar dataset as the one I sent you before... 66M rows with 11 predictors...  ","228":"@geponce That\\u2019s a nice improvement.","229":"@bghill  Still need to test the prediction part... I guess that's where it took a while before...","230":"Hey all.  Just new and trying out the first h2o demo - the prostate.ipynb, but it isn't able to load the CSV file even when the file path is correct.  Anyone come across that?  I am using the nightly build 3.1.0.3143 - maybe I should have used stable?","231":"@davidljung Do you mean prostate_gbm.ipynb?","232":"Yes","233":"I just get an exception: ValueError: ImportFiles of \/home\/jungd\/h2odev\/prostate.csv failed on [u'\/home\/jungd\/h2odev\/prostate.csv']  (which is the correct path. I've tried various combinations of paths, relative and abs, with and without locate(), but nothing seems to work.  I've just downgraded to 3.0 stable and same issue)","234":"That is part of our nightly test system, so it runs regularly.  Any chance it is a permissions issue?","235":"\\u201cFailed\\ isn\\u2019t helpful. I need to add a better set of messages to ImportFiles.","236":"Unsure.  The JVM and ipython notebook are both running as the same user..  file perms are read for everyone..  (Redhat EL)","237":"Server terminal just prints: 08-27 15:23:59.237 10.130.11.251:54321   6953   #00356-16 INFO: Method: GET   , URI: \/3\/ImportFiles, route: \/3\/ImportFiles, parms: {path=\/home\/jungd\/h2odev\/prostate.csv}","238":"(the jar is in and run from \/home\/jungd\/h2o, which is a sym link to a dir at the same level with the version in the name)","239":"I have a python stack-trace - unsure if you want that pasted in here..","240":"The last part is: \\n```\\n\/home\/jungd\/Enthought\/Canopy_64bit\/User\/lib\/python2.7\/site-packages\/h2o\/h2o.pyc in lazy_import(path)\\n     31   if isinstance(path,(list,tuple)): return [_import(p)[0] for p in path]\\n     32   elif os.path.isdir(path):         return _import(path)\\n---> 33   else:                             return [_import(path)[0]]\\n     34 \\n     35 def _import(path):\\n\\n\/home\/jungd\/Enthought\/Canopy_64bit\/User\/lib\/python2.7\/site-packages\/h2o\/h2o.pyc in _import(path)\\n     35 def _import(path):\\n     36   j = H2OConnection.get_json(url_suffix=\\ImportFiles\\ path=path)\\n---> 37   if j['fails']: raise ValueError(\\ImportFiles of \\ + path + \\ failed on \\ + str(j['fails']))\\n     38   return j['destination_frames']\\n     39 \\n```\\n","241":"@davidljung I\\u2019ve got our python packaging person looking into this.","242":"Is this from a pip install?","243":"@bghill  thanks - appreciate it.  From the same notebook, I can use pandas.read_csv() on the file just fine.  Yes, pip install.","244":"(into my local user site-packages, not system-wide one)","245":"Is your H2O instance only running locally, or is there more than one node?","246":"There are two nodes, but the ipython notebook is running on the node I started first.  (unsure if any node is special?  Does the order in flatfile.txt matter?)","247":"(I can certainly try it with one node, if that would help eliminate variables)","248":"Is the second node running on your notebook?","249":"The parse is parallel, so all nodes need to be able to see the file.","250":"(have to run to a meeting... back soon).   The init() response shows 2 nodes in the cloud, if that is what you mean.  There is no ipython notebook on the 2nd node.","251":"Ah - I didn't install python h2o on the 2nd node - I thought it was just a 'client' side part and the file would be read by JVM.","252":"If you have a file that only one H2O node can see then you can use UploadFile()","253":"the python H2O doesn\\u2019t need to be on both nodes.","254":"It is just a client talking to the H2O server cloud.  It is the server cloud that reads the file (unless you upload a file).","255":"ok, that did the trick: scaling back to 1 node where the file is locally.  I didn't understand that the 2 nodes needed the same file in their local filesystems at the same place (a case where reading a remote from S3 would be easier..).  Thanks for your help.","256":"@davidljung I\\u2019ve got it on my ToDo list to add an error message that clarifies this. I\\u2019m also considering letting one node parse the file, and distribute the data with a warning that the user is reading in the data the \\u201cslow\\u201d way. For playing around this is just fine and users with \\u201cBig Data\\u201d are suitably warned.","257":"@bghill Do you know if the resulting model will be available through my R-session once it finishes ?","258":"@geponce If your R-session has just lost connection or the connection has timed-out, then yes.  You should be able to connect and re-connect an R session to H2O at any point.","259":"@bghill Well, I didn't close my R-Session and the same h2o.init server is still running ","260":"h2oServer\\nIP Address: 127.0.0.1\\nPort      : 54321\\nSession ID: _sid_9c453a6c1971d9ece7c9cfab67c840ad\\nKey Count : 4","261":"I just don't see the object ","262":"[![blob](https:\/\/files.gitter.im\/h2oai\/h2o-3\/CeiX\/thumb\/blob.png)](https:\/\/files.gitter.im\/h2oai\/h2o-3\/CeiX\/blob)","263":"@bghill ","264":"@bghill How can I retrieve  model_DRF_66M_EEMT.hex  within my R-session?","265":"I belive h2o.getModel(model_id, conn = h2o.getConnection(), linkToGC = FALSE) should return a link to your model.","266":"myModel <- h2o.getModel(h2oServer, \\u201cmodel_DRF_66M_EEMT.hex\\u201d)","267":"@bghill Do you know if I can benefit from using Sparkling Water, in terms of speed? Not sure if I can access DRF from R using Sparkling Water","268":"@geponce Sparkling Water runs H2O inside of Spark.  There is no speed advantage.  The purpose is to give Spark users acess to the H2O algorithms.","269":"@bghill So, when I convert my data table into h2o object( using as.h2o), is the file converted into HDFS internally?  Spark is supposed to be a faster approach due to the 'run in memory' capabilities along with the RDD features for data from HDFS or any other file,  right?","270":"@geponce H2O runs in memory.  When you read in a file it is converted into our own internal in memory data structure where each chunk of data is compressed according to its type and properties.  This saves memory and gives you speed (due to cache efficiencies).  Spark is moving away from RDDs in favor of an approach similar to ours.","271":"@bghill Hi Brandon, do you have any case or example where you guys have implemented a solution using DRF?   I read some stuff that H2O is doing with paypal for fraud detection using deep learning algorithm... any other good example for other algorithms?    ","272":"Hi! When I train a model or parse data I'm not able to follow the progress. It stays at 0% and the \\view\\ button doesn't do anything. I can see in the job tracker that the tasks actually do complete without issue though. Is this an issue in the Edge browser on Windows 10 (which seems a bit strange) or have I not configured something correctly?","273":"That sounds like an Edge bug.  @lo5, have you seen this?","274":"@geponce Here are three sets of examples:https:\/\/github.com\/h2oai\/h2o-3\/tree\/master\/h2o-docs\/src\/product\/flow\/packs\/examples","275":"https:\/\/github.com\/h2oai\/h2o-3\/tree\/master\/h2o-r\/demos","276":"https:\/\/github.com\/h2oai\/h2o-3\/tree\/master\/h2o-py\/demos","277":"Sorry they weren\\u2019t easy to find. We\\u2019ve got that on someone\\u2019s ToDo list.","278":"@bghill \\n```\\ndt.model.prediction <- h2o.predict(model, dt.main.table)\\ndt.pred.column <- data.table(pred = dt.model.prediction$predict)\\nhead(dt.pred.column[, list(pred)])\\nError in `[.data.table`(x, i) :\\n  invalid type\/length (S4\/6) in vector allocation\\n```","279":"@bghill I don't remember if I already mentioned this to Matt D. \\n","280":"@bghill  Is he in this chat? ","281":"there's still no way to convert the resulting 'vector' of predictions into something that can be attached to another data.table right? ","282":"@geponce I\\u2019ve sent an invite to Matt to get him to join.","283":"I just recalled that what I ended up doing is saving the predict vector as csv and then reload it back as a data.table or data.frame...  I don't see how can I do an straight column-append, e.g. dt.table[,predictions:=dt.model.prediction$predict]","284":"@geponce That is probably simplest.  I don\\u2019t think Matt has added any means to directly import from H2O.","285":"I just went back to this chat log and found that Amy mentioned that as.data.frame works... dt.pred <- as.data.frame(dt.md.predictions)","286":"@bghill  I  keep getting this error everytime I try to access the prediction vector from H2OFrame","287":"dt.pred<-data.frame(predictions=dt.md.predictions$predict$predict)\\n\\nERROR: Unexpected HTTP Status code: 400 Bad Request (url = http:\/\/127.0.0.1:54321\/3\/DownloadDataset?frame_id=subset_40&hex_string=1)\\n","288":"already used as.data.frame, as.data.table,  data.frame and data.table... What would be the right way to get the predict vector out of a H2OFrame ?","289":"I guess h2o.downloadCSV should work... testing now... ","290":"It didn't work... I get the same ERROR 400: bad request","291":"How big is that frame?","292":"object.size(dt.md.predictions)  = 4120 bytes","293":"138M values (rows)","294":"The 4120 bytes is the size of the local prediction object, not the data itself (which is still held in H2O).","295":"Since H2O can run on huge datasets, many of the local H2O objects in R are pointers to the actual data on the cluster. Otherwise we\\u2019d fill your local laptop memory.","296":"How can I save that predic vector into disk ?","297":"I need to generate some raster\/image data with that... ","298":"@bghill  I need to append that predict vector to another table that has a reference to pixels (pixel_id)","299":"dt.pred <- as.data.frame(dt.model.predictions) didn\\u2019t work?","300":"No...  dt.pred <- as.data.frame(dt.md.predictions)\\n\\nERROR: Unexpected HTTP Status code: 400 Bad Request (url = http:\/\/127.0.0.1:54321\/3\/DownloadDataset?frame_id=predictions_a7eb_model_DRF_66M_cover_SRAD.hex_on_file6f862bada8\\n3b_csv_5.hex_6&hex_string=1)","301":"I really thought our limit on downloading was 2G.  Your prediction results should only be 1104M (138M *8bytes).  ","302":"It could be that the limit is lower than I realize (any limit is a bug). I know the limit issue was fixed for h2o.exportFile() recently. That should have no limit size.","303":"exportFile is working... ","304":"Ok, it may be a little slow since that is a fair bit of data to transfer.","305":"I tried h2o.downloadCSV  but didn't work... That method uses 'wget' and for some reason it didn't go through... ","306":"Once the data gets above a certain size, it needs to be streamed to the client. It seems exportFile is the only method that has had the streaming capability added so far.  All the rest are going to happen, but clearly haven\\u2019t yet.  Sorry for the hassle.","307":"@bghill thanks Brandon...  exportFile works :+1:  ","308":"I\\u2019m glad to hear it.  We need to put the limits into the documentation until the fixes are in.","309":"Even if it is to shame us into fixing it faster. Makes no sense to crunch big data but not be able to save the results because they are \\u201ctoo big\\u201d.","310":"@geponce I\\u2019m told that the fix has been put in over the weekend for other means of downloading the predictions frame.  There are some methods that aren\\u2019t going to be updated, and their documentation notes that they aren\\u2019t intended to pull big data frames. I need to check what the latest error messages are in this case, so users can understand what the issue and solutions are.","311":"@bghill :+1: ","312":"@bghill do you know how DRF deals with -Inf values within a data set ? ","313":"I'm working in R ","314":"Off the top of my head, I don\\u2019t know. I\\u2019d have to try on a small model to see. ","315":"Hi guys, I am new to H2O and before diving in I would like to know what NNs H2O supports. More specifically I am interested in ConvNets, Deep Belief Nets, Recurrent NNs, Long-Short Term Memory units.  I cannot seem to find this information on the website. Thanks in advance and I am sorry for any duplications.","316":"@mongoose54 we have feedforward NNs.  i am in the process of updating our deep learning booklet, but you can check out the work in progress here: http:\/\/h2o-release.s3.amazonaws.com\/h2o\/master\/3157\/docs-website\/h2o-docs\/booklets\/DeepLearning_Vignette.pdf","317":"I have a question regarding H2O flow. In my model output what is the unit of the run_time? I got this `run_time\\t160156`","318":"milliseconds","319":"@bghill Thanks!","320":"@r3tex I don\\u2019t have access to an Edge instance. Is the console reporting any errors? F12 to bring up dev tools, then Ctrl+2 for the console.","321":"I'm getting this error:\\n```\\nERROR: Unexpected HTTP Status code: 412 Precondition Failed (url = http:\/\/127.0.0.1:54321\/99\/Rapids)\\n\\nError in .h2o.doSafeREST(conn = conn, h2oRestApiVersion = h2oRestApiVersion,  : \\n  *Unimplemented* failed lookup on token: ``. Contact support@h2o.ai for more information.\\n````","322":"I have no ideia what is going on.","323":"I was able to run and not to get this error anymore. Not sure what happened but now it is working fine.","324":"Curious.","325":"Yeah ... I got the error when I ran:\\n`rand_vec <- h2o.runif(subset_sample) `\\n","326":"I\\u2019ll let the Rapids expert know.  What version are you using?","327":"@bghill \\u2018h2o\\u2019 version 3.2.0.3","328":"I couldn't find any example on how to use `weights_column` in  `h2o.glm`. Can someone point me to a place where I can find it? ","329":"@gdequeiroz Does this help: https:\/\/github.com\/h2oai\/h2o-3\/blob\/master\/h2o-r\/tests\/testdir_algos\/glm\/runit_GLM_weights2.R","330":"Hi , Are there any best practices or documention related to production implementation of work done in H2o R ","331":"The https:\/\/h2o.gitbooks.io\/h2o-world-2015-training\/content\/ says its being made , the older version says do not use this. ","332":"Is there any updated version available","333":"There are some drafts for other tutorials. Our docs person is checking with the different authors to see if they can be published.","334":"Thanks @bghill  , Can you please tell Are there any best practices or documention related to production implementation of work done in H2o R","335":"For going into production, you can either use H2O as a scoring server that you use via REST calls, or you can get your models as a Plain Old Java Object (POJO). You can then compile this code and put it into your own server environment without H2O.","336":"The later is discribed a bit here: http:\/\/h2o-release.s3.amazonaws.com\/h2o\/rel-slater\/5\/docs-website\/h2o-docs\/index.html#POJO%20Quick%20Start","337":"The JavaDoc for the POJO form of the models is here: http:\/\/h2o-release.s3.amazonaws.com\/h2o\/rel-slater\/3\/docs-website\/h2o-genmodel\/javadoc\/index.html ","338":"What can be unified approach for R , python , scala based work","339":"We are running Sparking water","340":"Let me get our Sparkling water expert to respond to that.","341":"Oh @mmalohlava where art thou?","342":"@bghill we are keen to get Enterprise Support for H2O at Telstra. Are you able to provide cost and best practice  guides for Spark deployments?\\ncc:@jagatsingh ","343":"@haty1 As far as costs, someone will contact you on that. As an engineer, I try to stay out of such things. We\\u2019ve got your contact info through the form you filled out. We can have an SE contact you to answer your questions on Spark deployment.","344":"@bghill it would be great to speak to a SE contact. Thanks","345":"We are running random forest on sparking water using r . if we specify more that one executors it takes long to run than when we specify 1. Do does it means we cannot run in parallel?","346":"@jagatsingh there is major difference between R\/Python and Scala. R\/Python clients communicating with H2O\/Sparkling Wate via REST API, on the other hand Scala code is running directly in JVM. That means with Scala you can access lower level internals of H2O and also Spark, on the other hand REST API provides well defined stable interface. Normally i would recommend to do main hard-work on big data in Scala and process results in R\/Python or Flow UI - for example, there is a demo which train a regression model on big data in Scala, but make predictions and residuals plot from R (see https:\/\/github.com\/h2oai\/sparkling-water\/tree\/master\/examples)","347":"@haty1 regarding Spark deployments - Sparkling Water is developed as an application on top of Spark, so it deployment is strictly driven by deployment of Spark applications - see Spark documentation (http:\/\/spark.apache.org\/docs\/latest\/cluster-overview.html). From our experience, the best way to deploy Spark and run Sparkling water is YARN environment since it is independent on Spark version and does not need any special configuration like standalone clusters.","348":"@jagatsingh  you can run in parallel, but RF by design is network dependent since it needs to collect information about data spread on different nodes. So RF right now scales better on fat machine (lot of cpus, lot of memory) than on many skinny machines. \\n\\nHowever, we are still working on improvements.","349":"[![blob](https:\/\/files.gitter.im\/h2oai\/h2o-3\/ddzw\/thumb\/blob.png)](https:\/\/files.gitter.im\/h2oai\/h2o-3\/ddzw\/blob)","350":"@bghill Testing DRF with an Dell R930 144 cores ","351":"Wow, pretty cool","352":"@geponce Progress is now being made on downloading and compiling POJOs for extremely large models like the ones you were making.","353":"@geponce wow! nice water meter screenshot!","354":"@bghill @mmalohlava should I expect a significant reduction in running time for h2o.randomForest compared with our previous server that has 16 cores?","355":"@bghill I'm kind of surprised that running time in one server with 16 cores took around 6.5 hrs to run DRF and with a 144 cores ~ 5.5 hrs... Should we expect a linear behavior on #cores  vs running time ? ","356":"@geponce you should see speedup, but not linear, since drf  parallelizes data histogram  preparation not actual tree building (which is done layer-per-layer, tree-after-tree) - we have several ideas to improve this process and working on them","357":"@mmalohlava Thanks Michal... Thus, #cores vs running time for DRF is more like an exponential to rise maximum relationship, where at some point (#cores), the running time rate will plateau, right? ","358":"@mmalohlava *Correction... Exp. decay of #Cores vs Elapsed seconds (DRF)","359":"[![blob](https:\/\/files.gitter.im\/h2oai\/h2o-3\/y1JX\/thumb\/blob.png)](https:\/\/files.gitter.im\/h2oai\/h2o-3\/y1JX\/blob)","360":"Model file produced by h2o is of 250mb. What are best practices to version control this. Do we need to ?","361":"@jagatsingh are you referring to the model saved to disk in binary form or generated model \\pojo\\ (model represented by java code)?","362":"I am working with @jagatsingh and he is referring to binary form. We had errors trying to save as polo. ","363":"@toddniven right now we do not have any versioning support for binary models (still on roadmap). However, you can version them using git or github LFS.\\n\\nCan you specify error getting from saving model as POJO? We updated the feature in the latest release 3.2.0.5 Slater (http:\/\/h2o-release.s3.amazonaws.com\/h2o\/rel-slater\/5\/index.html)","364":"Thanks we are not on github at this moment using gitlab free version.  I guess error we should be able to report on monday. ","365":"@jagatsingh perfect! thank you very much and please let us know the pojo-download error ","366":"Any plans to release sparking water with spark 1.5.1","367":"@mmalohlava @bghill We did not get email from your team. @haty1  sent request to find price of support. ","368":"@jagatsingh sorry for that, i am going to ping our sales team ","369":"@jagatsingh Sparkling Water for Spark 1.5 is already released - Spark 1.5.2 - http:\/\/h2o.ai\/download\/","370":"@haty1 can you contact me in private channel ? i will connect you directly with our sales machine","371":"@mmalohlava Cannot see on http:\/\/mvnrepository.com\/artifact\/ai.h2o\/sparkling-water-core_2.10","372":"@jagatsingh probably some synchronization issue between maven central and mvnrepository.com:\\n\\nIf i search for package at maven central: http:\/\/search.maven.org\/#artifactdetails%7Cai.h2o%7Csparkling-water-examples_2.10%7C1.5.2%7Cjar","373":"Thanks, have sent email to Max this morning","374":"What is the best way to solve this:  ` Version mismatch! H2O is running version 3.0.1.2 but R package is version 3.2.0.3`","375":"I'm running h2o on ec2.","376":"and R version 3.1.1","377":"hi @gdequeiroz , you have to use the right R-package with same h2o version. Please follow instructions on h2o download page: http:\/\/h2o-release.s3.amazonaws.com\/h2o\/rel-slater\/5\/index.html","378":"Hi @mmalohlava. We are running 1000 tree drf in sparkling water on our cluster using 2 executors, 40g ram per executor, and 15 cores per executor. The training set is 250k rows by 100 cols. The model build is taking roughly 1 hr 45 mins. Does","379":"this sound right? We are trying to manage our resources to get the right balance. ","380":"Thanks to awesome support by @mmalohlava  and @bghill . I have written short note on how we implemented Machine learning production pipelines in Telstra cc @toddniven  @haty1   https:\/\/www.linkedin.com\/pulse\/article\/production-implementation-machine-learning-models-jagat-singh","381":"@toddniven for this size of dataset i would expect long runtime even if you use only 2 executors (minimize network traffic) - what is depth of trees? 20?\\n\\nIf you are interested you can try top of master which contains several patches especially to speed up computation in DRF\/GBM","382":"@jagatsingh that's great! thank you for nice article!","383":"We are using all defaults except.\\n ```    \\nrfParams._ntrees = 50\\n rfParams._binomial_double_trees = true\\n``` \\nMaster we can try on Monday\\n","384":"thanks @mmalohlava. We will keep you updated with our progress and thanks so much for all the help you and everyone at h2o are providing.","385":"@jagatsingh you do not need ` rfParams._binomial_double_trees = true`","386":"i expect","387":"Hello everyone. I am new to h2o","388":"Is there any good book or article that I can start with","389":"Start with h2o docs on there website","390":"There is free ebook,right? Officially providedin the website","391":"Ar.. That's from world event last year","392":"Seems its for old version. ","393":"Did you check version ","394":"@bawongfai here are the latest versions of the booklets: https:\/\/github.com\/h2oai\/h2o-3\/tree\/master\/h2o-docs\/src\/booklets\/v2_2015\/PDFs\/online","395":"@bawongfai are you a R or Python user? (or something else)","396":"Also, the docs (for latest stable release) are here: http:\/\/h2o-release.s3.amazonaws.com\/h2o\/rel-slater\/5\/docs-website\/h2o-docs\/index.html","397":"@ledell  is it upgraded version of pdf ebook on gitbook","398":"@ledell Python ","399":"@jagatsingh the h2o-2 ebooks were on leanpub and i think the new h2o-3 books will be on gitbook.  right now, there is nothing on our gitbook: https:\/\/www.gitbook.com\/book\/h2o\/h2o-world-2015-training\/details","400":"We will put the H2O world training on there when its ready (soon)","401":"@bawongfai we are writing a \\H2O in Python\\ booklet (similar to the \\H2O in R\\ booklet) that will be ready in time for H2O World","402":"But there are examples of both Python and R in the GLM, DL and GBM booklets","403":"the only thing that is missing right now (R has but Python doesn't) is grid search","404":"that will be soon","405":"@ledell new books on h2o world ?","406":"At gitbook","407":"@jagatsingh At H2O World (next month http:\/\/h2oworld.h2o.ai\/) we will have a full day of H2O training and we will post those training materials at the link above: https:\/\/www.gitbook.com\/book\/h2o\/h2o-world-2015-training\/details","408":"Looking forward to those new booklets, thanks","409":"Does h2o work with Apache Spark 1.5?","410":"I have an EMR cluster on Amazon EC2","411":"@bawongfai yes, try Sparkling Water 1.5.3 - http:\/\/h2o.ai\/download\/","412":"sorry version 1.5.2","413":"Great I will try it out today. ","414":"Perfect! Let us know how it works for you!","415":"@mmalohlava Hi Michal. My prediction output is water.fvec.Frame.  Can I convert to H2OFrame? ","416":"Does h2o provide some text preprocessing such as tokenise, lemmatise as in NLTK, TextBlob in Python ?","417":"@toddniven yes, it is:\\n```\\nval fr: Frame = ...\\nval hfr : H2OFrame = new H2OFrame(fr)\\n...\\n```","418":"@bawongfai Not yet.  I am working on that.","419":"I want to expose my Spark Streaming App (job) via API. Does Sparkling Water help?","420":"@bawongfai Do you mean REST API? Or java API? Or simple thrift API?","421":"Hello Every one","422":"Iam new to H2o ","423":"Can someone please let me know ","424":"where can I get started with ","425":"@santy2509 You can take a look here:\\n\\n- https:\/\/github.com\/h2oai\/h2o-3\/tree\/master\/h2o-docs\/src\/booklets\/v2_2015\/PDFs\/online\\n- http:\/\/h2o-release.s3.amazonaws.com\/h2o\/rel-slater\/5\/docs-website\/h2o-docs\/index.html","426":"hey all! I'm running h2o on ec2 and I have  a few questions: \\n\\n1) All my data is on s3.  Do I need do download data everytime? \\n\\n2) Are there best practices related to working with data on S3? Should I export it in a more compressed way?\\n","427":"@gdequeiroz \\n1) You will need to upload the data into the H2O cluster each time you start up an H2O cluster.  So that means using `h2o.importFile` with your s3 URL\\n2) Having your data in S3 is the optimal way to use H2O on EC2.   How is your data currently formatted...as CSV files?  If you wanted to save space on S3 and speed in transferring you could gzip your CSV files and still use `h2o.importFile`","428":"@santy2509 :  If you go to docs.h2o.ai, click \\H2O 3.0\\ and then click \\New Users\\ at the top of the page (below \\Welcome to H2O 3.0\\), there are some helpful links for users just getting started with H2O: http:\/\/h2o-release.s3.amazonaws.com\/h2o\/rel-slater\/5\/docs-website\/h2o-docs\/index.html#Welcome%20to%20H2O%203.0-New%20Users \\n\\nYou can also access the latest version of the docs using this link: http:\/\/h2o-release.s3.amazonaws.com\/h2o\/latest_stable_doc.html\\nThe latest R doc is here: http:\/\/h2o-release.s3.amazonaws.com\/h2o\/latest_stable_Rdoc.html\\nAnd the latest Python doc is here: http:\/\/h2o-release.s3.amazonaws.com\/h2o\/latest_stable_Pydoc.html\\n\\nThe link @gdequeiroz provided also works, but is versioned to a specific software release (Slater 5). http:\/\/h2o-release.s3.amazonaws.com\/h2o\/latest_stable_doc.html will take you to the latest version every time. Hope this helps!","429":"Thanks for your help @ledell!","430":"@mmalohlava Rest API like spark job server ","431":"@gdequeiroz If you are running on EC2, I don\\u2019t believe you get charged for loading from s3 to EC2, so the only cost is the load time. Let me know if you have issues with the load time.","432":"@bghill The load time is great! No problem on that. :) ","433":"@gdequeiroz Warms my heart to hear it!","434":"@bawongfai yes, H2O and hence Sparkling Water provides REST API layer - look at this: https:\/\/github.com\/h2oai\/sparkling-water\/blob\/master\/core\/src\/main\/scala\/water\/api\/DataFrames\/DataFramesHandler.scala","435":"Hi, just wanted to give some friendly feedback. I want to be able to use the Flow interface using the Edge browser on Windows 10.","436":"Unfortunately some elements don't update correctly. When training a model for example, the progress bar doesn't move.","437":"Ah, @lo5 I'll see if I can troubleshoot a bit and get you some useful feedback.","438":"Hi , what are the ways track or best practices to monitor model performance while it is running in production using h2o","439":"Hello everyone. I'm new to H2O. Can any one tell me what kinds of MRTask methods does H2o have? where can I find related documents","440":"Can I just write public class Sample extends MRTask?\\n\\nWhy do I need to write public class Sample extends MRTask[Sample] ?","441":"@MNXT7  Because of java generics - `[Sample]` declares self-type so then exposed API of Sample class is strongly-typed and easier to use - especially \\nwhen you are writing `reduce` method.\\n\\nWithout `[Sample]` you need to write `public void reduce(MRTask t)`\\nWith `[Sample]` you just write `public void reduce(Sample s)`\\n\\nFor more info, see java generics documentation - http:\/\/www.angelikalanger.com\/GenericsFAQ\/JavaGenericsFAQ.html","442":"@mmalohlava @bghill  Any experience running R scripts with H2O and SLURM ?  the job scheduler system for Linux ","443":"@bghill @mmalohlava is it possible to run h2o on multiple nodes ?","444":"Wow, SLURM, I haven\\u2019t worked with that since building supercomputers for the DoD.","445":"@geponce H2O absolutely runs on more than one node.","446":"@geponce For SLURM, I figure it will just take a small script to launch on different nodes and cluster up.","447":"is that on the documentation for H2O in R ? ","448":"or any reference I can use to setup a script for SLURM and take advantage of more than 1 node  ","449":"@bghill Let me know if you have any reference I can use on how to move a h2o script beyond 1 node","450":"[![blob](https:\/\/files.gitter.im\/h2oai\/h2o-3\/kfQ9\/thumb\/blob.png)](https:\/\/files.gitter.im\/h2oai\/h2o-3\/kfQ9\/blob)","451":"I have been doing my exploratory analysis using the h2o interface. I was wondering if I can get the same summary (showing the %s as well) inside R.\\n\\n","452":"[![blob](https:\/\/files.gitter.im\/h2oai\/h2o-3\/JMtC\/thumb\/blob.png)](https:\/\/files.gitter.im\/h2oai\/h2o-3\/JMtC\/blob)","453":"@gdequeiroz In R, we don't have any extra functions that show percentage.  I would recommend using `summary` and\/or `h2o.table`","454":"```\\n> h2o.table(train$response)\\n  response Count\\n1        0  2330\\n2        1  2670\\n```","455":"@ledell Cool! I like the `h2o.table`. It prints  only the first 6 rows.  Is there a way to print more than 6 rows and to sort by count?","456":"@ledell I guess I could do: \\n```\\n h2o.summary(data$browser, factors = 10)\\n```","457":"@bghill Hi Brandon... Is this a good reference for multi-node for the SLURM ? http:\/\/h2o-release.s3.amazonaws.com\/h2o\/rel-noether\/4\/docs-website\/deployment\/multinode.html ","458":"@geponce Yes, except that is for an older version.  The docs for the current version are here: http:\/\/h2o-release.s3.amazonaws.com\/h2o\/rel-slater\/9\/docs-website\/h2o-docs\/index.html#%E2%80%A6%20From%20the%20Cmd%20Line","459":"@bghill how do you setup your flat file with IP's and ports if you start your h2o server within R?  I don't see parameters in the h2o.init() from R...  ","460":"@geponce We don\\u2019t have that","461":"@bghill I just saw that I need to setup a hadoop cluster out of R and then point to that cluster from R, right?","462":"Given all the different compute clusters that H2O may encounter, we haven\\u2019t had a one step launch on a cluster from R. The user launches H2O on the cluster using whatever is appropriate, and then gives h2o.init() the correct parameters for the H2O nodes that are running.","463":"Yes, you are correct.","464":"@bghill Is there any reference with a workflow to run H2O scripts with SLURM + Hadoop Cluster +  R ? ","465":"@geponce No, that is a unique setup. Are you just using HDFS for the file system and SLURM to launch jobs?","466":"I'm testing a HPC system and the  system administrators are asking me if there's any way to run my H2O scripts in a multi-node environment ","467":"I have my script in R- H2O  ","468":"The only work here is to launch H2O on your cluster.  Once it is launched, you can tell your R script to talk to the cluster and not a local instance of H2O.  That part is simple.","469":"ok... that means that they need to install hadoop (any version in particular?) and then run the cluster that I can point out within R","470":"H2O doesn\\u2019t need Hadoop. It can run without it just fine.","471":"The documentation mentioned earlier shows how to start H2O on an individual node and to get several nodes to see each other and form a cloud. I presume you would give SLURM a script to do this on each node.","472":"Once the script starts H2O on each node, you are then ready to run your R script.","473":"ok... got it... so they need to do the \\cloud formation behavior\\","474":"or better say: I do it through SLURM ","475":"Actually, there is one other step.  Your data must be stored somewhere that all nodes can see it.","476":"Yes, SLURM reserves compute nodes and launches a job on each node.","477":"got it... yes, one of the Luster FS is for tmp ","478":"lustre fs","479":"Ok, step 1 is push your data to a lustre","480":"Then you figure out what needs to be in your script for SLURM to launch on each node (from the earlier documentation link).","481":"Then once the cluster is up and running, you can run your R script using the IP address of your H2O cluster (H2O prints the address out when it starts up).","482":"So, for example: ","483":"java -Xmx2g -jar h2o.jar &\\njava -Xmx2g -jar h2o.jar &\\njava -Xmx2g -jar h2o.jar &","484":"that is three nodes with 2GB ","485":"what would be the IP ? ","486":"of my cluster ","487":"H2O prints the address out when it starts up","488":"so each onf of those java -Xmx2g... will be run using SLURM, right?","489":"If you run a single jar on your laptop you will see the messages","490":"Yes, each java will be run by SLURM","491":"Most research centers publish docs on how to get running on their HPC services.  Do you have a link for such a thing?","492":"not yet... this is a system just trying to take off... is under alpha testing stage","493":"this is going to be a USDA-Agricultural Research Service HPC infrastructure... ","494":"I'm wondering what is the final ip address that link all the nodes... which is the one I'm going to point out from R, right?","495":"You can use the IP address of any node, there is no \\u201cmaster\\u201d node.  Essentially H2O finds IP address and then finds a port for each node to use to talk to each other.","496":"You can specify the port if you like in the startup parameters (those given to the Java command). Then you might know the IP and the port ahead of time.","497":"got it... so I can use the flat file option to put several nodes IP addresses in a file and use something like this: java -Xmx20g -jar h2o.jar -flatfile flatfile.txt -port 54321","498":"then I just use any IP from that file to point it out from R ","499":"Yes, maybe. :) If SLURM picks your compute nodes for you, then your flatfile won\\u2019t have the right addresses.","500":"In that case, you might go with launching each H2O node with a cluster name instead.  The nodes will try to find each other.","501":"You would then use SLURM to figure out what are the IP addresses of the nodes you are assigned to.","502":"Got it... ","503":"@bghill Thanks Brandon... I'll keep you updated on how this works... ","504":"Let me warn you of a small possible catch.","505":"sure... ","506":"When I used to build those machine, I would actually build in different networks.  That means each node may have many IP addresses.","507":"That is part of the reason I was hoping for a docs page.  I could help you through it.","508":"Ok... In our case, I asked for the nodes IP-addresses and we have 62 nodes... 4 nodes are high memory nodes (1.5 TB each one) and the rest are 128 GB each one. The NodeAddresses  are 10.1.8.xx  we are under VPN connection and login into one of the nodes to setup SLURM jobs jobs","509":"I\\u2019ve got run to Ham class, but I\\u2019ll check in later tonight, or your can contact me directly at brandon@h2o.ai","510":"So, when your nodes are physically in different locations, is the network speed a main issue? I'","511":"ok... thanks a lot for your time ","512":"It depends on the algo. Each also has different scaling properties and network needs.","513":"@bghill  Any idea on this error:","514":"|===                                                                   |   5%  \\nError in .h2o.doSafeREST(conn = conn, h2oRestApiVersion = h2oRestApiVersion,  :\\n  Unexpected CURL error: couldn't connect to host\\nCalls: h2o.randomForest ... tryCatchOne -> doTryCatch -> .h2o.doSafeGET -> .h2o.doSafeREST\\nExecution halted\\nError in file(con, \\r\\) : cannot open the connection\\nCalls: <Anonymous> -> .h2o.startedH2O -> readLines -> file\\nIn addition: Warning message:\\nIn file(con, \\r\\) :\\n  cannot open file '\/test\/RtmpTWJq0M\/h2o_guillermo_ponce_started_from_r.pid': Too many open files\\nrm: traversal failed: `\/test\/RtmpTWJq0M': Bad file descriptor\\n","515":"That was a test running in a single node, still not running the multi-node option... ","516":"@geponce  increase your ulimit ","517":"@jagatsingh we tried this 'ulimit' options and still getting the same error... ","518":"@geponce This sounds like it could be a bug, but I am not sure what would cause it, I haven\\u2019t seen it before.","519":"@geponce I am wondering if you might have an H2O session started in R via h2o.init() and starting another on the command-line is confusing things. They should be fine if the command-line one has a name. h2o.shutdown() should close any instances in R.","520":"@bghill The process was scheduled using SLURM... This is running on single-node mode...  We just want to make sure that runs in a single node before we move forward with multi-node env  ","521":"@geponce What was the run command you used in SLURM?","522":"Just #SBATCH and batch R, this is:","523":"#!\/bin\/bash  \\n#SBATCH --job-name=\\gponce_H2O\\\\n#SBATCH -J test_h2o # Name for your job\\n#SBATCH -c 60 # Number of cores\\n#SBATCH -N 1 # Ensure that all cores are on one machine\\n#SBATCH -p mem # Partition to submit to the standard compute node partition in this example\\n#SBATCH -o h2o_example.out.%j.%N # Standard out goes to this file\\n#SBATCH -e h2o_example.err.%j.%N # Standard err goes to this file\\nmodule load r\/gcc\/64\/3.2.1\\nmodule load java\\nR CMD BATCH test_h2o.R test2_out.Rout\\n#End of file \\n","524":"@bghill so \\test_h2o.R\\ has the R script ","525":"where I call libraries, and h2o.randomForest","526":"@geponce Ok, you want to just execute \\njava -jar h2o.jar\\ninstead of the R script","527":"Then you can fire up R on your latop to connect to H2O.","528":"Think of H2O as a server that you can contact","529":"You run the H2O server and then talk to it through R, Python, or Flow.","530":"what about within the R script doing this?\\nlibrary(h2o)\\nh2oServer <- h2o.init(max_mem_size=\\1500g\\ nthreads=-1)\\n","531":"We just set up h2o.init() in R to presume you don\\u2019t have a server running and so it launches it a local copy.","532":"is the h2o.jar installed with h2o R installation ?","533":"You can also run h2o.init() with an IP and port address for an H2O server that isn\\u2019t running on your maching.","534":"Did you pull from CRAN or the H2O website?","535":"What version of H2O do you have?","536":"from CRAN, admins from HPC did it... So I guess they did it from CRAN","537":"I can give you the URL for the appropriate jar.","538":"h2o_3.2.0.3","539":"that's the R h2o package ","540":"http:\/\/h2o-release.s3.amazonaws.com\/h2o\/rel-slater\/3\/index.html","541":"Get the jar from the Download and run tab","542":"ok... ","543":"if I run the script without SLURM, it works fine... so, is this related to the SLURM processes ? ","544":"It could be","545":"isn't this the latest stable ? http:\/\/h2o-release.s3.amazonaws.com\/h2o\/rel-slater\/9\/index.html","546":"It is but your R client must use the same version as the server that is running.","547":"ok... ","548":"is the 9 already on CRAN ?","549":"I mean 3.2.0.9 ","550":"No, the CRAN folks don\\u2019t want to update everytime we make a new release","551":"The latest on CRAN is 3.2.0.3","552":"Already asked the folks from our HPC to get the h2o.jar with the corresponding version of our h2o package... ","553":"@geponce Slater-9 R package can be installed using:\\n``` \\ninstall.packages(\\h2o\\ type=\\source\\ repos=(c(\\http:\/\/h2o-release.s3.amazonaws.com\/h2o\/rel-slater\/9\/R\\)))\\n```","554":"Thanks @ledell  ","555":"Hi @bghill Can you please tell if there is any example of doing cross validation in H2o sparkling water for gbm model.","556":"@michal would know. He does most of the sparkling water stuff.","557":"Or without sparkling water ","558":"Would you like R or Python?","559":"I just went through our demos, and was suprised to find neither the R nor Python files seem to have been updated to use it. \\nhttps:\/\/github.com\/h2oai\/h2o-3\/tree\/master\/h2o-docs\/src\/product\/flow\/packs\/examples\\nhttps:\/\/github.com\/h2oai\/h2o-3\/tree\/master\/h2o-r\/demos\\nhttps:\/\/github.com\/h2oai\/h2o-3\/tree\/master\/h2o-py\/demos","560":"Really though, you can just supply a nfolds argument with an integer to specify the number of folds you want.","561":"@bghill thank you ","562":"@bghill when h2o R packages is installed, the h2o.jar is also installed and is exactly the same to the one we can download separately, right? ","563":"@geponce Yes","564":"You can test it on your laptop.  Start h2o with java -jar h2o.jar and then start an R session and use h2o.init to connect to it.","565":"@bghill  got it... ","566":"@bghill is there any booklet on h2o DRF ? ","567":"@geponce Not currently.","568":"@bghill I follow your suggestion about running h2o.jar and then within R point to the IP address... so I did 2 SLURM calls... one to initialize the server java... h2o.jar ... and the other to call my R script... ","569":"Then, the output of my R script gave me this: \\Unexpected CURL error: couldn't connect to host\\nCalls: h2o.randomForest ... tryCatchOne -> doTryCatch -> .h2o.doSafeGET -> .h2o.doSafeREST\\nExecution halted\\  \\n","570":"while running h2o.randomForest","571":"but if I check the web interface and do \\getJobs\\ the h2o.randomForest still working ","572":"That is odd.  How long is your script? Is there a reason to run it through SLURM?","573":"It takes ~ 6 hours ","574":"is the large data set, similar to the one  I sent you before ","575":"Yes, but once you start the process on the H2O server, you can disconnect and reconnect later.","576":"600 Million observations and ~ 10 predictors","577":"Have you heard\/seen anything about firewalls or seLinux related to that Curl error ? ","578":"That error would seem to indicate that there was communication (in order for the job to be started) but then later it was cut off.  That doesn\\u2019t seem like a firewall.","579":"so CURL is used intensively at some point  once you call one of the h2o algorithms? ","580":"It is only used to periodically check on the status of the job (to give a progress bar).","581":"[![blob](https:\/\/files.gitter.im\/h2oai\/h2o-3\/NsrV\/thumb\/blob.png)](https:\/\/files.gitter.im\/h2oai\/h2o-3\/NsrV\/blob)","582":"as you can see, the algo continues... ","583":"Yes, that is by design.  Sometimes training on large systems can take hours, so the user will want to close their laptops and reconnect later to see the results in the morning.  You should be able to connect with your laptop and an R session if you like.","584":"yes... ","585":"I haven\\u2019t see the disconnect you\\u2019ve got, but each HPC setup often ends up being pretty unique in my experience.","586":"ok... so you don't think can be related to some network security related... ","587":"It seems more like a connection was killed.","588":"The script was running as a SLURM job","589":"I understand. Connections still do get killed.  Timeouts are a common cause. I've seen a node get so busy that it doesn\\u2019t respond in time. The client isn\\u2019t sure if the node is dead or busy. That is one of several possibilities.","590":"ok... got it... ","591":"That specific case would be odd for DRF since it typically has to do more network communications than most algorithms.","592":"So, DRF won't benefit a lot from multi-node due to the network activity to improve the timing? ","593":"There are a number of ways to split DRF into a parallel process.  If each node can hold all the data, then you can split the work and very little communication is needed.  If the data is so large that it requires more than one node, a lot more communication is needed. In an older version we had both models. In the current version we currently only have a setup that splits the data across a few nodes to handle \\u201cbig data\\. There can be a speedup, but it isn\\u2019t as large as when the data is fully copied on both nodes.","594":"The \\smaller\\ data version is coming, but isn\\u2019t in right now.","595":"@bghill ok... got it... Talk more to the hpc admins... ","596":"thanks","597":"@geponce Glad to help","598":"Is there a  way to import folders in h2o using wildcard?\\n2015-10-1*","599":"@gdequeiroz To import more than one folder contents at once?","600":"Yes @bghill ","601":"For instance, all this\\n```\\n2015-10-10\\n2015-10-11\\n2015-10-12\\n2015-10-13\\n2015-10-14\\n2015-10-15\\n2015-10-16\\n2015-10-17\\n2015-10-18\\n2015-10-19\\n```","602":"@gdequeiroz We have a JIRA ticket open to add that, but we don\\u2019t have it currently.  We do import all the contents of a single folder at once. We also work around it sometimes by making a tmp directory, and then with a script fill it with symbolic links to all the desired files.","603":"@bghill Do you have a example of this script? ","604":"@gdequeiroz What OS are you on? ","605":"@bghill Mac OS","606":"@gdequeiroz I just wrote this:\\n#!\/bin\/bash\\n\\nMYDIR=\\.\\\\n\\nDIRS=`ls -l $MYDIR | egrep '^d' | awk '{print $9}'`\\n\\nfor DIR in $DIRS\\ndo\\n  FILES=`ls -l $DIR | awk '{print $9}'`\\n  for FILE in $FILES\\n  do\\n    ln -s $DIR\/$FILE h2otmp\/.\\n  done\\ndone","607":"The source directory should set for MYDIR, and then the destination directory should be set in the loop (currently called h2otmp).  ","608":"Cool! I'll try it out. thanks!","609":"It finds all directories underneath MYDIR, and the makes a symlink for each file in each of those directories.  It isn\\u2019t recursive though.","610":"Hi all, is it possible to disconnect from a H2O session in order to avoid it exiting when a Rscript ends?","611":"If you launch H2O outside of R, then no disconnect should happen. I am pretty sure if you launch from within R (via h2o.init()) then it kills the session when you close R, otherwise we\\u2019d be bad citizens and leave possible junk processes running on your laptop.","612":"@bghill Hi Brandon... if I'm in a multi node setup and I have a data.table copy at each node, and within my R script I convert that data.table into (as.h2o)... Is this going to slow down the DRF running ?  Should I save the h2o dataframe object at each node, instead?","613":"my data.table is my data source... I converted into h2o object as part of my R script, which is scheduled with the SLURM ","614":"as.h2o() dumps a table to a tmp file and then uploads that csv file to H2O.  Uploaded files only need to upload to a single node and that node will break the table into parts for each node to own.","615":"So, when you say that data should be copied to each node, that means that I should just copy my data.table to each node... ? ","616":"When you do h2o.importFile(), H2O checks if all nodes can see the file(s) because it will parse it\/them in parallel.  On enterprise systems, this is usually one copy on HDFS that all nodes can see. On non-hadoop systems this can be a NFS location that all nodes can read.  If neither of those are available, you can make a copy of the file for each node to read. If you use as.h2o() or uploadFile() the file is transferred from the computer that is running the R script to one node of H2O and then H2O distributes the file among the nodes of the cloud.","617":"So if you are using as.h2o() then only the node with the R script needs a copy.  This is slow since the entire copy is sent to a single node, parsed on one node, and then part are distributed.  It might make more sense to build the data in data.tables and export to an NFS mount.  Then H2O can read the file in parallel via h2o.importFile()","618":"ok... got it.. Right now I'm saving my data.table as binary (saveRDS), it is faster.   But I guess, need to create a csv file  and save it in the lustre file system... and then use h2o.importFile()","619":"That would work","620":"Hi @bghill, if you start H2O using Java from the command line and then connect in an R session (using h2o.init() ), when you end the R session, H2O is killed. I would like to be able to run H2O as a server (which is sort of the point....? ) and to be able to start up a Java\/Python\/R\/Scala script, connect to H2O, disconnect from H2O and then leave the script without ending H2O","621":"If you really want to score large datasets in distributed systems, you need to be able to run a 'scoring' script that can connect ot a continually running H2O instance with all the models in the H2O cloud","622":"my problem is that everytime the 'scoring script' ends, I have to restart H2O and upload my models, which is massively inefficient","623":"is there a more efficiency way to do this?","624":"@alexshires When you use h2o.init() are you giving it the IP and port of the H2O instance you started on the command-line?","625":"@bghill, I'm only giving it the port as localhost is fine for me","626":"@bghill Is there anyway to change the  response time where CURL is used? ","627":"I'm trying to use -flatfile option to run h2o.jar... ","628":"within HPC system  using the interactive \\srun\\  option...  ","629":"@geponce Is CURL too slow?","630":"Just wondering if there's any way to make the server\/client wait for a response a little longer... ","631":"but I guess that's not really relevant, since I can get back to the server and see my tasks anytime I want it... ","632":"right now I'm more with the multi-node and the use of 'flatfile' option ","633":"@geponce I can look into it, but my first guess is no. I believe that time is currently hard-coded.","634":"java -Xmx1400g -jar \/software\/apps\/h2o\/64\/3.2.0.3\/h2o.jar -flatfile \/project\/alphatesting\/flatfile.txt -port 54321","635":"I did that line... from a node in our HPC","636":"the flatfile.txt is visible to every single node ","637":"when I run it, the cloud size keeps as 1... ","638":"I'm running this from an interactive 'srun' node ","639":"the node I am at it, is part of the IP's within flatfile.txt","640":"Are you running that same command on each node?","641":"no... just in one ","642":"what I did, is that I connect to interactive mode using 4 nodes","643":"srun --pty -p mem -n 60 -N4 \/bin\/bash -l","644":"each node has 120 cores","645":"these nodes are high memory nodes","646":"1.5 TB each one","647":"Wow","648":"Can we meet over webex, it might be faster, and I can set up the meeting.","649":"sure","650":"my alpha testing time is almost due jejeje  want to see if I can run h2o on multi node on this system","651":"I\\u2019ve sent an invite","652":"@bghill   I added the Xmx and is working: ","653":"[![blob](https:\/\/files.gitter.im\/h2oai\/h2o-3\/lmP7\/thumb\/blob.png)](https:\/\/files.gitter.im\/h2oai\/h2o-3\/lmP7\/blob)","654":"@bghill Just to let you know that DRF using three nodes (120 cores each) took ~ 4 hrs... using only one of these nodes it took ~8hrs ","655":"I might try the speedRF you mentioned... ","656":"Does anyone know why am I getting this output messages from h2o.init() server running within R session?","657":"[![blob](https:\/\/files.gitter.im\/h2oai\/h2o-3\/k0K4\/thumb\/blob.png)](https:\/\/files.gitter.im\/h2oai\/h2o-3\/k0K4\/blob)","658":"@geponce That is just a record of when Java is doing garbage collection.  I didn\\u2019t realize someone had turned that on.  We usually only turn it on for debugging.","659":"@bghill Thanks...  ","660":"@bghill One of the steps on my workflow is to load my data using  data.table in R and then use \\as.h2o\\ to make it h2o object.   If we think about very large data file (several terabytes, as you mentioned yesterday) What API would you suggest to use?  From R, the fact that put tables and data frames in memory makes things a little bit complicated to run in a multi-node cloud environment, don't you think?","661":"@geponce I would save the data table as a cvs to LustreFS.  This can hopefully be done once.  You can then have H2O ingest the file with h2o.importFile.  Each node will parse the file in parallel.","662":" A very old bug recurred in bleeding release: 3.7.0.3248\\nCan not change Column Type in WEB UI","663":"Error calling POST \/99\/Rapids with opts {\\ast\\:\\(tmp= Key_Frame__train.hex (:= ...\\n\\nTemp ID Key_Frame__train.hex already exists","664":"Temp ID Key_Frame__train.hex already exists (java.lang.IllegalArgumentException)\\n  water.rapids.ASTTmpAssign.apply(ASTAssign.java:254)\\n  water.rapids.ASTTmpAssign.apply(ASTAssign.java:248)\\n  water.rapids.ASTExec.exec(ASTExec.java:46)\\n  water.rapids.Session.exec(Session.java:56)\\n  water.rapids.Exec.exec(Exec.java:63)\\n  water.api.RapidsHandler.exec(RapidsHandler.java:23)\\n  sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\\n  sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\\n  sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\\n  java.lang.reflect.Method.invoke(Unknown Source)\\n  water.api.Handler.handle(Handler.java:64)\\n  water.api.RequestServer.handle(RequestServer.java:644)\\n  water.api.RequestServer.serve(RequestServer.java:585)\\n  water.JettyHTTPD$H2oDefaultServlet.doGeneric(JettyHTTPD.java:617)\\n  water.JettyHTTPD$H2oDefaultServlet.doPost(JettyHTTPD.java:565)\\n  javax.servlet.http.HttpServlet.service(HttpServlet.java:755)\\n  javax.servlet.http.HttpServlet.service(HttpServlet.java:848)\\n  org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:684)","665":"@chrinide Thanks for the find!  The fix will be in the next release which should happen in the next day or so.","666":"https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-2339\\nhttps:\/\/0xdata.atlassian.net\/browse\/PUBDEV-2337","667":"@bghill  however in bleeding release version 3249, the bug still existed as like below:","668":"changeColumnType frame: \\prostate.hex\\ column: \\CAPSULE\\ type: 'enum'","669":"Actually, the code do nothing, the operation do not proceed at all, the \\Int\\ is still \\Int\\ never change to \\enum\\","670":"@chrinide We haven\\u2019t cut a new release since this morning when you reported this.","671":"@bghill This is good news. Have a good night.","672":"@chrinide I was mistaken, yes that was a cut made today by a dev ops person. The fix is in tibshirani-2 which we are in the process of cutting now.  It should be available at \\nhttp:\/\/h2o-release.s3.amazonaws.com\/h2o\/rel-tibshirani\/2\/index.html in a few hours","673":"@chrinide Ready when you are","674":"Hi","675":"What exactly does the response column mean ?","676":"I am always getting a `Response column 'x' not found in the training frame`","677":"Here's what I did","678":"Open a large csv","679":"Parse, do a split","680":"0.75, 0.25","681":"Put the 0.75 in training ","682":"And the 0.25 in validation","683":"Response column is the column that predicts right ?","684":"So I select that","685":"And I get that errir","686":"nvm, i didn't select that column -_-","687":"@bghill Is the code that Mark is running in the GBM and DRF available  ?","688":"Great presentations at H2O world 2015!  Streaming as much as I can... :smile: ","689":"@geponce can you please share streaming URL ","690":"@jagatsingh sure, here it is: http:\/\/library.fora.tv\/conference\/h2o_world_2015\/watchlive","691":"Right now is lunch break... ","692":"You won't hear anything... ","693":"Okay ","694":"Yes and he lunch they are providing is pretty good \\ud83d\\ude00","695":":+1: ","696":"Is the content of pen drive available online for download?","697":"@bghill ","698":"https:\/\/s3.amazonaws.com\/play-datarepo\/h2oworld\/h2oworld.tar","699":"Thanks","700":"@jagatsingh I have it","701":"@bghill @toddniven  I was looking for data sets , R code used for deep learning session going on now. Which folder has this ? I downloaded the tarball","702":"Got it , Thanks","703":"h2o-world-2015-training\/tutorials\/data\\nh2o-world-2015-training\/tutorials\/deeplearing","704":"@bghill, thanks I will read them","705":"And h2o.ai raised 20M in B round, congratud","706":"I\\u2019m running around a lot, so my responses are sometimes a little late.","707":"May I ask where is the latest training documentation for Python","708":"Which learning algorithms in H2O are now scalable?","709":"I'm totally new to H2O and apologize for ignorant questions. Is this a technology that uses my own hardware in a more efficient way, or is it (also) a cloud-based server where the H2O data is analyzed remotely on your cluster via the API?","710":"I think I understand that it leverages your existing hardware. Just making sure.","711":"@hack-r H2O is a cloud-based system that analyzes your \\u201cBig Data\\u201d on a cluster, but with client interfaces that you can easily drive like local Python and R analyses. H2O can also run locally, as a way to prototype your big data analyses. Folks have liked the local processing so much that many only use it that way.","712":"@bghill Thanks!","713":"@bawongfai The latest release is \\Tibshirani\\ which you can download here:http:\/\/h2o-release.s3.amazonaws.com\/h2o\/rel-tibshirani\/3\/index.html  Also on this page are links to all our booklets, including our new Python booklet.  You can also look at our training:  http:\/\/learn.h2o.ai\/content\/  \\nLastly, all our algos are scalable across clusters.","714":"Is there a link with the talks from H2O world 2015? ","715":"I missed some that I'd like to watch... ","716":"@geponce  There is link to videos and presentation on the website. For training material just scroll back little up in this chat there is link ","717":"See h2o world web page for link of videos ","718":"@jagatsingh Thanks...   I'm trying to find Matt Dowle's presentation on data.table ported to H2O but no luck... ","719":"Good morning all! I just started tinkering around with h2o and flow. I have gotten quite a bit of use out of running my data through the churn prediction model example. Is there any way to automate feeding new data to it and getting predictions out of it on a regular basis?","720":"@Compy  One way of doing that is to write a script in R, Python or Scala using our API.  I don't know if automation can currently be performed via the Flow interface, but I sent a note to our Flow developer and will let you know when I hear back.","721":"Yeah, I'm researching the python API now to try to see if there is a 1:1 mapping for the commands seen in the flow script to the python API","722":"Thankfully I know python! It sounds like it'll be a good route to take.","723":"@geponce The H2O-distributed join from Matt Dowle is about 15 mins in to this video here :  http:\/\/library.fora.tv\/2015\/11\/10\/machine_learning_platform_for_smart_applications_future_of_h2o","724":"@Compy yes you can do everything in Python that you can do in Flow.  If you are not using the latest version of H2O you should upgrade because there are a few new Python features. http:\/\/h2o-release.s3.amazonaws.com\/h2o\/rel-tibshirani\/3\/index.html","725":"@ledell I appreciate the help, really! :)","726":"On that same page, scroll to the bottom for our Python booklet","727":"that is a good place to start.  Also check out: http:\/\/learn.h2o.ai\/content\/","728":"Thank you so much! I'll check out the booklet and the conference content you linked! I've got the python libs and 3.6.0.3 set up on my macbook, so it looks like we're good to go on that front!","729":"@Compy, sounds great!  Just post here or on our google group if you have any questions: https:\/\/groups.google.com\/forum\/#!forum\/h2ostream","730":"I will certainly pester! Many thanks :)","731":":+1: ","732":"@bghill Hi Brandon... Have you seen any comparison between h2o DRF and Boruta ? ","733":"@geponce I have not.  Erin knows more about benchmarks than I, as she used to do them.","734":"@ledell  Hi Erin... Have you tested or compared Boruta vs H2O  in R, just wondering if someone at H2O have done it? ","735":"@bghill @ledell  Regarding the presentation from Rob Tibshirani on Cancer Detection, how Random Forest approach would compare vs the Lasso approach he is using...  Also, is the small data set issue that he mentions the real issue behind deep learning not performing as good as Lasso? ","736":"Just wondering if you might talked to Rob T. about it... ","737":"@geponce I can answer your second question. Small data is likely the first issue.  Deep learning has really come to shine in recent years, and while a few new methods have been introduced, it widely cited that the major change has been the size of datasets has grown.  If that data was larger would DL be as effective? We can\\u2019t know without the larger data. Quite possibly though.  Image data is strength for DL methods.","738":"@geponce Of course, training time is also something to always consider.","739":"@bghill Thanks... ","740":"@geponce Regarding Boruta, I have not tried it.  What is your use case?  As an alternative to the standard RF importances calculated randomForest (in R or H2O), I've used the VarSelRF package https:\/\/cran.r-project.org\/web\/packages\/varSelRF\/index.html which is good for gene selection","741":"@geponce There are different use cases where different types of variable importance are more useful than others.  If you are looking for more alternatives for variable selection\/importance within current H2O, you can also use Lasso or Ridge regression via `h2o.glm`","742":"@ledell I haven't tried Boruta... Right now I have been using DRF over satellite\/climate data regarding vegetation response from arid grasslands to climate and management practices... From one of the presentations on DRF and GBM at H2O world 2015 I got some tips that I'd like to give it a try... So, I'll get back to you with further info...   I have a small P domain (~10 features) and a large N domain (~1 Billion, this is just a small area)...  ","743":"@geponce since you only have 10 features, you might want to play around with (reduce) the `sample_rate` parameter to see if you can inject more randomness to your trees.   Or give h2oEnsemble a try :-) https:\/\/github.com\/h2oai\/h2o-3\/tree\/master\/h2o-r\/ensemble","744":"@ledell  Thanks for the suggestions... ","745":"I am having trouble configuring pysparkling shell, if anyone has done so it would be a great help.","746":"I have the following things installed: ","747":"1. Spark 1.3.x","748":" 2 . Sparkling Water 1.3.x","749":"3 . H2o python","750":"4 . pysparkling (pip installed)","751":"From https:\/\/github.com\/h2oai\/sparkling-water, for pysparkling  it says to run .\/gradlew build -x check","752":"I did that however, there is no pysparkling shell in bin to run","753":"Hi @asa88, pysparkling is not supported in Sparkling Water 1.3.x. Please use our latest release of Sparkling Water ( 1.5.6 ) from here http:\/\/h2o-release.s3.amazonaws.com\/sparkling-water\/rel-1.5\/6\/index.html and make sure you have Spark 1.5.1.\\n\\n The other thing is that the pysparkling package is not still available on pip (  there's one which is using same name though - https:\/\/pypi.python.org\/pypi\/pysparkling\/  which you've probably installed). So for now, you need to install it using the egg file which is part of the distribution. Please make sure you have easy_install installed on your system. So:\\n\\n0) Download the Spark 1.5.1 and set SPARK_HOME and MASTER variables\\n1) Download the latest sparkling water release - http:\/\/h2o-release.s3.amazonaws.com\/sparkling-water\/rel-1.5\/6\/index.html\\n2) Run this command within the unpacked sparkling-water directory \\n`easy_install --upgrade sparkling-water-1.5.6\/py\/dist\/pySparkling-1.5.6-py2.7.egg `","754":"@bhill","755":"Thanks @MadMan0708  ! instruction have been on the little confusing side regarding python. I will go ahead follow the steps you mentioned.","756":"@bghill  Are you guys at H2O planning on doing something with tensorFlow? ","757":"@geponce We haven't made any decisions about it yet, but its on our radar","758":"@asa88 Thanks for the feedback.  We will try to make the python Sparkling Water docs more clear","759":"@ledell :+1: ","760":"Really enjoy using H2O with R. Just started a week ago and really loving Flow. ","761":null,"762":"@scottstanfield That is great to hear!","763":"I'd like to get more performance from both my GBM and DL models. Right now just running on a MacBook Pro w\/16GB of RAM. There are GPU-optimized systems that support cuDNN. Namely http:\/\/exxactcorp.com\/index.php\/solution\/solu_detail\/225 and https:\/\/developer.nvidia.com\/devbox.","764":"Before I drop $10-15k on these guys I have to ask: are there announced plans to support cuDNN in the future with H2O? ","765":"@scottstanfield Not currently. We keep an eye on what happens in the GPU space, and even have some engineers with experience developing for them, but largely GPU computation isn\\u2019t really happening on the enterprise clusters. ","766":"Thanks @bghill. We'll focus on small clusters of inexpensive computers with 32-64GB of RAM. Still looking for hardware guidance in that area. At least we can play around with AWS in the meantime, to see what big RAM boxes will do for us. Thanks for the quick feedback!","767":"Trying to watch the H2O World 2015 videos, but man fora.tv is the worst. Would much rather have them on YouTube: speed-up playback, higher-quality non-Flash videos, see other viewers comments, etc. Any particular reason these got encoded to Fora? ","768":"@scottstanfield Thanks for the feedback on fora.tv.  They are the team we hired to do all the recording for H2O World, but as you've pointed out, the service is not top notch.  Right now they are still working on editing the videos, so we are waiting on them to send to the original video files to us.  Once we get those, we will put all the videos up on YouTube.","769":"@ledell Thanks for that. I think you'll find the videos will get more reach. But I'm grateful to have them in rough form now. Wish I could have made the conference. Like you, I live in Berkeley: I really didn't have an excuse!","770":"@asa88: Michal has added some new documentation for PySparking in his latest commit: https:\/\/github.com\/h2oai\/h2o-3\/commit\/183dc578c8f4500b83b778f99c6fe1e1f5e5a5d2 ","771":"@scottstanfield If we had copies, I would send them your way, but fora.tv has all the copies right now.  We were not expecting this much of a delay...   Is this the link you are using? http:\/\/library.fora.tv\/conference\/h2o_world_2015\/buy_programs","772":"That is the link. I'm just watching them at normal speed, like a regular human. So difficult :)","773":"@scottstanfield the horror!  :smile: ","774":"What is the current status of the word2vec implementation within the R version of h2o? The source is there for both R and Java but the official docs say that using it will just return an error. Is there a development version of h2o that is available for download (there doesn't appear to be a dev repo on GitHub)? If not, is there a rough eta for when a working version of word2vec will be incorporated into an upcoming stable release? ","775":"Hey all, how can I converted a `date` that was imported by h2o as milliseconds to `as.Date`? I tried as.Date but it doesn't seem to work. \\n\\n","776":"@mmalohlava Do you have h2o SW building with Spark 1.6 snapshot ? ","777":"@mmalohlava  What is the correct way to stop fully the Spark job which is running as yarn-client using spark-submit.\\n\\nWe are using sc.stop in the code and can see the job still running (in yarn resource manager) after final hive insert is complete.\\n\\nThe code flow is\\n\\nstart context\\ndo some h2o work\\ninsert to hive\\nsc.stop\\n","778":"@kprybol word2vec was a project that I had started in the fall of 2014. While the code for word2vec is in H2O and works, it really isn\\u2019t a useful tool without accompanying support for reasonable workflow. Putting in support for basic NLP tasks is on my TODO list, but unfortunately isn\\u2019t a major focus for H2O yet.  The soonest anything could happen would probably be in the spring.","779":"@gdequeiroz Are you talking about a column that encodes a date as milliseconds and gets read into H2O as numeric values? In that case, it looks like you are correct. I put in code to convert strings to dates, but I don\\u2019t see anywhere that I handle the case of numeric to date conversion. It is simple enough, I will file a JIRA ticket to add this.","780":"@gdequeiroz https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-2413","781":"Hi is this: http:\/\/stackoverflow.com\/questions\/31442820\/unable-to-convert-data-frame-to-h2o-object  still the current solution => loading from csv-file? I try to use un-ordered factors instead. http:\/\/stackoverflow.com\/questions\/33964062\/h2o-un-ordered-factor However the problem remains. Is it possible to find out which column is causing the `Provided column type c(\\ordered\\ \\enum\\) is unknown. error`?","782":"@geoHeil We currently still don\\u2019t support ordered factors. It is on our list, but isn\\u2019t in the current version. I\\u2019d use sapply(x, class) to find out the types of frame x","783":"Thank you very much! This will help me to solve the problem.","784":"@geoHeil Glad to help","785":"One more question. Uploading my training data worked. However trying it for my test-data results in the following error: ```water.parser.ParseDataset$UpdateCategoricalChunksTask; class java.lang.NullPointerException: null```","786":"@geoHeil Ooo, that shouldn\\u2019t happen. Any chance I could get a copy of the data?","787":"@bghill see pm","788":"How can i configure pysparkling to be used from and IDE, e.g. pycharm","789":"I have pysparkling working both shell and notebook. I can use pypark from my IDE.","790":"Hi guys. Does anyone know how to download a pojo through Sparkling Water? The documentation tells us to do so through R or Python, but not Java or Scala","791":"Is there any specific way to cite h2o algorithms? ","792":"Hi @kzr-soze , yes for example:","793":"```scala\\ndef exportPOJOModel(model : Model[_, _,_], destination: URI): URI = {\\n    val destFile = new File(destination)\\n    val fos = new java.io.FileOutputStream(destFile)\\n    val writer = new model.JavaModelStreamWriter(false)\\n    try {\\n      writer.writeTo(fos)\\n    } finally {\\n      fos.close()\\n    }\\n    destination\\n}\\n\\nexportPOJOModel(gbmModel, new File(\\.\/models\/GbmModel.java\\).toURI)\\n```\\n\\n","794":"@jagatsingh \\n>  Do you have h2o SW building with Spark 1.6 snapshot ?\\nNot yet","795":"@jagatsingh \\n> What is the correct way to stop fully the Spark job which is running as yarn-client using spark-submit.\\n\\nnormally. `sc.stop()` should be enough, but for older spark versions( 1.3, 1.4)  i saw same behavior - so i was calling explicitly `System.exit()`to signal Yarn that job finished","796":"Hi guys, don't know if this is the correct place to put a question but here we go. Right now I work as a consultant in the \\analytics area\\ but we use a lost of GUI tools like Knime, etc. I miss code and I never participated in a open source project.  I really wanted to contribute for h2o. I think it is a beautiful lib with a lot of of cool stuff to dig deeper.  Is h2o opened to collaboration? If so, how can I start? Thank you so much.","797":"We run spark on scala 2.11","798":"I do not see any maven repo for h20 on scala 2.11 only 2.10","799":"This is likely a showstopper. When will 2.11 support be available?","800":"Hi @javadba \\nright now we are building only for Scala 2.10, but we can probably build easily for 2.11 (it just need few changes in build infrastructure and repl integration). \\n\\nThere is already jira issue for that: https:\/\/0xdata.atlassian.net\/browse\/SW-57.  Aprox delivery date is after Christmas.","801":"great! that timing works for us","802":"@geponce citation info here: https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-2013","803":"@lucasvfventura yes, we are very much open to contributions from the open source community!  we accept pull requests.   if you want to discuss what you had in mind or if you are looking for ideas, please send me an email!   erin at h2o.ai","804":"@lucasvfventura More info on contributing here: https:\/\/github.com\/h2oai\/h2o-3\/blob\/master\/CONTRIBUTING.md","805":"Hiya Folks. Looking to do a Grid Search on a GBM with a fairly small data set (1.5GB as CSV)","806":"Have a 2 node (48GB RAM each) cluster","807":"Is it possible to have the Grid search build a model on each of the nodes as it searches rather than doing a distributed build of a single model?","808":"@cauldnz At the moment, we don't have a simple option to do this... but it's something we are working on.  currently, the optimal way to use your 2 nodes for grid is to run two H2O instances (one on each node) and split the grid in half.  although with a small dataset like that, your grid search should go pretty fast either way","809":"Cool. OK. If I am feeling bored over Xmas I might fork it and implement using a parallel backend to ahnd off the work :-)","810":"Hi guys! Could anyone of you help me extract cross-validated predictions from H2O model. Assume I build a model like this, clf <- h2o.gbm(X, y, train, model_id = \\clf_gbm\\ ntrees = 100,  max_depth = 8, min_rows = 3, learn_rate = 0.1, nfolds = 4). How do I extract cross validated predictions from clf object. Thank you!","811":"@binga You have to use `keep_cross_validation_predictions = TRUE`, while training the GBM, else they will be thrown away.  They are stored in a list of length k for k-fold CV.  If you want to extract the cv preds from a model as a single frame, you can use this function (which will be added to h2o package at some point), which will extract them from the list properly. \\n```\\n# Extract cross-validated predicted values (in order of original rows) as an H2O Frame\\nh2o.cvpreds <- function(object) {\\n  \\n  # Need to extract family from model object\\n  if (class(object) == \\H2OBinomialModel\\) family <- \\binomial\\\\n  if (class(object) == \\H2OMulticlassModel\\) family <- \\multinomial\\\\n  if (class(object) == \\H2ORegressionModel\\) family <- \\gaussian\\\\n\\n  # helper function\\n  .compress_to_cvpreds <- function(h2omodel, family) {\\n    # return the frame_id of the resulting 1-col Hdf of cvpreds for learner l\\n    V <- h2omodel@allparameters$nfolds\\n    if (family %in% c(\\bernoulli\\ \\binomial\\)) {\\n      predlist <- sapply(1:V, function(v) h2o.getFrame(h2omodel@model$cross_validation_predictions[[v]]$name)[,3], simplify = FALSE)\\n    } else {\\n      predlist <- sapply(1:V, function(v) h2o.getFrame(h2omodel@model$cross_validation_predictions[[v]]$name)$predict, simplify = FALSE)\\n    }\\n    cvpred_sparse <- h2o.cbind(predlist)  #N x V Hdf with rows that are all zeros, except corresponding to the v^th fold if that rows is associated with v\\n    cvpred_col <- apply(cvpred_sparse, 1, sum)\\n    return(cvpred_col)\\n  } \\n    \\n  cvpreds <- .compress_to_cvpreds(h2omodel = object, family = family)\\n  return(cvpreds)\\n}\\n```","812":"@binga  this will extract the predicted values for regression, predicted label for multiclass, and the P(Y=1) predicted values for binary classification.  ","813":"is there a scala version for this : http:\/\/learn.h2o.ai\/content\/tutorials\/deeplearning\/index.html & am I on the right spot to get started with H2O?","814":"@vijaykiran most of our training is geared toward our R & Python API, are you looking for DL examples with Scala and\/or Sparkling Water?","815":"@vijaykiran learn.h2o.ai is a good place to get started, and also our pdf booklets are good too: https:\/\/github.com\/h2oai\/h2o-3\/tree\/master\/h2o-docs\/src\/booklets\/v2_2015\/PDFs\/online  The booklets are good if you want to go deeper, but only have R\/Python code examples","816":"@ledell thanks - I'm primarily working with scala - will take a look at Sparkling water","817":"there's a broken link \\H2O Enterprise Edition: This web page describes the benefits of H2O Enterprise Edition.\\ on http:\/\/h2o-release.s3.amazonaws.com\/h2o\/rel-tibshirani\/8\/docs-website\/h2o-docs\/index.html","818":"@vijaykiran we have several scala examples in Sparkling Water repository: https:\/\/github.com\/h2oai\/sparkling-water\/tree\/master\/examples or you can also follow the training session from QCon2015: https:\/\/github.com\/h2oai\/qcon2015","819":"@vijaykiran thanks for the report on broken links.  i pushed a fix and it will show up in the next docs (our docs are versioned by release).","820":"Hi. Just a question about tree based models in H2O. I'm doing scoring using the POJO and would like to know what value I should map NULL to in numeric columns? Should it be mapped outside the range of the training set column?  ","821":"hi  any one here ?","822":"@joostshao hi","823":"do you have a question","824":" i found the UI has changed","825":"i download the sandbox from traing 2014","826":"@joostshao The Flow UI has changed a bit since it was first developed, but its largely the same.  DO you have a specific question?","827":"@toddniven If you mean N\/A values, they should be Java Double.NaN.","828":"Thanks @ledell. I thought that was the case. ","829":"@toddniven @mmalohlava said he saw you post about this on the SW gitter and he can follow up with more info :)","830":"Hi @toddniven , sorry for delayed response. Regarding your question - I expect you are using EasyAPI wrapper or Pojo api directly. In both cases,  you should use Double.NaN for marking value as missing. ","831":"Thanks @mmalohlava I tried that and it works perfectly. ","832":"We are accessing the pojo directly. For scoring, it removes a lot of the dependencies on spark version, H2O version etc. ","833":"@toddniven Do you mean GenModel interface? I am just curious","834":"Yes GenModel interface.","835":"Hello, I'm trying to understand the typical workflow with H2O - here's what I've in my mind so far: Explore\/analyze the data with Flow,  export the model, build model-gen and model-prediction programs and deploy to (spark) cluster - is this a reasonable way? ","836":"hi hello","837":"Hello","838":"DKV ? what is this ? k-v store  implimented  by h2o ?","839":"distributored ?  what is it for ?","840":"H2O can run across a large clusters.Since data needs to be exchanged between compute nodes, you need to have a way of establishing which node is the official \\u201cowner\\u201d of that data.  You also need a way for a compute node to keep track of whether or not its copy of a piece of data is the newest copy or if it needs to fetch an update. The DKV is the engine that facilitates this.","841":"It is a distributed key-value store.","842":"The key is a name for the data item you want, and the value is the actual data item.","843":"but i confused  ","844":"HDFS  and Spark  are  all distributed ...","845":"BTW   if the api GET \/3\/DownloadDataset and GET \/3\/DownloadDataset.bin is same, why not remove  one ?","846":"Yes, HDFS and Spark are distributed.","847":"as you said, the computing by H2O is distributed . ","848":"I\\u2019d have to look at the internals of each of those to endpoints to see if there is a difference. ","849":"and what about spark  machine learning  and mahout ?","850":"they are all  distributed","851":"Correct, they are.","852":"I am unclear on what your question is.","853":"my team want to build some model new about finacal stock marketing","854":"Ok","855":"if so , we should write a new Algrthom  by H2O way or mahout way ?","856":"i want to get some resource  about the architecture","857":"You don\\u2019t need to write an algorithm in H2O.","858":"Most folks are using the pre-existing algorithms for their needs.","859":"This is typically true for the other libraries as well. Is there an algorithm you need, that these libraries don\\u2019t provide?","860":"what i wonder is that the distribured kv store is for just store or for the  distributred algorithms ?","861":"are the algorithms  in H2O is distributored ?","862":"The algorithms in H2O are distributed.  They rely on the distributed KV store when the request and update data.","863":"for example , i want to impliment a   http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC   distributored , what should i do ?","864":"Do you know how you are going to parallelize the calculations? Most algorithms take significant work to parallelize efficiently.","865":"i seee","866":"http:\/\/h2o-release.s3.amazonaws.com\/h2o\/rel-tibshirani\/8\/docs-website\/h2o-docs\/index.html#schema-InteractionV3     \/3\/Interaction  i think the rest api design  is something wrong...","867":"diffcult to understand","868":"What makes you think something is wrong?","869":"may be  i misunderstand . InteractionV3  (an action transfor the job and data)","870":"It is applied to a data frame and creates new factors that represent the interactions of the chosen factor columns.","871":"it is also a  restful api.  i see","872":"Yes","873":"how do i use spark MLLib in H2O  when i create a new Model or Algos ?","874":":h2o-core:generateBuildVersionJava\\n\\nERROR:  H2OBuildVersion emitBuildVersionJavaFileIfNecessary failed\\n\\njava.lang.NullPointerException\\n","875":"``` ubt@ubt:~\/h2o-3-master$ .\/gradlew build -x test\\n","876":"I\\u2019m trying to export and import a model and this is the code i\\u2019m using\\n```\\ndef exportH2OModel(model : Model[_,_,_], destination: URI): Unit = {\\n\\n    val modelKey = model._key.asInstanceOf[Key[_ <: Keyed[_ <: Keyed[_ <: AnyRef]]]]\\n    val keysToExport = model.getPublishedKeys()\\n    keysToExport.add(0, modelKey)\\n    new ObjectTreeBinarySerializer().save(keysToExport, destination)\\n  }\\n\\n  def loadH2OModel[M <: Model[_, _, _]](source: URI) : M = {\\n    val l = new ObjectTreeBinarySerializer().load(source)\\n    l.get(0).get().asInstanceOf[M]\\n  }\\n```\\nI\\u2019m having a very strange behavior. This code works fine when I run my spark locally from IntelliJ (spark and h2o dependencies as maven dependencies) but when I try to run it using spark-submit it is failing. Anybody experineced this before? Thanks","877":"The problem only appears if the model is saved to s3","878":"If the URI is file:\/\/ it seems to be ok","879":"@joostshao you would not \\use MLLib in H2O\\.  However, you can use H2O in place of MLlib with Spark.  Check out this slidedeck for some high-level H2O architecture slides if you want to learn more: http:\/\/www.slideshare.net\/0xdata\/high-performance-machine-learning-in-r-with-h2o  Also a video: https:\/\/www.youtube.com\/watch?v=WPGPiPGzVCs and a blogpost: http:\/\/www.cliffc.org\/blog\/2014\/03\/20\/h2o-architecture\/","880":"@joostshao if you are new to H2O, you may want to watch some H2O World videos: https:\/\/www.youtube.com\/playlist?list=PLNtMya54qvOH6YAVFigzoXb4iIzl0cvgd and look at our training: http:\/\/learn.h2o.ai\/content\/","881":"```\\n:h2o-core:generateBuildVersionJava\\nERROR:  H2OBuildVersion emitBuildVersionJavaFileIfNecessary failed\\njava.lang.NullPointerException\\n```\\nwhen i build the h2o from github master branch  ```.\/gradlew build -x test```\\n","882":"i think is a bug","883":"@joostshao It is at least a bug in our documentation. We\\u2019ve got lots of test systems doing just that command. I\\u2019ve seen that error before, let me poke around to see if I can find what would trigger that.","884":"and  i wonder the version named \\https:\/\/github.com\/h2oai\/h2o-3\/releases\/tag\/jenkins-master-3343\\ \\n","885":"jenkins-master-3343 ","886":"@joostshao Our system makes a nightly release and tagging (which is published each day as the Bleeding Edge).","887":"how to skip build R package ? ","888":"@joostshao .\/gradlew javaDevBuild -x test","889":"Any javascript\/angular.js examples?","890":"@njss Sorry, I don\\u2019t think so.  I will double check as we have had some basic web front-ends on demo pieces, but I don\\u2019t know what they were written in.","891":"web ui  flow = coffee + jade","892":"@joostshao\\nhi, any one here ?\\ni confused  how to designed the modules ?\\n\/mnt\/data\/h2o\/h2o-flow\/src\/core\/modules\/autosave.coffee\\n\/mnt\/data\/h2o\/h2o-flow\/src\/core\/modules\/dataflow.coffee","893":"@joostshao Do you mean how to compile them?","894":"@joostshao Those are the source code for the Flow user interface. Do you need to modify them?","895":"i know, it seems to use Knockout to agnaize the bussiness logic","896":"I was looking from some \\sexy\\ examples using angular.js and standard javascript","897":"or some gulp template","898":"I resume model from a checkpoint, but I have to re-specify the hyperparameters again, can h2o auto-complete from the checkpoint configuration?","899":"Hey guys, I'm running several boosting models (grid search) in a single node and the performance seems worst than R xgbTree. I noticed that my CPU consumption rarely goes over 30%. I know the implementations are really different but I would expect that h2o would be faster. I also noticed that in R if you search in the number of tree parameters, the model is only trained with the biggest number but R score the model in all other possibilities as well. Does h2o apply the same technique? Any thoughts on how can I speed it up?","900":"just a correction, *rarely goes over 40%","901":"@lucasvfventura How big is your dataset? We\\u2019ve seen this on smaller datasets. A correction for this has been added to the nightly build and will be in the next stable release. I expect that release to be a week or two away.","902":"@125626748 I presume you are talking about doing this in Flow, correct? We have ticket open to fix it.","903":"@lucasvfventura I need to ask the authors about your tree question","904":"@bghill yeah, my dataset is small, about 15000 rows and 250 columns.  I'll try the nightly build thank you very much. ","905":"I want to script the download and install of the latest stable H2O (3.6.0.8) in this case. But the only link I can find, the one from http:\/\/www.h2o.ai\/download\/h2o\/desktop, does a redirect. I'm trying to use `wget` or `curl`. Can we have a clean download link that's stable?","906":"It's weird: the link goes to marketto.com. Ick.","907":"Perhaps we can find a `stable` tag here? https:\/\/github.com\/h2oai\/h2o-3\/releases","908":"I _think_ this is the latest stable: https:\/\/github.com\/h2oai\/h2o-3\/releases\/tag\/jenkins-rel-tibshirani-11","909":"But it's just a source tarball. I'm just looking for the JAR.","910":"After using Chrome Dev tools, it appears this is the link to the file I'm looking for: http:\/\/download.h2o.ai\/versions\/h2o-3.6.0.8.zip","911":"To wrap this thread up, this is the command for the latest stable version\\n```\\ncurl -O http:\/\/download.h2o.ai\/versions\/h2o-3.6.0.8.zip\\n```","912":"@bghill Thank you for the help. I tried the nightly build and it worked like a charm. 99% CPU =]","913":null,"914":"@125626748 Are you using Flow or our R\/Python API for modeling & checkpointing?","915":"Hi guys me again... I'm trying to use h2o in a AWS clusters... everything seems alright but right now i have multiple h2o instance instead of a cluster =\/.. I'm using the scripts in the ec2 folder, any thoughts? My guess would be that each node is unable to reach the others, is there any specific rule I need to put on my AWS security group? Thank you very much","916":"@lucasvfventura I'm following your progress. I too will be setting up a cluster of AWS instances later this week. As of now, I have a single `c3-8xlarge` instance running, with great results. Next step is to scale out to 10.","917":"@scottstanfield nice... I'm trying with only 2.. I'll scale when I managed to make it work","918":"@lucasvfventura ah...of course: if you can get 2 working, you can get n working. I assume you're using the H2O AWS scripts?","919":"@scottstanfield I'm... everything working but instead of having one cluster with 2 nodes , I have 2 clusters of 1 node each =\/","920":"Yep.. my bad guys... I just had to change the security groups, now that each instance is able to reach the other I have one \\big\\ cluster ... Let the fun begins","921":"@lucasvfventura awesome. Good tip.","922":"@lucasvfventura @scottstanfield Our main AWS guy is on a plane right now, but once he lands I will let you know if we have any tips written up for running on AWS.","923":"@bghill they have WiFi on planes now...no need to wait :)","924":"Just kidding. That's awesome. Thanks!","925":"Let me know if this is helpful: https:\/\/h2o-release.s3.amazonaws.com\/h2o\/rel-tibshirani\/8\/docs-website\/h2o-docs\/index.html#%E2%80%A6%20On%20EC2%20and%20S3","926":"If it isn\\u2019t we can work on clarifying it.","927":"Thanks @bghill. Will start looking through it. This looks cool: http:\/\/play.h2o.ai\/login","928":"BTW, that play.h2o.ai signup link doesn't work. Just times out.","929":"@scottstanfield I think the play.h2o.ai project is ending. I need to find out what the plan is there to update the docs. It is still used internally for demos, but I don\\u2019t know where we stand on making new accounts. I\\u2019ll inquire.","930":"Hello! Does anyone know how to delete a h2o dataframe or it's possible to change existing one?\\nI work in spling water and I use ipython notebook. I asked in the goup about method h2o.delete(x).\\n\\Hi, \\n\\nThe object has been removed from the backend, but appears to still be present because it is in the Python cache. The fix for this issue is in the nightly development build (Bleeding Edge) and will be in the next stable release. Trying to read an H2OFrame that has been removed will give the following output\\\\nI make a circle and inside it every iteration I use the h2o dataframe with the same name but I do the next:  data_h2o = hc.as_h2o_frame(data, \\data_h2o\\)\\napache spark dataframe changes every iterations but after the first iteration h2o dataframe is a constant and because of that a work of my circle is incorrect.\\nCould anyone help me?","931":"@bghill @scottstanfield I did all the steps described in the link on windows using the cmder shell. Just some points I had to do: 1) had to change the file nodes-public to a single line, space between the hosts public dns, 2) Add 3 rules to my security group that basically says that every host in that security group can access the others, 3) Run every sh file like \\sh ....\\ 4) Add all keys to my env variables, using the python code didn't work =\/","932":"Guys just a feedback about gbm with small dataset. I know that h2o is designed toward big data but it has some features to me that are essential like POJO generation and unfortunately most of my work is done using small datasets. \\nIn the 3.7.0.3351 release using a single machine works like a charm but things gets a little weird when using a cluster. I tried this in a 5 nodes cluster each node with 8 cores. With build_tree_one_node = FALSE all CPU stays about 10%, I assume a lot of networking is been done.  I also tried to put build_tree_one_node = TRUE and make parallel calls for the cluster, but all processing is done only by the machine I connected to. My solution was to connect with each of the nodes and run a grid search in each node. ","933":"@lucasvfventura thanks Lucas! I'll be following your footsteps later this week.","934":"@lucasvfventura Thanks for the notes on the Windows issues.  I\\u2019ll pass them on to our windows folks and the docs people.","935":"@lucasvfventura We break the data into chunks that are distributed across the cluster. For datasets that are small, the data may all be in only a few chunks and thus unable to split out the work across nodes. What client are you using (R, Python, or Flow)? I can talk you through seeing how many chunks your data is split into (it is also output into the H2O logs after you parse a file). ","936":"@AlexanderModestov From the response you quote, the next release should have the fix. The next release is coming out shortly (I am aiming for the 1\/10).  You can either try a copy of bleeding edge, or wait for the release.","937":"@bghill I'm using R at the moment. I understand this behavior of splitting the dataset, which needs to be done for big datasets. What could be interesting for the users with small datasets is the behavior that I set up but transparently. Copy the dataset to each node then run one combination of the parameters in the gridsearch in each node or other email fold of a cv, then merge the grid back.  That way all nodes would be used in 100% capacity and the overall gridsearch faster. If you want I can send to you part of my code to discuss the idea. ","938":"@lucasvfventura We are planning to add that kinds of scheduling capability, but we don\\u2019t have it right now. Also what algo are you using?","939":"@bghill gbm...  I'd be glad to help with code =) ","940":"@lucasvfventura Are you a Java developer? ","941":"@bghill To  be honest I'm a little rusty in Java, but nothing that a week would do.  I also know Python, R and Js(Coffee Script wouldn't be a problem).  I already cloned the git repository and started to look at the code ","942":"@scottstanfield The official word is that \\u201cWe\\u2019re phasing out play and replacing it with a new platform for running H2O on your cloud over the next few months. To get early access or to learn more, please contact sales@h2o.ai\\","943":"@scottstanfield The engineering word is that we are working on a cloud launch\/management called Steam. It will be an enterprise product. We may be opening a pay as you go version of Steam on various cloud systems in the future. Beyond enterprise Steam, for running things yourself  we have VMs, ami\\u2019s, docker and vagrant images available.  If those are more your speed, I can hunt down where they are and figure out if they need greater visibility.","944":"@scottstanfield It sounds like you already have things working but our cloud engineer says that for now the general advise is to use the ami:\\n-capture the private ip's make a flat file and do java -jar h2o.jar -flatfile flatfile.txt\\n-we have h2o-latest-stable\\n-that is the name of the AMI, it is in every region","945":"@lucasvfventura That\\u2019s great! Feel free to ask questions.","946":"does anyone know good resources on how to prepare datasets? and perform good labelling of data \\by hand\\? I am not finding good resources on this topic and most specially related with H2o. Thank you","947":"@njss preparing a gold standard is an art but there are some things you need to pay attention to. First if you are trying to predict the future make sure that you will have all variables values when you will perform your prediction. This means if you want predict if it's going to rain tomorrow don't use tomorrow's temperature, you could use the today's prediction for tomorrow's temperature. Second, each record\/row in your gold standard is an event you are trying to predict, make sure that each event is independent from the others. Third, in machine learning we use the long representation of your data, which means columns are variables and rows records\/events. Fourth, always cross-validate your models, do a stratified sampling. Besides that there are several techniques like normalization, one-hot encoding, pca, etc...that h2o provides and can impact your model's performance","948":"Hey guys I built a model using the version3.7.0.3355 and I need to download it again. May someone provide me the link? I've tried everything... I can't import the models in the 3357 version =\/","949":"@lucasvfventura I\\u2019ll get the URL for you. Not sure why the standard tricks failed.","950":"@lucasvfventura Try this: download.h2o.ai\/download\/h2o-3.7.0.3355","951":"@bghill Thank you.. that worked... I swear I trie this before lol","952":"The first time I tried it I left .zip on the end of the filename which fails. I can\\u2019t tell you why though.","953":"Here's a fun data point for you all.... I like to use Kaggle comps to try new stuff.... new stuff this month was the (awesome!) Ensemble\/SuperLearner that @ledell has put together. While all the folks grinding the crap out of the data with over-fitted XGBoost models stayed put.... I jumped over 300 places from Public to private leaderboard.... That was for a model that did zero-nilch-nada feature engineering...","954":"Go @cauldnz and go @ledell!","955":"I do have one question though... which is why I can't saturate my CPUs building DRF models... I have no problem pegging all 48 cores in my cluster with GBMs but DRFs arebely make a dent and they feel a bit slow... Am I missing something? Given that they should all be completely independent models shouldn't the cluster be saturated?","956":"Our current DRF is built for large data. Datasets so large it won\\u2019t fit on one machine. We need to bring back an alternate version that works for smaller datasets and does embarassingly parallel solving.","957":"Yes please.... ","958":"If you think you've got a Big Data problem.... But you haven't got a big data problem... you'll very soon have a big data problem","959":"@bghill did it used to work? Something I can go and tweak in the code?","960":"@cauldnz Great to hear about your Kaggle ensemble boost!  Ensembling is so much more fun than feature engineering. :smile:   ","961":"@cauldnz It was a mode we had for DRF in the last version of H2O. We just haven\\u2019t put it back into the latest H2O.","962":"Myself and @scottstanfield  will do beers for you guys next time I am in Berkeley!","963":"@cauldnz Or Mountain View. :)","964":"Oh hell... let's all go to Tahoe then!","965":"When you say previous version of H2O @bghill  you are talking about v2? Just wondering if I should go and dig around to try and get embarassingly parallilized DRFs going","966":"@cauldnz Yes, we had it in v2. How good is your Java? I think we may need to host a hacking session for H2O development soon.","967":"My C# is good. My Java throws...","968":"I mean blows....","969":":clap: ","970":"Hmm, shame no major languages seem to use hurl as a keyword.","971":"Isn't that just curl with a binary payload?","972":"H2O guys: this is the first time I'm seeing this exception thrown. May have to do with bad data in a data.frame that's been uploaded to my single-machine cluster. I'm running 3.6.0.8.","973":"```\\nGot exception 'class java.lang.ArrayIndexOutOfBoundsException', with msg '0'\\njava.lang.ArrayIndexOutOfBoundsException: 0\\n\\tat hex.tree.SharedTree.initial_MSE(SharedTree.java:606)\\n\\tat hex.tree.SharedTree$Driver.compute2(SharedTree.java:168)\\n\\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1069)\\n\\tat jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\\n\\tat jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\\n\\tat jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:974)\\n\\tat jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1477)\\n\\tat jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\\n```","974":"Soon, I might have this down to a trivial reproducible state. But if this looks familiar...would help.","975":"might have it figured out; will report","976":"Bug report: if you create an empty as.h2o() validation frame (we had an error here), and try to use it in h2o.gbm(), you get the exception above. Maybe have an assertion that checks that the frames are not empty?","977":"Thanks for tracking the cause down. I\\u2019ll file a JIRA ticket.","978":"@bghill let me know if you all need more repro steps","979":"hi guys I'm training 2 very similar gbm models with the same small data, one is a regression and the other a classification. Is there any reason to the classification training be 10x longer?","980":"@lucasvfventura How many classes in your response?  If there are a X classes, then it will take X times longer than training a binary classifier, since under the hood, that multiclass classifiers are training X binary classifiers.","981":"hi  any one here ?","982":"hello","983":"i have a question","984":"why there is a importfiles request before parse file when my file has imported","985":"hi, i found some thing. when i call  ```  setupParse parseFiles  extendImportResults requestImportFiles importFiles requestParseSetup requestImportAndParseSetup``` for http files, it will request the files again and again , i wonder what the DKV for ? ","986":"why not storage  the files in DKV ? ","987":"or  manage them .. ","988":"@ledell it is a binary classification =\/","989":"product suggestion - where should they go?","990":"```  Running 'texi2dvi' on 'Rd2.tex' failed.\\nLaTeX errors:\\n! LaTeX Error: File `zi4.sty' not found.```","991":"what's wrong with it ? i am not so familar to R","992":"i sloved it. ","993":"R has release the latest  version 3.2.3.  but in  Jekins may be 3.2.2.  when i syncRPackages ","994":"@joostshao yup, we are storing file references inside DKV, however, only parseFiles and setupParse touch actual files on disk. \\n","995":"@EngrStudent can you post your suggestions in h2ostream (https:\/\/groups.google.com\/forum\/#!forum\/h2ostream)?","996":"@joostshao the missing zi4.sty is Latex message. You need to install latex package (texlive, texlive-packages)\\n\\nor you can just skip the build task which is producing error by:\\n`.\/gradlew build -x <task which failed>`","997":"@mmalohlava  thank you, i sloved it.   ```sudo apt-get install texlive-full ```","998":"is h2o flow used bootstrap2.3.1 ?  h2o-core\/build\/resources\/main\/www\/perfbar.html  i think it has been replaced by flow","999":"Hi, why is the string representaiton of the dataset in python the entire dataset? if I accidentally `print x` for my million row dataset, why does it print out the entire data to screen","1000":"would it be possible to write a summary or something?","1001":"Feature request: Flow should *not* ask warn me \\That I'm about to exit Flow. Are you sure?\\. I'm pretty sure I know what I'm doing and don't need to be prompted. I have to dismiss that dialog many times per day.","1002":"@scottstanfield   you can edit the coffeescript and disabled the dialog by youself , i think","1003":"anyone at +8 timeZone ?  it is so diffcult to using H2O-3  for me ","1004":"Is there any issue reported with the Water Meter in the newest version (Turkey) of h2o for R-Linux? ","1005":"H2O Build git branch \\trel-tukey\\nH2O Build git hash \\t8d4f03ec3adcb39011acfaeb8d729fa18282f9ca\\nH2O Build git describe \\tjenkins-rel-tukey-4\\nH2O Build project version \\t3.8.0.4\\nH2O Built by \\tjenkins\\nH2O Built on \\t2016-02-17 10:31:29\\nFlow version \\t0.4.18","1006":"I can't see the cores\/bars, instead I get a message saying [Not Linux] ","1007":"@bghill I'm running R under Linux Red-Hat 7 ","1008":"@mattdowle  Is there anyway to convert a data.table into h2o in a \\parallelized way\\...? Right now I'm using \\as.h2o(DT)\\...  I don't want to save DTs as CSVs, instead I save my DTs as binary with saveRDS.  However, when I need to run some of the models in h2o, it has to be h2o frame and need to use as.h2o... Any suggestion to speed up this part?   ","1009":"@bghill  I'm able to see the cores' activity from htop but not from Water Meter... ","1010":"*tukey","1011":"@bghill What is the default for mtries in Random Forest? ","1012":"a joke:  package water.parser;\\n\\n\/**\\n * Created by brandon on 9\/22\/15.\\n *\/\\npublic class ORCParser {\\n}\\n","1013":"```\\npackage water.parser;\\n\\n\/**\\n * Created by brandon on 9\/22\/15.\\n *\/\\npublic class ORCParser {\\n}\\n```","1014":"Hi, i have a problem with rest api and i can't find examples. i get an error about double quotes when i try to use `parse`","1015":null,"1016":"resolved","1017":"i needed -d for each argument","1018":"@geponce default value for mtries is in the docs.... \\Number of variables randomly sampled as candidates at each split. If set to -1, defaults to sqrtp for classification, and p\/3 for regression, where p is the number of predictors.\\","1019":"just look in R docs for `h2o.randomForest` and description of `mtries` argument","1020":"or Python docstring, https:\/\/github.com\/h2oai\/h2o-3\/blob\/master\/h2o-py\/h2o\/h2o.py#L1407","1021":"@scottstanfield regarding feature request... yes i think the same thing.  in firefox, you just hit the \\x\\ twice and don't actually need to click on the \\Leave Page\\ button","1022":"@alexshires when you type `print x` and `x` is an H2OFrame in Python, it only prints a few rows & cols","1023":"it doesn't print them all...","1024":"@alexshires \\nIn [6]: print data\\n    AF3       F7       F3      FC5       T7       P7       O1       O2       P8       T8      FC6       F4       F8      AF4    eyeDetection  split\\n-------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  --------------  -------\\n4329.23  4009.23  4289.23  4148.21  4350.26  4586.15  4096.92  4641.03  4222.05  4238.46  4211.28  4280.51  4635.9   4393.85               0  valid\\n4324.62  4004.62  4293.85  4148.72  4342.05  4586.67  4097.44  4638.97  4210.77  4226.67  4207.69  4279.49  4632.82  4384.1                0  test\\n4327.69  4006.67  4295.38  4156.41  4336.92  4583.59  4096.92  4630.26  4207.69  4222.05  4206.67  4282.05  4628.72  4389.23               0  train\\n4328.72  4011.79  4296.41  4155.9   4343.59  4582.56  4097.44  4630.77  4217.44  4235.38  4210.77  4287.69  4632.31  4396.41               0  train\\n4326.15  4011.79  4292.31  4151.28  4347.69  4586.67  4095.9   4627.69  4210.77  4244.1   4212.82  4288.21  4632.82  4398.46               0  train\\n4321.03  4004.62  4284.1   4153.33  4345.64  4587.18  4093.33  4616.92  4202.56  4232.82  4209.74  4281.03  4628.21  4389.74               0  train\\n4319.49  4001.03  4280.51  4151.79  4343.59  4584.62  4089.74  4615.9   4212.31  4226.67  4201.03  4269.74  4625.13  4378.46               0  test\\n4325.64  4006.67  4278.46  4143.08  4344.1   4583.08  4087.18  4614.87  4205.64  4230.26  4195.9   4266.67  4622.05  4380.51               0  test\\n4326.15  4010.77  4276.41  4139.49  4345.13  4584.1   4091.28  4608.21  4187.69  4229.74  4202.05  4273.85  4627.18  4389.74               0  test\\n4326.15  4011.28  4276.92  4142.05  4344.1   4582.56  4092.82  4608.72  4194.36  4228.72  4212.82  4277.95  4637.44  4393.33               0  train\\n\\n[14980 rows x 16 columns]\\n","1025":"@alexshires to try that out, you can load an H2OFrame as follows:","1026":"```\\nimport h2o\\nh2o.init()\\ncsv_url = \\https:\/\/h2o-public-test-data.s3.amazonaws.com\/eeg_eyestate_splits.csv\\\\ndata = h2o.import_file(csv_url)\\n```","1027":"@lucasvfventura if its taking 10x longer for binary classification vs regression, then it might have to do with the number of categorical variables in your data.  do you have only numeric features?  what is your data size?","1028":"@ledell the data used for the binary classification and the regression is the same, just the target column that change. I'll try to build a dataset  which I can share to reproduce this behaviour.","1029":"@lucasvfventura ah ok.  yeah that's strange, might be a bug.  if you have a sample dataset, you can send it to me at erin _at_ h2o.ai","1030":"The download location is still opaque. We need to be able to `curl` by version, and to get old versions. ","1031":"I had this code at one point, but no longer working. Need it for devops. \\n`curl -O http:\/\/download.h2o.ai\/versions\/h2o-3.6.0.8.zip`","1032":"Problem with download link! `Rel-Turan - 3.8.1.3` is pointing to `http:\/\/h2o-release.s3.amazonaws.com\/h2o\/latest_stable.html` My browser receives the file `h2o-3.8.1.3.zip` but the contents of that zip are for 3.8.0.6!","1033":"Screenshot here: https:\/\/s3.amazonaws.com\/f.cl.ly\/items\/46202S2H3D062R0k2j0a\/h2o-version.png","1034":"Would really appreciate a direct link to the ZIP with the java binary to download. I'm at 30k feet over Gogo Wireless. Downloading source and rebuilding is not an option. Disregard after 15:00 PT.","1035":"Should be easy to reproduce. 1. download whatever link h2o.ai\/download is offering for Turan. Then on the command-line, type `unzip -l h2o-3.8.1.3.zip`. It's possible my wires got crossed, but I just used Google Chrome for the download.","1036":"@scottstanfield i completely agree that we need a CURL-able link to the zip. ","1037":"ok this works for me:  `curl -o h2o.zip http:\/\/download.h2o.ai\/versions\/h2o-3.8.1.3.zip`","1038":"For some reason `curl -O` doesn't seem to work (has something to do with how we are serving the file), but `curl -o` little o does","1039":"@ledell can you verify that the contents are actually v3 of Turan? `unzip -l` should show that.","1040":"yeah they are, i even started up a cluster using the unlabeled `h2o.jar` inside to make sure and it said Turan","1041":"hmm. Might need to use `wget` as it will follow redirects. I'm bandwidth constrained right now over Texas. ","1042":"Thanks for confirming! I'll pull it down using your curl link above right now.","1043":"ok let me know!  ill be online","1044":"Ha! 2 hours left to download 150MB. I'll pull it down at the airport :). Thanks Erin!","1045":"Hi, I've set up an H20 cluster and I'm trying to figure out how to use it from R. I see in the command line documentation the option \\-flatfile <filename>\\ but I don't see that listed as an   ","1046":"option to \\h2o.init()\\ in the R documentation","1047":"@qspencer : When I use a cluster (of 3 machines), for my h2o.init() call, I just pass in one of the cluster IP addresses. Namely, the first one (not sure if order matters).","1048":"I appreciate honoring mathematicians and statisticians with versions, but the past string of T's have caused a little confusion on this end, as they're so similar looking.\\n\\n```\\n3.8.0.6 Tukey\\n3.8.1.3 Turan\\n3.6.0.8 Tibs\\n```","1049":"so if you pass in the IP of one of the machines in the cluster H2O will be able to discover the rest?","1050":"That's how it works for me, yes. I'll describe my steps...","1051":"On my main H2O cluster, I manually run the java command that includes the --flatfile argument.","1052":"Then I quickly switch over to my other two boxes and run the same command.","1053":"They instantly find each other: you can see the \\cloud 3 of 3 formed\\ message. But after some period of time, or after a job is submitted, the cloud locks down, for no new members to join. ","1054":"To make sure I understand, you manually run \\java -jar h2o.jar -flatfile \\flatfile.txt\\ on all machines in the cluster?","1055":"BTW, I have found the whole system goes belly-up if one of the machines is subsequently removed from the cluster. It's not handled gracefully. The error log gets full of messages complaining that it can't see the missing node.","1056":"yes. I'll give you the exact command...stand by.","1057":"`java -Xmx10g -jar h2o.java -flatfile ..\/flatfile.txt`","1058":"Give my processes 10G of RAM. And I keep the flatfile.txt up a level, so it's not clobbered if I reinstall R.","1059":"Thanks! the documentation doesn't cover this that I've found","1060":"Have you found much of a speed-up using 3 systems?","1061":"It's there somewhere...that's how I learned it. Also: look through the AWS batch files. They're really good. I'm have the poorman's cluster.","1062":"Yes: instead of say 4 seconds per tree on my i7 macbook pro, I can get about 1.5 sec \/ tree using a cheap cluster of random machines. Totals about 20 cores (CPU + hyperthreads). ","1063":"thanks again","1064":"My colleague and I have been purchasing old Dell Precision T7500 workstations (Dual Xeon 6-core) machines from various sources and making them *cluster zombies*","1065":"I've even recruited my wife's tricked-out iMac i7 32GB and she doesn't know it.","1066":"I'm using EC2 systems in AWS as I only have to pay for them when I use them","1067":"Be careful...","1068":"how's that?","1069":"I'm fairly new to EC2 and purposefully jumped into that to do some modeling in the cloud.","1070":"I managed my CPU hours well, even using spot instances. But got hammered on the IOPS charges.","1071":"My normal monthly $30 bill ballooned to $750 last month.","1072":"I was over-allocating 200GB SSD drives or something. Haven't touched it since.","1073":"For the next H2O World 2016, I would suggest a deeper dive into (budget) modeling in the cloud. Running spot instances for < 59 minutes, and proper allocation of disk space, etc.","1074":"yeah, it can get tricky","1075":"I got my cluster working - thanks for your help scottstanfield, it was invaluable","1076":"Awesome @qspencer!","1077":"@qspencer it sound slike @scottstanfield helped you out, but these are my instructions for running H2O on AWS clusters (they are for h2o-2, but I think they probably still work): https:\/\/github.com\/ledell\/h2oEnsemble-benchmarks\/tree\/master\/ec2","1078":"They are a clone of the ec2 subfolder in h2o: https:\/\/github.com\/h2oai\/h2o-3\/tree\/master\/ec2 with a cleaned up README","1079":"thanks  @ledell - there's definitely some errors in the H2O R documentation regarding running on a cluster or at least some omissions. I  had to dive into the Boto documentation to figure a few things out.","1080":"Hey guys, reading the change log I saw that Python 3.5 is now supported, but in the download page it list Python 2.7 as a prerequisite.. I got confused, is Python 3.5 really supported?","1081":"@lucasvfventura Let me check I'll check on that for you, i think the last release was the first that officially supported 3.5.  we might have not updated our Downloads page","1082":"@lucasvfventura Yep, we support 3.5 now.  The Downloads page has not been updated, someone will do that now.  Thanks for the heads up. :)","1083":"@qspencer Apologies for the sub-par documentation.  Our documentation is something that is slowly being revised behind the scenes.  I will make a note of that and perhaps we will reach out to you after it's revised to get your feedback, would you mind?","1084":"@ledell Glad to help =] ...  I have some architectural\/usage ideas i'd like to discuss but i think  I'll need some visual aids to explain it... Is there an e-mail that I can send my idea?","1085":"hello all,\\nI try to make my gbm-model.\\nI used the method splitFrame for making test and train frames.\\n\\n\\import org.apache.spark.examples.h2o.DemoUtils._\\nval keys = Array[String](\\train.hex\\ \\test.hex\\)\\nval ratios = Array[Double](0.8, 0.2)\\nval frs = splitFrame(data_h2o, keys, ratios)\\nval (train, test) = (frs(0), frs(1))\\\\n\\nReally, there is a class SplitFrame but it doesn't work:\\n\\n\\import _root_.hex.SplitFrame\\nval keys = Array[String](\\train.hex\\ \\test.hex\\)\\nval ratios = Array[Double](0.8, 0.2)\\nval frs = SplitFrame(data_h2o, keys, ratios)\\nval (train, test) = (frs(0), frs(1))\\\\n\\nOK, I used the first one option and I got an error when I was trying to set up parameters of the model:\\n\\n\\scala> gbmParams._train = test\\n<console>:58: error: type mismatch;\\n found   : water.fvec.Frame\\n required: water.Key[water.fvec.Frame]\\n       gbmParams._train = test\\\\n\\nWhy could I not give a h2oDataFrame in the model?\\n\\nThank you!","1086":"@AlexanderModestov  need to `import h2oContext._` there's next method there: `implicit def toH2OFrameKey(fr: Frame): Key[Frame] = fr._key`","1087":"@petro-rudenko Thank you! But could you explain me what data type it is? I mean water.Key[water.fvec.Frame]","1088":"@petro-rudenko there is an error. \\\\n<console>:60: error: not found: value h2oContext\\n       import h2oContext._\\","1089":"import h2oContext._ that's OK","1090":" Each frame has a key. You need to pass a key to training\/testing parameters of the model. Scala allows to implicit convert from frame to key. You can rather do `gbmParams._train = test._key`","1091":"@petro-rudenko thank you!","1092":"@petro-rudenko but really, I cannot import  h2oContext._\\n\\<console>:60: error: not found: value h2oContext\\nimport h2oContext._\\\\nWhat does it mean?\\nAnd which is the best way to learn the hierarchy of scala packages?\\nIt is too difficult to understand in which package the metod is included...\\nI use javadoc http:\/\/h2o-release.s3.amazonaws.com\/h2o\/rel-tibshirani\/8\/docs-website\/h2o-core\/javadoc\/index.html\\nbut may be there is better documentation?\\nThanks a lot!","1093":"Hello all,\\nI have an object GBMParameters and I want to teach a GBMModel:\\n\\val gbmParams = new GBMParameters()\\ngbmParams._train = train._key\\ngbmParams._valid = test._key\\ngbmParams._response_column = \\label\\\\ngbmParams._ntrees = 500\\ngbmParams._max_depth = 6\\n\\nval gbm = GBMModel(gbmParams)\\\\nWhat does this error mean?\\n<console>:98: error: object hex.tree.gbm.GBMModel is not a value\\n       val gbmModel = GBMModel(train, test, \\label\\)\\n","1094":"I've understood.... Sorry for bothering...","1095":"Hi, i have a next error:\\n```\\nAn exception or error caused a run to abort: 65535 \\njava.lang.ArrayIndexOutOfBoundsException: 65535\\n\\tat water.DKV.get(DKV.java:202)\\n\\tat water.DKV.get(DKV.java:182)\\n\\tat org.apache.spark.h2o.H2OContext$.toH2OFrame(H2OContext.scala:371)\\n\\tat org.apache.spark.h2o.H2OContext.asH2OFrame(H2OContext.scala:65)\\n\\tat org.apache.spark.h2o.H2OContext.asH2OFrame(H2OContext.scala:64)```  \\n- what could cause it?","1096":"@ledell I'm happy to review updated H2O-R documentation for you. I understand what a chore it is to keep the documentation up to date when the core software is being revised at such a fast rate!","1097":"@lucasvfventura my email is erin at h2o.ai you can send emails\/ideas there","1098":"@qspencer Thanks!  I started revising the EC2 readme myself today... I will definitely appreciate your feedback if you have any when I'm done.   Yeah it's a chore to keep the docs up-to-date, but we could do a better job of it... We are recruiting for a full time docs person at the moment, and one of our next sprints will probably be a 100% docs sprint, all of which will definitely help.","1099":"@bghill @ledell  Any idea why I don't see the Water Meter on RedHat 7 ?","1100":"[![blob](https:\/\/files.gitter.im\/h2oai\/h2o-3\/9gTM\/thumb\/blob.png)](https:\/\/files.gitter.im\/h2oai\/h2o-3\/9gTM\/blob)","1101":"@bgi","1102":"@geponce No, I think its supposed to work on all linux.  Maybe there is some default tool that needs to be installed at the OS.  I\\u2019ll find out","1103":"@bghill @ledell It is working, you can see it on htop ","1104":"[![blob](https:\/\/files.gitter.im\/h2oai\/h2o-3\/ierE\/thumb\/blob.png)](https:\/\/files.gitter.im\/h2oai\/h2o-3\/ierE\/blob)","1105":"@geponce Can you paste the output of: `cat \/etc\/redhat-release`","1106":"@ledell Red Hat Enterprise Linux Server release 7.1 (Maipo)\\n","1107":"thanks @geponce someone\\u2019s looking into it","1108":"@ledell Thanks :-)","1109":"@geponce If you are open to it, would you mind jumping on a webex at some point to debug with our engineers?  you can get in touch with me at erin at h2o.ai","1110":"@ledell Sure... I probably got to leave in a couple of hours for a meeting, not sure the returning time to my place... ","1111":"No problem, we can set up the call for next week or whenever is convient for you","1112":"Ok... Next week I'll be traveling without access to the server... Probably the week after... ?","1113":"@ldell","1114":"@ledell @bghill Is there any plan on making \\as.h2o\\ a parallelized process that can take advantage of multi-cores\/nodes ?  Right now I'm doing this on a data.table and it takes a while and the main thing is that only uses one core... ","1115":"@geponce i think this may be a limitation of R rather than H2O, but i\\u2019ll look into it.  have you compared performance\/speed of using `as.h2o` vs writing the data.table to disk and using the parallel `h2o.importFile`?  I wonder if data.table has a parallel write function...","1116":"Or maybe we can work out something smarter by talking to Matt Dowle data.table (who also works at H2O)","1117":"Yeah, I have followed that approached before... data.table -> csv -> h2o.importFile ","1118":"ok, so it\\u2019s not any faster in your case?","1119":"saving as csv takes a lot","1120":"for large tables","1121":"i think under the hood `as.h2o` is saving to disk actually...","1122":"so it might be more or less the same thing","1123":"I save my data.tables as binary with saveRDS... I found this is the fastest way to save a large data.table","1124":"Ok... just wondering about it... ","1125":"Yeah its a good question, ill let you know if anyone over here has a better solution.","1126":"Thanks... I think  I discussed this before with Matt Dowle... But that was few months ago...  ","1127":"I saw his presentation in H2O World 2015 regarding distributed H2O data frame... ","1128":"Not sure if that approach could help in the process of handling large data.tables... ","1129":"@geponce Matt Dowle is thinking about ways to make `as.h2o` faster\\u2026 He has been working on porting data.table functionality into H2OFrame.  The biggest achievment is his distributed radix sort in H2O, which is what he talked about at H2O world.  It might be possible to do all your munging in the H2OFrame directly without having to use data.table right now, depending on what type of munging you are doing.  ","1130":"I'm experiencing a strange behavior. An autoencoder trained on MNIST with c(400,250,100,2,100,250) for 10 epochs gives nice results, but when trained with c(400,250,100,2,100,250,400) it produces garbage. Why might that be?","1131":"@r3tex More layers is harder, sometimes it may not converge at all.","1132":"For autoencoders, prob best to start with three hidden layers and scale up in complexity","1133":"at some point it will start to fail and it looks like you found that edge","1134":"@ledell , thanks for the help. I was trying to copy Hinton's original paper on autoencoders and make a nice 2D plot of the middle layer but it looks like they did pretraining and some other stuff. Also they used logistic units in all layers except for the middle layer which used linear units.","1135":"Hi! I am checking out sparkling water and was wondering if there are rules of thumb with regard to allocation of memory to spark executors. Are there any gotchas that I need to be aware of when I consider deploying a sparkling water application in production? Also I would love to see some numbers with regard to the scalability of H2O in production environments if someone has them. Thanks!","1136":"@NitinKumar94 We also have a sparkling-water gitter (since it\\u2019s a separate git repo), do you mind reposting your question there?","1137":"hi, i have a question about using H2O and R. Is there a way to 'smart' way to read in incremental data? using cbind() duplicates the dataset","1138":"@ying-w do you mean `h2o.cbind`?  that does not duplicate data","1139":"it may appear as data is being duplicated in R, since it will make a new pointer","1140":"but the data will not be duplicated in the H2O cluster","1141":"@ledell i did a getFrames on flow and it shows a new frame","1142":"and yea, im using h2o.cbind()","1143":"h2o.rbind()*","1144":"@ying-w The \\u201cframes\\u201d (names like RTMP_6, RTMP_7, etc) that you see in flow are just objects in R.  These objects are just pointers to a particular collection of columns that already exist in H2O memory.  The actual data is not copied.  I know they look like frames, since you can do a `dim(RTMP_6)` and it will return a dimension, but that is just metadata.  ","1145":"I agree that it is confusing for the newcomer though.  I thought the same thing. :)","1146":"how would i differentiate between a pointer and a real object?","1147":"@ying-w All H2OFrames and models are stored only in the H2O Cluster","1148":"so any reference to them in R is really just a pointer","1149":"if `class(myframe)` is \\u201cH2OFrame\\u201d  or  `class(mymodel)` is \\u201cH2OBinomialModel\\u201d etc","1150":"@ying-w I agree that it is kind of messy to have all those RTMP frames show up in Flow though\\u2026 I\\u2019ve been trying to come up with a better solution for that","1151":"i understand that its pointers, was just wondering if there was a way to gleam insight into how the h2o frames were stored server side in case i want to delete \/ force cleanup","1152":"tho it is good to know that after h2o.rbind() the pointer is not pointing to duplicated data","1153":"i thought it might be because first evaluation on the rbinded object always takes a while (assuming lazy evaluation and copy of objects being made)","1154":"anyways, i guess i'll only find this out for sure if i work in a more memory constrained setup","1155":"@ying-w unless you create a brand new column (for example, by taking the log of a column or something), then any time you use an existing column in a new frame, it will simply point to the column in the original frame","1156":"but if you have any ideas how to make it easier for the user to see what\\u2019s going on, let me know!","1157":"yea so that gets to the heart of my concern because if i do a transform on a column of the data, dump that data or subset of that data into R and then i don't need it anymore. i can delete the R object that i dumped into memory and delete any pointers referencing that data but I cannot delete the actual data created right?","1158":"i realized that i can't just go around deleting RTMP_# cuz thats how H2O seems to cache certain subests of data","1159":"@ying-w Ok, so it sounds like you just need to use `h2o.rm()` function, that will delete objects in the H2O cluster","1160":"\\u201ccolumns\\u201d in H2OFrames are really just H2OFrames","1161":"yea but unless i inspect on flow or do many h2o.getFrames() i won't know what the tmp objects are storing (for removal purposes)","1162":"so if you load in columns one by one, each with a unique name, you can easily delete them from the cluster memory","1163":"Oh right, sorry I forgot you were using Flow...","1164":"and you seemed to imply earlier that sometimes the h2o.ls() objects could also be pointers?","1165":"im using both R and flow","1166":"the names returned by `h2o.ls()` are key names to the actual H2O frames\/models in cluster memory","1167":"then that gets back to my initial question about why does h2o.rbind() create a new object instead of a pointer","1168":"i guess i could rotate the matrix","1169":"Earlier you asked about `h2o.cbind()` not `h2o.rbind()`...","1170":"They function differently","1171":"since H2O is a column store","1172":"yea just put it together","1173":"i was thinking cbind but doing rbind","1174":"sorry, let me run some tests","1175":"aah, ok.  I think `h2o.rbind` probably makes copies","1176":"in the cluster, i should probably double check with someone though","1177":"hmm, it doesn't make sense based on the analysis i want to run to transform everything","1178":"i have a time based dataset thats continuously growing, so i'll get more and more rows","1179":"so theres no way to append rows without making a copy?","1180":"Hi all,\\n\\nH2O team is pleased to announce availability of **Sparkling Water 1.6.1** supporting **Spark 1.6**.\\nIt improves overall Sparkling Water performance and stability and introduces several new features.\\n\\nSome of the highlights:\\n  * Scala expressions are now directly supported in H2O Flow UI (no more switching between terminal and Flow UI! Yeah!)\\n  * Spark data sources support read and write from\/to H2O frame\\n  * PySparkling: enables Sparkling Water API in pySpark\\n  * Transformation from\/to H2O frame are now available via REST API and also Flow UI\\n  * H2O frame statistics (mean, quantiles) are attached as metadata to Spark DataFrame\\n  * Sparkling Water bundles the latest release of H2O 3.8.1.3 (Turian)\\n  * H2O web server port is configurable now\\n  * Fix a crucial bug in starting H2O services across Spark cluster\\n\\nFull list of changes is available at GitHub: https:\/\/github.com\/h2oai\/sparkling-water\/blob\/rel-1.6\/CHANGELOG.md#v161-2016-03-15\\n\\nDownload is available here: http:\/\/www.h2o.ai\/download\/sparkling-water\/spark16\\n\\nMaven central artifacts: http:\/\/search.maven.org\/#search%7Cga%7C1%7Cg%3A%22ai.h2o%22%20AND%20v%3A%221.6.1%22%20AND%20a%3Asparkling-water*\\n\\nIn parallel with the 1.6 release, we introduced new releases for **Spark 1.4** (Sparkling Water 1.4.12) and **Spark 1.5** (Sparkling Water 1.5.12), both include the same set of features as the 1.6.1 release. You can download your favorite version from: http:\/\/www.h2o.ai\/download\/sparkling-water\/choose\\n\\nPlease let us know your feedback via **H2OStream** (https:\/\/groups.google.com\/forum\/#!forum\/h2ostream) or **Gitter** (https:\/\/gitter.im\/h2oai\/sparkling-water)\\n\\nAt the end let me thank to all contributors for code and\/or valuable feedback: Kuba Hava (https:\/\/github.com\/MadMan0708), Petro Rudenko (https:\/\/github.com\/petro-rudenko), Todd Niven (https:\/\/github.com\/toddniven), and Ted (https:\/\/github.com\/tcfuji).\\n\\nEnjoy!\\nMichal ","1181":"Hello! I'm attempting to tackle https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-2004 \\n\\nCan someone please do me a quick favour and screenshot the Water Meter? It's at \/perfbar.html","1182":"@signedbit Oh, cool.  That would be great, have you made any progress?","1183":"@ledell I think so. I'm in need of a screenshot of what it's supposed to look like. I edited my last message as I wasn't expecting enter to send the message!","1184":"ok, let me see if I can find a screenshot for you\\u2026 (I don\\u2019t have a linux h2o cluster running at the moment)","1185":"@signedbit Here\\u2019s a screenshot from Arno\\u2019s twitter account: https:\/\/twitter.com\/ArnoCandel\/status\/691779736230596612","1186":"That one is a 10-node cluster (looks like 32 cores on each)","1187":"Here is one more (a single-node, many-core cluster): https:\/\/twitter.com\/ArnoCandel\/status\/649090746335694848","1188":"@signedbit Anything that resembles this would be great.  The perfbar is one of my favorite features and it\\u2019s sad that it\\u2019s missing from OS X!","1189":"@ledell Thank you very much! You also read my mind with regarding follow-up questions. However, what is the number above the server port?","1190":"@signedbit That\\u2019s a good question, I\\u2019m not sure but it looks like the last number in the IP address","1191":"In the latter screenshot, I\\u2019m guessing that\\u2019s running locally at 127.0.0.1","1192":"@ledell I don't have OS X but I'm looking at Sigar which claims support for all three.","1193":"I recognize the IPs of the first one, that\\u2019s a local server at H2O","1194":"Got it! I'll see what I can do. :smile: ","1195":"Great! I have not seen Sigar before.  Looks cool, i\\u2019ll leave this link here for anyone else interested: https:\/\/support.hyperic.com\/display\/SIGAR\/Home","1196":"Does anybody know why i get this error message when initializing h2o?  No instance found at ip and port: localhost:54321. Trying to start local jar...","1197":"@signedbit we were using Sigar before, it was removed since even now people using old linux machines with antique glibc and sigar was blocking them","1198":"@mmalohlava can u take a look at my error above? someone else had the same error and he fixed it somehow but didnt share how he fixed it. I am not behind a proxy.","1199":"@miladf2 Did you try any of the solutions posted on h2ostream? https:\/\/groups.google.com\/forum\/#!searchin\/h2ostream\/$20No$20instance$20found$20at$20ip$20and$20port$3A$20localhost$3A54321.$20Trying$20to$20start$20local$20jar...","1200":"@ledell  yes. I tried installing new h2o and tried some of the other fixes but they didnt work.... I cant find the connection.py file","1201":"@miladf2 what OS and what version of Python?","1202":"win 10 64bit and Python 2.7.1","1203":"Ok, we\\u2019ve seen this issue on Windows before\\u2026 Can you try starting H2O from the command line, then in Python, `import h2o;  h2o.init()`","1204":"This will show you how to start from command line using the `java` command: http:\/\/www.h2o.ai\/download\/h2o\/desktop","1205":"Thanks. That worked. ","1206":"@miladf2 Do you have a space in your Windows username?","1207":"no","1208":"Ok, just checking.  We have a bug filed already for that: https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-2563","1209":"is h2o.summary() in R supposed to return approximate values?","1210":"i am trying to find the fastest way to get min\/max from h2o Frame","1211":"```r\\n> tmp = as.data.table(x[X$ID == \\1967306\\])\\n> head(tmp$TIMESTAMP)\\n[1] 1454106131749 1454106131749 1454239029926 1454239029926 1454957426664 1454957426664\\n\\n> min(tmp$TIMESTAMP)\\n[1] 1454106131749\\n> max(tmp$TIMESTAMP)\\n[1] 1456773077876\\n\\n> h2o.summary(x[x$ID == \\1967306\\\\TIMESTAMP\\])\\n TIMESTAMP              \\n Min.   :1454106131750  \\n 1st Qu.:1455028351520  \\n Median :1455102334120  \\n Mean   :1455319438340  \\n 3rd Qu.:1455156335000  \\n Max.   :1456773077880 \\n> h2o.quantile(x[x$ID == \\1967306\\\\TIMESTAMP\\], 0)\\n[1] 1454106131749\\n> h2o.quantile(x[x$ID == \\1967306\\\\TIMESTAMP\\], 1)\\n[1] 1456773077876\\n```","1212":"the summary values are rounded","1213":"@ying-w `range()` works","1214":"its one of the base R functions that we overloaded to work on columns of a frame","1215":"@ying-w `min()` and `max()` also work","1216":"it must be numeric, so as long as your TIMESTAMP column is numeric, it will work","1217":"@mmalohlava Oh dear! I suppose my effort was in vain. Thank you for letting me know.","1218":"@signedbit yeah sorry about that, i was not aware that we already tried that a while back :(","1219":"@ledell No worries. I'll just try something else. Any other pointers or advice? I'm currently a little stuck on Windows right now so I thought of writing a vbs script programmatically and calling it programmatically to return the interesting data.","1220":"@signedbit How do you mean you are stuck?  ","1221":"@ledell I don't have a Linux box and can't really install it now on this machine. I'm working on getting my desktop shipped here.","1222":"@signedbit I see, so you are not able to install H2O on windows at all?","1223":"@ledell Install? Other than building it I haven't tried. It took me two whole days of fighting with Windows specific issues just to get it to build. I can't run tests without babysitting or it exhausts all the memory. I'm able to run it but not well. This laptop is underpowered relative to H2O.","1224":"@signedbit you don\\u2019t need to build it to get it running on Windows\\u2026 you just download the jar file and start it up using the java command: http:\/\/www.h2o.ai\/download\/h2o\/desktop","1225":"building is optional, most people just install the R or Python library and start using it","1226":"or if you want to use the GUI, you start via command line and point your browser","1227":"@ledell Correct but I want to contribute code.","1228":"@signedbit aaah ok, sorry.  personally i have not built on windows so i am not too familiar","1229":"@ledell To be honest, I don't actually know how to use it. I don't even know what half of those acronyms and such mean. I pretty much have almost no clue what I'm looking at. I definitely want to learn though. I'm interested in fixing bugs and assisting with the code. Some of the bug reports I just don't even understand because I have no clue what they're talking about.","1230":"cool, well if you know Python or R, that\\u2019s the easiest way to get started\\u2026 there are a number of R and Python bugs that dont require going too deep into the code","1231":"or are you a Java programmer?","1232":"@ledell Mostly yes. I'll probably have more luck with the Python bugs. I can and want to learn both but I only have minimal experience in Python. I read some books on Python but haven't really used it. Shouldn't take long at all to pick up.","1233":"@signedbit Did you see this? https:\/\/github.com\/h2oai\/h2o-3\/blob\/master\/CONTRIBUTING.md","1234":"@ledell Of course!","1235":"@signedbit ok i just wanted to make sure, people have hard time finding that doc sometimes","1236":"@ledell I thought the de facto standard is to call it \\CONTRIBUTING\\?","1237":"yeah\\u2026 i have had several people ask on h2ostream \\u201chow do i contribute\\u201d and i have to point them there","1238":"@ledell Oh I see. What is the \\h2ostream\\ exactly?","1239":"The Google discussion group?","1240":"yep, exactly: https:\/\/groups.google.com\/forum\/#!forum\/h2ostream","1241":"@signedbit Java unit tests might be a good place to start","1242":"platform tests in Java: h2o-core\/src\/test\/java\/\\nalgorithm tests in Java: h2o-algos\/src\/test\/java\/","1243":"@ledell Understood. Thank you. ","1244":"@signedbit That\\u2019s just a suggestion though, feel free to explore other areas of the software ","1245":"@signedbit looks like you\\u2019ve already gotten your feet wet\\u2026 https:\/\/github.com\/signedbit\/h2o-3\/compare\/9b308a3b69...860d5f2b3d  :)","1246":"@ledell Oh no, I didn't write any of that. I didn't even touch those files.","1247":"@signedbit Oh, oops, i didnt look carefully, those are Spencer\\u2019s changes\\u2026 ","1248":"@ledell It's all good","1249":"(i\\u2019m trying to do too many things at once!!)","1250":"@ledell I don't believe in multitasking for that exact reason. It's just not possible.. especially where thinking is involved. Jumping around only increases chances of mistakes\/lowers quality and increases the potential for future headaches. I personally prefer to focus on one thing at a time, get it done well and get it done quickly. It takes ~15 minutes to get \\in the zone\\ and small but constant interruptions prevent achieving that maximum focus and productivity. I may forget a small but important detail after being interrupted and then the code breaks months later and I can't quite remember exactly what I was thinking when I wrote it. So now I have to spend more time to figure it out than I \\saved\\ by multitasking. I personally have not seen anyone who can really truly multitask well (as in without greatly increasing chances of mistakes.) Just my 2 cents.","1251":"I'm gonna go squash bugs now.","1252":"@ledell thanks, didn't know those were overloaded","1253":"We have a ticket open to make a `h2o.*` version of all our overloaded functions, so that users can always count on the `h2o.*` being there","1254":"because some of the functions we overloaded and some we prepended with `h2o.*`","1255":"Hi, do you if H2O has  Fuzzy logic algorithms? I did not find any.","1256":"@Lana777 No we do not","1257":"thank you!","1258":"Hi, what is this error, i am new to spark & sparling water","1259":"run-example.sh: 40: [: local-cluster[3,2,2048]: unexpected operator\\nrun-example.sh: 40: [: local-cluster[3,2,2048]: unexpected operator\\nError: Could not find or load main class org.apache.spark.launcher.Main","1260":"@agaddale Please post sparking-water specific questions to the h2oai\/sparkling-water Gitter.  thanks!","1261":"Sure, thanks!","1262":"you\\u2019ll get better help over there :)","1263":":smile:  thanks!","1264":"I just follow the python document, but there is some errors","1265":"'module' object has no attribute 'system_file'","1266":"how can I solve this?","1267":"and I get another error like the following\\n","1268":"No enum constant hex.Distribution.Family. multinomial","1269":"Is there any solution to this?","1270":"I can not find anything about this after using the Google","1271":"sorry for the multinomial problem, because I just copy the code in the pdf document, there is a blank, so this is just a bug in the document","1272":"but the first problem seem not get solved.","1273":"Hi, i was trying to create a multi node h2o cluster using flatfile, i see this error","1274":"\\n03-26 09:37:37.352 192.168.1.10:54321    4335   #93881-16 INFO: Method: GET   , URI: \/3\/About, route: \/3\/About, parms: {}\\n03-26 09:37:37.376 192.168.1.10:54321    4335   #93881-18 INFO: Method: GET   , URI: \/3\/ModelBuilders, route: \/3\/ModelBuilders, parms: {}\\n03-26 09:37:37.423 192.168.1.10:54321    4335   #93881-18 INFO: Locking cloud to new members, because hex.schemas.DeepLearningV3\\n03-26 09:37:58.726 192.168.1.10:54321    4335   #34:54321 ERRR: Got IO error when sending batch UDP bytes: java.net.ConnectException: Connection refused\\n03-26 09:38:17.759 192.168.1.10:54321    4335   #38:54321 ERRR: Got IO error when sending batch UDP bytes: java.net.ConnectException: Connection refused","1275":"@djvulee If you post the code or a link to what code you are talking about, we can help you out","1276":"@ledell iris_data_path = h2o.system_file(\\iris.csv\\)","1277":"the code in H2O_Python_booklet\\n","1278":"it seem that there is no `system_file ` API","1279":"@djvulee which version of H2O are you using?  ","1280":"@djvulee i have confirmed that `h2o.system_file` does not work on h2o-master, ill file a bug report and have our QA team take a look.  thanks!","1281":"@djvulee I have created a bug report here, where you can follow the progress: https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-2783   For now, you can replace the code with:  `iris_data_path = \\https:\/\/s3.amazonaws.com\/h2o-public-test-data\/smalldata\/iris\/iris.csv\\u201d`","1282":"Hi, is there a way to calculate the epoch value for DeepLearning, based on the training & validation records? or any best practices to follow?","1283":"@agaddale it\\u2019s hard to know in advance\\u2026 so by default H2O DL will do \\u201cearly stopping\\u201d.  this means that you can set a large epochs value and it will stop early if performance stops increasing","1284":"the default of 10 epochs is pretty reasonable, but if you want you could set it to 50-100 and use the early stopping to choose","1285":"the default value of stopping_rounds is 0? is this the parameter for early stopping? ","1286":"@agaddale yes it is.  it is set to 5 by default in DL","1287":"on all the other algos, early stopping is disabled by default","1288":"I see that the default value is set to 0 in H2O 3.8.1.4","1289":"@bghill @mattdowle  Have you seen \\feather\\ (arrow.apache) for reading and writing data frames?  http:\/\/blog.rstudio.org\/2016\/03\/29\/feather\/  ","1290":"@bghill @mattdowle  I tested for saving a 10M rows(760MB) data.table.  With \\saveRDS\\ it took 110 secs and with \\feather\\  1.2 secs.  ","1291":"@geponce  Nice!  Do you mind if I tweet this?  What's your twitter handle?","1292":"@ledell Thanks for your answer!","1293":"How can I find the meaning of field in` Model.Parameters`","1294":"there is not much description in the Java docs","1295":"Hi all,\\nI try to explain or visualize decision tree in H2O, could someone tell about the best ways for describing model's results?\\nI see a pojo-model but it's difficult for understanding.\\n","1296":"Anyone seen this issue pop up? Loading frames using as.h2o from a data.table. ","1297":"```\\n03-31 08:01:08.010 10.0.0.40:54321       41236  FJ-1-29   ERRR: DistributedException from \/10.0.0.40:54321, caused by java.lang.IllegalArgumentException: Operation not allowed on string vector.\\n03-31 08:01:08.010 10.0.0.40:54321       41236  FJ-1-29   ERRR: \\tat water.MRTask.getResult(MRTask.java:472)\\n03-31 08:01:08.010 10.0.0.40:54321       41236  FJ-1-29   ERRR: \\tat water.MRTask.doAll(MRTask.java:389)\\n03-31 08:01:08.010 10.0.0.40:54321       41236  FJ-1-29   ERRR: \\tat water.MRTask.doAll(MRTask.java:376)\\n03-31 08:01:08.010 10.0.0.40:54321       41236  FJ-1-29   ERRR: \\tat water.MRTask.doAll(MRTask.java:375)\\n03-31 08:01:08.010 10.0.0.40:54321       41236  FJ-1-29   ERRR: \\tat hex.tree.SharedTree.getInitialValue(SharedTree.java:746)\\n03-31 08:01:08.010 10.0.0.40:54321       41236  FJ-1-29   ERRR: \\tat hex.tree.gbm.GBM.access$1700(GBM.java:23)\\n03-31 08:01:08.010 10.0.0.40:54321       41236  FJ-1-29   ERRR: \\tat hex.tree.gbm.GBM$GBMDriver.initializeModelSpecifics(GBM.java:147)\\n03-31 08:01:08.010 10.0.0.40:54321       41236  FJ-1-29   ERRR: \\tat hex.tree.SharedTree$Driver.compute2(SharedTree.java:223)\\n03-31 08:01:08.010 10.0.0.40:54321       41236  FJ-1-29   ERRR: \\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1181)\\n03-31 08:01:08.010 10.0.0.40:54321       41236  FJ-1-29   ERRR: \\tat jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\\n03-31 08:01:08.010 10.0.0.40:54321       41236  FJ-1-29   ERRR: \\tat jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\\n03-31 08:01:08.010 10.0.0.40:54321       41236  FJ-1-29   ERRR: \\tat jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:974)\\n03-31 08:01:08.010 10.0.0.40:54321       41236  FJ-1-29   ERRR: \\tat jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1477)\\n03-31 08:01:08.010 10.0.0.40:54321       41236  FJ-1-29   ERRR: \\tat jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\\n03-31 08:01:08.010 10.0.0.40:54321       41236  FJ-1-29   ERRR: Caused by: java.lang.IllegalArgumentException: Operation not allowed on string vector.\\n03-31 08:01:08.010 10.0.0.40:54321       41236  FJ-1-29   ERRR: \\tat water.fvec.CStrChunk.atd_impl(CStrChunk.java:47)\\n03-31 08:01:08.010 10.0.0.40:54321       41236  FJ-1-29   ERRR: \\tat water.fvec.Chunk.atd(Chunk.java:255)\\n03-31 08:01:08.010 10.0.0.40:54321       41236  FJ-1-29   ERRR: \\tat hex.tree.SharedTree$InitialValue.map(SharedTree.java:770)\\n03-31 08:01:08.010 10.0.0.40:54321       41236  FJ-1-29   ERRR: \\tat water.MRTask.compute2(MRTask.java:621)\\n03-31 08:01:08.010 10.0.0.40:54321       41236  FJ-1-29   ERRR: \\tat water.MRTask.compute2(MRTask.java:577)\\n03-31 08:01:08.010 10.0.0.40:54321       41236  FJ-1-29   ERRR: \\tat water.MRTask.compute2(MRTask.java:577)\\n03-31 08:01:08.010 10.0.0.40:54321       41236  FJ-1-29   ERRR: \\tat water.MRTask.compute2(MRTask.java:577)\\n03-31 08:01:08.010 10.0.0.40:54321       41236  FJ-1-29   ERRR: \\tat water.MRTask.compute2(MRTask.java:577)\\n03-31 08:01:08.010 10.0.0.40:54321       41236  FJ-1-29   ERRR: \\tat water.MRTask.compute2(MRTask.java:577)\\n03-31 08:01:08.010 10.0.0.40:54321       41236  FJ-1-29   ERRR: \\tat water.MRTask.compute2(MRTask.java:577)\\n03-31 08:01:08.010 10.0.0.40:54321       41236  FJ-1-29   ERRR: \\tat water.MRTask.compute2(MRTask.java:577)\\n03-31 08:01:08.010 10.0.0.40:54321       41236  FJ-1-29   ERRR: \\tat water.MRTask.compute2(MRTask.java:577)\\n03-31 08:01:08.010 10.0.0.40:54321       41236  FJ-1-29   ERRR: \\tat water.MRTask.compute2(MRTask.java:577)\\n03-31 08:01:08.010 10.0.0.40:54321       41236  FJ-1-29   ERRR: \\tat water.MRTask.compute2(MRTask.java:577)\\n03-31 08:01:08.010 10.0.0.40:54321       41236  FJ-1-29   ERRR: \\tat water.H2O$H2OCountedCompleter.compute1(H2O.java:1184)\\n03-31 08:01:08.010 10.0.0.40:54321       41236  FJ-1-29   ERRR: \\tat hex.tree.SharedTree$InitialValue$Icer.compute1(SharedTree$InitialValue$Icer.java)\\n03-31 08:01:08.010 10.0.0.40:54321       41236  FJ-1-29   ERRR: \\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1180)\\n03-31 08:01:08.010 10.0.0.40:54321       41236  FJ-1-29   ERRR: \\t... 5 more\\n```","1298":"Does the H2O can support the high dimension well?","1299":"@mattdowle Sure... no problem at all, my twitter handle is @guillermo_ponce","1300":"[![blob](https:\/\/files.gitter.im\/h2oai\/h2o-3\/JVZi\/thumb\/blob.png)](https:\/\/files.gitter.im\/h2oai\/h2o-3\/JVZi\/blob)","1301":"@mattdowle ","1302":"@geponce @mattdowle i think feather is designed for fast reading, not neccessarily fast writing","1303":"@ledell Actually saving a file with feather it is extremely fast....No compression at all... Size of files is almost double size compared to binary (saveRDS)","1304":"[![blob](https:\/\/files.gitter.im\/h2oai\/h2o-3\/j74V\/thumb\/blob.png)](https:\/\/files.gitter.im\/h2oai\/h2o-3\/j74V\/blob)","1305":"@geponce oh yeah im sure its fast to save too\\u2026 however i think their #1 goal was to design a binary format that was super fast to read.","1306":"@ledell  What is Feather?\\n\\nFeather is a fast, lightweight, and easy-to-use binary file format for storing data frames. It has a few specific design goals:\\n\\nLightweight, minimal API: make pushing data frames in and out of memory as simple as possible\\nLanguage agnostic: Feather files are the same whether written by Python or R code. Other languages can read and write Feather files, too.\\nHigh read and write performance. When possible, Feather operations should be bound by local disk performance.","1307":"@geponce Ok\\u2026 thanks for pointing that out.  I heard Hadley give a talk on it a few days ago and he mentioned that read time was most important (i guess he forgot to mention that write time was too)","1308":"@geponce   saveRDS has a 'compress' argument which by default is TRUE.  Did you try FALSE?  To compare like-with-like to Feather (since Feather doesn't compress you said).","1309":"@mattdowle  Thanks Matt... The compress argument set as FALSE has pretty much the same speed as feather...  ","1310":"@mattdowle I guess the resulting stored file from feather can be used across languages? What about RDS bin file?  ","1311":"@geponce  Interesting.  Based on your statement about speed, then feather is 'just' a cross language version of existing RDS then.  I had the impression feather was really a breakthrough in speed. RDS (XDR) format has been cross _platform_ (windows, unix, mac, 32bit, 64bit) for a long time.  Now I'm wondering what the difference between XDR format and feather is.","1312":"@geponce   btw, why not use `system.time()` ?","1313":"@mattdowle I guess the idea of saving a data structure in R and be able to open it in Python?","1314":"@geponce   Yes I said that - which is good.  I was wondering what is the specific format change, why change it and what's better; e.g. why not make XDR the standard and read XDR in python.  I guess there's a good reason.  Just curious what it was.","1315":"@mattdowle  I think the use of proc.time() goes back to some issues (I don't remember what) I had running some code from \\parallel\\ package...   ","1316":"@mattdowle I agree, more on improving what is already available... ","1317":"@geponce   btw, I don't normally use gitter.  Too many open channels, too much distraction.  I see some previous @'s to me from you but I haven't been getting notified (not sure why).  Maybe I should start 'batching' emails\/chat.","1318":"@mattdowle  I guess the only thing I was discussing with  Erin Ledell was about some of my workflow using h2o and data.table ","1319":"@mattdowle  and it's only about doing  the \\as.h2o(DT) \\  which takes a little bit of time...   I keep my data as data.table because of the amount of rows I handle.  ","1320":"@mattdowle  I guess my question would be more like:  What'd be your suggestion if I have my data as DT's and I need to go from DT --> h2o.frame --> model --> predictions --> back to DT (I need to create maps with resulting predictions, so I use DT to keep track of pixels, x,y,z as data.table)","1321":"@geponce does `hf <- as.h2o(DT)` work?","1322":"then you do your modeling using `hf` and use `h2o.predict` to get predictions","1323":"which are another H2OFrame","1324":"and then maybe @mattdowle can tell you if something like this works:  `newdt <- as.data.table(as.data.frame(predhf))`","1325":"we should probably overload the `as.data.table` function to accept H2OFrames if it doesn\\u2019t do that already","1326":"@mattdowle @ledell  h2o.df <- as.h2o(DT) works fine...  It's just about the time it takes to move from DT to H2O frame","1327":"@geponce i assume that you can\\u2019t use `h2o.importFile` instead to skip the DT -> H2OFrame step?","1328":"so you are doing some munging in R to get the DT first?","1329":"I wonder if you could do the equivalent munging in H2O as an H2OFrame?  depends on how complex your munging steps are","1330":"@ledell Yes... I'm working everything in R... Satellite\/Climate models  imagery -> DT -> h2o frame  -> model -> predictions... ","1331":"imagery are converted into x,y,z,time","1332":"within R ","1333":"so, if I do h2o.importFile that implies that I already have a CSV file... which I don't... or at least I don't want to have, because it takes a long time to save big data.tables as CSV... ","1334":"I save everything as binary with saveRDS....","1335":"but when I want to do something with H2O, I basically need to move everything involved in the modeling into CSV...  ","1336":"@geponce I guess it\\u2019s just a trade-off right now\\u2026 do you spend time on read\/write or modeling with pure R?  I don\\u2019t know how big your data is, but I\\u2019d assume its still faster to do the extra steps and model in H2O","1337":"We would like to expand H2O\\u2019s capabilities to include more of the munging pipeline","1338":"@geponce Did you see that fwrite has been contributed to data.table very recently?  PR I need to look at.   Binary (either XDR or feather) would be fastest,  but perhaps fwrite would alleviate the write.csv bottleneck in the short term. H2O reads .csv in parallel as you know.","1339":"+1 here for feather. We just started looking into it. I follow @geponce workflow. ","1340":"Also: would love to split on a rule or column once the DT is loaded into H2O....","1341":"Thanks @mattdowle @ledell   I didn't know about the new fwrite....  Does h2o.importFile reads csv in parallel ? ","1342":"@geponce Yes `h2o.importFile` reads in parallel","1343":"@geponce  h2o.importFile also compresses as it reads too and stores simple things like number of NAs, min and max, so that subsequent ops are faster (saving a full scan).  It's pretty cool.","1344":"According to this, iiuc,  fread can be faster than feather?  https:\/\/gist.github.com\/markdanese\/28b9f5412df55efceba754fee2363444","1345":"@mattdowle I tried that script and got:\\n$fread_time\\n   user  system elapsed \\n 31.569   1.250  32.808 \\n\\n$read_feather_time\\n   user  system elapsed \\n 11.864   1.474  13.335 \\n\\n\\n","1346":"@mattdowle and @geponce won\\u2019t these times vary greatly by machine?","1347":"would be interesting to benchmark on a number of different machines to see if the ratios change or stay the same","1348":"Also, whether the file has been seen before by the OS and cached can make a difference.  Need to time 3 consecutive repeats.  Someone posted somewhere how to clear the OS cache, iirc.","1349":"Hi, i was trying to model for DL,  data of 40 odd million records(train, valid & test samples) used, for the epoch value of 10, which it ran for some 80+ hrs on a single node,  it was in running running mode although the percentage completion was marked to 100%, before marking to complete it failed for the below error.","1350":" 30299  FJ-2-19   INFO: Training time: 88:44:10.312 (scoring: 42 min 41.510 sec). Processed 13,899,594 samples (3.685 epochs).\\n04-02 02:01:44.124 192.168.1.13:54321    30299  FJ-2-19   INFO: Iterations: 4,498. Epochs: 3.68484. Speed: 579 samples\/sec. Estimated time left:  0.000 sec\\n04-02 02:01:59.025 192.168.1.13:54321    30299  FJ-1-11   ERRR: java.lang.IllegalArgumentException: 0 > -2147483648\\n04-02 02:01:59.025 192.168.1.13:54321    30299  FJ-1-11   ERRR: \\tat java.util.Arrays.copyOfRange(Arrays.java:2549)\\n04-02 02:01:59.025 192.168.1.13:54321    30299  FJ-1-11   ERRR: \\tat water.MemoryManager.malloc(MemoryManager.java:235)\\n04-02 02:01:59.025 192.168.1.13:54321    30299  FJ-1-11   ERRR: \\tat water.MemoryManager.malloc(MemoryManager.java:207)\\n04-02 02:01:59.025 192.168.1.13:54321    30299  FJ-1-11   ERRR: \\tat water.MemoryManager.arrayCopyOfRange(MemoryManager.java:263)\\n04-02 02:01:59.025 192.168.1.13:54321    30299  FJ-1-11   ERRR: \\tat water.AutoBuffer.expandByteBuffer(AutoBuffer.java:682)\\n04-02 02:01:59.025 192.168.1.13:54321    30299  FJ-1-11   ERRR: \\tat water.AutoBuffer.putA4f(AutoBuffer.java:1311)\\n04-02 02:01:59.025 192.168.1.13:54321    30299  FJ-1-11   ERRR: \\tat hex.deeplearning.Storage$DenseRowMatrix$Icer.write132(Storage$DenseRowMatrix$Icer.java)\\n04-02 02:01:59.025 192.168.1.13:54321    30299  FJ-1-11   ERRR: \\tat hex.deeplearning.Storage$DenseRowMatrix$Icer.write(Storage$DenseRowMatrix$Icer.java)\\n04-02 02:01:59.025 192.168.1.13:54321    30299  FJ-1-11   ERRR: \\tat water.Iced.write(Iced.java:61)\\n04-02 02:01:59.025 192.168.1.13:54321    30299  FJ-1-11   ERRR: \\tat water.AutoBuffer.put(AutoBuffer.java:730)\\n04-02 02:01:59.025 192.168.1.13:54321    30299  FJ-1-11   ERRR: \\tat water.AutoBuffer.putA(AutoBuffer.java:842)\\n04-02 02:01:59.025 192.168.1.13:54321    30299  FJ-1-11   ERRR: \\tat hex.deeplearning.DeepLearningModelInfo$Icer.write131(DeepLearningModelInfo$Icer.java)\\n04-02 02:01:59.025 192.168.1.13:54321    30299  FJ-1-11   ERRR: \\tat hex.deeplearning.DeepLearningModelInfo$Icer.write(DeepLearningModelInfo$Icer.java)\\n04-02 02:01:59.025 192.168.1.13:54321    30299  FJ-1-11   ERRR: \\tat water.Iced.write(Iced.java:61)\\n04-02 02:01:59.025 192.168.1.13:54321    30299  FJ-1-11   ERRR: \\tat water.AutoBuffer.put(AutoBuffer.java:730)\\n04-02 02:01:59.025 192.168.1.13:54321    30299  FJ-1-11   ERRR: \\tat hex.deeplearning.DeepLearningModel$Icer.write113(DeepLearningModel$Icer.java)\\n04-02 02:01:59.025 192.168.1.13:54321    30299  FJ-1-11   ERRR: \\tat hex.deeplearning.DeepLearningModel$Icer.write(DeepLearningModel$Icer.java)\\n04-02 02:01:59.025 192.168.1.13:54321    30299  FJ-1-11   ERRR: \\tat water.Iced.write(Iced.java:61)\\n04-02 02:01:59.025 192.168.1.13:54321    30299  FJ-1-11   ERRR: \\tat water.Iced.asBytes(Iced.java:42)\\n04-02 02:01:59.025 192.168.1.13:54321    30299  FJ-1-11   ERRR: \\tat water.Value.<init>(Value.java:334)\\n04-02 02:01:59.025 192.168.1.13:54321    30299  FJ-1-11   ERRR: \\tat water.TAtomic.atomic(TAtomic.java:22)\\n04-02 02:01:59.025 192.168.1.13:54321    30299  FJ-1-11   ERRR: \\tat water.Atomic.compute2(Atomic.java:56)\\n04-02 02:01:59.025 192.168.1.13:54321    30299  FJ-1-11   ERRR: \\tat water.Atomic.fork(Atomic.java:39)\\n04-02 02:01:59.025 192.168.1.13:54321    30299  FJ-1-11   ERRR: \\tat water.Atomic.invoke(Atomic.java:31)\\n04-02 02:01:59.025 192.168.1.13:54321    30299  FJ-1-11   ERRR: \\tat water.Lockable.unlock(Lockable.java:181)\\n04-02 02:01:59.025 192.168.1.13:54321    30299  FJ-1-11   ERRR: \\tat water.Lockable.unlock(Lockable.java:176)\\n04-02 02:01:59.025 192.168.1.13:54321    30299  FJ-1-11   ERRR: \\tat hex.deeplearning.DeepLearning$DeepLearningDriver.trainModel(DeepLearning.java:468)\\n04-02 02:01:59.025 192.168.1.13:54321    30299  FJ-1-11   ERRR: \\tat hex.deeplearning.DeepLearning$DeepLearningDriver.buildModel(DeepLearning.java:302)\\n04-02 02:01:59.025 192.168.1.13:54321    30299  FJ-1-11   ERRR: \\tat hex.deeplearning.DeepLearning$DeepLearningDriver.compute2(DeepLearning.java:203)\\n04-02 02:01:59.025 192.168.1.13:54321    30299  FJ-1-11   ERRR: \\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1181)\\n04-02 02:01:59.025 192.168.1.13:543","1351":"Can somebody please tell me what is this error, why it has occurred, so that it will help in re-modeling it next time","1352":"[h2ologs_20160402_125912.zip](https:\/\/files.gitter.im\/h2oai\/h2o-3\/BFmC\/h2ologs_20160402_125912.zip)","1353":"@geponce I saw via google that you were hoping to get h2o to work on slurm back in october. did you figure it out \/ find some sample code? I\\u2019m trying to get that working too but am new to slurm","1354":"@ck37 Yes... I did some interactive srun and recall that worked fine... I got some help from Brandon ( @bghill)...  ","1355":"@ck37  This is what I did from a session into our HPC:  srun --pty -p main -N40 java -Xmx120g -jar \/path\/to\/h2o\/64\/3.2.0.3\/h2o.jar -name justName-h2o -port 54321 -network 10.11.22.0\/24 > outH2O.txt &\\n ","1356":"@ck37 That initializes h2o server... So, when I open a R-session, the \\h2o.init()\\ will find that server... The rest is just running models, objects, etc ","1357":"@ck37 -p main -N40   indicates that from the main pool of nodes use 40 nodes and run the h2o.jar with 120GB (Xmx120g)  ","1358":"`h2o.getModel(\\foo\\)` throws an exception: all the logs are filled with about 40 lines of text...I think this is a bit excessive. At the very least, if there's a `h2o.doesObjectExist(\\foo\\)` method, we can call that first before blowing up H2O. ","1359":"@geponce interesting, thanks a bunch! I will give that a try","1360":"So I guess this is a feature request: don't throw exceptions on 404 resource not found? Or let us query for the existence of frames, predictions, models, etc. in a non-exceptional way. I can wrap it on my end, but the logs fille up.","1361":"(Sorry for jumping in the middle of your thread @ck37)","1362":"@ck37  the -network parameter is something I still trying to better understand how it actually works","1363":"no problemo, I support multithreading :P","1364":"Just don't throw an exception in here; keep it clean :)","1365":"@ck37 I thought that 10.11.22.0\/24 indicated the ip for the nodes... But I'm using 40 nodes...   @bghill Could you explain the meaning of the -network parameter? I remember we were doing some troubleshooting on this... ","1366":"@geoponce, right, the \/24 is a bitmask for the IP subnetwork , see https:\/\/en.wikipedia.org\/wiki\/Subnetwork#Subnetting","1367":"BTW H2O, this is a completely useless error message: `java.lang.IllegalArgumentException: Actual column must contain binary class labels, but found cardinality 1!`","1368":"I appreciate the exclamation mark though.","1369":"Maybe tell us *which* _actual_ column? Because I have 130.","1370":"@scottstanfield if you are looking for class labels, it would be your Y column","1371":"huh...well there's only one of those.","1372":"yup","1373":"This is during a `predict`, btw. ","1374":"Ok: I dropped the `Target` from the frame and `predict` worked. This must have been a change from Tibs (3.6.0.8) to Turan (3.8.1.4). ","1375":"I\\u2019m importing an R dataframe of 6,735 rows using as.h2o(df), but if I check the dims of the h2o object it reports 10,818 rows - any ideas?","1376":"ah figured it out - h2o cannot accurately import dataframes where a column has newlines in its values, which is tough for text data","1377":"the problem is that as.h2o() outputs a csv that will mess up with newslines in any data field: https:\/\/github.com\/h2oai\/h2o-3\/blob\/master\/h2o-r\/h2o-package\/R\/frame.R#L2121","1378":"it would be good to at least check if number of rows differ between the original dataframe and the imported h2o object","1379":"does h2o analyses comma separated values for a column in csv? or rather text analysis?","1380":"@agaddale hmm hard to understand what you are hoping to do, unfortunately","1381":"like a column in my csv file is having values like \\BASE5.3.0,ADMIN5.3.0,FWDG5.3.0,LC5.3.0,ROUT5.3.0\\ is h2o capable of analysing these multi values to find patterns, or rather it considers as one string","1382":"ah, gothca, well I\\u2019d just try it and see","1383":"*gotcha","1384":"ok","1385":"test chat","1386":"@scottstanfield I agree, we should expose the getModels, getFrames, and getGrids utils that we have in Flow in our R\/Py APIs","1387":"that way you can see a list of models and frames before you try to `h2o.getFrame` them","1388":"I don\\u2019t think we currently have this (waiting for a confirmation) and then I\\u2019ll create a JIRA","1389":"Welcome, @cliffclick !","1390":"@ledell thanks Erin. I tried using tryCatch to protect my `h2o.getModel` and it's not working either. +1 for this feature!","1391":"@scottstanfield https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-2818","1392":"@ledell two enthusiastic thumbs up :thumbsup: ","1393":"My Friday evening: watching Giants beat up on the Dodgers and running a giant h2o.grid() search using these techniques: https:\/\/github.com\/h2oai\/h2o-3\/blob\/master\/h2o-docs\/src\/product\/tutorials\/GridSearch.md","1394":"Quick question: is it possible to rename a model after it's generated? I have one with periods in it, which isn't valid for Java classes (trying to POJO)","1395":"@Everyone:  one quick question...  Is there any way to calculate cv logloss for h2o.ensemble???? (just like cvAUC)","1396":"That's a good one for @ledell ","1397":"Hi i have a problem with python API from ipython notebook:\\n\\n```python\\ndf = h2o.create_frame(\\test\\ rows=1000, cols=10, randomize=True, factors=100, missing_fraction=0.8,\\n                      categorical_fraction=0.5, string_fraction=0.0, binary_fraction=0.0, integer_fraction=0.5)\\nfor col in df.col_names:\\n       df[col].impute(values=[-1])\\n\\ndf\\n#Will show table with missing values\\n\\ndf.describe()\\n#will show missing\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0\\t0```\\n","1398":"What is the status of parquet support in H2O?  Thanks ","1399":"@rajshah4 : you can read parquet from spark and convert to h2o with  [sparkling water](https:\/\/gitter.im\/h2oai\/sparkling-water)","1400":"Any chance there will be something more direct down the road?  Thanks","1401":"@petro-rudenko Is sparkling water the only way to go from Spark DF to H2O DF? i.e. using H2OContext?","1402":"@vmarchen : you can convert back h2o frame to spark DF using `h2oContext.asDataFrame(h2oframe)`","1403":"Yes. My question is, can you go spark -> h2o WITHOUT using h2oContext?","1404":"@rajshah4 direct parquet support is on the roadmap, i don\\u2019t have a timeframe though","1405":"Unfortunately no AFAIK, using sparkling-water. ","1406":"Thanks for the quick answer ","1407":"Hi Erin, is Matt on this channel?  I'm wondering what the state of Big Join and Big Sort is?  I have an interesting use-case","1408":"Thanks. (Direct parquet support would be great  too.)","1409":"@cliffclick Good to hear from you!  He appears on here sometimes\\u2026 I\\u2019ll ask him to sign in","1410":"@rajshah4 and @vmarchen Right now we are working on a JDBC connector, so perhaps after that.  Not sure if Avro or Parquet will be supported first","1411":"@rajshah4  will be available soon, Avro support first","1412":"How i can get best model or hyperparams founded by the grid search in the `Grid` object?","1413":"@petro-rudenko you can access models directly (`Grid` object provides set of model keys) and sort them based on your criterion. There is also explicit support for grid' models sorting via REST API, however right now not sure about Java\/Scala API (need to look but in meantime CCing: @rpeck if he can provide more info about best models)","1414":"@petro-rudenko examples in R and Python (scroll to end) http:\/\/tinyurl.com\/h2o-eeg-r  http:\/\/tinyurl.com\/h2o-eeg-py","1415":"shows how to grab best model, by some metric like AUC","1416":"@erin - thx!  Good to hear from you too","1417":"how do I get pySparkling to show up as a library in Databricks? I attach the .jar and .egg file, but it never shows yup as a library afterwards.","1418":"Never mind. Found out what I was doing wrong. Regards. > how do I get pySparkling to show up as a library in Databricks? I attach the .jar and .egg file, but it never shows yup as a library afterwards.","1419":"@cliffclick Hey Cliff.  I don't usually watch this channel and @'s don't seem to notify me. What's your use-case.  Yes big-join is functional and you can try it with h2o.merge(..., method=\\radix\\).  Tuning still to do for skewed or lumpy keys. No string keys yet but enum should work.  No good api for 'just' sort yet.  Not hooked to python at all, just R h2o.merge().","1420":"@cliffclick Python folk seem to be working to \\avoid the cost of JVM serialization\\.  What's your view?  Did you see feather?  The cross-language cross-system standards push on the binary front seems good to me.","1421":"Is there an h2oEnsemble package for Python (as there is for R)?","1422":"@vmarchen It\\u2019s in development right now\\u2026 The basic functionality is near completion.  I am looking for help testing it, so if you have any interest, let me know.","1423":"@mattdowle - yeah, no notification for @cliffclick!  Sorry, just now reading your response.  This is for a python data science shop.  Classic high-group-count tailor made for \\radix\\ join\/sort.  Looking at all the actions on a single trader+stock-trade, on a single day.  Expect ~10 actions per trade, 1 billion actions a day, 100M \\groups\\ of trader-in-action.  Then end up doing a lot of ML on the groups.  Sorting is another path forwards.  If it works, but just needs python hooks I'll try to poke at it that way.","1424":"I just looked at feather, seems sane but not terribly exciting.  Or at least h2o .hex format probably gets 2x to 4x better compression, and thus higher ingest speeds.  Probably pretty easy format to ingest.","1425":"Who knows what does it mean?\\n\\by class water.fvec.Frame$DeepSelect; class java.lang.NullPointerException: null\\n\\njava.lang.NullPointerException\\n        at water.fvec.Vec.chunkForChunkIdx(Vec.java:835)\\n        at water.MRTask.compute2(MRTask.java:639)\\n        at water.MRTask.compute2(MRTask.java:614)\\n        at water.H2O$H2OCountedCompleter.compute(H2O.java:1069)\\n        at jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\\n        at jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\\n        at jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:974)\\n        at jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1477)\\n        at jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\\n04-19 13:56:24.557 192.168.107.30:54321  3609   #6496-100 ERRR: Caught exception: water.DException$DistributedException: from \/192.168.107.30:54321; by class water.fvec.Frame$DeepSelect; class java.lang.NullPointerException: null; Stacktrace: [water.MRTask.getResult(MRTask.java:505), water.MRTask.doAll(MRTask.java:379), water.MRTask.doAll(MRTask.java:375), water.fvec.Frame.deepSlice(Frame.java:1005), water.rapids.ASTRowSlice.apply(ASTColSlice.java:157), water.rapids.ASTExec.exec(ASTExec.java:46), water.rapids.ASTTmpAssign.apply(ASTAssign.java:255), water.rapids.ASTTmpAssign.apply(ASTAssign.java:248), water.rapids.ASTExec.exec(ASTExec.java:46), water.rapids.Session.exec(Session.java:56), water.rapids.Exec.exec(Exec.java:63), water.api.RapidsHandler.exec(RapidsHandler.java:23), sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method), sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.lang.reflect.Method.invoke(Method.java:497), water.api.Handler.handle(Handler.java:64), water.api.RequestServer.handle(RequestServer.java:644), water.api.RequestServer.serve(RequestServer.java:585), water.JettyHTTPD$H2oDefaultServlet.doGeneric(JettyHTTPD.java:617), water.JettyHTTPD$H2oDefaultServlet.doPost(JettyHTTPD.java:565), javax.servlet.http.HttpServlet.service(HttpServlet.java:755), javax.servlet.http.HttpServlet.service(HttpServlet.java:848), org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:684)]\\","1426":"@AlexanderModestov There\\u2019s  not enough info here to diagnose your issue.  A reproducible code example will help (also H2O version, which API, etc).","1427":"Hi, what's the best way to import\/export h2o model binary using Java API? It's easy to find R, python code, REST API reference, and I can do that in the UI too. But I would like to use native Java like the ModelImportV3, ModelExportV3 classes. Thanks","1428":"@gbrock16 should be fixed in the next release of Sparkling Water (CC: @MadMan0708 ). We are going to release it soon\\n\\n@AlexanderModestov it seems your data was deleted... Can you pleas provide more details?","1429":"@yongjiaw I found a Scala example for you (POJO and binary model examples): https:\/\/github.com\/h2oai\/sparkling-water\/blob\/master\/core\/src\/main\/scala\/water\/app\/SparklingWaterApp.scala#L140-L168  Hopefully that is helpful.  I asked around and no one could point me to an example, so it looks like that\\u2019s a gap in our documentation at the moment.","1430":"@yongjiaw If you can modify the Scala code to Java and make a working example, we\\u2019d love to use it in our docs :)","1431":"@yongjiaw Two more links: Java API:\\n- model export (binary form): https:\/\/github.com\/h2oai\/h2o-3\/blob\/master\/h2o-core\/src\/main\/java\/water\/api\/ModelsHandler.java#L198-L211\\n- POJO export: https:\/\/github.com\/h2oai\/h2o-3\/blob\/master\/h2o-core\/src\/main\/java\/water\/api\/ModelsHandler.java#L147-L152\\nThe class ModelsHandler is a good entry point for API usage pattern...","1432":"@ledell Thanks for the quick response. I'm actually looking for the equivalent of the 'Export Model', 'Import Model' in the UI,  to save the entire Model object. I found ModelsHander.java as well, and the importModel, exportModel methods is the right thing. But they are not static methods, I don't know what's the right way to get hold of a ModelsHandler object.","1433":"@ledell ModelsHandler is farthest I went, could find example code using it, any more help please?","1434":"@yongjiaw Maybe @mmalohlava can explain further?  I don\\u2019t use the Java API myself so I\\u2019m just passing on info from the rest of the team.","1435":"@ledell the scala code you showed looks does what I want to do: serialize model to some URI and load back. But I got the following exception when calling export. I'm exporting a valid GLMModel object. Exception in thread \\main\\ java.lang.UnsupportedOperationException\\n\\tat java.util.AbstractList.add(AbstractList.java:148)\\n\\tat water.app.ModelSerializationSupport$class.exportH2OModel(SparklingWaterApp.scala:142)\\n\\tat water.app.ModelSerializationSupport$.exportH2OModel(SparklingWaterApp.scala:166)\\n","1436":"@ledell  I figured out. I was using sparkling-water release 1.5.10, it appears to have issues exporting the key. Updating to 1.5.12 solved the problem. But the serialization format is not compatible between the two releases.  1.5.10 uses a directory with multiple files, while 1.5.12 uses a single file. This is not a big deal though. The current problem is I cannot set the model_id the same any more. I was able to use glmParams._model_id = Key.make(\\test_model\\) in 1.5.10. It's quite important to control naming of the model","1437":"@ledell never mind, found it in the ModelBuilder constructor, this actually makes better sense.","1438":"Can someone provide an example in Python of using H2OScaler directly on data (not in pipeline)? Say I just want to return a dataframe with columns (excepting response col) demeaned and with unit variance, would I do something like `scaled = H2OScaler().fit(df, y=df[:-1]).transform(df, y=df[:-1])`?","1439":"Oh, maybe it's as simple as `df.scale()`..","1440":"@vmarchen the `H2OScaler()` is way of \\u201ctraining\\u201d on some dataset, then applying the means\/sds from the \\u201ctraining\\u201d data on some new unseen data (for example, a test set)\\n```\\nmy_scaler = H2OScaler()\\nmy_scaler.fit(train_data)\\nmy_scaler.transform(test_data)\\n```\\nThere is similar functionality in sklearn that you may be familiar with: http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.preprocessing.StandardScaler.html\\n\\n`df.scale()` will return a scaled H2OFrame, but the means\/sds will not be preserved in some nice way","1441":"Thanks!","1442":"@yongjiaw the ModelsHandler is used by REST API via reflection. It provides more like patter which you can use for implementation. In Sparkling Water we have ModelSerializationSupport which contains extracted model serialization methods.","1443":"Apologies if this isn't the right place to post this, or if it's already been caught, but I believe there's a typo in h2o\/transforms\/preprocessing.py. (My h2o version is 3.8.1.4.) In `def inverse_transform()` I think `for i in X.ncol` needs to be something like `for i in range(X.ncol)`.","1444":"@vmarchen i think you might be right.  thanks for pointing it out, we will take a look!","1445":"@vmarchen Fixed!  https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-2878","1446":"Hi, I wonder if it is possible to do k-folds and lambda_search at the same time in GLM. Thanks.","1447":"@hamuchiwa we do not support that currently","1448":"i reccomend doing a lambda search with a train and validation set first, find the best lambda and then do k-fold cv","1449":"Hello - I'm trying to create a multi-node cluster - but getting \\Got IO error when sending batch UDP bytes\\ any pointers ?","1450":"fyi - just pushed a partial fix for python3; test :h2o-test-integ:runPythonMultiJVMTests fails on python3; unders WinPython (the recommended default build for windows) it fails *silently*.","1451":"Thanks, Cliff.  Obviously we weren't able to talk on Friday; and a bunch of us are in Chicago for H2O World M-W.   We're still sorting out the best way to incorporate community improvements with good speed and still getting all the testing done.  If you have larger scale changes in mind, we should discuss first...","1452":"Ok, let's keep trying at it.  I've more changes (still small) to come.  But eventually I hope to work out bigger stuff.","1453":"Cool.","1454":"Weird problem: H2O wants to write a column parse error to my 5-error.log file, but the log file just doesn't exist. So that throws an exception. `File \/tmp\/h2o-scott\/h2ologs\/h2o_10.9.0.3_54321-5-error.log does not exist`","1455":"```\\nss-imac \/tmp\/h2o-scott\/h2ologs \\u2219 ll\\ntotal 7,430,144\\n-rw-r--r-- 1 scott wheel 1,874,351 May  2 11:24 h2o_10.9.0.3_54321-3-info.log\\n-rw-r--r-- 1 scott wheel 2,097,197 Apr 30 16:42 h2o_10.9.0.3_54321-3-info.log.1\\n-rw-r--r-- 1 scott wheel   154,734 May  2 11:19 h2o_10.9.0.3_54321-4-warn.log\\n-rw-r--r-- 1 scott wheel   138,595 May  2 11:24 h2o_10.9.0.3_54321-httpd.log\\n-rw-r--r-- 1 scott wheel 1,048,666 May  1 18:40 h2o_10.9.0.3_54321-httpd.log.1\\n-rw-r--r-- 1 scott wheel 1,048,684 May  1 16:11 h2o_10.9.0.3_54321-httpd.log.2\\n-rw-r--r-- 1 scott wheel 1,048,594 Apr 30 15:51 h2o_10.9.0.3_54321-httpd.log.3\\nss-imac \/tmp\/h2o-scott\/h2ologs \\u2219\\n```","1456":"I'll send an email out. I suspect that 3.8.2.3 isn't creating the error log file upon startup. I'll try to send minimum repro steps and what I expect.","1457":"Update: the file `5-error.log` and `6-fatal.log` seem to be created with size 0 when H2O starts (using 3.8.2.3). I'm not sure why my files were missing. Probably not worth worrying about. Just leaving this note here in case someone else encounters this.","1458":"not sure if this is the right place to ask, but I'm looking for an automatic way to choose whether to transform a feature in case it is skewed. So my two questions are: does H2O support for Skewness calculation? If so, is there already a procedure to apply the \\right\\ transformation if the feature is skewed? Thanks!","1459":"I'm a dev out here in the user community and want to know what is the correct way to add DBSCAN for clustering -- kmeans is not making good-enough clusters although its nice as first algo -- and LSH for approximate distance computation -- my data is too large for O(n^2) exact distance. Thanks","1460":"I'm happy to make contribs for LSH and DBSCAN but I don't see what the way is for this on h2o.","1461":"@lilloraffa BoxCox might be able to help you transform a skewed feature.","1462":"Hi, does H2O have Churn modeling? I see this http:\/\/www.h2o.ai\/verticals\/use-cases\/churn\/, but did not find any modeling","1463":"just tried to save my first model with h2o, basically doing something in R like: h2o.download_pojo(airlines.glm, \\~\/h2o\\)\\ni am a bit surprised to see that it sticks an apache license on the generated file. from what i understand (and thats not too much) if i generate this file for a model i fitted then i get to choose the license on it (usage of a library doesnt mean its license transfers to the results)?","1464":"also this possible error strikes me as confusing:\\nYou have requested a premium feature and your H<sub>2<\/sub>O software is unlicensed.\\nthe apache software license is a license. so the software is licensed. is not NOT unlicensed. maybe you should say: \\your software license does not support this feature\\","1465":"(mhh maybe that error message was only in older versions of h2o, i dont see it in h2o-3, if so never mind!)","1466":"Hi, I have noticed that numbers for MSE and deviance on a gbm model are exactly the same: I am checking by running  head(as.data.frame(m@model$scoring_history)) ","1467":"the same is true for the DNN models, I am running H2O  3.8.2.2  on Windows 64bit, using R version 3.2.5 (2016-04-14)","1468":"Hi, Can trees from h2o.randomForest() and h2o.gbm() be plotted similar to the one in the image in link below or plotted at all in any form? Perhaps by parsing h2o.download_pojo(rf1) or h2o.download_pojo(gbm1)?\\nhttp:\/\/i.stack.imgur.com\/3OWx1.png","1469":"I have a dataframe column that contains 0, if I divide this column by -1, it returns -0. Is there a reason why for this? How do I get a normal value 0\/(-1) = 0 ? ","1470":"@geoffreya DBSCAN requires kd-tree structures, which we don\\u2019t have, so it would be major work to add it to H2O","1471":"@geoffreya I can point you to a few links though if you are interested in giving it a shot","1472":"@geoffreya Here is an example of someone adding a clustering algo to H2O, it is Partitioning Around Metoids (PAM), it might be a good example to follow: https:\/\/github.com\/h2oai\/h2o-3\/commit\/a81248b1566f84db59d2d5890d61a807462fca42","1473":"@geoffreya And here\\u2019s our general \\u201ccontributing\\u201d instructions: https:\/\/github.com\/h2oai\/h2o-3\/blob\/master\/CONTRIBUTING.md","1474":"@neallwebster No, we do not have tree-plotting yet, but it\\u2019s possible that we will add it in the future.  You are not the first person to ask about it. :)","1475":"@koertkuipers sounds like you found an deprecated feature of H2O Classic (2.0).  As for the Apache license on the POJO model, I guess the idea is that it\\u2019s just code that was autogenerated by H2O, so it falls under the same license?   This is what I see at the top of a POJO:\\n```\\n\/*\\n  Licensed under the Apache License, Version 2.0\\n    http:\/\/www.apache.org\/licenses\/LICENSE-2.0.html\\n\\n  AUTOGENERATED BY H2O at 2016-05-06T19:40:08.340-07:00\\n  3.8.2.3\\n  \\n  Standalone prediction code with sample test data for DRFModel named DRF_model_R_1462494061769_135\\n\\n  How to download, compile and execute:\\n      mkdir tmpdir\\n      cd tmpdir\\n      curl http:\/\/127.0.0.1:54321\/3\/h2o-genmodel.jar > h2o-genmodel.jar\\n      curl http:\/\/127.0.0.1:54321\/3\/Models.java\/DRF_model_R_1462494061769_135 > DRF_model_R_1462494061769_135.java\\n      javac -cp h2o-genmodel.jar -J-Xmx2g -J-XX:MaxPermSize=128m DRF_model_R_1462494061769_135.java\\n\\n     (Note:  Try java argument -XX:+PrintCompilation to show runtime JIT compiler behavior.)\\n*\/\\n```","1476":"@koertkuipers However, if you don\\u2019t want your models to be open source, then all you need to do is keep them to yourself and don\\u2019t release them to the public \\u2014 they were generated with your (possibly) private data, as you said.  It\\u2019s good to always have a license on any code, including the model Java files, which is probably why its been automatically added there.","1477":"@hamuchiwa Can you post a reproducible example?  I just tried it and I didn\\u2019t get the same result","1478":"@mnorayr I am just going to link to the answer to your question on H2OStream so that others will be able to find the answer too: https:\/\/groups.google.com\/forum\/#!topic\/h2ostream\/zNH2GAzfRG8","1479":"@ledell if I want to do some changes to h2o.stack what's the best way for me to work on that? Create some issues in Jira, we can discuss there and go from there.","1480":"Thinking about a) Implementing support for user-defined CV b) Thinking about whether enforcing the same Response column in the base learners is too strict c) Thinking about whether there is a mechanism we could use to pass in predictions from non h2o base learners (XGBoost, C5.0)","1481":"@cauldnz This is a good time to discuss new features you\\u2019d like to see in H2O Ensemble\\u2026 we are probably going to move everything into Java soon so that it can be exposed in Flow.","1482":"@cauldnz a) what do you mean exactly about user-defined CV\\u2026automatic stratified folds via some argument, or passing in a fold_id column that defines the internal folds?  sounds like you are referring to `h2o.ensemble` rather than `h2o.stack` because the latter assumes the models have already been trained & cross-valdiated","1483":"b) what use case do you have for this?  i\\u2019m curious\\u2026 people have asked about combining a classifiers and regressors in the base learners, however the assumption is that the response is the same.   technically, you can already include base learners trained on different response columns using `h2o.stack`, but when you train the stack, you need to choose a single response.","1484":"c) You can combine h2o models with xgboost or any other R models using either the SuperLearner or subsemble R packages.  All you need is SuperLearner wrapper functions for h2o and xgboost, which I have written (not finished, but working for binomial), but have not had the chance to commit to the SuperLearner package yet.  \\nHere are the SL wrappers for h2o: https:\/\/gist.github.com\/ledell\/ebfa4ba0569d7869f6b2b3f996dc5e39, the SL wrapper for xgboost: https:\/\/gist.github.com\/ledell\/93e0dcf3470ee8f16233eb8d95082c8e and lastly an example of how to use it: https:\/\/gist.github.com\/ledell\/314a89217c9dde579c84a0088e1bc773","1485":"@cauldnz These might have some bugs, I only used this code once and have not looked at it in a few weeks, but this should give you the general idea of how you can do (c) today","1486":"Hiya @ledell: So for context I am working with @scottstanfield  a) Yes, I want to have my own `fold_column` at the moment `h2o.stack` is enforcing modulo folding.","1487":"b) We have a discrete choice type scenario so I'm interested in having both a binomial (win\/!win) and regression (position) target in my base learners.","1488":"c) Will take a look at superlearner. ","1489":"\\n@AlexanderModestov\\nHello all,\\nevery time I get the error:\\n\\ERROR:py4j.java_gateway:Error while sending or receiving.\\nTraceback (most recent call last):\\n  File \\....\/java_gateway.py\\ line 746, in send_command\\n    raise Py4JError(\\Answer from Java side is empty\\)\\nPy4JError: Answer from Java side is empty\\nERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server\\nTraceback (most recent call last):\\n ......\\nerror: [Errno 111] Connection refused\\.\\nMy conf-file:\\n\\spark.serializer org.apache.spark.serializer.KryoSerializer \\nspark.kryoserializer.buffer.max 1500mb\\nspark.driver.memory 65g\\nspark.python.worker.memory 65g\\\\nThe amount of data is about 5Gb.\\nDoes anybody know the answer?","1490":"Hello all, is it possible to access H2OContext after launching H2O as client node: H2OClientApp.main(Array(\\-client\\))? If so, how?","1491":"@cauldnz Ah yeah, that makes sense.  I have that marked as \\u201cTo do\\u201d https:\/\/github.com\/h2oai\/h2o-3\/blob\/master\/h2o-r\/ensemble\/h2oEnsemble-package\/R\/stack.R#L62","1492":"@cauldnz I\\u2019ll make a JIRA for it and get that added ASAP","1493":"@cauldnz https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-2899","1494":"@kamiKAZIK H2OContext has a getOrCreate() method which you can use for this","1495":"Thanks @ledell You going to do that JIRA? I am happy (keen) to do it.","1496":"@cauldnz Glad to accept your help!  Have at it...","1497":"@cauldnz I added some notes to the ticket, feel free to post comments on the JIRA ticket or discuss development here.  Thanks!","1498":"Hiya @ledell ... trying to work on that Jira but having issues running current stack branch.","1499":"```\\nBrowse[9]> s\\ndebug: if (is.function(FUN)) return(FUN)\\nBrowse[9]> s\\ndebug: return(FUN)\\nBrowse[9]> f\\ndebug: if (!is.vector(X) || is.object(X)) X <- as.list(X)\\nBrowse[8]> s\\ndebugging in: is.vector(X)\\ndebug: .Internal(is.vector(x, mode))\\nBrowse[9]> s\\ndebug: .Internal(lapply(X, FUN))\\nBrowse[8]> s\\ndebugging in: FUN(X[[i]], ...)\\nError in FUN(X[[i]], ...) : could not find function \\chk.H2OFrame\\\\n```","1500":"Wondering if that chk.H2OFrame might have ben renamed or someting like that?","1501":"```\\nR version 3.2.4 (2016-03-16)\\nPlatform: x86_64-w64-mingw32\/x64 (64-bit)\\nRunning under: Windows >= 8 x64 (build 9200)\\n\\nlocale:\\n[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252   \\n[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C                          \\n[5] LC_TIME=English_United States.1252    \\n\\nattached base packages:\\n[1] stats     graphics  grDevices utils     datasets  methods   base     \\n\\nother attached packages:\\n[1] h2oEnsemble_0.1.8   devtools_1.9.1      h2o_3.8.2.3         statmod_1.4.21      RevoUtilsMath_3.2.4\\n\\nloaded via a namespace (and not attached):\\n [1] magrittr_1.5    tools_3.2.4     RCurl_1.95-4.8  roxygen2_4.1.1  Rcpp_0.12.1     memoise_1.0.0  \\n [7] stringi_0.5-5   stringr_1.0.0   digest_0.6.9    jsonlite_0.9.19 bitops_1.0-6   \\n> \\n```","1502":"@cauldnz I just tried it on the stable release of h2oEnsemble and the GitHub dev version and I didn\\u2019t see any errors\\u2026  Can you send a reproducible example?","1503":"I don\\u2019t think `chk.H2OFrame` has been removed from H2O\\u2026 not sure what the issue is.","1504":"Hello all","1505":"does anybody know why i get this error on Jupyter? It was working yesterday but I added some environment variables for a reason......                                                                      EnvironmentError: Version mismatch. H2O is version 3.8.1.3, but the h2o-python package is version 3.8.2.3. Install the matching h2o-Python version from - http:\/\/h2o-release.s3.amazonaws.com\/h2o\/rel-turan\/3\/index.html.","1506":"Nevermind I had to downgrade python-h2o to 3.8.1 and now it is working","1507":"@gitdek hello!  welcome ","1508":"@miladf2 prob best to upgrade your H2O jar instead of downgrade your h2o python module","1509":"or you can kill the cluster started by the jar, and use the `h2o.init()` in Python to start the cluster ","1510":"hi","1511":"could i call .score() on a model object concurrently from multiple threads or i should have one instance of the model per thread?","1512":"@michaelr524 The `.score()` method is designed to do single-threaded prediction, but you could probably do it either way.  ","1513":"@ledell do you mean that multi threaded calls into the model would probably work but there is no guarantee? or something else?","1514":"fyi, sorry for multiple pushes to a minor parser heuristic tweak.  Working out a reliable workflow over here.","1515":"@michaelr524 models are all multi-thread safe.","1516":"Hi guys,, I am trying to start an H2O cluster but I get the following error when there are actually no clusters at that IP address:","1517":"05-23 15:46:30.138 172.16.30.19:54321    91604  FJ-126-15 FATAL: Attempting to join \/172.16.30.19:54327 with an H2O version mismatch (md5 differs).  (Is H2O already running?)  Exiting.","1518":"How do I find and shutdown all the existing clusters?","1519":"@cliffclick @ledell thanks","1520":"hi, we're scoring single rows at a time. the number of fields in a row isn't large, maybe up to 20.  is this a viable use case? creating a frame per row seems very costly...","1521":"our use case is real time scoring of small events so latency is a priority.. also we're not using a cluster but rather an embedded h2o node in the scoring service","1522":"cluster would have made sense for big data, but i think that our case is small data with respect to h2o. we do parallelize scoring by starting more scoring service nodes to handle the stream of events","1523":"so i'm trying to figure if we're working in the right direction or we better chose a different approach?","1524":"ah, i think that i figured it out, i should probably use POJO models","1525":"thanks","1526":"would be great if someone could confirm that the way to go with h2o for real time scoring is POJO models... or something else?","1527":"hey @michaelr524 yes using the generated POJO is the way to go :-)","1528":"@mdymczyk glad to hear.. thanks a lot!","1529":"Some specifics on @michaelr524 's use case:  We are training models with millions of events using H2O, and then exporting the models to score a data stream that can output 100K - 1M req\/s.  We need extremely low latency scoring for about 5-10 models for each request.  We are exploring two ways to do this:  1) Using H2O models; 2) using POJO models.","1530":"One thing that we need to consider - the models will be trained hourly, and will be updated often.  With POJO, that would mean a software upgrade for each model upgrade, and for H2O models, it would be a bit easier (we need to test this, but that is my initial thought).  Do you still suggest POJO?  What is the latency difference?","1531":"@switzer let me ask the team for some benchmarks and get back to you if we have some! \\n\\nit will definitely be slower (using H2O models) as first you\\u2019ll have to create a Frame and then use it for predictions, both operations will hit the distributed KV store. In case of POJO models everything is done locally but as you mentioned redeploying the POJO every hour might be painful :-)","1532":"@mdymczyk if you have the H2O model spec for this case study:  https:\/\/github.com\/h2oai\/app-consumer-loan - that would be IDEAL :)\\n","1533":"Hi, i have a problem. For some reason GLM models predicts my data with null values (all columns: prediction, p0, p1 are missing). Other models  (DL, GBM) that was trained on the same data predicts correctly on the same scoring frame.","1534":"@petro-rudenko you may want to look into your input data and check for quality issues. just for a check replace all missing values with 1 and see if that fixes the issue. Sometimes the implementation of these models are not consistent. ","1535":"The problem with a target variable. \\nI'm using from sparkling water but the same with plain csv:\\n```scala\\nval fr = h2oContext.asH2OFrame(dataset.select($(featuresCol), $(labelCol)))\\nval h2oScore = h2oModel.score(fr)```\\n\\nThis works.\\n\\n```scala\\nval fr = h2oContext.asH2OFrame(dataset.select($(featuresCol)))\\nval h2oScore = h2oModel.score(fr)```\\n\\nThis works for all models except of GLM","1536":"Data is the same for all modls","1537":"@petro-rudenko i guess you have to wait for one of the H2O guys. My experience has been the model's act differently in presence of missing data. ","1538":"Thanks","1539":"@petro-rudenko what kind of glm are you running? ","1540":"@toddniven for classification - GLM with binomial distribution and all other default values, for regression with Gaussian ","1541":"@petro-rudenko can you provide a reproducible example (including data)?  all the algos handle missing values automatically; GLM imputes mean by default","1542":"@petro-rudenko so it should predict an value (not NULL).  if not, it might be a bug","1543":"@ledell - fyi, getting requests from my class for time-series or lag-calculations (my own fault for asking them to predict global warming using 80yrs of temperature data).  Do you know if any such thing has made it into h2o?","1544":"@cliffclick Not yet, Navdeep is working in ARIMA, but it\\u2019s not done yet. https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-2590.  Looks like there is a frame sorting prereq that is not complete: https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-2592","1545":"Time series doesn't depend on sorting, but creating the input frame with a time series per row (to fit h2o)","1546":"Ah, ok.  Thanks for clarification, @arnocandel.","1547":"@ledell created a jira with data and steps to reproduce: https:\/\/0xdata.atlassian.net\/browse\/OLD-1197 - my version is 3.8.2.2, don't know why it marked as OLD","1548":"Also have a next exception:\\n```\\n05-31 20:36:21.843 10.0.0.1:54321        21759  FJ-1-13   ERRR: Unexpected incompatible espc, [0, 0, 0, 0, 0, 0, 0, 0, 0, 632, 1269, 1775, 2284, 3058, 3834, 3834, 3834, 3834, 3834, 3834, 3834, 4803, 5770] != [0, 0, 0, 0, 0, 0, 0, 0, 0, 632, 1269, 1775, 2284, 3058, 3834, 3834, 3834, 3834, 3834, 3834, 3834, 4803, 5770, 5770, 5770]\\n05-31 20:36:21.844 10.0.0.1:54321        21759  FJ-1-13   ERRR: java.lang.IllegalArgumentException: Vec C2 is not compatible with the rest of the frame\\n05-31 20:36:21.844 10.0.0.1:54321        21759  FJ-1-13   ERRR: \\tat water.fvec.Frame.checkCompatible(Frame.java:198)\\n05-31 20:36:21.844 10.0.0.1:54321        21759  FJ-1-13   ERRR: \\tat water.fvec.Frame.<init>(Frame.java:119)\\n05-31 20:36:21.844 10.0.0.1:54321        21759  FJ-1-13   ERRR: \\tat water.fvec.Frame.<init>(Frame.java:80)\\n05-31 20:36:21.844 10.0.0.1:54321        21759  FJ-1-13   ERRR: \\tat water.fvec.Frame.<init>(Frame.java:78)```\\n\\nHave no idea what's wrong. Have a working frame on which score is working - it's the same as this one","1549":"OK seems to found issue with latest error. Need to shuffle predictions, because it can't compute correctly confusion matrix if predictions are sorted by target","1550":"That's why it needs target column","1551":"Is it possible to disable metcis calculation on `rfModel.score(testFrame)` or need only to download pojo?","1552":"@petro-rudenko The score method is entirely for metrics calculation.   If you don\\u2019t want to compute metrics, then you don\\u2019t have to execute the score method.  If you want to download a binary copy of the model use `h2o.save_model` or `h2o.download_pojo`to save the POJO.","1553":"[![Screen Shot 2016-06-01 at 4.09.53 PM.png](https:\/\/files.gitter.im\/h2oai\/h2o-3\/B8PP\/thumb\/Screen-Shot-2016-06-01-at-4.09.53-PM.png)](https:\/\/files.gitter.im\/h2oai\/h2o-3\/B8PP\/Screen-Shot-2016-06-01-at-4.09.53-PM.png)","1554":"@petro-rudenko You created the bug on the wrong project (OLD is H2O 2.0) and PUBDEV is the right project.  I should probably clarify that on the README.md file","1555":"@petro-rudenko I think the only thing you can\\u2019t edit is which project the ticket is in, so you might have to create a new one. :-(","1556":"hello - when .split_frame is called, does it randomly shuffle the data when it does the splits? Or is it based off the way the data is ordered?","1557":"@gbrock16 split_frame does not technically shuffle the data (we don\\u2019t like to move around big data), however the splits you will get will be random (there is a seed arg for reproducibility).  Each row is determined by probability whether it will be included in each partition.","1558":"Hi I could really use help finding answers to two hardware related questions.  I have searched already in the usual places. I am making decisions for hardware purchases.","1559":"Q1: Does H2O use GPU and if so how many per host","1560":"Q2: Does 8 GB RAM per node work and if so where are settings or variables for controlling spilling to disk versus RAM","1561":"Of course it depends on my data and model. I still need some answers about H2O -- let's use an analogy here OK? I know how to control RAM vs DISK spillover on Spark using the configuration variables. Where are these variables on H2O? thanks","1562":"@geoffreya Q1. we don\\u2019t currently support GPU but that\\u2019s something that\\u2019s in development as part of our TensorFlow integration Q2. 8GB RAM per node is perfectly fine.  H2O never spills to disk (an earlier version of H2O did, but we turned that feature off).  ","1563":"Hi @ledell Tensorflow integration - very good news - is there any document\/roadmap\/branch in github where can I find more info about it?","1564":"@ledell @petro-rudenko  I moved the Jira ticket from OLD-1197, new ID is https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-2990","1565":"@engr - \\n\\n\\nMore background: the parser's \\newish\\ enum unification with UTF8 was implemented with a NBHM.toArray - which currently has the bad default implementation, which is part of the problem. Behavior is after loading a 100M file in like 2 or 3 seconds the parser runs single-threaded for 10 or 20 seconds. There are a bunch of interlocking problems:\\n\\n* Parser calls NBHM.toArray, really without a huge need; it was just convenient.\\n* File has more than ~100K String enum columns, which vary by 1 character by counting: 76AAA, 76AAB, 76AAC, ..., 76AAZ, 76ABA, etc.\\n* String.hashCode differs by 1 for such strings.\\n* BufferedString.hashCode matches String.hashCode\\n* NBHM default hash spreader (copied direct from Doug Lea) does not spread low bits\\n* Keys then jammed in adjacent in the table with no gaps; first collision caused all following keys to misalign, and lookups turn into linear-scan of 100K keys (well actual avg key reprobe was something like 10K probes vs the expected 2)\\n* Default toArray impl does The Obvious Thing, uses the default iterator which calls \\get\\ for every key and get() is doing a linear scan now due to the bad spread.\\n* BufferedString.hashCode is not caching the hashes and is getting called for each of the 100K times 10K lookups, so showed up in all profiles.\\n* BufferedString.hashCode uses accessors, which immediately hide the cost model.\\n\\nFixes then address these issues:\\n\\n* BufferedString.hashCode & compare & equals no longer use accessors (they remain for external users); the code is \\obviously efficient\\ at a glance. i.e., the problem is not a slow hashCode() call, the problem is a hashCode() being called literally 1 billion times.\\n* NBHM picks up a low-bit spreader. This fixed the single-threaded issue all by itself, but has other speed consequences which are hard for me to measure without more benchmarks handy.\\n\\nNext PR will address these:\\n\\n* BS.hashCode probably should cache hashes same as String.hashCode.\\n* NBHM needs a \\NBHM aware\\ version of toArray instead of the default one inherited from AbstractMap. The \\NBHM aware\\ version will remain linear time to convert toArray independent from all bad key spreads or fill-rates.\\n\\nCliff\\n","1566":"The info on the RAM requirement and associated settings for H2O is just all over the planet as to what RAM the H2O product needs to terminate properly when training a model, from \\8GB RAM per node is perfectly fine\\ (Erin LeDell at H2O) to \\30GB RAM is required for a 200,200 neural net example\\ (Arno the H2O architect of H2O at the 2015 presentation on Youtube) all the way up to \\a 1TB machine just solves a lot of problems\\ (Nachum Schacham of Paypal in his 2015 presentation on Youtube).  Can someone please give me a URL to the written doc on the out of core architecture and configuration settings? Like any data scientist who needs to do modeling, I need some basic but reasonably accurate guidance before spilling time and money on the wrong hardware, and whether H2O is literally and strictly \\in-core processing\\ or can it also do any out of core processing if it needs to on larger than RAM models --- or will it just crash and abend on a RAM shortage. ","1567":"@yarenty Not yet...","1568":null,"1569":"@calvertj\\nHello, I would like to create some parsers for genomic data, what would be the best way to do this?  \\nis there some kind of plugin framework?","1570":"is there a plugin framework?  Any docs on making custom parsers?","1571":"F","1572":"@calvertj What is the format you are working with (e.g. gwaa.data)? Does the genomic data easily convert to a matrix?  ","1573":"Does there exist any work or demo using H2O with transfer learning for image object detection using Neural nets?  In NLP domain the word2vec offers some pretrained data. Although I could use unsupervised learning additionally with transfer learning, I fear my own supervised learning would not be enough. Also we can save precious time if we share learned image detection features common in the lower layers.  I have a lung xray image set of just around 300 images of 4 megapixel each image, of which there are only about 220 positive examples. I would get millions of pictures but still only 220 positive examples, if I chop the images up. So learning needs all the help it can get in this. I think transfer learning is the way forward in medical xrays. thanks for link if anyone did transfer learning with H2O.","1574":"Is there a doc which can guide customers to deciding on equipping hardware with one of 8, 30, or 1000 gigabytes of RAM when using H2O? What has the H2O lab or industry partners found the effect to be on correct termination guarantees of applications at different RAM levels?  Thanks for more guidance.","1575":"Can we share checkpoints?  What if transfer learning in H2O were to be augmented by a git\/github kind of thing. The H2O community could save time by sharing prelearned image checkpoints with each other. I'm thinking of H2Ohub.com, if you will.","1576":"seems like you could share checkpoints if you also shared the model with them...then just import the model and update the checkpoint field","1577":"Yes agreed... It seems like the weight matrices are what we need to share, without other data that might be in a checkpoint like regularization params, learning rate params, et al. So just strip it down to the weights matrices, I expect.","1578":"Hi Guys , I need help to improve my model in Deep learning","1579":"I am using h2o to compare bagging , boosting ensemble machine learning algorithms and also deep learning on dataset found in the link https:\/\/www.cs.purdue.edu\/commugrate\/data\/credit_card\/ , I am using AUC to compare model performance. I could achieve 85.5 AUC using SMOTE sampling methods  , But I wanted to check the power of H2O and train model on the whole dataset instead of sampling , but I could not get AUC more than 71 by using H2O , GBM , RF and Deeplearning , So need assistance in improving my models.  My Model parameters are h2o.model <- h2o.deeplearning(x = 1:19, \\n                              y = 20, \\n                              \\h2otrain\\\\n                               balance_classes = TRUE,\\n                              activation = 'Rectifier',\\n                             hidden = c(50,50,50,50,50,50),\\n                             epochs = 500)","1580":"Hi all. Anybody able to provide exact list of dependencies required to build h2o from source on clean ubuntu\/debian? if possible, a docker image. The dockerfile included in root dir is only for running h2o. Tried with jdk, nodejs but still getting errors.","1581":"@jangorecki did you follow documentation https:\/\/github.com\/h2oai\/h2o-3#Building ? It would be useful to see the errors you are referring to. Thank you!","1582":"@mmalohlava I missed the custom nodejs install script before and was installing from apt-get. Now dealing with R pkgs sync. I should manage to build it soon.","1583":"@geoffreya right now we do not support image recognition, but we allow to export model and share them (at least between the same H2O versions). Nevertheless, your idea is really good - we already evaluating different strategies how to make model sharing easier. H2Ohub.ai would be great (CC: @srisatish :-)","1584":"@mmalohlava any plans to move to R 3.3.0 from 3.2.2? kernal R pkg provided in h2o fails to install for R 3.3.0, while it's latest version works fine.","1585":"@jangorecki good question... right now, not sure - probably we should move - @ledell what do you think?","1586":"@mmalohlava typo: not \\kernal\\ but \\kernlab\\.  Building h2o with R 3.3.0 now","1587":"just pushed h2o build environment on Ubuntu 16.04 and R 3.3.0 as [dockerfile](https:\/\/github.com\/jangorecki\/dockerfiles\/blob\/master\/h2o-dev\/Dockerfile)","1588":"@SggGupta Try fewer hidden layers, and fewer neurons in each layer.  Follow Arno\\u2019s DL tips and tricks here: http:\/\/www.slideshare.net\/0xdata\/h2o-world-top-10-deep-learning-tips-tricks-arno-candel and the video here: https:\/\/www.youtube.com\/watch?v=LM255qs8Zsk&index=6&list=PLNtMya54qvOH6YAVFigzoXb4iIzl0cvgd","1589":" @jangorecki  You\\u2019re saying that h2o R package fails to install on R version 3.3.0?  If that\\u2019s the case, we should definely fix that @mmalohlava   ","1590":"@jangorecki Ah, ok ...you are saying there is just a problem with the version of kernlab that we have in our dependencies for the Dockerfile.  Got it.  Thanks for the report","1591":"@ledell h2o uses R 3.2.2 now, and h2o has a repo for R packages, there is kernlab which works fine for R 3.2.2, but the same version of kernlab fails to install on R 3.3.0. But packages needs to be updated anyway if moving from 3.2.2 to 3.3.0. So there is nothing to fix now. Building current h2o with R 3.3.0 (probably not recommended anyway) requires just a minor workaround.","1592":"@ledell , Thank you so much Erin , you are right , I need to do Grid search and try different combinations of hyper parameter optimization.  Thanks for sharing these links.  ","1593":"@ledell , Hi Erin , do you know how to reconstruct my label column from Anomaly detection using deep learning? ","1594":"have you guys seen this error before: DistributedException from \/<IP>:54321, caused by java.lang.IllegalArgumentException: 0 > -2147483648\\n\\nError: DistributedException from \/<IP>:54321, caused by java.lang.IllegalArgumentException: 0 > -2147483648","1595":"just updated to 3.8.2.9 and that error occurs when i upload files in R using h2o.uploadFile()","1596":"did not occur in 3.8.0.6","1597":"Hi @ying-w I think a bug snuck into `h2o.uploadFile` recently.  Use `h2o.importFile` instead.  ","1598":"@ying-w looks like you also posted this error to https:\/\/groups.google.com\/forum\/#!topic\/h2ostream\/GPtiL8Vqy_k, just linking here for documentation.  It looks like it hasn\\u2019t been fully answered yet by Tomas...","1599":"@SggGupta What do you mean by \\reconstruct your label column\\u201d?","1600":"Hiya folks. Should POJO execution (gbm) with categorical values not see in the training set work? We are getting exceptions... If it should work I can go and build a repro and open a Jira. ","1601":"@cauldnz from memory the categorical variables get mapped to enums. So unseen categoricals just need to be mapped to na's. ","1602":"Yes, unseen cat's should work and definitely not give exceptions","1603":"@geoffreya @mmalohlava yes, a model hub of  repository for sharing , reuse and learning patterns is something folks like @tonychu are designing ","1604":"be good to chat live one of these days.","1605":"Hi, do ensemble models support  fine-tuning\/ warm start  ? I am planning to change my codebase to use h20 and wanted to check if this is possible as I do not want to retrain the model everyday in production environment. ","1606":"@asa88 which ensemble models are you referring to, RF, GBM or h2oEnsemble?","1607":"RF and GBM support checkpointing (add more trees and grow deeper trees, etc).","1608":"fyi, TOT master fails \\gradle build -x test\\ in the h2o-binding step","1609":"Exception in thread \\main\\ java.lang.TypeNotPresentException: Type water.api.ModelParametersSchema not present\\n\\n","1610":"Hi, any straight way to call system calls on all nodes from R and gather results?","1611":"@jangorecki You mean using `system2()`?","1612":"@ledell yes, on every node. I want to collect resident set size memory of each node using `ps -o RSS pid`. I found memory info available in `h2o:::.h2o.fromJSON(jsonlite::fromJSON(h2o:::.h2o.doSafeGET(urlSuffix = h2o:::.h2o.__CLOUD), simplifyDataFrame = FALSE))` but those seems to be referring the size of memory available for processing, not a RSS occupied by h2o process in h2o node.","1613":"Hey @cliffclick do you know the answer to @jangorecki\\u2019s question about resident set size memory?","1614":"Hey,","1615":"Is there any easy example to setup a trained","1616":"model and use it with a UI as REST API?","1617":"Hi Team, Is there a way we can try building an app recommedation system using h2oai? Is there any particular ML algorithms which I can use to deploy the same? ","1618":"Another question which I have is regarding the maps. Is there a way to use the scores\/outputs which we got to be plotted in some sort of maps? If not, do we have an API which we can use to forecast the values which we get to some  googlestreetmaps?","1619":"@txr150430 you can use GLRM to build a particular type of recommendation system with h2o by filling in the missing values as in this example: https:\/\/github.com\/h2oai\/h2o-3\/blob\/739ec856995d066ccecb8eb605ca9ef5a9d3baa6\/h2o-r\/demos\/rdemo.glrm.movielens.medium.R","1620":"@txr150430 Regarding your mapping question, that is not related to H2O.  You will have to look into mapping frameworks.","1621":"@ledell : Hello Erin. Will look on to it. Appreciate your help.","1622":"@jangorecki H2O does not collect RSS info, but it does have IP addresses and PID's.  You could ssh-script your way to calling 'ps -o RSS pid' with those.","1623":"@cliffclick is there any reasonable h2o internal API which I can use to develop collection of that data? I would like to automate that process, so ssh-ing isn't really way to go.","1624":"These things are really OS specific - different kinds of information is available on eg. Windows vs Linux.  Look in util\/LinuxProcFileReader.java","1625":"Most of this kind of stuff is brought out to the Cloud status page.","1626":"@cliffclick thanks, I'm generally interested into linux only, and want to measure memory footprint in benchmark.","1627":"What is the logic behind having H2OFrame.set_names() only change the column names locally (i.e. only in Python)? If I set the names, detach from H2O, and then reattach, the names are gone. Is this intended?","1628":"@bghill I think this is not intended.  we noticed a problem with the colnames in Python the other day.  Let me see if I can find a JIRA","1629":"@ledell Great, thanks.","1630":"I am looking for an example code of the usage of survival analysis with H2O","1631":"@mlazarew_twitter H2O v2 had Cox PH. I think it was the last algo on the list to port back over to v3. I don\\u2019t know if it ever was done.  If the port wasn\\u2019t done, the code is there, but needs to be tested to see what, if anything needs to be fixed.","1632":"Hey @bghill, I looked, but I don\\u2019t think we have a JIRA for that yet. Do you mind filing one with a reproducible example?","1633":"@ledell Will do.","1634":"@bghill thanks, can you post the JIRA here when you\\u2019re done?","1635":"Hi guys, did you know that those lines make (R function) h2o.init unable to use `port` and `host` parameters and make this function trying to always use some default parameters? https:\/\/github.com\/h2oai\/h2o-3\/blob\/master\/h2o-r\/h2o-package\/R\/connection.R#L109-L112\\nEven though I use hto.init(port=12345) it will ignore that fact and will use port=as.numeric( Sys.getenv(\\H2O_R_CMD_CHECK_DOC_EXAMPLES_PORT\\))","1636":"@all @here anybody :P ?","1637":"@MarcinKosinski just don\\u2019t set the `H2O_R_CMD_CHECK_DOC_EXAMPLES_PORT` env variable and all will be ok","1638":"@MarcinKosinski call h2o.init with env vars `h2o.init(ip=Sys.getenv(\\...\\), ...)`","1639":"```\\nException in thread \\H2O Launcher thread\\ java.lang.NoSuchMethodError: water.H2O.registerPOST(Ljava\/lang\/String;Ljava\/lang\/Class;Ljava\/lang\/String;Ljava\/lang\/String;)V\\n\\tat hex.api.Register.register(Register.java:32)\\n\\tat water.H2O.registerRestApis(H2O.java:793)\\n\\tat water.H2OStarter.start(H2OStarter.java:23)\\n\\tat water.H2OStarter.start(H2OStarter.java:40)\\n\\tat org.apache.spark.h2o.H2OContextUtils$$anonfun$7$$anon$1.run(H2OContextUtils.scala:140)\\n```","1640":"My `build.sbt` looks like this, trying to use the latest versions of sparking water core, h2o core etc.","1641":"```\\nname := \\selector\\\\n\\nversion := \\1.0\\\\n\\nscalaVersion := \\2.10.6\\\\n\\nlibraryDependencies ++= Seq(\\n  \\org.apache.spark\\ % \\spark-core_2.10\\ % \\1.6.0\\\\n  , \\org.scalaz\\ %% \\scalaz-core\\ % \\7.1.5\\\\n  , \\javax.servlet\\ % \\javax.servlet-api\\ % \\3.0.1\\\\n  , \\junit\\ % \\junit\\ % \\4.12\\\\n  , \\ai.h2o\\ % \\sparkling-water-core_2.10\\ % \\1.6.5\\\\n  , \\ai.h2o\\ % \\h2o-core\\ % \\3.8.3.4\\\\n  , \\com.github.nscala-time\\ %% \\nscala-time\\ % \\1.8.0\\\\n  , \\com.databricks\\ % \\spark-csv_2.10\\ % \\1.4.0\\\\n)\\n```","1642":"@sauravp dont\\u2019 put the `h2o-core` in your dependencies, it\\u2019s already in `sparkling-water-core` dependency list (and for 1.6.5 we bundle H2O 3.8.2.6), you probably have both versions on the classpath and the JVM is confused","1643":"@mdymczyk Yes I found that out. But I need to use H2O 3.8.3.2 or higher (because we are trying to use the genmodel utilities). That is why I was trying to overwrite the transitive dependency","1644":"How do I get to later h2o version?","1645":"you can download the source code from the repo (master branch) and build the sparkling-water-core jar yourself (docs are in the github readme)","1646":"Okay thanks","1647":"we are using h2o-core 3.8.3.2 there","1648":"of course it won\\u2019t be on maven central so you\\u2019ll need to handle that dependency differently","1649":"I see. Thanks @mdymczyk ","1650":"you can try to exclude the h2o-core dep from sparkling-water-core (http:\/\/www.scala-sbt.org\/0.13\/docs\/Library-Management.html#Exclude+Transitive+Dependencies) and then leave your h2o-core in the dependency list but not sure if that will work","1651":"actually @sauravp I just double checked and there are some incompatibilities between SW1.6.5 and H2O 3.8.3.2 so you might need to wait for the next release (or change SW code and build the jar yourself)","1652":"@mdymczyk Care to elaborate what incompatibilities? We built the latest sparkling water locally (`gradlew install`) and set it as dependency in the the sbt project which upped the transitive h2o version to 3.8.3.2 which includes the features in the genmodel code that we needed. We were able to train\/export POJO\/score. Seems to be working. Are you saying we may run into other issues down the line with these versions?","1653":"there might be some cases where it might fail, 3.8.3.2 renamed some methods we call from SW but I guess you are not using those so it\\u2019s ok for now","1654":"Hi guys! I tried  `h2o-3\/h2o-bindings\/src\/main\/java\/water\/bindings\/examples\/Example.java` but got an error, when execute `GBMV3 gbmBody = (GBMV3)ModelBuilders.Helper.trainGbm(modelBuildersService, gbmParms).execute().body();`. This is the error: com.google.gson.JsonSyntaxException: java.lang.IllegalStateException: Expected BEGIN_OBJECT but was BEGIN_ARRAY at line 1 column 4320 path $.parameters\\n ","1655":"Is anyone know how to fix it?","1656":"hello. In version 3.6 I was using the following code for importinga nd exporting models:\\n\\n```\\n val modelKey = model._key.asInstanceOf[Key[_ <: Keyed[_ <: Keyed[_ <: AnyRef]]]]\\n    val keysToExport = model.getPublishedKeys()\\n    keysToExport.add(0, modelKey)\\n    new ObjectTreeBinarySerializer().save(keysToExport, new URI(\\file:\/\/\\ + tmpFilePath))\\n\\n\\nval l = new ObjectTreeBinarySerializer().load(new URI(\\file:\/\/\\ + tmpFilePath))\\nl.get(0).get().asInstanceOf[M]\\n\\n```\\n\\nIt\\u2019s breaking with 3.8. Anybosy knows which methods should I use instead ? Thanks","1657":"@pelatimtt I use `exportH2OModel()` (or `exportPOJOModel()`)","1658":"and `loadH2OModel()`","1659":"@sauravp it\\u2019s a method of which class ?","1660":"```.getPublishedKeys()``` does not seem to be exposed anymore in 3.8 and I\\u2019m also unable to find the class ```ObjectTreeBinarySerializer```. Anybody knows which other method\/classes I should use? Thanks","1661":"@pelatimtt See `SparklingWaterApp.scala` in water.app","1662":"im sorry guys a i have question i dont know if it out of subject","1663":"i have a matrix  with this size shape=(100000,5) with random values and i was to do a cluster to this matrix to have a group a values that are near in a group \\cluster\\","1664":"@pelatimtt Yes, @sauravp is correct, you should use those methods rather than writing custom code.  They are methods for an H2O model.","1665":"@Hassanbenlebsir clustering on random data is not goign to work well...","1666":"@Hassanbenlebsir But if you want to do clustering in H2O, check out our Kmeans algo","1667":"I\\u2019m trying to migrate from 3.6 to 3.8 and I keep getting this error\\n```\\nException in thread \\main\\ java.lang.RuntimeException: Could not initialize the interpreter\\n\\tat org.apache.spark.repl.h2o.H2OInterpreter.initializeInterpreter(H2OInterpreter.scala:131)\\n\\tat org.apache.spark.repl.h2o.H2OInterpreter.<init>(H2OInterpreter.scala:329)\\n\\tat water.api.scalaInt.ScalaCodeHandler.createInterpreterInPool(ScalaCodeHandler.scala:100)\\n\\tat water.api.scalaInt.ScalaCodeHandler$$anonfun$initializeInterpeterPool$1.apply(ScalaCodeHandler.scala:94)\\n\\tat water.api.scalaInt.ScalaCodeHandler$$anonfun$initializeInterpeterPool$1.apply(ScalaCodeHandler.scala:93)\\n\\tat scala.collection.immutable.Range.foreach(Range.scala:141)\\n\\tat water.api.scalaInt.ScalaCodeHandler.initializeInterpeterPool(ScalaCodeHandler.scala:93)\\n\\tat water.api.scalaInt.ScalaCodeHandler.<init>(ScalaCodeHandler.scala:37)\\n\\tat org.apache.spark.h2o.H2OContext$.registerScalaIntEndp(H2OContext.scala:871)\\n\\tat org.apache.spark.h2o.H2OContext$.registerClientWebAPI(H2OContext.scala:791)\\n\\tat org.apache.spark.h2o.H2OContext.start(H2OContext.scala:234)\\n\\tat org.apache.spark.h2o.H2OContext$.getOrCreate(H2OContext.scala:358)\\n\\tat org.apache.spark.h2o.H2OContext$.getOrCreate(H2OContext.scala:384)\\n```","1668":"@pelatimtt this is a sparkling-water issue, could you write in that channel what\\u2019s your setup (sparkling shell vs standalone app via spark submit, what dependencies and setting are you using)","1669":"Thanks @mdymczyk i\\u2019m switching to that channel","1670":"I have another issue. I\\u2019m training hundreds of RF models using the same H2O context. After some tens of models trained, the system just freezes diaplying teh result of the last trained model","1671":"and the entire process is hanging","1672":"again could you please post this in SW channel?","1673":"with some more context (maybe you could check the status of the jobs in Flow and Spark WebUI)","1674":"Given a cross-validation set, is there something in-built to plot the ROC and\/or Precision-Recall charts?","1675":"I am using the POJO and predictcsv, I have it scoring, but the predictions are coming out as hex numbers.  Is there a way to get non-hex numbers out as a prediction (I am just running a RF regression on a small dataset - Icecream) - thanks","1676":"@sauravp do you mean, \\u201cgiven a validation set\\u201d?  If so, then yes, the ROC curve for a model where you pass a validation set is generated automatically in Flow (even if you are training the model in the R, Python or Scala APIs)","1677":null,"1678":"@ledell I am not using Flow. I guess I could. Just curious, what's the back end call in, say, the Scala API?","1679":"@sauravp if you\\u2019re running Sparkling Water you can check this demo https:\/\/github.com\/h2oai\/sparkling-water\/blob\/20a35dad6e38acd484d5b950c5ca5e62494bb928\/examples\/src\/main\/scala\/org\/apache\/spark\/examples\/h2o\/HamOrSpamDemo.scala#L85 ","1680":"it will collect metrics using a model and a set of data","1681":"you can check the `modelMetrics` code to see how you can do something similar using vanila H2O","1682":"Thanks @ledell  and @mdymczyk ","1683":"Hi, I hope it will be quick for you to answer: I\\u2019m trying to use KMeans for anomaly detection, after modelling I have some clusters\/ scoring just give me cluster id - is there any easy way to get MSE to closest cluster instead (for each row in the frame) ?  ","1684":"@yarenty no, we only return the closest cluster centre. You\\u2019d have to compute it yourself using each rows coordinates and the cluster center data from the model\\n\\nwe only return cumulative MSE per cluster in model metrics","1685":"thanks @mdymczyk,  I\\u2019m scala guy -  is my thinking right?:  I can get cluster coordinates from kMeansModel._output._centers_raw and I can get rows by converting to RDDs and map each row to frame - that will give me  closest cluster center and then \\u2026 is there some simple method to calculate MSE or should I copy \/use GenModel.KMeans_distance ","1686":"@yarenty I wouldn\\u2019t really map each row to a frame, that\\u2019s not very performant. Instead you can get the centers from `_output` as you mentioned, map the frame to an RDD, run a `.map()` on it where you\\u2019d do a map `row => (row-centre)^2` (or however you want to calculate the MSE), then if you want you can convert that RDD you get from the map function, transform it into an H2O Frame and append it to the original frame you used for predictions","1687":"does that make sense?","1688":"@mdymczyk  thats what I\\u2019m looking for! thanks","1689":"cheers","1690":"hi h2o, can someone explain the reason for the dependency on `jline` in the resulting h2o.jar? there are a number of other dependencies that seem suspicious in the h2o.jar as well.","1691":"@mmalohlava perhaps has a good answer :)","1692":"from looking at `..\/gradlew dependencies` inside of h2o-assembly:\\n\\n\\n```\\n+--- project :h2o-persist-hdfs\\n|    +--- project :h2o-core (*)\\n|    +--- net.java.dev.jets3t:jets3t:0.6.1\\n|    |    +--- commons-codec:commons-codec:1.3 -> 1.6\\n|    |    +--- commons-logging:commons-logging:1.1.1 -> 1.1.3\\n|    |    \\\\--- commons-httpclient:commons-httpclient:3.1\\n|    |         +--- commons-logging:commons-logging:1.0.4 -> 1.1.3\\n|    |         \\\\--- commons-codec:commons-codec:1.2 -> 1.6\\n|    \\\\--- org.apache.hadoop:hadoop-client:2.0.0-cdh4.3.0\\n|         +--- org.apache.hadoop:hadoop-common:2.0.0-cdh4.3.0\\n|         |    +--- org.apache.hadoop:hadoop-annotations:2.0.0-cdh4.3.0\\n|         |    +--- com.google.guava:guava:11.0.2 -> 18.0\\n|         |    +--- commons-cli:commons-cli:1.2\\n|         |    +--- org.apache.commons:commons-math:2.1\\n|         |    +--- xmlenc:xmlenc:0.52\\n|         |    +--- commons-codec:commons-codec:1.4 -> 1.6\\n|         |    +--- commons-io:commons-io:2.1 -> 2.4\\n|         |    +--- commons-net:commons-net:3.1\\n|         |    +--- commons-logging:commons-logging:1.1.1 -> 1.1.3\\n|         |    +--- log4j:log4j:1.2.17\\n|         |    +--- junit:junit:4.8.2\\n|         |    +--- commons-lang:commons-lang:2.5 -> 2.6\\n|         |    +--- commons-configuration:commons-configuration:1.6\\n|         |    |    +--- commons-collections:commons-collections:3.2.1\\n|         |    |    +--- commons-lang:commons-lang:2.4 -> 2.6\\n|         |    |    +--- commons-logging:commons-logging:1.1.1 -> 1.1.3\\n|         |    |    +--- commons-digester:commons-digester:1.8\\n|         |    |    |    +--- commons-beanutils:commons-beanutils:1.7.0\\n|         |    |    |    |    \\\\--- commons-logging:commons-logging:1.0.3 -> 1.1.3\\n|         |    |    |    \\\\--- commons-logging:commons-logging:1.1 -> 1.1.3\\n|         |    |    \\\\--- commons-beanutils:commons-beanutils-core:1.8.0\\n|         |    |         \\\\--- commons-logging:commons-logging:1.1.1 -> 1.1.3\\n|         |    +--- org.slf4j:slf4j-api:1.6.1 -> 1.7.7\\n|         |    +--- org.codehaus.jackson:jackson-core-asl:1.8.8 -> 1.9.13\\n|         |    +--- org.codehaus.jackson:jackson-mapper-asl:1.8.8 -> 1.9.13 (*)\\n|         |    +--- org.mockito:mockito-all:1.8.5\\n|         |    +--- org.apache.avro:avro:1.7.4 -> 1.8.0 (*)\\n|         |    +--- com.google.protobuf:protobuf-java:2.4.0a\\n|         |    +--- org.apache.hadoop:hadoop-auth:2.0.0-cdh4.3.0\\n|         |    |    +--- org.slf4j:slf4j-api:1.6.1 -> 1.7.7\\n|         |    |    +--- commons-codec:commons-codec:1.4 -> 1.6\\n|         |    |    +--- log4j:log4j:1.2.17\\n|         |    |    \\\\--- org.slf4j:slf4j-log4j12:1.6.1 -> 1.7.5\\n|         |    |         +--- org.slf4j:slf4j-api:1.7.5 -> 1.7.7\\n|         |    |         \\\\--- log4j:log4j:1.2.17\\n|         |    +--- com.jcraft:jsch:0.1.42\\n|         |    +--- org.apache.zookeeper:zookeeper:3.4.5-cdh4.3.0\\n|         |    |    +--- log4j:log4j:1.2.16 -> 1.2.17\\n|         |    |    \\\\--- jline:jline:0.9.94\\n```","1693":"the primary problem is using h2o.jar in classpath when invoking a groovy shell.","1694":"@spennihana it\\u2019s not really suspicious, it\\u2019s just a transitive dependency from some libraries that we are using in H2O","1695":"sigh it's too bad that it's 0.9.94 when the current version of groovysh depends on 2","1696":"that's why i said it was suspicious @mdymczyk -- but it appears to be a cdh problem","1697":"the option here is to essentially build h2o without the h2o-persist-hdfs (where a large number of dependencies come in that core h2o does not need if it doesn't want to acccess an HDFS)","1698":"thanks anyways @mdymczyk ","1699":"why does the h2o python module hijack the standard exception handling and print all kinds of garbage?","1700":"@spennihana is that new functionality?  Pasha has been working on updating the Python module, so maybe he knows.  Otherwise, you are the most likely person to know the answer to this question.  :)","1701":"ya it's new functionality","1702":"it means it doesn't play nice with any other python module, and prints out all the environment objects (which for things like H2OModels, is quite a lot of output)","1703":"@spennihana Ok, thanks for the feedback.  I suggest you file a JIRA outlining the issues and assign to Pasha.  We should fix that...","1704":"Hi , I am looking for `h2o-java-rest-bindings` for H2O release `3.10.0.6` , the latest one which I could find on maven repository is `3.8.2.11`. Questions 1) Where I can find that  ? 2) Can I use old Java bindings `3.8.2.11` with new H2O core release 3) Is this removed \/ replaced with some other functionality ?","1705":"@spennihana yup, we need to polish all dependencies and list them explicitly (i figured out similar problem by writing pom files using h2o artifacts). Thx for reporting! Btw: if you put  your `jline` into your gradle dependencies, so it should upgrade it to the your `jline` 2.0 version. Or at runtime, you need to make sure that your jline version is in front of h2o.jar (or h2o artifacts)","1706":"@jagatsingh sorry for confusion, there was rename of the package and it is now publish under name `h2o-bindings`","1707":"see here: http:\/\/search.maven.org\/#artifactdetails%7Cai.h2o%7Ch2o-bindings%7C3.10.0.6%7Cpom","1708":"The REST API should be stable and should contain only additive changes - so regarding question 2) - it should work however, i will ask @rpeck to confirm that.","1709":"Thanks @mmalohlava . I will try that","1710":"is there a way in h2o to score a model and tell h2o which is the id field of the dataframe so that h2o will return a list of tuple with id and prediction ?","1711":"@pelatimtt : you can use add method with a frame with id: `h2oModel.score(fr).add(dataset.select(\\row_idx\\))`","1712":"Hi, Does H2O UI support to schedule a python job (that uses H2O Python) to run for every 10 mins?","1713":"is there a way to train an h2o model using a sparsevector instead of a frame ?","1714":"@2020testuser No, but we have the ability to perform a grid search for a specified amount of time","1715":"if that helps...","1716":"@pelatimtt You can load data into H2O from SVMlight format.  We are currently working on better sparse handling ","1717":"Hi Everyone","1718":"Is there a guide to how to contribute to h2o?","1719":"I'm having trouble compiling deepwater. The documentation says to copy water.gpu.jar to the deepwater branch of h2o-3 but I'm not able to compile that branch because it says deepwater.backends is missing. ","1720":"There seems to be a build step missing in the documentation","1721":"found it! had to copy deepwater.backends-1.0-SNAPSHOT.jar ","1722":"and deepwater.backends.mxnet-1.0-SNAPSHOT.jar for that matter","1723":"nooooo, only classification supported for now :)\\noh well, looking forward to these features!","1724":"@AnkitAggarwalPEC Yes, it\\u2019s here: https:\/\/github.com\/h2oai\/h2o-3\/blob\/master\/CONTRIBUTING.md  Also you can chat on Gitter to discuss in advance what you\\u2019d like to contribute \/ work on","1725":"@r3tex Thanks, I\\u2019ll make sure the docs get updated for Deep Water.  It\\u2019s in very active development, so check back soon for new features","1726":"Hi,\\n\\nI am using the sample java code to build a GLM Model which is working fine. I can also predict\/score using the sample java code but I am not able to fetch the GLM specific parameters like - r2, AUC etc. for GLM Model Output from java code. \\nIf, I examine the same model which I have created using java code in flow UI then I can see all the model metrics (like - RMSE, r2, logloss, AUC, Gini etc.) .\\n\\nThe reason of it that - I can only get the base class object of \\ModelOutputSchemaV3\\ and not the GLMModelOutputV3 response object using below code. It looks like a limitation to me. Please suggest how to work around or resolve it.\\n\\n\/\/ TODO: Retrofit seems to be only deserializing the base class. What to do?\\nModelsV3 models = h2o.model((ModelKeyV3) job.dest);\\nGLMModelV3 glmModelV3 = (GLMModelV3) models.models[0];\\n\/\/below is giving error - java.lang.ClassCastException:water.bindings.pojos.ModelOutputSchemaV3 cannot be cast to water.bindings.pojos.GLMModelOutputV3\\nGLMModelOutputV3 output = (GLMModelOutputV3)glmModelV3.output;\\n\\nThanks Gaurav","1727":"I\\u2019m trying to run multiple h2o jobs in parallel (starting from different threads) in the same h2oContext and it is failing. Is it supported ?","1728":"@pelatimtt depends, might be ok. Could you give us an example and the error you're getting? Also could we continue in the sparklintg water gitter?","1729":"sure @mdymczyk ","1730":"@mdymczyk Are u in the sparkling water channel? cannot find you","1731":"I get an arrayoutofbound exception coming from teh sparkcontext","1732":"You can just post to the channel, im there (h2oai\/sparkling-water)","1733":"Hi guys, I'm about to install h2o with python, is it compatible with Python 3.5?","1734":"@lucasvfventura yes","1735":"Any idea what usually causes this? ```IllegalArgumentException: Vec C2 is not compatible with the rest of the frame```\\nMy model training\/validation pipeline works fine as is. But when I try filtering both the training and testing frames before model training, I get this error.","1736":"@petro-rudenko You seemed to have seen this before. I see your comment above:\\n\\OK seems to found issue with latest error. Need to shuffle predictions, because it can't compute correctly confusion matrix if predictions are sorted by target\\nThat's why it needs target column\\","1737":"can you please elaborate?","1738":"hi guys, im new in deep learning, machine learning im learning h2o, im trying to learn doing some applications , just i  would like to know which tools are you  using for extracting, ingest information for analyzing  in h2oai?","1739":"Hey guys, I just sat down for a hackathon. I work in a company which has call and sms APIs. It's a company level, internal hackathon. Do we have some Ideas!","1740":"@alextorar_twitter what kind of data do you have?","1741":"@sauravp is your testing frame missing a response column?","1742":"Question on Recommender:\\n  There are other open source like PredictionIO for recommender,\\n  Wondering how can we build recommender Application (= Scala\/Java, not the Interactive R\/python) with H2O ?\\n  What are the advantages of H2O from PredictionIO (on recommender side) ?\\n","1743":"@ledell  web logs ","1744":"Hi, I am trying to load data from a CSV using the Python API. Everything went well until I added a large number of columns. Now the header is not read anymore but instead I get C1, .., CN instead of meaningful column names. Any advise how I can correct this?","1745":"Hi, is there an example of using MOJO's in Java? I am trying to use MOJO as my model POJO is > 1GB.","1746":"@abossenbroek can you post an issue at community.h2o.ai with a code snippet?  if your data is sensitive, then just use the head or your csv file or something","1747":"that sounds like it could be a bug, but i wonder if there is something strange in one of your column names.  it looks like it\\u2019s failing to recognize the header, and loading that as the first row of the data and then adding generic colnames","1748":"@alextorar_twitter if your web logs are structured, then maybe you can create some simple features to extract from them.  however, if they are kind of a mess, then I\\u2019d recommend a more complex approach \\u2014 use an LSTM","1749":"@alextorar_twitter LSTM (now available in H2O Deep Water) is good for sequence data, and I\\u2019d say web logs could be considered as such","1750":"@alextorar_twitter But it may be easier to start with extracting some simple features from your data that you think might be predictive of your response variable.","1751":"@deepak_s_rawat_twitter Are you looking for an example of how to download\/export the MOJO in Java?  There is this, which shows how to use the MOJO in Java (once it\\u2019s been exported): https:\/\/github.com\/h2oai\/h2o-3\/blob\/master\/h2o-docs\/src\/product\/howto\/MOJO_QuickStart.md","1752":"@ledell I was looking for a way to download MOJO in flow. But as flow bindings are not done yet, I was hoping to do it using Java\/Rest API. Found the API call inside Python's bindings. I was looking for \\\/3\/Models\/<model_id>\/mojo\\ API. Now I am able to download MOJOs using this API :smile: ","1753":"@deepak_s_rawat_twitter ok good.. MOJOs from Flow should be available very soon","1754":"i think they will be in the next release","1755":"@ledell that's great news ! Thank you!","1756":"@deepak_s_rawat_twitter i heard it was just pushed to master, so it might not be in the release today but the next one","1757":"@ledell will do so over the next few days","1758":null,"1759":"is there an easy way to convert a common Java type to a `h2o.gemodel.easy.RowData`?","1760":"hi,always fail to download steam of Linux version,I'm in BeiJing.Anyone knowns? Thanks much.URL: www.h2o.ai\/download\/steam\/","1761":"@dongxuzhao the link is right on that page","1762":"@dongxuzhao currently it points to: https:\/\/s3.amazonaws.com\/steam-release\/steam-1.1.3-linux-amd64.tar.gz","1763":"@ledell  Got it.Thanks so much! I'll  check my network and browser again.","1764":"@ledell  ok, thanks for the answer )","1765":"How can i use autoencoder for univariate time series forecasting","1766":"How do I disable INFO logging in H2o ?","1767":"Howdy - we are running into an issue where our H2O model has a different score than the POJO model.  We have confirmed that they are exports of the same model.  Can I confirm that POJO and H2O models should product EXACTLY the same score 100% of the time?","1768":"In case it\\u2019s useful to anyone, I have some demo code for how to create a multi-node h2o cluster on a SLURM system in R: https:\/\/github.com\/ck37\/savio-notes\/blob\/master\/h2o-slurm-multinode.Rmd","1769":"doesn\\u2019t seem to exist on the internet otherwise","1770":"@ck37 that\\u2019s awesome, thanks!!","1771":"Hi, I'm currently interested in Kaggle competitions and in using H2O, however I haven't found any Factorization Machines algos in H2O","1772":"Any chance on adding Factorization Machines to H2O in a near future?","1773":"Something like libFFM: https:\/\/www.csie.ntu.edu.tw\/~cjlin\/libffm\/","1774":"FM are highly successful in click-through-rate type problems","1775":"@radek1st we\\u2019ve talked about it, but not officially planeed for development yet","1776":"ill mention your interest...","1777":"hi","1778":"Hi I am getting an `ArrayIndexOutOfBounds` exception while trying to score with a deep learning POJO","1779":"```\\njava.lang.ArrayIndexOutOfBoundsException: 491831\\n    at h2o.generated.pojo.DeepLearning_model_1479246827119_1.score0(DeepLearning_model_1479246827119_1.java:175)\\n    at adq.io.models.EasyModelImpl.score0(EasyModelImpl.java:48)\\n    at io.adq.h2o.EasyPredictModelWrapper.predict(EasyPredictModelWrapper.java:457)\\n    at io.adq.h2o.EasyPredictModelWrapper.preamble(EasyPredictModelWrapper.java:386)\\n    at io.adq.h2o.EasyPredictModelWrapper.predictBinomial(EasyPredictModelWrapper.java:255)\\n    at predictor.Model.predict(Models.scala:25)\\n    at predictor.Scorer$$anonfun$receive$1.applyOrElse(Scorer.scala:27)\\n    at akka.actor.Actor$class.aroundReceive(Actor.scala:482)\\n    at predictor.Scorer.aroundReceive(Scorer.scala:15)\\n    at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526)\\n    at akka.actor.ActorCell.invoke(ActorCell.scala:495)\\n    at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257)\\n    at akka.dispatch.Mailbox.run(Mailbox.scala:224)\\n    at akka.dispatch.Mailbox.exec(Mailbox.scala:234)\\n    at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)\\n    at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)\\n    at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)\\n    at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)\\n\\n```","1780":"Note that I can score fine with the h2o model, the POJO is the problem. Also this only happens with the deep learning POJO. I have been successfully scoring with a DRF model POJO","1781":"This is the line in the POJO that throws the error","1782":"```\\n  public static final int[] CATOFFSETS = {0,491831,961475,1125553,1289631,1408883,1491222,1530397,1566966,1573240,1579207,1580560,1581632,1582660,1583688,1584360,1585023,1585641,1586143,1586413,1586637,1586719,1586781,1586793,1586805,1586811,1586815,1586819,1586822};\\n```\\n\\n","1783":"Any pointers will be highly appreciated!","1784":"Hey. Would someone please give me some pointers on how to start contributing to H2o?","1785":"Hi @adityabhatia52 what\\u2019s your background?  we are always in need of interesting demos","1786":"But if you want to contribute to the codebase, you can look through our open JIRAs","1787":"https:\/\/0xdata.atlassian.net\/projects\/PUBDEV\/issues\/PUBDEV-3242?filter=allopenissues","1788":"@adityabhatia52 https:\/\/github.com\/h2oai\/h2o-3\/blob\/master\/CONTRIBUTING.md","1789":"Hi. When I try to use the website (https:\/\/www.h2o.ai) I get a certificate error (wrong domain):  `*.wpengine.com, wpengine.com` Error code: SSL_ERROR_BAD_CERT_DOMAIN","1790":"You guys been hacked?","1791":"Hello, I've got a problem. Is there everyone who suffers like this?\\nNow, I'm using h2o 3.10.x.x version which works very well, but the character value in h2oFrame(hex) shows broken image like '??','?'. I know it is really fine when I put the English word into h2oFrame but other languages are NOT. (All of my character-set have already set the UTF-8) Actually, when I use h2o 2.x.x.x version, this problem wasn't occurred.\\nLet me know if you solve this problem. Thanks.","1792":"hi, does h2o have something equivalent to sparse.model.matrix() in R? I have a dataframe that I want to expand, ideally on the h2o instance","1793":"also, can R matrices be transferred to h2o? for example sparse matrices from Matrix package? It would be unfortunate if the sparse matrix needs to be cast to data frame, then transferred as h2o","1794":"I am reading instructions here for creating a multi node h2o setup http:\/\/h2o-release.s3.amazonaws.com\/h2o\/master\/3052\/docs-website\/h2o-docs\/index.html#%E2%80%A6%20From%20the%20Cmd%20Line-Flatfile%20Configuration%20for%20Multi-Node%20Clusters","1795":"the machines I am trying it out on are on ec2. The machines can ssh into each other and I can see H2O flow on port 54321. However when I run h2o-jar with a flatfile the machines report only \\cloud of size 1\\. What other things should I look out for to make sure these machines can talk to each other?","1796":"communucation happens on port 54322","1797":"@jeffwong-nflx ","1798":"is this port also reachable?","1799":"hi, is there any example to implement word2vec h2o???","1800":"@FRosner Thanks, I\\u2019ve reported to our web dev team.  The wpengine thing is wordpress, so it might be related to our blog being updated","1801":"@MartinPark Please provide a reproducible example and post at community.h2o.ai or file a bug at jira.h2o.ai.  Thanks","1802":"@jeffwong-nflx You can load sparse data as an SVMLight\/LibSVM file using `h2o.importFile` with parse = \\u201cSVMLight\\","1803":"@jeffwong-nflx also we support converting sparse matrices in Python via `h2o.h2oFrame(mysparsemat)` and in R using `as.h2o(mysparsemat)`","1804":"@rezaAdie No examples of word2vec in H2O that I know of.  There was some work on this a while back, but it was never completed.  There is existing code though, so if you wanted to work on that, it would be an awesome conttribution to H2O!  https:\/\/github.com\/h2oai\/h2o-3\/search?utf8=%E2%9C%93&q=word2vec","1805":"@FRosner please follow the instructions here: https:\/\/github.com\/h2oai\/h2o-3\/blob\/master\/ec2\/README.md  You are looking at an old version of the docs","1806":"@jeffwong-nflx please follow the instructions here: https:\/\/github.com\/h2oai\/h2o-3\/blob\/master\/ec2\/README.md You are looking at an old version of the docs","1807":"thanks @FRosner (sorry tagged wrong person)","1808":"@rezaAdie I was wrong\\u2026 one of the engineers is working on Word2Vec at the moment: https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-2058  It was orphaned for a while, but is actively being developed right now","1809":"has anyone used the solvers in h2o for traveling salesperson problem by chance?","1810":"Hey, i want to ask, in sparkling water there is example \\CraigslistJobTitlesApp\\ that implement word2vec, can i use it for base to implement distributed word2vec from H2O in spark???","1811":"Hi all, how would I do knowledge representation in H2O?","1812":"@rezaAdie I think that CraigslistJobTitlesApp is a good starting point. This example doesn't make use of some Spark features that you might find handy in actual production implementation. The tokenize function can be simplified by using Spark's RegexTokenizer and StopWordsRemover.","1813":"I also want to let you know that I am working on adding word2vec to H2O. The implementation will be comparable to Spark's implementation in the very first version - it will also be using skip-gram and hierarchical softmax. CBOW and negative sampling will be added later. I will also provide a basic tokenization functionality. word2vec will be first exposed in our R client and I will provide a example script implementing the \\CraigslistJobTitlesApp\\ in R.","1814":"@michalkurka i kind of lose here, i want to train data using word2vec in h2o and make dataset for the output, when i run \\ CraigslistJobTitlesApp\\ i can run it, but i canlt find any output file, just value that print on my console.","1815":"@michalkurka could you send me a notif, if you already done on working on it, or is there any info about it. Thank You.","1816":"I'm trying to understand the build process for the H2O \\nightly bleeding edge\\ builds. It seems like these aren't really nightly since the most recent one to download is 3.11.0.3724 which looks like it was built on 12\/18. There is a fix for the mojo downloading in R that I am very anxious to get that I think was merged into master yesterday. Does anyone know when the next \\nightly bleeding edge\\ build will be available?","1817":"Quiet place","1818":"@dkincaid they are built nightly\\u2026 the latest nightly as of today is 3.11.0.3730.  After installing I can see that it\\u2019s from last night: `H2O cluster version age:    11 hours and 42 minutes`","1819":"@dkincaid Alternatively, you can always `git clone` the h2o-3 repo and build it yourself with the command `.\/gradlew build -x test` (in the root directory of the repo)","1820":"@dkincaid http:\/\/h2o-release.s3.amazonaws.com\/h2o\/master\/3730\/index.html","1821":"@dkincaid Sometimes the nightly builds fail for whatever reason and it doesn\\u2019t get pushed to S3.  In those cases, I\\u2019d recommend building locally to get daily updates","1822":"@dkincaid I can see that the build failed for a few days in a row, so it makes sense what you were seeing.  Here is where you can look at the nightly master build status: http:\/\/test.h2o.ai\/job\/h2o-dev.build.master\/","1823":"\\ud83d\\udc4d ","1824":"Thanks, Erin! Much appreciated. I didn't even think about building locally. Great idea! Have a good weekend. Except for a few bumps here and there we are really excited about implementing H2O in our latest project.","1825":"@dkincaid glad to hear, let us know if you have any other questions and check out community.h2o.ai","1826":"Hello, everyone","1827":"May i ask something ?","1828":"Can i use Deep Learning algorithm in h2oai with Hadoop's MapReduce and Spark's RDD ?","1829":"I mean, i want to achieve this in distributed system (many nodes) not in a single node. I ask this because there are many Deep Learning Framework out there, but they are cant to be executed in distributed\/parallel way. ","1830":"@rendi7936 Yes, you can use H2O\\u2019s Deep Learning with Spark.  Check out the Sparkling Water project https:\/\/github.com\/h2oai\/sparkling-water\/, which also has Py\/R interfaces:  https:\/\/github.com\/h2oai\/sparkling-water\/tree\/master\/py & https:\/\/github.com\/h2oai\/rsparkling","1831":"@ledell ok, thanks. But, i want it to run with Hadoop's MapReduce not Spark's RDD. Can i achieve that ?","1832":"Is h2o publish journals or paper to explain how h2o works with Hadoop and Spark ?\\n\\nI only get this whitepaper https:\/\/h2o2016.wpengine.com\/wp-content\/themes\/h2o2016\/images\/resources\/Datasheet-2015.pdf\\n\\nIt's explain it clearly, but i need detailed information. Do you know where to get this journals and papers?","1833":"@rendi7936 Have you read this yet? http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/hadoop.html","1834":"@rendi7936 Yes, you can use with either Hadoop or Spark, it\\u2019s your choice.  ","1835":"@rendi7936 Here are some H2O DL resources: http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/data-science\/deep-learning.html http:\/\/docs.h2o.ai\/h2o-tutorials\/latest-stable\/tutorials\/deeplearning\/index.html http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/booklets\/DeepLearningBooklet.pdf","1836":"And if you want to use GPUs, you can check out the Deep Water project: https:\/\/github.com\/h2oai\/deepwater (which is different from the H2O\\u2019s multilayer perceptron network which is CPU based)","1837":"Deep Water lets you use several different backends: TensorFlow, MxNet, Caffe and H2O","1838":"Hello,  I am playing with the sparkling water examples, but I have some issues when I define a new MRTask class.\\nI reduced my code to it's simplest buggy expression: \\n\\nimport org.apache.spark.SparkFiles\\nimport org.apache.spark.sql.{DataFrame, SQLContext, Row}\\nimport org.apache.spark.h2o._\\n\\nimplicit val sqlContext = sparkSession.sqlContext\\nimport sqlContext.implicits._\\nval h2oContext = H2OContext.getOrCreate(sparkSession.sparkContext)\\nimport h2oContext._\\nimport h2oContext.implicits._\\n\\ncase class PAIR (a:Int, b:Int){}\\nval data = Array[String](\\1,2\\\\3,4\\\\5,6\\\\7,8\\\\9,10\\)\\nval rdd = sc.parallelize(data).cache().map(_.split(\\\\)).map(row => PAIR(row(0).toInt,row(1).toInt))\\nval df = rdd.toDF()\\nval heof:H2OFrame = df\\n\\nimport water.MRTask\\nimport water.fvec.{Chunk, NewChunk, Vec, AppendableVec}\\nimport org.apache.spark.h2o.H2OFrame\\n\\nclass Filter extends MRTask[Filter] with Serializable {\\n  def doIt(a: H2OFrame):H2OFrame =  new H2OFrame(doAll(Array(Vec.T_NUM), a).outputFrame(Array[String](\\c\\), null))\\n\\n  override def map(a:Chunk, c: NewChunk):Unit = {\\n    for (i <- 0 until a.len) {\\n      c.addNum(a.at8(i) * 10); \\n    }\\n  }\\n}\\n\\nnew Filter().doAll(heof.vec(0))\\n\\n","1839":"If I do this, I get the following error:\\nwater.util.DistributedException: DistributedException from 192.168.0.13\/192.168.0.13:54321\\n  at water.MRTask.getResult(MRTask.java:478)\\n  at water.MRTask.getResult(MRTask.java:486)\\n  at water.MRTask.doAll(MRTask.java:390)\\n  at water.MRTask.doAll(MRTask.java:377)\\n  at water.MRTask.doAll(MRTask.java:376)\\n  ... 71 elided\\nCaused by: java.lang.RuntimeException: javassist.NotFoundException: Filter\\n  at water.Weaver.genDelegate(Weaver.java:96)\\n  at water.TypeMap.getIcer(TypeMap.java:192)\\n  at water.TypeMap.getIcer(TypeMap.java:180)\\n  at water.H2O$H2OCountedCompleter.icer(H2O.java:1240)\\n  at water.H2O$H2OCountedCompleter.compute(H2O.java:1202)\\n  at jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\\n  at jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\\n  at jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:974)\\n  at jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1477)\\n  at jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\\nCaused by: javassist.NotFoundException: Filter\\n  at javassist.ClassPool.get(ClassPool.java:450)\\n  at water.Weaver.javassistLoadClass(Weaver.java:226)\\n  at water.Weaver.genDelegate(Weaver.java:86)\\n","1840":"Could anybody help finding the cause of this ?\\nThanks in advance!","1841":"@quertenmont could you post this in the SW chat? also please add which SW version are you using and how are you running your code - sparkling shell? if so then this might be normal","1842":"it's indeed in the shell","1843":"I just tried compiled and it works nicely","1844":"any idea why it is not suppose to work in the shell ?","1845":"it might be a problem with how Scala wraps classes created in the shell","1846":"ok, thanks","1847":"hello there. I'm new to h2o, and I want to do some text mining\/sentiment analysis with deep learning. Do you have any suggestions? Any ideas will be appreciated.","1848":"@WangAllen I\\u2019m working now on porting this TensorFlow model http:\/\/www.wildml.com\/2015\/12\/implementing-a-cnn-for-text-classification-in-tensorflow\/ into DeepWater. You can read that post to see what kind of architecture was used.\\n\\nI should be done soonish (most probably sometime this week) and you can track the progress in this PR https:\/\/github.com\/h2oai\/sparkling-water\/pull\/165 (the example is for Sparkling Water but with a few changes - leaving the data loading and preprocessing in TensorFlow - it should work in vanilla H2O)\\n\\nMost commonly for sentiment analysis LSTMs and CNNs are used which we don\\u2019t support in vanilla H2O so your best bet is to have a look at DeepWater","1849":"@mdymczyk That's amazing! I'll read it then. Thank you very much. ","1850":"breaking change to PersistManager with no doc update: 237afaf09843369a5b9c24e47228b978c4e73b37 @navdeep-G please update the usage docs there? or keep backwards compatibility?","1851":"code-reviewing a bit... \\pattern\\ is passed to each impl of importFiles, but no impl makes use of it :(","1852":"I am reading  http:\/\/h2o-release.s3.amazonaws.com\/h2o\/rel-tutte\/1\/docs-website\/h2o-docs\/hadoop.html#walkthrough it looks H2O on Hadoop only supports CDH,HDP and MapR, does it support Apache Hadoop?","1853":"@WangAllen We will also have word2vec soon, its in testing now","1854":"@spennihana thanks for the report\\u2026 ill pass on to @navdeep-G ","1855":"@spennihana https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-3886","1856":"I've asked this before, how do I do knowledge representation with H20? Please anyone.. Thanks","1857":"@Ij888 H2O does supervised and unsupervised machine learning and is not a general \\u201cknowledge representation\\u201d engine","1858":"Forgive my noob naivety @ledell, need not the data that you need to do supervised\/unsupervised learning on represented in some way? ","1859":"Can Deep Water only run GPU?","1860":"@bithw1 it runs on both CPU and GPU","1861":"the H2O Deep Learning algo (multilayer perceptron is CPU only), but Deep Water (including TensorFlow, Caffe, MxNet) can do both","1862":"Hi all, is there \\h2o developer cookbook\\ or something like that where I can find some examples of using MRTask?  I need to do some columns\/rows\/filtering\/sum\/group_by (without spark) in scala - and looking for any examples (java will be ok)???","1863":"Hi all!\\n\\nNewbie question here... I'm calculating the reconstruction error for each one of the rows of my autoencoder model (model.anomaly(h2oframe) using the Python API).\\n\\nI'm noticing that, during the training phase (model.train(...) using the Python API), I was able to see a job running on the flow console, but this is not the case when the error is being calculated (no error calculation job on the console, though machine CPUs are busy and the result frame appears on it after the process is finished)\\n\\nIs this the expected result? Is there any way to monitor the process?\\n\\nBest Regards, and thank you for your support!","1864":"hi @here!","1865":"do you guys offer enterprise support ?","1866":"@burkaygur yes, please send an email to sales@h2o.ai","1867":"@here getting an error on databricks, when i try to initialize h2context","1868":"java.lang.NoSuchMethodError: org.eclipse.jetty.server.AbstractConnector: method <init>()V not found","1869":"library is sparkling-water-core_2.11-2.0.4","1870":"spark instance is Spark 2.0.2-db3 (Scala 2.11)\\n","1871":"it looks like most of the documentation is out of date","1872":"i managed to get the context","1873":"however whenever i try to convert a dataframe into h2oframe i get this error:","1874":"java.lang.ArrayIndexOutOfBoundsException: 65535\\n","1875":"at water.DKV.get(DKV.java:202)\\n\\tat water.DKV.get(DKV.java:175)\\n\\tat water.parser.ParseSetup.createHexName(ParseSetup.java:591)\\n\\tat water.fvec.H2OFrame.<init>(H2OFrame.scala:67)\\n\\tat water.fvec.H2OFrame.<init>(H2OFrame.scala:76)","1876":"this is the initialization that worked:","1877":"import org.apache.spark.h2o._\\nval conf = new H2OConf(sc).setInternalClusterMode()\\nval h2oContext = H2OContext.getOrCreate(sc, conf)\\n","1878":"@ledell Hi. early_stopping on validation_frame might not be working. There's a test case. want to see?","1879":"@ledell Hi. You might be interested. I took time to research a decent unit test for sharing with H2O staff. https:\/\/community.h2o.ai\/questions\/1786\/early-stopping-on-validation-frame-might-not-be-wo.html","1880":"Hi @geoffreya I saw your community post, someone will take a look at it in the next few days.  I appreciate you taking the time to write that up\\u2026 it will help with debugging. :thumbsup: ","1881":"Hi @burkaygur can you repost to the sparkling-water channel? https:\/\/gitter.im\/h2oai\/sparkling-water","1882":"hi  guys,i come from china! i come here for the first day!","1883":"Hi @xiuxiuxiaodi !","1884":"welcome","1885":"anybody here? i have a question about  h2o.ai ","1886":"when i read a file from hdfs which is remote,i can read that  by spark  ,but  when i read it  from h2o.init ,then use'h2o.import_file(\\hdfs:\\u2026\\u2026\\)  i find a mikstake like this\\  Error: HDFS IO Failure: \\n accessed URI : hdfs:\/\/pingjia1114.com.cn:8020\/init_data\/test\/server.2017-02-09.1486636273208.txt\\n configuration: Configuration: core-default.xml, core-site.xml, mapred-default.xml, mapred-site.xml, yarn-default.xml, yarn-site.xml, hdfs-default.xml, hdfs-site.xml\\n java.io.IOException: Failed on local exception: com.google.protobuf.InvalidProtocolBufferException: Message missing required fields: callId, status; Host Details : local host is: \\pingjia112.com.cn\/10.27.11.2\\; destination host is: \\pingjia1114.com.cn\\:8020;\\","1887":"but  when i use the  sparkling-water ,it  will initiate a h2o cluster automately  when i use 'H2OContext.getOrCreate(sc)', i can use this h2o.import_file  to read the hdfs file,but  the default memory is not enough and i don't  know how to modify the  memory by the clause'H2OContext.getOrCreate(sc)'","1888":"anybody can help me?","1889":"@xiuxiuxiaodi This sounds like a Sparkling Water question.  Please repost in the sparkling-water channel","1890":"@ledell  thank you ,can you give a suggestion how may be  i can get a resolution! ","1891":"i  just  want to read hdfs file  from  hadoop  that  is not  local","1892":"another question,if  I have a 25GB data ,but I just have  10GB memory ,i import_file the 25GB file to h2o.cluster, it  raise a error named 'too much data or big cluster',but  i can load it by spark.Does the h2o can't  load  a big dataset  than the cluster? Am i right?","1893":"Thank you very much!","1894":"@xiuxiuxiaodi Is your data very very sparse?","1895":"@ledell   no , it's dense,actually,the data is just for test  that  how the h2o.cluster process the bigger dataset   than its memory.Because in reality,we have to process such  dataset ,  size more than 100g, even more!","1896":"i want to  how   to load a bigger  dataset  ,and by the way,why you ask me weather my data is sparse?   ","1897":"my data is on the hadoop  cluster","1898":"@xiuxiuxiaodi H2O does not support offloading of data to disk, so we cannot process more data than memory\\n\\nSpark is totally different - by design SPark does not need to load all data into memory if they do not fit into the memory. It is using ~2~ 3 tricks:\\n - voluntary caching (user has to explicitly specify which computed results are going to be cached)\\n - offloading computed\/cached data to some offline memory (disk, out-of-process memory, out-of-jvm memory)\\n - recomputing missing piece of data (this is given for free by the fact that Spark just recording lineage of operations to invoke)","1899":"@ledell   thank you so much for your detailed answer!","1900":"Hi all! any reason why there is no confusion matrix for k-means? `No Confusion Matrices for H2OClusteringMetrics` or am I doing something wrong? There is nothing wrong in producing confusion matrix for k-means as long as cluster labels\/id are unified, correct?","1901":"@jangorecki Hi Jan, it\\u2019s becuase k-means is unsupervised so there\\u2019s not neccessarily labels (and hence cant produce a confusion matrix","1902":"@ledell thanks Erin. So in basic examples when I can map predicted clusters id to actuals cluster id then confusion matrix works fine.","1903":"Hiya folks. Understand that @arnocandel show d some GPU accelerated boosted trees stuff today? XGBoost wrapper? H2o native? Is there a branch in Git that we can play with?","1904":"Hi, everyone. I'm a newbie of h2o and I want to do some NLP with h2o. How can I get started? Any suggestion will be appreciated!","1905":"@cauldnz There is a PR where the work is being tracked: https:\/\/github.com\/h2oai\/h2o-3\/pull\/699 and the branch: https:\/\/github.com\/h2oai\/h2o-3\/tree\/arno-xgboost","1906":"@cauldnz We have some jars floating around internally with the xgboost extensions,\\u2026 ill have to check with @arnocandel if we can release any of those publicly yet","1907":"@WangAllen NLP is pretty broad\\u2026 what are you looking to do? ","1908":"Thanks @ledell. Off skiing for a week now but would love to have a play once I am back. ","1909":"I am stuck when I try to load a sparse matrix to h2o cluster with R function as.h2o(). The ERROR Message suggests that \\File \/tmp\/Rtmp0iL0BK\/file506a10090a1.svm does not exist\\.  I have tried to restart the h2o cluster as well as the R session, but with no lucky. Anyone can help me?","1910":"@ledell I want to do some sentiment analysis, specially try to figure out the rating stars correlated to a review text(e.g., a Yelp review text). I want to use h2o's word2vec, but it seems hard to use and has few documentations. And I just start my practice for a while, and need more suggestions.","1911":"Hi. I am trying to add my own algorithm to H2O, I created my class in h2o-algos, but I don't know how to make it visible in the web GUI (in the Models menu). Could you please help? Thanks.","1912":"@rudnyt_twitter  - i'm not the best person to help with this here, but check xgboost branch mentioned above: https:\/\/github.com\/h2oai\/h2o-3\/compare\/arno-xgboost\\n\\nMostly need to register algo in `RegisterAlgos.java`, add a schema in `h2o-algos\/src\/main\/java\/hex\/schemas\/`, etc.","1913":"Thank you! That's what I needed.","1914":"@WangAllen Can you provide a reproducible example? Let me ask our word2vec author.  We will have full word2vec docs in an upcoming release.","1915":"@WangAllen https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-3977","1916":"@rudnyt_twitter @petro-rudenko We need to add some stuff ot our docs about how to do this.  Thanks for bringing it up\\u2026 I\\u2019ve created a ticket for this https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-4145","1917":"@WangAllen I would love to hear your feedback on our word2vec. I am sure we can make things easier. Could you share what you find particularly difficult? The documentation is almost done, you can preview it here: https:\/\/github.com\/h2oai\/h2o-3\/blob\/9413c18900cf0497646197674710ea2e73629179\/h2o-docs\/src\/product\/data-science\/word2vec.rst","1918":"The documentation also link to a demonstration of w2v in R, I think this could be a good starting point.","1919":"@ledell Hi Erin! My colleague tried to run a classification job yesterday on H2O and he said it crashed because the dataset had too many classes (over 4000). Does that sound reasonable \/ expected?","1920":"I ran into a problem today when I was trying to convert a R data frame to H2OFrame, indicating that \\Error in asMethod(object):Cholmod error'problem too large' at file ..\/core\/cholmod_dense.c, line 105\\. But the sparse matrix seems not too large with size 518Mb, about 6 billion elements. Is it really too large to precess?","1921":"@WangAllen there is a bug in conversion of sparse matrices into H2O, we are working on a fix - I can send you a fixed version of the method after we have the fix available","1922":"@r3tex Do you which which algo he was using?  To my knowledge we don\\u2019t have a hard limit (or if we do, its much larger than 4k).  My guess is that he simply didn\\u2019t have enough memory on his cluster to run this","1923":"@r3tex I realized that we have a (somewhat arbitrary) limit of 1,000 classes on tree-based models.  If you set `ntrees = 250` (a relatively small number for RF\/GBM), that will actually create 4,000 x 250 = 1M trees!  So this hard limit is not technical, it\\u2019s to enourage (or force, rather) users to use a different model.  Either they should use a Mulitlayer perceptron (via `h2o.deeplearning` or `h2o.deepwater`) or they use a hierarchal structure where you first train a GBM (for example) on 100-1,000 classes (by grouping classes together) and then create submodels that further classify into the 4,000 individual classes. The reason for this limit is to encourage people to think more about what they are trying to do\\u2026 ","1924":"That said, your colleague could hunt down the place in the code where we hardcode to 1,000 classes, change it himself, run the model and see what happens.  ","1925":"Some days before I posted that when transferring a sparse matrix to h2o frame, it always went wrong. And I tested it again today. Here is the error log.","1926":"Hi, I wanted to know is there a way to get probabilities of a binary classification using h2o?","1927":"> library(Matrix)\\n> aaa <- sparseMatrix(i = 3, j=4, x =5)\\n> aaa\\n3 x 4 sparse Matrix of class \\dgCMatrix\\\\n            \\n[1,] . . . .\\n[2,] . . . .\\n[3,] . . . 5\\n> as.h2o(aaa, \\ccc\\)\\n\\n**ERROR: Unexpected HTTP Status code: 404 Not Found (url = http:\/\/localhost:54321\/3\/ImportFiles?path=%2Ftmp%2FRtmp72HJZC%2Ffile4e9f5b26c294.svm&pattern=)\\n**\\nwater.exceptions.H2ONotFoundArgumentException\\n [1] \\water.exceptions.H2ONotFoundArgumentException: File \/tmp\/Rtmp72HJZC\/file4e9f5b26c294.svm does not exist\\            \\n [2] \\    water.persist.PersistNFS.importFiles(PersistNFS.java:135)\\                                                      \\n [3] \\    water.persist.PersistManager.importFiles(PersistManager.java:271)\\                                              \\n [4] \\    water.api.ImportFilesHandler.importFiles(ImportFilesHandler.java:24)\\                                           \\n [5] \\    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\\                         ","1928":"[37] \\    org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543)\\                                \\n[38] \\    java.lang.Thread.run(Thread.java:745)\\                                                                          \\n\\nError in .h2o.doSafeREST(h2oRestApiVersion = h2oRestApiVersion, urlSuffix = page,  : \\n  \\n\\n**ERROR MESSAGE:**\\n\\n**File \/tmp\/Rtmp72HJZC\/file4e9f5b26c294.svm does not exist**","1929":"> h2o.init()\\n Connection successful!\\n\\nR is connected to the H2O cluster: \\n    H2O cluster uptime:         3 minutes 38 seconds \\n    H2O cluster version:        3.10.4.1 \\n    H2O cluster version age:    18 days  \\n    H2O cluster name:           root \\n    H2O cluster total nodes:    1 \\n    H2O cluster total memory:   3.56 GB \\n    H2O cluster total cores:    4 \\n    H2O cluster allowed cores:  4 \\n    H2O cluster healthy:        TRUE \\n    H2O Connection ip:          localhost \\n    H2O Connection port:        54321 \\n    H2O Connection proxy:       NA \\n    H2O Internal Security:      FALSE \\n    R Version:                  R version 3.3.2 (2016-10-31) ","1930":"Hi, I wanted to know is there a way to print probabilities of a binary classification?","1931":"@deepak_s_rawat_twitter  yesjust use `model.score(frame)` method :\\n```\\n\/**\\n   * Bulk score the frame, and auto-name the resulting predictions frame.\\n   * @see #score(Frame, String)\\n   * @param fr frame which should be scored\\n   * @return A new frame containing a predicted values. For classification it\\n   *         contains a column with prediction and distribution for all\\n   *         response classes. For regression it contains only one column with\\n   *         predicted values.\\n   * @throws IllegalArgumentException\\n   *\/\\n  public Frame score(Frame fr) throws IllegalArgumentException \\n```\\nFor binary classification you'll have `p0` and `p1` columns. ","1932":"thank you @petro-rudenko ! ","1933":"is there a way to get a gains\/lift table with more bins...default seems to be 10","1934":"Hello!\\nI am trying to run [JUnit Tests on PCA functionality](https:\/\/github.com\/h2oai\/h2o-3\/blob\/50d79ab5869cdeb5a83b6ee5cc353aefafe2c65a\/h2o-algos\/src\/test\/java\/hex\/pca\/PCATest.java), but it fails because of missing CSV datasets:\\n```\\njava.lang.AssertionError: File not found: smalldata\/prostate\/prostate_cat.csv\\n\\tat org.junit.Assert.fail(Assert.java:88)\\n\\tat water.TestUtil.makeNfsFileVec(TestUtil.java:272)\\n\\tat water.TestUtil.parse_test_file(TestUtil.java:278)\\n\\tat hex.pca.PCATest.testCatOnlyPUBDEV3988(PCATest.java:233)\\n```\\nThere some other datasets missing in other tests - decathlon.csv, USArrests.csv etc. Do you know where to get these datasets?","1935":"@mathemage did you sync the smalldata first? .\/gradlew syncSmalldata","1936":"@michalkurka No, I'll try that immediately.","1937":"@michalkurka The connection to Amazon AWS is rather bad. The `.\/gradlew syncSmalldata` fails with\\n```java\\nFailed to download file https:\/\/h2o-public-test-data.s3.amazonaws.com\/smalldata\/arcene\/arcene_test.data\\n```\\nand when I download manually with `wget`, the download speed drops down to ~5 KB\/s. Is there a mirror or some other source of smalldata?\\n","1938":"@mathemage where are you located? I\\u2019m curious because we have heard of bad S3 connections in certain places.  We don\\u2019t have a mirror, but I can look into creating one","1939":"@retroam are you using Flow (web GUI) or R\/Py interface?","1940":"@WangAllen Can you create a JIRA for your sparse matrix bug and assign to @michalkurka ?","1941":"@WangAllen Please include the dataset as well","1942":"R\/Py interface","1943":"@ledell I'm in the Czech Republic, middle Europe. @mmalohlava had the same suspicion about the cause due to S3 location. In the end, I used a [script](https:\/\/gist.github.com\/mmalohlava\/717ad7b7441a6ff91b5f0a907482bd5d)  with wget, which perservers until the download finishes, unlike `.\/gradlew syncSmalldata` which gives up much more easily.","1944":"@ledell I guess a mirror in Europe would be helpful, since H2O.ai plans to open up a QA office in Prague...","1945":"@mmalohlava How are JMH benchmarks done in h2o? I checked the [jmh-gradle-plugin](https:\/\/github.com\/melix\/jmh-gradle-plugin) tutorial, but still struggling. Do these Groovy commands from tutorial go to `h2o-3\/build.gradle` or is it a different Gradle file?","1946":"@mmalohlava OIC, one needs to specify a specific subproject as in `.\/gradlew :h2o-core:jmh` Ok, my bad, it's okay now :smile: ","1947":"hi h2o :smile:, is there any place in the Java API to force a node-local parse of a dataset? I am on the verge of writing (rewriting) some internal parser bits if not. I want each node to suck in a local large csv file; I'd prefer to  not parse globally and pass around chunks. thanks!","1948":"where i can get autoencoder source code?","1949":"HI @spennihana , there are just pieces of functionality, but to my knowledge no way for forcing local parsing. I will pass your message to parse masters :)","1950":"Hey guys, I'm new to H20 and excited to see what it can do. Can someone point me to an EMR deployment script for setting up H20 on an EMR cluster?","1951":"https:\/\/github.com\/navdeep-G\/sparkling-water-emr","1952":"@AnkurRaj https:\/\/github.com\/h2oai\/h2o-3\/search?utf8=%E2%9C%93&q=autoencoder&type=","1953":"I'm trying to install DeepWater on Redhat 7.0... Any idea on this error:  ","1954":"[![blob](https:\/\/files.gitter.im\/h2oai\/h2o-3\/tNew\/thumb\/blob.png)](https:\/\/files.gitter.im\/h2oai\/h2o-3\/tNew\/blob)","1955":"@ledell Hi Erin","1956":"Hi, I've been playing around a bit directly with the java API and have a few questions - I can't figure out how to set a model key\/id programatically, there doesn't seem to be a field on the ModelParams object ","1957":"secondly, is there an easy way to go from trained model in java to using the pojo for that model (with an EasyPredictionWrapper)? At the moment, I am training the model, then getting the String for the pojo and compiling and loading it inprocess for further testing","1958":"thirdly, I am working on a problem which can be represented in a number of ways (regression, classification etc), prediction accuracy\/RMSE is not necessarilly the best measure for my problem, there are some problem representations where a \\too high prediction\\ is far worse than a \\too low prediction\\ and vice versa. Part of the way I deal with this is too load the generated model POJOs and evaluate them individually using a custom measure. However, this can mean that when I add a new feature to my data set it is chosen by an algrithm as it increases the theoretical model performance, but when I use my custom scoring method on the generated POJO the inclusion of the new feature can actually display far worse performance. How can I better use the models to encapsulate this knowledge directly, even if it means writing a custom scorer in java?","1959":"@geponce Hmm, it looks like you are trying to install an xgboost enabled version of h2o, not Deep Water.  Are you building from source?","1960":"@ledell I just followed the installations instructions, you can see it in the screenshot, I'm just doing:   `R CMD INSTALL h2o_3.10.3.99999.tar.gz` ","1961":"@bettoper 1) you pass the mode key by passing destination key to model builder constructor, .e.g. GLM glmjob = new GLM(params,Key.make\\my_glm_model\\)  ","1962":"2) I think the way you do it is the right way, there is a convenience method JCodeGen.compile which should compile the pojo string and load the class for you, see Model.testJavaScoring ","1963":"3) I am not sure if I understand what you mean. In GLM and GBM you can use different family(GLM) of distribution(GBM) which should adapt your loss function. Or in general you can use observation weights to change how model is built. ","1964":"@betopper sorry I noticed I had a typo in your id ","1965":"@bettopper regarding your questions (following @tomasnykodym answers): \\n\\n1. model key needs to be passed via model builder. See this one for example:\\n```java\\npublic GBM( GBMModel.GBMParameters parms, Key<GBMModel> key) { super(parms, key); init(false); }\\n``` \\nExample:\\n```java\\nGBMParameters gbmParams = new GBMParameters();\\ngbmParams._train = myInputData._key;\\nGBMModel gbmModel = new GBM(gbmParams, Key.make(\\myGbmModel\\)).trainModel().get()\\n```\\n2. I would point you to our test code: `https:\/\/github.com\/h2oai\/h2o-3\/blob\/master\/h2o-algos\/src\/test\/java\/hex\/tree\/gbm\/GBMTest.java#L1698` and `https:\/\/github.com\/h2oai\/h2o-3\/blob\/master\/h2o-core\/src\/main\/java\/hex\/Model.java#L1580-L1760`\\nHowever, I would strongly recommend to use MOJO approach for models export. We figured out that POJO scales and performs really well for small-size models, but for huge models (e.g., 10k GBM trees) it is really painful to compile generated POJO code (there are limits of `javac`and you need to fine tune it as well) and also the performance is suffering.","1966":"@geponce Thanks for the confirmation, ill pass this on to the Deep Water team to let them know.  ","1967":"It looks like a simple fix though\\u2026 I think they forgot to add a single line to the Collate field in the R package","1968":"@geponce They will push a fix (apperently the fix didn\\u2019t get pushed to master for some reason).  It should be fixed on master soon","1969":"thanks for the report!","1970":"@ledell Thank you Erin, Do you know if I can do a training with deep water if I don't have GPUs setup on my server or is mandatory for deep water to have GPU enabled?  ","1971":"Hi, I've been trying to create a GLRM model to predict the movie ratings. I am referring \\rdemo.glrm.movielens.medium.R\\ sample R script and h2o-flow. I have few questions around it :- \\n(1) I am able to create a GLRM model (using the 70% data) and now I want to use predict movie rating to new user(s) in real time mode, so I am trying to explore the MOJO or POJO for it. I have downloaded the MOJO (from h2o-flow) and looking for any exmaple to use MOJO for GLRM.  \\n(2) I tried to download POJO from flow and R but it's only generating the partial (or truncated) java file. The last line of POJO is  :-  \\n' public final double[] score0( double[] data, double[] preds ) {'","1972":"@geponce No, you can use CPUs if you want.","1973":"@geponce Deep Water folks pointed out that the R package you were trying to install was 3.10 rather than a dev build 3.11, so they thought maybe you were in the wrong place in your filesystem?","1974":"@geponce Can you tell me the filepath location of the R tar.gz package that you\\u2019re using?","1975":"> Hi, I've been trying to create a GLRM model to predict the movie ratings. I am referring \\rdemo.glrm.movielens.medium.R\\ sample R script and h2o-flow. I have few questions around it :- \\n(1) I am able to create a GLRM model (using the 70% data) and now I want to use predict movie rating to new user(s) in real time mode, so I am trying to explore the MOJO or POJO for it. I have downloaded the MOJO (from h2o-flow) and looking for any exmaple to use MOJO for GLRM.  \\n(2) I tried to download POJO from flow and R but it's only generating the partial (or truncated) java file. The last line of POJO is  :-  \\n' public final double[] score0( double[] data, double[] preds ) {'\\nNB: - I forgot to mention that I am using h2o 3.10.4.3.","1976":"@ledell I'm using the link from this github https:\/\/github.com\/h2oai\/deepwater","1977":"@ledell in that section: ","1978":"[![blob](https:\/\/files.gitter.im\/h2oai\/h2o-3\/nEIC\/thumb\/blob.png)](https:\/\/files.gitter.im\/h2oai\/h2o-3\/nEIC\/blob)","1979":"@ledell link: https:\/\/slack-files.com\/T0329MHH6-F3X5Z9NN5-9ff02f4773","1980":"Hi, I am getting error while running demo R script for GLRM - \\rdemo.glrm.movielens.medium.R\\. It was working fine with previous version of h2o but it's not working after upgrading h2o to version 3.10.4.3. The following error is coming at code line - ```pred <- predict(ratings.glrm, ratings.hex)``` \\n`Error in as.data.frame.default(x[[i]], optional = TRUE) : \\n  cannot coerce class \\structure(\\H2ODimReductionModel\\ package = \\h2o\\)\\ to a data.frame \\n12 stop(gettextf(\\cannot coerce class \\\\\\%s\\\\\\ to a data.frame\\ deparse(class(x))), \\n    domain = NA) \\n11 as.data.frame.default(x[[i]], optional = TRUE) \\n10 as.data.frame(x[[i]], optional = TRUE) \\n9 data.frame(C1 = x) \\n8 as.h2o.default(job.title) \\n7 as.h2o(job.title) \\n6 .set(node, \\eval\\ li) \\n5 .newExprList(op, list(...)) \\n4 .newExpr(\\tokenize\\ x, .quote(split)) \\n3 h2o.tokenize(sentences, \\\\\\\\\\\\\\\\\\W+\\) \\n2 tokenize(as.character(as.h2o(job.title))) \\n1 predict(ratings.glrm, ratings.hex) `\\n\\nLet me know if I am missing anything.\\nThanks\\nGaurav","1981":"@tomasnykodym Many thanks for that, I totally missed that param! In regards to 3) I am not sure how I can use observations to change how the model is built, if you can point me in the right direction I'd really appreciate it, am keen to learn more and improve my knowledge","1982":"@mmalohlava Thanks for your answers, I'd already noticed that for large models (not just number of trees but for example using enum instead of numeric) and had to do some tuning! I'll take a look at the MOJO approach","1983":"Hi all. I was wondering whats the process of contributing fixes to h2o-3? In particular, I found some minor issues with the REST Api generation in Java (and I'm sure I'll find more in the next couple of weeks). Do you want me to first open an issue in jira or directly open a PR?","1984":"@dietzc thank you for trying H2O! The best way is to create pull request which we\/community can review and merge into master.","1985":"ok perfect. will do. I made only small changes. Do you prefer individual PRs or is one PR \\Fixes in gen_java.py\\ or whatever good enough? Happy to do either.","1986":"@betopper Observation weights allow you to provide per-row multiplicative constant to the loss function. \\nSo you  can use it prioritize or de-prioritize observations based on your metric. I am not sure if that would work in your case to be honest, it's just a suggestion.  ","1987":"@bettopper oops, sorry same typo in your id again","1988":"@tomasnykodym Thanks","1989":"I am unable to build deep water on Ubuntu 17.04 with compilation errors. Are there any workarounds to build it on ubuntu 17.04 with gcc 5.4.1?","1990":"ok I figured this out. CUDA needs gcc compiler less than 5.3 and I had 5.4","1991":"@ganeshkrishnan1 is the CUDA version documented anywhere in Deep Water?  if not, feel free to file a pull request to edit the docs\/installation instructions","1992":"@ggauravuee The GLRM movie demo is working for me on master\\u2026 can you upgrade to 3.10.4.6 https:\/\/h2o-release.s3.amazonaws.com\/h2o\/rel-ueno\/6\/index.html ","1993":"and try again?","1994":"@ledell  The Cuda version is documented but Cuda in turn needs GCC 5.3. And anyway Tensorflow did not work with Deep Water. I got runtime error \\No native backend\\ but mxnet worked well","1995":"@ganeshkrishnan1 We build for Ubuntu 16.04. Can't guarantee anything for 17.04. We plan to make a docker image for 17.04 soon though","1996":"@ganeshkrishnan1 could you file issues in the deepwater github repo issue tracker? we\\u2019ve been building with gcc 5.4 all the time and saw no problems","1997":"I will do that and post the stack trace as well. ","1998":"hello","1999":"DataScience Digest, Issue #7 - http:\/\/bit.ly\/2p9NaRc  Please share;)","2000":"the first gitter spammer","2001":"@FlyElephant-M31 Please don\\u2019t use this channel to post links that are unrelated to H2O ","2002":"hello @rendi7936 ","2003":"Hello, I am new to h20ai. Just trying to setup on my windows PC following the README.md instructions. \\n.\/gradlew.bat build leads to below errors... Any help?","2004":"Running h2o-algos junit tests...\\nError: Could not find or load main class water.junit.H2OTestRunner\\nError: Could not find or load main class water.H2O\\nError: Could not find or load main class water.H2O\\nError: Could not find or load main class water.H2O\\nError: Could not find or load main class water.junit.H2OTestRunner\\nError: Could not find or load main class water.H2O\\nError: Could not find or load main class water.H2O\\nError: Could not find or load main class water.H2O\\nError: Could not find or load main class water.junit.H2OTestRunner\\nError: Could not find or load main class water.H2O\\nError: Could not find or load main class water.H2O\\nError: Could not find or load main class water.H2O\\nError: Could not find or load main class water.junit.H2OTestRunner\\nError: Could not find or load main class water.H2O\\nError: Could not find or load main class water.H2O\\nError: Could not find or load main class water.H2O\\nError: Could not find or load main class water.junit.H2OTestRunner\\nError: Could not find or load main class water.H2O\\nError: Could not find or load main class water.H2O\\nError: Could not find or load main class water.H2O\\nh2o-algos junit tests FAILED\\n:h2o-algos:testMultiNode FAILED\\n:h2o-algos:testMultiNode took 12.642 secs\\n\\nFAILURE: Build failed with an exception.\\n\\n* What went wrong:\\nExecution failed for task ':h2o-algos:testMultiNode'.\\n> Process 'command 'bash'' finished with non-zero exit value 1\\n","2005":"Any instructions to deploy h2o on cloudfoundry ?","2006":"I would like to access the API from Spring boot in cloudfoundry. That is the usecase.","2007":"https:\/\/github.com\/trustedanalytics\/h2o-broker Is this current ?","2008":"Another question. Reinforcement Learning learns from raw pixels. I am looking for a way to pipe pixels to the NN. Any examples ? I found http:\/\/h2o2016.wpengine.com\/wp-content\/themes\/h2o2016\/images\/resources\/DeepLearningBooklet.pdf","2009":"Hiya Folks. Is the GPU stuff in the nightly branch? I am doing a session at a community event next week on GPU accelrated machine learing and would be grat to cover H2O as part of my session too.","2010":"@pandravada did you use the instructions here?  https:\/\/github.com\/h2oai\/h2o-3#43-setup-on-windows","2011":"it\\u2019s failling on the distributed tests","2012":"you can also try `.\/gradlew.bat build -x test` and see if that works (it will skip the tests).  i haven\\u2019t tried it on windows, but hopefully it works","2013":"Hi @ledell  quick one: I'm preparing big wokrshops in China about machine learning, and I want to present H2O as best solution for company.  Working on slides, also working to prepare  3 days \\hands on\\u201d  workshops with h2o  - would like to talk to someone to \\u201creview\\u201d whatever I\\u2019ll  produce, also maybe give me some tips - what should I \\u201cshow\/tell\\u201d? Can you give me some contacts ?","2014":"Hi @yarenty sure i can take a look at it.  erin@h2o.ai is my email address","2015":"@cauldnz The GPU demos from GTC are located here: https:\/\/github.com\/h2oai\/perf\/tree\/master\/gtc","2016":"Hi, I just learned about H2O, and I have a very general question \\u2015 From the readme I understand that it has a relationship with Spark. \\nI gather Sparkling Water can be used to use H2O on top of Spark. But other than that does it fulfil the distributed nature of this promise through its own software stack?\\n> H2O is an in-memory platform for distributed, scalable machine learning.\\n\\nThank you in advance for the high level clarification!","2017":"@matanster Yes, H2O can optionally be used with Spark via the Sparkling Water Spark package.  Full, distributed data frames and algos, exactly the same as if you ran H2O w\/o Spark.  There is a Sparkling Water channel where you can ask more questions: https:\/\/gitter.im\/h2oai\/sparkling-water","2018":"Any plans to make the R package easier to contribute to, e.g. using testthat and not having to use gradle? Related: https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-3689","2019":"How can I configure very basic level of authetication (user id \/pwd) on flow.","2020":"hi all.  I faced the same problem https:\/\/community.h2o.ai\/questions\/2117\/using-frames-endpoint-with-java-rest-bindings.html. Any ideas?","2021":"@ArunLakhotia pls follow documentation here: https:\/\/github.com\/h2oai\/h2o-3\/blob\/master\/h2o-docs\/src\/product\/security.rst#embedded-web-port-by-default-port-54321-security","2022":"Hello H2O community!\\n\\nThere are many new changes in the H2O ecosystem, and we are working furiously to publish and share these with the community.\\nIn this context, we are preparing a new H2O release 3.12 with amazing features (e.g., AutoML, XGBoost support). We are also planning some changes that can affect existing code bases. This message is meant to inform you and start discussions about them.\\n\\nThe changes include:\\n  - Migrating from Java 6 to Java 7\\n  - Modularization of the code base with the help of Java Service Provider Interface (SPI) instead of using reflections library\\n  - Improvement of Stacked Ensemble API\\n  - New feature: Automatic Machine Learning (AutoML)\\n\\nFor more details, please, see description of changes in [PUBDEV-4450](https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-4450)\\n","2023":"@mmalohlava What about reinforcement learning from raw pixels ?","2024":"So, has anyone noticed the confusion matrix description on R and Python is backwards?  I am trying to find validation to make sure I am not crazy.  IT says that vertical is actual and across is predicted but it looks like vertical is predicted and across is actual.  Thoughts everyone?","2025":"@mohanr No, that is not coming any time soon.","2026":"Hi @kevinykuo thanks for the reminder\\u2026 that ticket never got completed, but I agree it would be nice.  I will re-assign it to myself and take a look.  We do use testthat for testing, and we use gradle for building H2O including the R package","2027":"@kevinykuo but the only thing we really need gradle for (with the R package) it to auto-generate the version information for the DESCRIPTION file","2028":"@kevinykuo if you are looking to contribute to the R package, here is the list of open \/ in-progress R issues: https:\/\/0xdata.atlassian.net\/issues\/?filter=17703  I am happy to help walk you through any of them if you have questions.  Just let us know if you\\u2019re interested in working on any of them.","2029":"@atroiano This is the standard for confusion matrices: https:\/\/en.wikipedia.org\/wiki\/Confusion_matrix  and that\\u2019s my understanding of what we have in the confusion matrix\\n","2030":"@atroiano I am happy to take a look if you can write up an example in a gist.  If it\\u2019s flipped, I think someone would have noticed by now, but you never know!  So if you have an example showing otherwise, please let me know","2031":"@ledell  https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-4250?page=com.atlassian.plugins.atlassian-connect-plugin%3Azendesk_for_jira__issue-tab-panel","2032":"@ledell  Thanks!","2033":"hello, can I give package name as parameter while downloading pojo: h2o.download_pojo(my_model, my_path, get_jar=False)?\\n","2034":"@yalcinyenigun_twitter i dont understand your question","2035":"@atroiano thank you very much for writing up the issue as a JIRA!  we will take a look","2036":"@ledell when I trained a model and downloaded POJO with h2o there isn't any package name of POJO. Just a class name. I mavenize it and add to another project as dependency. I tried to load model with reflection but it needs package name to import. When I edit pojo and add a package name manually it works. If I can give package name as parameter while exporting pojo or training, I don't need this manual step. ","2037":"@yalcinyenigun_twitter ok i see what you are asking and it sounds like a feature request.  You can write that up as a JIRA and we will consider it a feature request: https:\/\/0xdata.atlassian.net\/projects\/PUBDEV I don\\u2019t know that we will add this soon, but the first step is to file a feature request","2038":"@atroiano yes you are totally correct, that header is not right.  Arno, who created it has a different interpretation of what its saying, but I agree that it\\u2019s suggests the opposite than what we want it to.  Ive fixed it https:\/\/github.com\/h2oai\/h2o-3\/pull\/1171","2039":"@atroiano thank you very much for your report!","2040":"@ledell thanks for your support. I opened an issue for that: https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-4486","2041":"@ledell  Cheers","2042":"@yalcinyenigun_twitter if you know how to write Java code, the other option is to submit a pull request on our code base.  if you want to go that route, let me know and we can try to help","2043":"@yalcinyenigun_twitter I had the same problem, but I am creating the pojo myself from a String in Java, so I pre-pend a stringbuilder with my desired package name","2044":"@ledell I was wondering if you knew if there was a video of the \\Trump and the art of machine learning\\ meetup (https:\/\/www.meetup.com\/Silicon-Valley-Big-Data-Science\/events\/234342356\/) from last year? I can't find it on the youtube channel, as I've started looking at using H2O for NLP related tasks","2045":"@ledell ok I would like to submit a pull request. ","2046":"@bettopper if it\\u2019s not on our youtube, then we probably didnt record it.  we have a community manager now (Ian) who is better at making sure meetups are recorded","2047":"@yalcinyenigun_twitter ok feel free to do that, we will take a look.  please until a unit test","2048":"Hello,there. I know it is simple to predict scores when the problem is multi-in and one-out, but now I have to solve a multi-in multi-out problem. How can I fix this with h2o? Is there a method can be used for this kind of problems? Thank you.","2049":"@WangAllen If you need to predict all the outputs at once, that is not supported by H2O (nor most ML libraries).  If you can predict each output independently, then you can do that in H2O.","2050":"OK. Thank you. I'll build several independent models then. @ledell ","2051":"@ledell I think currently h2o-r uses RUnit and not testthat, and it doesn't seem like its' using roxygen for documentation. It'd be nice if there were a brief guide on the development workflow for those of us who are used to \\cmd-shift-DBT\\ in RStudio...","2052":"anyone experienced problems with building models via REST Api using:  3.12.0.1?","2053":"basically, previously running code doesn't work anymore: `15465  #82278-49 ERRR: water.exceptions.H2ONotFoundArgumentException: POST \/3\/ModelBuilders\/drf not found `","2054":"seems the path should be `\/3\/ModelBuilders\/model_id\/drf` or so.","2055":"(I'm using the auto-generated java-api on client side)","2056":"maybe this helps. it seems that the problems have been introduce with `3.10.5.1`. Works fine with `3.10.4.9`","2057":"code snippet would be `H2oApi api = new H2oApi(... ); api.train_dlf(new ...);`. ","2058":"@dietzc Hi Christian, I just tested the java bindings and it worked fine for me (on 3.10.5.1). Can you please share more details? Is your h2o embedded in your java program or is it started independently? Does model building work from H2O Flow? What version of java are you running?","2059":"hi @michalkurka thanks for looking at this. Quick answer is: h2o is running in same VM as my application.Ccommunication via rest anyway (testing etc).  I don't use H2O flow  in my application. I'm running java 8. I'll (however, maybe this will take some days) write a unit test which fails in my fork and point you to the code. I hope this will makes easier for you.  Again thanks for the support, I'm surprised it works for you.","2060":"Hi.  I wonder if symbolic and numeric differentiation would be relevant\/useful to Machine Learning and\/or this project?  I have a system that computes derivative both symbolically and numerically, and would be glad to contribute to the project","2061":"is there a preferred way to filter rows of a frame based on a certain condition in `h2o-core`? ","2062":"Is Stacked ensemble still in experimental phase or good enough for production use?","2063":"Ok, maybe I don't understand something or doing something horrible wrong (sorry in advance). But given the following file","2064":"[test.csv](https:\/\/files.gitter.im\/h2oai\/h2o-3\/jihw\/test.csv)","2065":"and the following code `        Frame f = DKV.get(\\key_to_test.csv\\).get();\\n        ModelMetricsBinomial make =\\n            ModelMetricsBinomial.make(f.vecs()[1], f.vecs()[0], new String[]{\\Cluster_0\\ \\Cluster_1\\});\\n        make.cm().toString();`\\n\\n","2066":"It seems that the resulting confusion matrix is not correct?","2067":"running on 3.10.4.9","2068":"@dietzc GBM_Example_Test passes on my machine and it also passes in the test system. If it doesn't pass for you it might be a classpath issue, what does H2O say when it boots up?\\n\\nDo you see something like this:\\n\\nRegistered REST API extensions: [water.api.RegisterResourceRoots, Core V3, Core V4, Algos]\\n\\nin the standard output?","2069":"yep @michalkurka I guess I found one problem already. So the test is passing now (I had to rebuild in order to get a compatible version of `h2oApi`... )","2070":"still the other error. but again, I am afraid it's something on my system... ","2071":"I will try to find out more","2072":"thanks for your help","2073":"by chance, did you check the BiNominal scorer? This is really weird... ","2074":"@ArunLakhotia Now that you can save\/load binary ensemble models (as of 3.10.5.1), I\\u2019d say it\\u2019s ready for production.  It is under active development though, so there will be new features added periodically.","2075":"@ArunLakhotia If you have any issues with it, just let me know. erin@h2o.ai","2076":"@defoye What algorithms do you have in mind?  If you\\u2019re not sure how it can be used in ML, this is an interesting paper to read: https:\/\/arxiv.org\/abs\/1502.05767","2077":"hi everyone i want to do chat bot with h2o and tensorflow but I do not know how to do it and where do it  so i want help you.I give idea for me.Thank you everyone.\\n","2078":"@ozgemeva that\\u2019s a pretty broad question, but there\\u2019s a blog post about doing something similar  with H2O and Tensorflow & Keras here https:\/\/blog.altoros.com\/building-an-answerbot-with-tensorflow-and-keras.html","2079":"@ozgemeva seq2seq is something you can use in tensorflow for chatbots https:\/\/www.tensorflow.org\/versions\/master\/tutorials\/seq2seq#sequence-to-sequence_basics","2080":"I see Water Meter appears blank in H2o Flow for Windows and Mac. Any workaround for this? ","2081":"@nimesh-mittal the water meter is only supported on Linux, there is no workaround","2082":"thanks for the info. I will try to understand the code and see if I can contribute in some way. ","2083":"@nimesh-mittal awesome! good starting point is this class: https:\/\/github.com\/h2oai\/h2o-3\/blob\/master\/h2o-core\/src\/main\/java\/water\/util\/WaterMeterCpuTicks.java","2084":"thank you so much @michalkurka ","2085":"@ledell Thanks. As usual with products that have this duality of ontop v.s. instead of, a bit confusing whether to use it on top or instead of spark.","2086":"@ledell For example what would one gain by using it on top of spark, and at what \\costs\\ v.s. plain spark. Will move it to the other specialized gitter room","2087":"@ledell Thanks for having pointed me in the right directino","2088":"anyone any idea why https:\/\/gist.github.com\/dietzc\/bab31b1d0cd49d7d608a08b772ab9bad fails? I'm sure I'm doing something wrong here, but couldn't figure out what...","2089":"General question. How does Sparking water mix R and Java ? I am trying to understand the desing that allows this. I have used rJava in the past.","2090":"Has anyone used H2O on watson platform?","2091":"@r_mohan_twitter H2O is all in Java and so if you use it from R (with no spark) it makes REST calls to the Java server.  It does not use rJava.   If you want to use H2O + R + Spark, you use can use the rsparkling R package.  Its a lightweight connector that allows you to use Sparking Water (which itself is just a way to use the same Java H2O algos on Spark)","2092":"@ledell Ok Will try to look at the connector code.","2093":"Hi,\\nlet me how \\EasyPredictModelWrapper\\ handles unseen categorical values treated during scoring. In gemodel-3.10.4.3, it's failing it with exception - \\hex.genmodel.easy.exception.PredictUnknownCategoricalLevelException: Unknown categorical level (Type,p)\\. \\n\\nLet me know if there is way or configuration in \\gemodel\\  to replace unseen categories with \\most frequent level present in training (mod)\\ , simialr to what one has in h2o.predict() \\n\\n**In h2o.predict()**:-\\nHow are unseen categorical values treated during scoring?\\nUnseen categorical levels are treated based on the missing values handling during training. If your missing value handling was set to Mean Imputation, the unseen levels are replaced by the most frequent level present in training (mod). If your missing value treatment was Skip, the variable is ignored for the given observation.","2094":"Hi All: Why is the size of a GBM model (binary saved from R) much larger in latest versions (trained on same data). E.g.\\n3.10.1.2 - 6MB\\n3.10.2.2 - 17MB\\n3.10.5.3 - 47MB (GBM with 100 trees, 20 deep) ?","2095":"@ggauravuee sounds like you got your questioned answered https:\/\/groups.google.com\/forum\/#!topic\/h2ostream\/Xc3tT0No_S0","2096":"@szilard0 I think it\\u2019s a known issue that tree based model size blew up in 3.10.5.*, ill try to find a JIRA.  i think someone is looking into it already","2097":"@szilard0 Yep, @michalkurka is working on it already: https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-4694 ","2098":"@ledell thanks a lot","2099":"Hi, warm greetings to all members. I am a postgraduate student of Geoinformatics at Indian Institute of Technology Bombay, India and I have been exposed to machine learning concepts lately. I have had some experience in coding Regression model, and neural network using numpy. I wish to get involved here and make some contributions. Is there scope for machine learning beginners in h2o? If yes, how can I start?","2100":"Hi @daas-ankur-shukla do you have any experience in Python or R?  That\\u2019s the easiest way to start contributing to H2O.  ","2101":"Or rather, the easiest thing would be to contribute to our documentation.  And then up from there, you could make contributions  to the R or Python API.  ","2102":"List of open Python tickets: https:\/\/0xdata.atlassian.net\/issues\/?filter=17702 and R tickets: https:\/\/0xdata.atlassian.net\/issues\/?filter=17703  Take a browse around and see if there are any that look interesting to you.","2103":"If you had something else in mind (like coding actual algorithms), that\\u2019s much more of a steep learning curve and requires knowledge of distributed systems, H2O and Java.  So even if that\\u2019s your goal, the easiest way to get started is to work on some R\/Python tickets to get comfortable\/familiar with the codebase","2104":"Also check this out for more info: https:\/\/github.com\/h2oai\/h2o-3\/blob\/master\/CONTRIBUTING.md","2105":"@ledell thanks alot for the information. I have some experience in Python. I am working on two applications which involve Django as backend. I have also done some machine learning related code on Python for course project. Ill browse through the links. As a part of my 6 months experience at a leading consultancy firm in India I had the exposure to hadoop, java. But that was 2 years back. I can brush up the concepts gradually and try to make some contribution on algorithmic level in the future. Thanks again for your help. ","2106":"Hi, not sure if this is the correct room, but I have a question in relation to missing data and H2OFrames :)","2107":"To be more specific with my query, here is what I am trying to achieve in H2O: https:\/\/gist.github.com\/bwv988\/349bbf5e7a911052556dea67a93e7243","2108":"replace \\?\\ with \\n\\ in the data set....I really like the syntactic sugar in H2O but there seem to be some differences in semantics of boolean expressions...anyway advise if this is is not the best channel to ask :smile: ","2109":"Ok in case anyone is interested, the solution was to fix each column in a loop","2110":" df[df[, col] == \\?\\  col] = \\n\\ over all columns","2111":"probably not the most efficient way","2112":"https:\/\/gist.github.com\/bwv988\/670d351c07e17524b845d6091002de98","2113":"@bwv988 Hi Ralph, first I want to make sure you know that you don\\u2019t need to impute data in H2O.  H2O will do a column-mean imputaion automatically for any missing values in your `training_frame`","2114":"@bwv988 However, sometimes people want to impute the data in their own way.  So in that case, we recommend using the `h2o.impute()` function","2115":"@bwv988 Ok, I guess your use-case is slightly different since your missing values are not the standard NaN, but a \\u201c?\\u201d instead.  Let me look into whether there is currently a non-hacky way to do this","2116":"We should definitely support this in a non-hacky way, so if I can\\u2019t figure it out, ill make a JIRA for us to add support","2117":"we have this page in the docs about repalcing values, but it only covers numeric data: http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/data-munging\/replacing-values.html  it says that this doesn\\u2019t work on factors, but i see that you loaded your data in as strings, so i assume that means that strings are also not supported","2118":"@ledell  Hi Erin, thanks for your response, yeah I actually tried a couple of different things, I attempted to load columns as factors (enums) and replace this way, but ran into issues too. So the easiest was the solution I posted, although I fear it's the worst, performance-wise. I really like the direction H2O is taking with regards to sticking to common R idioms when manipulating data, the use case I presented just doesn't seem to be covered yet.","2119":"@ledell Referring to the above code, it appears to boil down to how conditionals are interpreted when sub-setting a data frame. In my example, compare the output of party.data == \\?\\ (pure R) to the output of voting.data.raw == \\?\\ (H2OFrame)  ","2120":"btw if anyone is interested, here is an Rpubs of the demo I did: http:\/\/rpubs.com\/bwv988\/h2odemo","2121":"@bwv988 ok, i have a solution for you!","2122":"```\\nlibrary(h2o)\\nh2o.init()\\n\\nvoting.url <- \\http:\/\/archive.ics.uci.edu\/ml\/machine-learning-databases\/voting-records\/house-votes-84.data\\\\nfeature.cols <- paste0(\\vote\\ 1:16)\\nvoting.data.raw <- h2o.importFile(path = voting.url, \\n                                  col.names = c(\\party\\ feature.cols), \\n                                  col.types = rep(\\string\\ 17))\\n\\nnewdf <- h2o.sub(\\\\\\\\\\\\\\\\\\?\\ \\n\\ x = voting.data.raw)\\n```","2123":"@ledell  Thanks very much, that's far more efficient!","2124":"@bwv988 :thumbsup: ","2125":"@ledell  Just noticed that has an interesting side effect, in that it removes the previously assigned column names...","2126":"@ledell Let me just double-check that it's not my code :D","2127":"@bwv988 weird!  i will file a bug report, just confirmed on my end","2128":"@ledell Yeah definitely wipes them, but it's easily fixed. colnames(voting.data) = colnames(voting.data.raw)","2129":"@ledell Good enough for me, thanks again!","2130":"@bwv988 https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-4739","2131":"@ledell :+1: ","2132":"hi guys, is in the roadmap text analytics, topics extraction?","2133":"I'm trying to build h2o-3 with tests and I get the error that 'git2r' cannot be installed because `ssl.h` cannot be found.","2134":"But I've already installed it with brew. The SO posts telling me to `xcode-select  --install` didnt work because I already have it installed.","2135":"What is the proper way to provide include links  to h2o for installaing R packages","2136":"Hi Everyone, I have newbie question related to usage of generated h2o pojo in Java. \\nWe have created an \\autoencoder\\ category model in flow UI. We are able to predict and test from over there. It gives us per-feature reconstructed output as well as \\Reconstruction.MSE\\.\\nNow we exported the model as POJO and deployed this in another java server where we can pass data and get outputs using EasyPredictionWrapper. For GBM we have been using \\BinomialModelPrediction\\ class successfully for quite sometime. \\nBut upon using the class \\AutoEncoderModelPrediction\\ we only get Reconstructed output, but not the \\Reconstruction.MSE\\ value. Is there a way if can be computed from input and output RowData we have, or I am doing something in very wrong direction ? Any help or pointer is much appreciated. Thanks again for your time.","2137":"@0biwanken0bi you are on the right track. The EasyPredictionModelWrapper doesn't support MSE atm. We will be adding this feature in one of the upcoming versions","2138":"Hi,\\nIs sample_rate=1.0 is a valid value for Random Forest (DRF) ? It's working for any value <1 .0. I replicated it using below \\Airlines demo\\  R Script \\n\\n` filePath <- h2o:::.h2o.locate(\\smalldata\/airlines\/AirlinesTrain.csv.zip\\)\\nair <- h2o.uploadFile(filePath, \\air\\)\\ns <- h2o.runif(air)    # Useful when number of rows too large for R to handle\\nair.train <- air[s <= 0.8,]\\nair.valid <- air[s > 0.8,]\\n\\nmyX <- c(\\Origin\\ \\Dest\\ \\Distance\\ \\UniqueCarrier\\ \\fMonth\\ \\fDayofMonth\\ \\fDayOfWeek\\ )\\nmyY <- \\IsDepDelayed\\\\n\\nair.rf         <- h2o.randomForest(x = myX, y = myY, training_frame = air.train, seed = 12,\\n                                   validation_frame=air.valid, ntrees = 10, max_depth = 20,\\n                                   balance_classes=F, sample_rate = 1.0)\\nprint(air.rf) `\\n\\nOUTPUT\\n----------\\nH2OBinomialMetrics: drf\\n** Reported on training data. **\\n** Metrics reported on Out-Of-Bag training samples **\\n\\nMSE:  NaN\\nRMSE:  NaN\\nLogLoss:  NaN\\nMean Per-Class Error:  NaN\\nAUC:  0\\nGini:  0\\n\\nNULL\\nNULL","2139":"@ggauravuee It doesn\\u2019t make sense to use sample rate 1.0 (because then there is no difference between the indivual trees in the forest, so it\\u2019s really no better than a single decition tree) but rather than training an RF and then printing out garbage metrics with a bunch of NaNs, we should prevent the user from using that value, or at least provide a warning message","2140":"@ggauravuee thanks for the report; ill file a JIRA for this","2141":"it looks like those metrics are based on OOB training samples, and if there are 0 OOB training samples (because sample_rate = 1.0), then the metrics it produces won\\u2019t be real numbers","2142":"@ggauravuee JIRA is here: https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-4790","2143":"@rohan-kekatpure it sounds like you are missing the requirements for git2r package: https:\/\/cran.r-project.org\/web\/packages\/git2r\/index.html \\SystemRequirements:\\tzlib headers and library. OpenSSL headers and library. LibSSH2 (optional on non-Windows) to enable the SSH transport.\\","2144":"what OS are you on?","2145":"@alextorar_twitter the text support right now includes Word2Vec, but we don\\u2019t have any topic model algos on the roadmap at this time.  Do you have a particular algorithm and\/or use-case in mind?","2146":"@ledell Thanks Erin for prompt update","2147":"is more like a use  case,   im trying to do some  text analytics in social networks, regarding,  for example, what is talking the people  about a particular product  or notice and then do sentiment analysis ","2148":"Hello everyone, can anyone please tell me if we can implement our own algorithms on H2O?","2149":"Is H2O extensible?","2150":"@Ahsaan-566 Yes it is (although it\\u2019s not trivial since you have to know about distributed computing and map reduce).  It certainly can be done, though.","2151":"Thanks @ledell ","2152":"you can definitely do it though, @Ahsaan-566 i can\\u2019t point you to any examples of people doing this in the open source community, but i know that our customers have added custom models in Java.  Once the model is registered in Java, a lot of the other stuff happens more or less automatically (it will show up in Flow, and out R and Python bindings are auto generated) ","2153":"I'm looking to interface a MPP database to h2oai.  Can you point me towards a tutorial for parallel ingest into the framework?","2154":"@jrivers96 If your database has a JDBC connector, you can load your data directly into H2O.  There\\u2019s more info here and some links to tutorials: http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/getting-data-into-h2o.html  ","2155":"Hello Everyone, \\nThis is my first message here in the room . I was curious if H2O has APIs for convex optimization and other advanced non-convex methods. I think this can be a good feature allowing machine learner practioners customizing machine learning algorithms for their own problems and even experiment new methods. I would be happy to contribute for such a feature as I have good experience in R, Python and distributed programming.\\n","2156":"Hi, is there anywhere I can download h2o-python 3.13.0.369. I got the following error when I try to use the nvidia docker image of h2o deep water. Thanks\\nH2OConnectionError: Version mismatch. H2O is version 3.13.0.369, but the h2o-python package is version 3.13.0.356. Install the matching h2o-Python version from - http:\/\/h2o-release.s3.amazonaws.com\/h2o\/(HEAD detached at 32b81a9e4)\/369\/index.html.","2157":"is there driverless ai discussion happening somewhere?","2158":"@mbaddar1 we don\\u2019t have something like that now, we may add a GPU-based POGS interface in the future: https:\/\/foges.github.io\/pogs\/ but i\\u2019m not 100% sure on that.   if you are interested in contributing a convex optimization method to h2o-3, please write up your proposal in a JIRA ticket https:\/\/0xdata.atlassian.net\/projects\/PUBDEV and then paste the link to the ticket back here","2159":"@mbaddar1 another option is that we have convex optimization code in the backend of H2O\\u2019s GLM that could possibly be re-worked into a generic interface.  ","2160":"Hi, I'm running steam with TLS and am wondering if it is possible to serve deployments with TLS?","2161":"[![IMG_8551.JPG](https:\/\/files.gitter.im\/h2oai\/h2o-3\/S1vT\/thumb\/IMG_8551.jpg)](https:\/\/files.gitter.im\/h2oai\/h2o-3\/S1vT\/IMG_8551.JPG)","2162":"H2O on raspberry pi  ;-) \\u2026 just tested how is performing on ARM architecture  ;-)","2163":"\\n@ledell Thanks a lot I will prepare a proposal and send the link","2164":"Hi everyone, I found a bug I would like to report: The hex.genmodel.MojoModel#load() function does not close its InputStream. It would probably make sense, if the hex.genmodel.MojoReaderBackend interface extends the Closeable (or AutoCloseable) interface, so that hex.genmodel.MojoModel#load() is able to close them in general?","2165":"Hi @SimonSchmid, this issue was addressed in one of the latest versions of H2O. What version are you running? If MojoReaderBackend is Closeable it is closed, please see: https:\/\/github.com\/h2oai\/h2o-3\/blob\/aff4699400e79fb986346329f96ac19bfe41cc87\/h2o-genmodel\/src\/main\/java\/hex\/genmodel\/ModelMojoReader.java#L36 (ModelMojo.load(..) simply calls this method).\\n\\n","2166":"@yarenty nice, did you try to create a cluster for PIs as well?","2167":"@SimonSchmid nice catch! thank you!","2168":"Hello everyone, I was wondering if the steam repository (https:\/\/github.com\/h2oai\/steam\/) is still being maintained?","2169":"I posted an issue there yesterday: https:\/\/github.com\/h2oai\/steam\/issues\/377","2170":"Thanks for the response @michalkurka . Actually none of the classes which extend  ModelMojoReader is Closeable, so this line seems never to be invoked. Some of the MojoReaderBackends are Closeable, e.g. the ZipfileMojoReaderBackend, but ModelMojo.load(..)  never tries to close the backend. Since I only want to read zip files at the moment, my fix looks like this:\\n```\\nMojoReaderBackend backend = MojoReaderBackendFactory.createReaderBackend(file);\\nMojoModel model = MojoModel.load(backend);                \\n                    if (backend instanceof Closeable) {\\n                        ((Closeable)backend).close();\\n                    }\\n```","2171":"Hi! So I'm thinking about the following:","2172":"I got a huge H2OFrame (150gb), on which I need to enrich a little. Let's just say I have a bunch of cities, and I need to look up the ZIP codes for each city and add it to each row. To do that, I need a way to apply a function to each row of the frame. With the the frame's apply() function I can only use a lambda function, which H2O understands (meaning no complex stuff). I really didn't find a way to do this. Converting it to a python frame and doing it locally is not an option, because of the huge data size.","2173":"One way I was thinking of is to use Spark\/pysparkling, because spark's dataframes have the capability of applying a function to each of the frame's rows. However, I would really prefer to only use H2O for now, because this would be the only thing I would need Spark for","2174":"So yes, is there really no way to do this? Thanks in advance!","2175":"Same question as @ksbg has  ->  in my company we are start research of model repositories. I just tested steam - my feelings are mixed at the moment ;-) but working on that ;-)  \\nJust want to check as I think your focus is not really on that product, is it ?   Do you  have roadmap for steam?\\n   *PS: I\\u2019m checking: Steam, ModelDB(mit), prediction.io, clipper.ai*","2176":"Hi,\\nCould you let me know if I can try H2O GPU Edition in Windows. I come across below but it says - \\Import dependencies (This requires Linux Ubuntu 16.04 with CUDA 8)\\\\nhttps:\/\/blog.h2o.ai\/2017\/05\/machine-learning-on-gpus\/\\nhttps:\/\/github.com\/h2oai\/perf\/blob\/master\/gtc\/Multi-GPU-H2O-GLM.ipynb","2177":"@ggauravuee No its not supported on windows yet","2178":"@saltcake00_twitter have you searched \\u201cH2OFrame.apply\\ in our github?   there are some examples.  this one is from the Python booklet code https:\/\/github.com\/h2oai\/h2o-3\/blob\/581a0f2e7f6da916c6b9bbbd015867e46d5192df\/h2o-docs\/src\/booklets\/v2_2015\/source\/Python_Vignette_code_examples\/python_apply_funct_to_columns.py","2179":"@yarenty I know the author of ModelDB.  that tool only does model evaluation\/comparison, it\\u2019s not capable of running a prediction service.  are you looking for a tool to compare models or to actually deploy them?","2180":"@SimonSchmid you are absolutely correct! I found bunch of other places where we don't handle IO properly.\\n\\nThis PR should fix the problem: https:\/\/github.com\/h2oai\/h2o-3\/pull\/1539","2181":"Hello, I took a lot at FolderMojoReaderBackend ( https:\/\/github.com\/h2oai\/h2o-3\/blob\/d989409c8d7936de78ece53d8c5290eb3fd7f717\/h2o-genmodel\/src\/main\/java\/hex\/genmodel\/FolderMojoReaderBackend.java ) and did a slight refactoring to it, so the code is more readable and an empty try-catch block is avoided. I could not push a new branch and create a pull request. Is there a way to contribute the code, if any ? (The new code is available as GIST here: https:\/\/gist.github.com\/Pscheidl\/369e8fabe384a0f97be6311008e035f8 )","2182":"Hi @Pscheidl, thanks for the contribution. We want gen-model.jar to be Java 6 compatible and possibly even compile on Java 6 (this might not be necessary anymore). Let me check what is the policy","2183":"@michalkurka Ok then, I will make it Java 6 compatible. I already know the process to make a pull request. Thank you.","2184":"@yarenty  @ksbg regarding your question about steam - we have 2 version of steams - open source and enterprise. Right now, open source version is behind enterprise version, but our plan is still to apply idea of delayed open-source here and propagate changes from enterprise to open source.  ","2185":"Hello Guys, I have a question maybe stupid. H2O is implemented in Java, how does the Java code call Tensorflow methods? ","2186":"@allenjack I personally never worked on the Deep Water codebase so I can\\u2019t answer definitively. There might be more info in http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/booklets\/DeepWaterBooklet.pdf  I think @mdymczyk can provide some more technical detail...","2187":"@allenjack we are calling the TF Java API - it is pretty limited so the networks we support out of the box in DW are generated with their Python API","2188":"@mdymczyk Thank you. If I am right, you don't train the model in the DW. Instead, you train the model by the TF Python API then save it somewhere. After that, you call the saved model in the DW. Is that correct?","2189":"Hi all, maybe a question for @michalkurka ? I just realised that the doing a prediction using a MOJO Deep Learning model seems not to be thread safe. I learned a Deep Learning Regression model on the prostate data set and did predictions on several rows concurrent. The results got confused and assigned to the wrong input rows. This problem did not appear with any other model I used. Is this a known issue? ","2190":"hi! I am trying to use autoML and adjust the stopping_metric (to 'rmsle' instead of 'AUTO') but it keeps telling me that ```Server error java.lang.IllegalArgumentException:\\n  Error: Field = stopping_metric cannot be set to value = rmsle```","2191":"has anyone run into issues with this? it works when I use the h2o console. But when i try to use h2o in python it brings this error. ","2192":"@allenjack we only build the model graph using TF Python API, then we save the meta file on disk. The training is done using DW, which internally loads that meta file and feeds it to TF Java API for training","2193":"@Aakash282 The client should give you an error that tells you what stopping metrics are allowed.  It looks like we only support \\u201cRMLSE\\u201d instead of \\u201crmsle\\u201d.  I\\u2019ll make a JIRA so that we can support both cases:\\nR Example:\\n```\\nlibrary(h2o)\\nh2o.init()\\n\\n\\ndata <- h2o.importFile(\\https:\/\/h2o-public-test-data.s3.amazonaws.com\/smalldata\/extdata\/australia.csv\\)\\nx <- c(\\premax\\ \\salmax\\ \\minairtemp\\ \\maxairtemp\\ \\maxsst\\ \\maxsoilmoist\\ \\Max_czcs\\)\\ny <- \\runoffnew\\\\n\\naml <- h2o.automl(x = x, y = y, training_frame = data, max_runtime_secs = 60, stopping_metric = \\rmlse\\u201d)  #not working\\naml <- h2o.automl(x = x, y = y, training_frame = data, max_runtime_secs = 60, stopping_metric = \\RMSLE\\u201d)  #working\\n```","2194":"@SimonSchmid I overheard someone  at H2O saying that there were issues with the Deep Learning POJO\/MOJO recently, i think this is a known issue\\u2026 @michalkurka can confirm.","2195":"@Aakash282 i can\\u2019t edit that script, but there;s a typo.  i mean to type \\u201crmsle\\u201d.  ","2196":"@Aakash282 This in in R, but I assume it\\u2019s the same issue in Python.  To fix, use \\u201cRMSLE\\","2197":"@SimonSchmid you are correct, there were some issues with Deep Learning POJO - we fixed them in the latest release. It should be thread-safe as long as you create a new instance of the POJO for each execution thread (it is not stateless, there is still state modified when you executed the pojo).","2198":"@michalkurka Ok, thanks. Same for MOJOs I guess?","2199":"The [JIRA ticket system](https:\/\/github.com\/h2oai\/h2o-3\/blob\/master\/CONTRIBUTING.md) link on [CONTRIBUTING.md](https:\/\/github.com\/h2oai\/h2o-3\/blob\/master\/CONTRIBUTING.md) shows an error *The requested filter doesn't exist or is private.* Could you please point me to the issues for new contributors?","2200":" I want to convert a sparse matrix to a h2o objective` train_h2o <- as.h2o(train3, \\sparse_matrix\\)` but it is too slow,it has runing almost 1 hour, train3 is a sparse matrix with 400MB,any solutions ?thanks","2201":"@pqrth this link?  https:\/\/0xdata.atlassian.net\/","2202":"it works for me","2203":"ah, i see there is a second link https:\/\/github.com\/h2oai\/h2o-3\/blob\/master\/CONTRIBUTING.md#contribute-code","2204":"please use the above link, ill fix the broken link in Contributing.md","2205":"Hey @michalkurka have all the sparse matrix optimizations been pushed to master and are in latest stable release?  cc @hutaohutc ","2206":"@hutaohutc I know that we\\u2019ve made some updates to that recently, are you using the latest stable release?","2207":"@ledell Hi,thanks for your answer,my R version is 3.3.2 and h2o version is 3.14.0.3","2208":"@hutaohutc can you tell me what the class of `train3` is?  Is it this?\\n```\\n> class(m)\\n[1] \\dgCMatrix\\\\nattr(,\\package\\)\\n[1] \\u201cMatrix\\u201d\\n```","2209":"While building with `.\/gradlew build -x test`, the `commandLine` in task `runGenerateRESTAPIBindingsSrc`of `h2o-bindings\/build.gradle` didn\\u2019t use my python virtual environment. So I replaced the command `python` with the path of my virtual env python. But now I\\u2019m getting\\n\\n```\\n+ CMD: \/Users\/<username>\/.jenv\/versions\/oracle64-1.8.0.112\/bin\/java -Xmx4g -ea -cp \/Users\/<username>\/repos\/h2oai\/h2o-3\/build\/h2o.jar water.H2OApp -name H2O_runit_<username>_6476453 -baseport 48000 -ga_opt_out\\n\\nERROR: Too many retries starting cloud 0.\\n```","2210":"@ledell yeah,                                                                                             \\n ```                                                                                                \\nclass(train3)\\n[1] \\dgCMatrix\\\\nattr(,\\package\\)\\n[1] \\Matrix\\                                                                                                   ```                                                                                                                                                                                                                                                              \\n                                                                                                             \\n  `as.h2o` has been running more than 12hours...","2211":"@hutaohutc Yikes\\u2026 I hope that @michalkurka can share some advice, he know more about that piece of the code than I do.  I wonder if you need more memory in your H2O cluster, are you using the default size of 4G or something bigger?  ","2212":"@ledell yeah,I gave 6 G memory to h2o cluster\\u3002                                                    ```                                                                                                           h2o.init(nthreads=-1, max_mem_size=\\6g\\)                                ```                                   ","2213":"@pqrth do you have  log of jvm process? It should be in \/tmp\/h2o*","2214":"@mmalohlava I looked at all the logs & all the info ones have\\n> 10-11 13:23:05.057 127.0.0.1:48004       33781  main      INFO: H2O started in 78281ms\\n> 10-11 13:23:05.057 127.0.0.1:48004       33781  main      INFO: Open H2O Flow in your web browser: http:\/\/127.0.0.1:48004\\n\\nComplete logs: https:\/\/gist.github.com\/pqrth\/c264759995ae1bb903ba0bac06933a46","2215":"@ledell Thank you!","2216":"Does H2O support embedded language besides CS?","2217":"like python or R","2218":"Hello everybody.\\n\\nI try to use H2O together with xgboost, but I do not get any result. \\nMore precisely, the result is present, but this data initializes the model.\\nThe same result is obtained when an error occurs in the native code, but in my case there are no errors.\\n\\nI tried several versions from 3.10 to 3.15, the result is the same everywhere. \\nI took versions from here: https:\/\/h2o-release.s3.amazonaws.com\/h2o\/rel-weierstrass\/6\/index.html\\nI used this sample code: https:\/\/blog.h2o.ai\/2017\/06\/xgboost-in-h2o-machine-learning-platform\/\\n\\nI used \\xgboost\\ and \\H2O\\ from under R, from under Python, ran the jar-package and everywhere the result is the same - no result, only the initial initialization of the model.\\nHere is an example of a work result:\\n```\\n10-16 10:34:32.405 10.11.10.120:54321    15424  FJ-1-11   INFO: Scoring History:\\n10-16 10:34:32.405 10.11.10.120:54321    15424  FJ-1-11   INFO:            Timestamp   Duration Number of Trees Training RMSE Training MAE Training Deviance\\n10-16 10:34:32.405 10.11.10.120:54321    15424  FJ-1-11   INFO:  2017-10-16 10:34:09  0.148 sec               0       0,50000      0,50000           0,25000\\n10-16 10:34:32.405 10.11.10.120:54321    15424  FJ-1-11   INFO:  2017-10-16 10:34:11  1.454 sec               1       0,50000      0,50000           0,25000\\n10-16 10:34:32.405 10.11.10.120:54321    15424  FJ-1-11   INFO:  2017-10-16 10:34:11  1.927 sec               2       0,50000      0,50000           0,25000\\n10-16 10:34:32.405 10.11.10.120:54321    15424  FJ-1-11   INFO:  2017-10-16 10:34:12  2.402 sec               3       0,50000      0,50000           0,25000\\n10-16 10:34:32.405 10.11.10.120:54321    15424  FJ-1-11   INFO:  2017-10-16 10:34:12  2.860 sec               4       0,50000      0,50000           0,25000\\n10-16 10:34:32.405 10.11.10.120:54321    15424  FJ-1-11   INFO:  2017-10-16 10:34:13  3.329 sec               5       0,50000      0,50000           0,25000\\n10-16 10:34:32.405 10.11.10.120:54321    15424  FJ-1-11   INFO:  2017-10-16 10:34:13  3.782 sec               6       0,50000      0,50000           0,25000\\n10-16 10:34:32.405 10.11.10.120:54321    15424  FJ-1-11   INFO:  2017-10-16 10:34:14  4.245 sec               7       0,50000      0,50000           0,25000\\n10-16 10:34:32.405 10.11.10.120:54321    15424  FJ-1-11   INFO:  2017-10-16 10:34:18  8.487 sec              17       0,50000      0,50000           0,25000\\n10-16 10:34:32.405 10.11.10.120:54321    15424  FJ-1-11   INFO:  2017-10-16 10:34:22 12.738 sec              27       0,50000      0,50000           0,25000\\n10-16 10:34:32.405 10.11.10.120:54321    15424  FJ-1-11   INFO:  2017-10-16 10:34:26 17.007 sec              37       0,50000      0,50000           0,25000\\n10-16 10:34:32.405 10.11.10.120:54321    15424  FJ-1-11   INFO:  2017-10-16 10:34:31 21.280 sec              47       0,50000      0,50000           0,25000\\n10-16 10:34:32.405 10.11.10.120:54321    15424  FJ-1-11   INFO:  2017-10-16 10:34:32 22.592 sec              50       0,50000      0,50000           0,25000\\n10-16 10:34:32.451 10.11.10.120:54321    15424  FJ-1-11   INFO: Model Metrics Type: Regression\\n10-16 10:34:32.451 10.11.10.120:54321    15424  FJ-1-11   INFO:  Description: Metrics reported on training frame\\n10-16 10:34:32.451 10.11.10.120:54321    15424  FJ-1-11   INFO:  model id: xgboost-d04ecfa3-477d-4afa-a057-a9ff353cef0d\\n10-16 10:34:32.451 10.11.10.120:54321    15424  FJ-1-11   INFO:  frame id: higgs_train_imbalance_100k.hex\\n10-16 10:34:32.451 10.11.10.120:54321    15424  FJ-1-11   INFO:  MSE: 0.25\\n10-16 10:34:32.451 10.11.10.120:54321    15424  FJ-1-11   INFO:  RMSE: 0.5\\n10-16 10:34:32.451 10.11.10.120:54321    15424  FJ-1-11   INFO:  mean residual deviance: 0.25\\n10-16 10:34:32.451 10.11.10.120:54321    15424  FJ-1-11   INFO:  mean absolute error: 0.5\\n10-16 10:34:32.451 10.11.10.120:54321    15424  FJ-1-11   INFO:  root mean squared log error: 0.40521333\\n```\\nI tested xgboost from under python and it works great. \\nI also tried xgboost4j separately from Java and it works fine too.\\nThe problem occurs only when using xgboost in conjunction with H2O. \\nI need this use case, since H2O allows you to generate POJO from a trained model, which is very convenient.\\n\\nP.S.  all actions performed on linux Ubuntu 16.04","2219":"@velconia are you asking if we have Python or R APIs?  Yes.  there is a Python h2o package and an R h2o package, that\\u2019s what most people use","2220":"@JohnnyWallker In your example, you trained a regression model.  The example from the blog post trained a binary classification model \\u2014 since the response column in Higgs is encoded as 0\/1, you must tell H2O that you want this to be a \\u201cfactor\\u201d (aka \\u201cenum\\u201d) in order for it to train a classificaiton model.  This is included in the sample code, so I think you are missing a step.","2221":"I am not sure if that will 100% solve your issue, but you should try again following the exact steps from the blogpost.  In the Python example, it\\u2019s these liens of code:\\n```\\n# Transform first feature into categorical feature\\ndf_train[0] = df_train[0].asfactor()\\ndf_valid[0] = df_valid[0].asfactor()\\n```","2222":"@ledell  yes, I also want to train a binary classification model.\\nIn accordance with an example, I changed the type of response column to a \\factor\\ (aka \\u201cenum\\u201d). \\nI do not see where can specify H2O to use the classification model, as far as I understand the application automatically determines the type of classification depending on the type of response column.\\n\\nBut let's set aside the python and I'll try to build a model using only the web interface of the H2O application.\\n\\nI took the version of h2o-3.15.0.4065 and the data files(higgs_train_imbalance_100k.csv and higgs_test_imbalance_100k.csv) from the example from here https:\/\/blog.h2o.ai\/2017\/06\/xgboost-in-h2o-machine-learning-platform\/\\n\\nRan the application H2O with the command java -jar h2o.jar.\\n\\nI do all the manipulations only in the web interface.\\n\\n1) Importing files from an example\\n![import_dataset.png](https:\/\/www.dropbox.com\/s\/d2qq7a6rh7wfueb\/import_dataset.png?dl=0)\\n[import dataset](https:\/\/www.dropbox.com\/s\/d2qq7a6rh7wfueb\/import_dataset.png?dl=0)\\n\\n2) As we see the column \\response\\ is of type enum\\n![response_column_of_dataset.png](https:\/\/www.dropbox.com\/s\/y5sqyu4k4472m9r\/response_column_of_dataset.png?dl=0)\\n[response column of dataset](https:\/\/www.dropbox.com\/s\/y5sqyu4k4472m9r\/response_column_of_dataset.png?dl=0)\\n\\n3) Building a model: choose the algorithm \\XGBoost\\; as the column with the answer we select the column \\response\\. The remaining parameters are left by default.\\n![build_a_model.png](https:\/\/www.dropbox.com\/s\/42qr7wt0ckhbw80\/build_a_model.png?dl=0)\\n[build a model](https:\/\/www.dropbox.com\/s\/42qr7wt0ckhbw80\/build_a_model.png?dl=0)\\n\\n4) We get the default (empty) model with the graph and metrics presented in the screenshots.\\n![final_model.png](https:\/\/www.dropbox.com\/s\/zp8z2nmwz52mymv\/final_model.png?dl=0)\\n[final model](https:\/\/www.dropbox.com\/s\/zp8z2nmwz52mymv\/final_model.png?dl=0)\\n\\n![final_model_metrics.png](https:\/\/www.dropbox.com\/s\/lrqej5pv9lspvyy\/final_model_metrics.png?dl=0)\\n[final model metrics](https:\/\/www.dropbox.com\/s\/lrqej5pv9lspvyy\/final_model_metrics.png?dl=0)","2223":"Hi folks, I'm getting started with H2O and I have some issues with an API call to \/3\/ModelBuilders\/glm. I'm using a 3.10.4.2 H2O server with the java bindings of the same version.","2224":"the server isn't happy with the lambda param of the request, which is supposed to be an array of double, but the actual array seems to be an array of Strings, according to my h2o logs","2225":"@JohnnyWallker thanks for the detailed report.  we will look into this.  ","2226":"@JohnnyWallker I have added your comments to a JIRA and you can track the progress of this issue here: https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-5018","2227":"I know H2o has some dockerfiles setup, but I don't see any that are pre-configured to work with the rstudio base image and h20....if I have developed one, is there a way to contribute to the community? Not sure if others would be interested in this as well","2228":"@ledell thoughts?","2229":"Hi @pgensler that would be great.  are you thinking of making a new dockerfile or would you edit the existing one to work better with RStudio?","2230":"That seems like a nice contribution (either way).  The process is that you\\u2019d make a PR, we\\u2019d test it out and then we\\u2019d approve it.","2231":"@ledell I've already created a dockerfile, do i just make the PR on Github ?","2232":"@pgensler Yep, thanks!","2233":"Hello all","2234":"I could not find any channel for Steam so I'm here instead :)","2235":"Having really troubles with it. First of all, inner 4g memory limit is way too low. I'm currenly making Docker image for our project that increases it. But. Build process is on of a kind thingy wingy,","2236":"https:\/\/hub.docker.com\/r\/h2oai\/steam\/~\/dockerfile\/","2237":"That is not currently working","2238":"I switched to alpine linux, and it's just exiting to seg fault ","2239":"latest ubuntu has some ts compile errors","2240":"What was the original version someone made the dockerfile? It should use that as a base image, and lock versions","2241":"hey @jerbome were you able to figure your issue out?","2242":"you are correct that the class is `public double[] lambda;`","2243":"so i am not sure why you think it\\u2019s strings, is there something in the logs you can post to clarify why you\\u2019d think that","2244":"Can we install driverless ai docker image on a machine without GPU?","2245":"@ArunLakhotia this is the h2o-3 Gitter, not for Driverless AI questions.  but the answer is yes.  please take a look at the Driverless documentation (this is stated in there): https:\/\/www.h2o.ai\/driverless-ai-download\/  If you have DAI code questions, please post those to Stack Overflow with \\u201cdriverless-ai\\u201d tag or use our google group: https:\/\/groups.google.com\/forum\/#!forum\/h2ostream (we may open a different Q\/A format in the future)","2246":"Hello, I was wondering how I can implement custom scoring i.e. use a custom scoring methodology for trees, rather than entropy or gini to be used for deciding splits","2247":"custom splitting criterion i guess....happy to do it directly in java","2248":"@bettopper do you mean adding a new metric and exposing it the user via some new paramter like `splitting_crierion` where the user can choose between say, \\u201cgini\\u201d or \\u201centropy\\u201d or \\u201csome_new_option\\?  or exposing a paramter that allows the user to define their own custom split technique?","2249":"here\\u2019s our currently technique: http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/data-science\/gbm-faq\/splitting.html","2250":"@ledell Either or both, I imagine if its the latter then it would be something like","2251":"implementing an interface","2252":"I've looked at bits of the codebase to see if there is a standard way of doing it already (still getting the hang of how it's architected and how this would fit in)......I took a quick look at how the same kind of thing can be implemented in something like scikit where it seems to be about implementing a custom criterion (https:\/\/github.com\/scikit-learn\/scikit-learn\/blob\/master\/sklearn\/tree\/_criterion.pyx)......Iam not sure how the vernacular maps between scikit and h2o! ","2253":"we only support one splitting criterion right now, so its a bit more work to add a new one, since there\\u2019s no precedent in the code for doing that.","2254":"if you\\u2019re interested, i\\u2019d write up a proposal of what you want to do and you can send it to me at erin _at_ h2o.ai and ill forward it to the right people.  also check out this. https:\/\/github.com\/h2oai\/h2o-3\/blob\/master\/CONTRIBUTING.md  if we decide that it\\u2019s a useful\/good idea then you\\u2019d code it up and make a PR","2255":"or you can go right ahead and fork h2o and try implementing it, but i am just trying to avoid you spending your time if we decide that its not something we want to add & thus continue to support","2256":"what criteron did you want to add?","2257":"@ledell Yes, understood, I am more than happy to submit a PR but like you say it seems to be a bit more involved as there is no existing precedent, I will submit a proposal and we'll see where it goes - if it's decided not to go ahead I'd still appreciate any pointers (the best unit tests to look at, which packages and classes will be most pertinent) from the right people as to how to implement on my own fork. ","2258":"I wanted to be able to explore how the use of different\/custom criterions impacts the kind of trees formed and how that impacts my domain application....at the moment my target variable ends up being having to be a heuristic, the prediction for which my application uses. However, with a custom splitting criterion maybe I can express that target variable as a non-heuristic (i.e. the actual thing which I want to predict and not some intermediary value)","2259":"and for some problems, there is this kind of \\maximisation classification\\ I am not sure what the technical term really is, but it's where I am looking to classify something to either minimize or maximize something else like a cumulative sum or product","2260":"and I think that this latter kind of problem can maybe be expressed with a custom splitting criterion","2261":"or maybe I want to be able to decide the splitting criterion as a function of the dataset in an automated manner","2262":"@bettopper if you\\u2019re not sure yet what you want to implement or if you want to experiment to see how different criteria affect your specific problem, then you might just consider using scikit-learn as a prototyping tool instead of H2O bc it will be easier","2263":"at least i *think* it will be easier.  i haven\\u2019t looked at the sklearn code closely to see what\\u2019s going on there.  it might be even easier to experiment w\/ diff criteria if you use some very basic\/barebones RF code on github (in your language of choice) to try it out.  ","2264":"@ledell you read my mind, i only checked how scikit was doing it because I thought it may be easier, I didn't want to reinvent the wheel if I could do it easily (relatively) in h2o so I didn't try to write RF\/DRF from scratch, will take a look at some barebones impls on github - many thanks","2265":"I am finding that the reported training error for models trained in autoML is inconsistent with using the model to predict on the training set and checking the errors using sklearn metrics.  In fact, its a very different number coming back. almost 25% difference in RMSE values. anyone else notice something like this or does training with autoML sometimes do this. I used a training and validation frame. This means the training frame shouldn't be changed at all and the errors should match exactly. thanks","2266":"@Aakash282 If you only provide a train & validation set, AutoML will still chop off half of your validation frame to use to score the leaderboard.  We are changing this in the next release (it will use xval metrics for leaderboard ranking by default hopefully starting in 3.16), so that you don\\u2019t have to \\u201cwaste\\u201d this data for scoring.  This is probably the reason that the metrics don\\u2019t match up.  http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/automl.html#auto-generated-frames","2267":"@Aakash282 In your case, half of your original `validation_frame` will be used for early stopping and the other half will be used for scoring models to rank on the leaderboard","2268":"hello  i run h2o-3.15.0.4100-hdp2.6  like hadoop jar h2odriver.jar -nodes 1 ,access the web ui, but i  alogs list,no xgboost  found ,  how to add in ? thanks ","2269":"hi all, x-posting issue in jira: https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-5078\\n","2270":"can someone verify that `rand()` (and therefore `Key.make()`) isn't thread-safe","2271":"hi @spennihana looks like your issue is already resolved :thumbsup: ","2272":"@ledell : Hello i am new to h2o and i have some doubts:\\n* H2o normally supports FNN and using deep water we can use CNN based networks using backend as caffe, tensorflow or mxnet. Is there a way we can use RNNs. I was planning to integrate RNNs and CNNs for a work.\\n* I have seen h2o is fast from some benchmarks. But in deepwater its basically creating a cnn using h2o flow and training using tensorflow or any other backend. What is the role of h2o here then ??","2273":"@sooraj2189 The role H2O as it relates to Deep Water is that H2O serves as a wrapper\/API for the other libraries.  It\\u2019s designed to make it easy to switch back and forth between core H2O algos and the other DNN libraries like TF, Caffe, MXNet","2274":"but if you had only planned to use Tensorflow (and no other H2O models) then you could just as easily use Tensorflow\/keras.  If you wanted to use the Flow GUI, however, then you should use Deep Water","2275":"I think @mstensmo can comment on support for RNNs in Deep Water","2276":"hi! quick question about the csv parser","2277":"anyone online?","2278":"@\/all Hey everyone, H2O World is Monday\/Tuesday this week.  If you want to watch the livestream, you can do so here: https:\/\/www.h2o.ai\/h2oworld\/  We will also put the videos up on youtube later.  Enjoy!","2279":"@ledell Hey Erin , I created a proposal in this jira\\nhttps:\/\/0xdata.atlassian.net\/browse\/PUBDEV-5141\\nI will add more details about the scope and steps to gradually add optimization layer in H2O. If you have comments on the current abstract in the jira please let me know","2280":"What are the differences between AutoML and Driverless AI. Is AutoML only about ML algorithms and using stacked ensemble for better model? And Driverless AI is about combinig the Auto feature engineering , AutoML and other tunning logic to provide end to end ML fetaure.   Also, I learnt from Sri Satish's  today session that AutoML is open source but Driverless AI is not. Is my understanding correct ?","2281":"@ggauravuee good question. H2O becomes messy to understand what is what","2282":"@ggauravuee Yes, that\\u2019s essentially the difference.  AutoML is automatic modeling (with some basic preprocessing like all H2O algos have).  DriverlessAI is 1. automatic feature engineering & modeling, 2. machine learning interpretability suite and 3. automatic visualization","2283":"and yes, AutoML is part of H2O-3, so it\\u2019s open source.  DriverlessAI is a commercial product.","2284":"@AntonPolishko_twitter Take a look at our docs.h2o.ai page if you want detailed descriptions to each of the different projects.  Open source: H2O, Sparkling Water, Deep Water, Steam, H2O4GPU. and Closed source: Enterprise Steam, DriverlessAI","2285":"@ledell thanks for the reply and clarification. Congratz to h2o team for pulling such a great conference. Are the livestreams going to be accessible later?","2286":"I have a model from xgboost in binary format and want to convert in h2o mojo\/format used by h2o. Specifically, h2o doesn't provide a way to use pairwise ranking loss function present in xgboost through its interfaces, so I have trained it locally using xgboost  and now I want to convert it into mojo\/pojo that can be used by h2o.","2287":"@mohit-shrma I am not sure there\\u2019s an easy way to do that.  We are still missing a few XGBoost parameters, but the missing ones should be added soon https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-5105?filter=21100","2288":"@AntonPolishko_twitter yep, we will put all the videos on youtube soon https:\/\/www.youtube.com\/user\/0xdata","2289":"@ledell do you have an estimate when those will be added, if a month or so then we can wait otherwise we may have to spend some significant time doing that or use other linear model for ranking.","2290":"hey @mohit-shrma sorry no i don\\u2019t have an estimate, but if i had to guess it would be in the next 1-2 months.  it\\u2019s marked as 3.18 so it will be done by then (that will prob be 2 months from now)","2291":"it\\u2019s actually not much of a big change, so if you\\u2019re interested in trying to contribute it yourself, please let me know!  I can point you to an previous PR where I added some other params","2292":"Here\\u2019s a PR that shows how to edit XGBoost params: https:\/\/github.com\/h2oai\/h2o-3\/pull\/1449  you only need to make changes to the Java XGBoost files, then run `.\/gradlew build -x test` and that will (re) autogenerate the R and Python bindings","2293":"and a few more related examples of changing xgboost params: https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-4753","2294":"@ledell  It's about enabling  pairwise ranking  loss functions and unlike classification\/regression this is a different loss function and will require incorporating evaluation metric like NDCG etc. XGBOOST provides an optimized implementation out of the box with eval metrics as well. I will try to see if some minor code changes can help me to resolve this. Thanks for your help.","2295":"@mohit-shrma if this is something XGBoost already does, it just means that we are missing this parameter so it should be a fairly easy change.   We wrap the original XGBoost software (vs writing our own xgb implementation), so all the functionality is available, we just happen to have not exposed all the parameters yet through the H2O API.   Can you tell me which parameter from this list are you referring to, exactly? https:\/\/xgboost.readthedocs.io\/en\/latest\/\/parameter.html","2296":"Hi everyone! has anybody deployed a model using AWS Lambda? I\\u2019m aware of the \\Malicious domain application\\u201d example (http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/productionizing.html#malicious-domain-application), but it hasn\\u2019t been straightforward to adapt it to my own models (I\\u2019m currently using AWS Elastic Beanstalk to deploy real-time predictions into production, but I want to move to a serverless architecture). congrats for the great work! Cheers!","2297":"What is the expected timeline for doc2vec release on h2o?","2298":"@ArunLakhotia doc2vec is not in our near-term pipeline","2299":"@ledell : hi.. I guess there is no immediate integration for RNNs in deepwater ?","2300":"@sooraj2189 no.  also deep water is not being actively developed (its in maintence mode at this point), so there won\\u2019t be RNNs any time soon.","2301":"I'm starting to experiment with automl after watching Erin's excellent tutorial from H2OWorld last night. Is there a way in R to get the H2OAutoML object from the H2O instance? I am running automl through Flow and wanted to pull the results into R for further processing. Looking for something like h2o.getModel() for the AutoML object.","2302":"Hi @dkincaid we don\\u2019t have this capability yet.  I created a ticket here: https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-5177","2303":"Thanks! I pieced together my own function for now by copying some of your code out of the h2o.automl() function. Sufficient workaround for now. Appreciate the help.","2304":"I created a ticket PUBDEV-5175 too for another issue I came across. If you have run an AutoML job, running getJobs or calling the API \/3\/Jobs returns a ClassNotFoundException.","2305":"@dkincaid glad you found a work-around.  would you mind posting your function as a comment to the PUBDEV-5177 JIRA?","2306":"thanks for the additional bug report too","2307":"Sure thing!","2308":"how to  use h20.ai in an android app","2309":"@syam3526 perhaps someone has done this before becuase H2O is Java it\\u2019s possible to do, but we don\\u2019t have any tutorials on how to do this.  However, it probably makes more sense to run an H2O prediction server and make REST calls from inside the app to get predictions.","2310":"@ledell thank you.","2311":"Are there any plans to make your k-LIME functionality available outside of the Driverless AI product? Or maybe just a basic LIME implementation that works well with the H2O models? The current R lime package sort of works with H2O models, but doesn't handle missing data and doesn't use the predicted class from the model. Thought I would check before I spent time on my own implementation or fixing the current lime package.","2312":"@dkincaid The lime package in R already (supposedly) works well with H2O Models, have you tried it recently?  I haven\\u2019t used it myself yet, so I can\\u2019t say how seamless it is...  \\n\\nIf there are features missing, maybe you can chat with Matt Dancho about it, he\\u2019s the one who added the support.  If you could open an issue on the lime repo.  \\n\\nHere\\u2019s a recent meetup about lime + h2o, by the way: https:\/\/www.youtube.com\/watch?v=CY3t11vuuOM&list=PLNtMya54qvOErCPus07wKDqHlTyMjgTbX&index=1","2313":"@dkincaid To answer your question, I am not sure if k-LIME will be made available or not.  \\n\\nThis is in Python, but this might be interesting to you: https:\/\/github.com\/h2oai\/mli-resources\/blob\/master\/notebooks\/lime.ipynb","2314":"Thanks! I am working with the R lime package. It works pretty well with H2O, but the biggest problem I'm having with it is that it doesn't handle missing values, so I'm seeing really odd results. I've been spoiled by H2O's nearly seamless handling of missing values. It also doesn't use the actual class prediction of the model when determining the label for the cases. It just uses 0.5 as a threshold.","2315":"I actually just watched that youtube talk just the other day. It is excellent!","2316":"@all we run h20 ui flow thru URL http:\/\/a.b.c.d:54321\/flow\/index.html   How to enable security on H2O ui for authentication \/ authorization? ","2317":"Currently all flows are accessible by everyone on network, we would like restrict the accessibility using security mechanism.","2318":"Hi everyone,  I joined today first time. today","2319":"nice to meet you all.","2320":"I don't know your time zones so good morning, good afternoon, or good evening. \\n\\nI'm very amateur, please redirect me if I'm in the wrong place. \\n\\nI'm looking to build a data extraction program to be used to grab emails and numbers from Craigslist. This would have to access the API, bypass the web-crawler security measures, qualify (filter) the massive quantity of user's posts based on their posting-behavior, and return the contact information along with the characteristics of the user's behavior.\\n\\nWhat concepts, as in depth as you are willing to delve, would go into building this?","2321":"@tjowers95 i don\\u2019t see how this relates to machine learning or H2O...","2322":"Hello, I'm facing difficulties with H2O XGBOOST model deployment using MOJO. I follow example on [H2O Steam Prediction Service Builder](http:\/\/docs.h2o.ai\/steam\/latest-stable\/steam-docs\/prediction_service.html) using following commands: \\n```\\ncurl -X POST --form mojo=@tmp_dir\/XGBoost_model_python_1514898693837_59.zip --form jar=@tmp_dir\/h2o-genmodel.jar localhost:55000\/makewar > tmp_war.war\\n```\\n\\nand later:\\n\\n```\\njava -jar jetty-runner-9.3.9.M1.jar --port 55001 tmp_war.war\\n```\\n\\nand I get following errors:\\n```\\n2018-01-03 17:32:45.248:INFO::main: Logging initialized @114ms\\n2018-01-03 17:32:45.255:INFO:oejr.Runner:main: Runner\\n2018-01-03 17:32:45.383:INFO:oejs.Server:main: jetty-9.3.9.M1\\n2018-01-03 17:32:45.641:WARN:oeja.AnnotationConfiguration:main: ServletContainerInitializers: detected. Class hierarchy: empty\\nSLF4J: Class path contains multiple SLF4J bindings.\\nSLF4J: Found binding in [jar:file:\/private\/var\/folders\/22\/t_djqmjs35n02x7nwgpltw100000gn\/T\/jetty-0.0.0.0-55001-tmp_war.war-_-any-7461152874368912835.dir\/webapp\/WEB-INF\/lib\/h2o-genmodel.jar!\/org\/slf4j\/impl\/StaticLoggerBinder.class]\\nSLF4J: Found binding in [jar:file:\/private\/var\/folders\/22\/t_djqmjs35n02x7nwgpltw100000gn\/T\/jetty-0.0.0.0-55001-tmp_war.war-_-any-7461152874368912835.dir\/webapp\/WEB-INF\/lib\/slf4j-simple-1.7.7.jar!\/org\/slf4j\/impl\/StaticLoggerBinder.class]\\nSLF4J: See http:\/\/www.slf4j.org\/codes.html#multiple_bindings for an explanation.\\nSLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\\nlog4j:WARN No appenders could be found for logger (PredictBinaryServlet).\\nlog4j:WARN Please initialize the log4j system properly.\\nlog4j:WARN See http:\/\/logging.apache.org\/log4j\/1.2\/faq.html#noconfig for more info.\\n2018-01-03 17:32:45.856:INFO:oejs.AbstractConnector:main: Started ServerConnector@1d7acb34{HTTP\/1.1,[http\/1.1]}{0.0.0.0:55001}\\nException in thread \\main\\ java.lang.NoClassDefFoundError: org\/apache\/commons\/logging\/LogFactory\\n\\tat ml.dmlc.xgboost4j.java.Booster.<clinit>(Booster.java:34)\\n\\tat ml.dmlc.xgboost4j.BoosterHelper.loadModel(BoosterHelper.java:19)\\n\\tat hex.genmodel.algos.xgboost.XGBoostMojoReader.readModelData(XGBoostMojoReader.java:25)\\n\\tat hex.genmodel.ModelMojoReader.readAll(ModelMojoReader.java:149)\\n\\tat hex.genmodel.ModelMojoReader.readFrom(ModelMojoReader.java:34)\\n\\tat hex.genmodel.MojoModel.load(MojoModel.java:35)\\n\\tat ServletUtil.addMojoModel(ServletUtil.java:90)\\n\\tat ServletUtil.loadModels(ServletUtil.java:41)\\n\\tat PredictBinaryServlet.init(PredictBinaryServlet.java:40)\\n\\tat org.eclipse.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:640)\\n...\\n```\\n\\nIt seems that org\/apache\/commons\/logging\/LogFactory is missing. However, when I use H2O native GBM with MOJO file everything works like a charm. It seems to be related only with H2O's XGBOOST. Anybody could help?","2323":"@gediminaszylius This looks like a bug on our side, we will look into it. XGBoost uses different logging infrastructure from h2o's native gbm, that is why you see the error. ","2324":"We will track the bug here: https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-5195","2325":"Hello I am having problems with H2o deepwater","2326":"While trying to train a lenet model for multiclass classification using h2o deepwater using mxnet backed i am getting the following errors:\\n\\nLoading H2O mxnet bindings.\\nFound CUDA_HOME or CUDA_PATH environment variable, trying to connect to GPU devices.\\nLoading CUDA library.\\nLoading mxnet library.\\nLoading H2O mxnet bindings.\\nDone loading H2O mxnet bindings.\\nConstructing model.\\nDone constructing model.\\nBuilding network.\\nmxnet data input shape: (32,100)\\n[10:40:16] \/home\/jenkins\/slave_dir_from_mr-0xb1\/workspace\/deepwater-master\/thirdparty\/mxnet\/dmlc-core\/include\/dmlc\/logging.h:235: [10:40:16] src\/operator\/.\/convolution-inl.h:349: Check failed: (dshape.ndim()) == (4) Input data should be 4D in batch-num_filter-y-x\\n[10:40:16] src\/symbol.cxx:189: Check failed: (MXSymbolInferShape(GetHandle(), keys.size(), keys.data(), arg_ind_ptr.data(), arg_shape_data.data(), &in_shape_size, &in_shape_ndim, &in_shape_data, &out_shape_size, &out_shape_ndim, &out_shape_data, &aux_shape_size, &aux_shape_ndim, &aux_shape_data, &complete)) == (0) \\n\\nThe details of my setup :\\nRam : 12gb\\nGraphics card : Nvidia 920mx driver version : 384.90\\nCuda : 8.0.61\\ncudnn : 6.0\\nR version : 3.4.3\\nH2o version : 3.15.0.393 & h2o-R package : 3.16.0.2\\nmxnet : 0.11.0\\nTrain data size : 400mb (when converting to the h2o frame object it comes around 800mb)\\n\\nThings i have done :\\n1.) Gave enough memory to java heap while running h2o cluster (java -Xmx9g -jar h2o.jar)\\n2.) Build the mxnet from source for gpu\\n3.) Monitored the gpu and system via nvidia-smi and system monitor. At no point do they eat up all the ram to show \\out of memory\\ issue. I still will be having around 2-3gb free before the error shows up\\n4.) Have tried with tensorflow-gpu(build from source). Checking the pip list made sure that its installed but during model creation in R it gives the error :\\n    Error: java.lang.RuntimeException: Unable to initialize the native Deep Learning backend: null\\n 5.) The only method i got it the h2o deepwater to work with all the backend and gpu is through docker setup provided in the installation tutorials. \\n\\nI wanted the same functionality in my laptop instead of using docker. Any help or advice will be greatly appreciated !","2327":"guys i am new to h2o. have some doubts regarding it. how to run a model file trained via h2o to do predictions on inputs on a web or android app. please help.","2328":"anyone here","2329":"@syam3526  I have not yet worked in implementation level. But i what i think is that you have to create a server containing R code which loads the h2o trained model. The input will be going as data frame into your model and you will be getting the output. The android app will serve as the frontend which takes the input , pass it to server process it, then display the output in the app itself. Same goes for the web application. ","2330":"@michalkurka Thank you. Another question about preprocessing in H2O Steam Prediction Service Builder using python. Are there any more explanations: 1) how curl POST should be formatted for python (and java) preprocessing codes (in spam detection example I see ```curl -X Post --data \\$text\\ http:\/\/localhost:55001\/pypredict```, maybe API supports more options to pass other format instead of raw string for preprocessing step); 2) If there is support for other than raw string POST format for preprocessing, how preprocessing script should catch POST'ed data? 3) Are there options to host several models under same port? If there are, where I could find example? Thank you for you support again!","2331":"Hi there, can anybody help me with this issue: https:\/\/stackoverflow.com\/questions\/48094985\/how-to-get-h2o-modelmetricsbinominal-using-rest-api-with-retrofit-and-h2o-bindin","2332":"Hi, I ran into a problem running `xgboost` with `h2o` when one of the column names is in unicode. Is this a known bug? The problem disappeared when I renamed the column. If it's an unknown one, I can file a bug report","2333":"@cdagnino not sure if that\\u2019s new or not, can you report and mark with the \\u201cXGBoost\\u201d component in JIRA?  thanks!","2334":"@sooraj2189 @syam3526 see http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/save-and-load-model.html or http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/productionizing.html","2335":"@ledell  saw that. any way to deploy using aws or azure. anyone have steps to do so. please reply.","2336":"tried tried to deploy the war file created on azure and aws but deployment is not working correctly","2337":"Could someone explain how to scale application with MOJO file to multiple requests? From example when I use ```java -jar jetty-runner-9.3.9.M1.jar --port 55001 tmp_war.war``` the deployed process doesn't scale to available resources (number of cores in my system). Do I need to configure java, jetty somehow or war file produced by H2O Steam Prediction Service Builder decides upon that?","2338":"@gediminaszylius If the issue is handling multiple simultaneous requests, couldn't you launch the same service on multiple ports & servers?  ","2339":"Hi all, I would like to report a bug I found using the https:\/\/github.com\/h2oai\/h2o-3\/blob\/master\/h2o-algos\/src\/main\/java\/hex\/splitframe\/ShuffleSplitFrame.java . It does not create frames with the desired size. I am using the iris dataset (having 150 rows) and the following code to split it:\\n```\\nFrame[] splitFrames = ShuffleSplitFrame.shuffleSplitFrame(frameIris, new Key[]{Key.make(), Key.make()},\\n\\t            new double[]{0.5, 0.5}, 123456789l);\\n```\\nSo I am expecting to get two frames back each with size 75, but what I get is a frame with size 65 and a frame with size 85. I tried using different ratios, but I always get frames with unexpected sizes. Do I use the function wrong in some way or is it a bug? I didn't found an issue in your open JIRA for this.","2340":"@ledell There you go: https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-5207?filter=-2","2341":"I'm trying to find an example in docs that does batch `.csv`  prediction.  I found [this](http:\/\/projects.rajivshah.com\/blog\/2016\/08\/22\/H2O_prod\/) but I couldn't get it to work (the post itself admits some of the things it has are outdated). Is there any tutorial or updated docs I could look at? Is `PredictCsv` still the right choice?","2342":"@SimonSchmid splitframe gives approximate splits (this is optimized for big data).  on bigger data, the expected value is that it will be close to the ratio that you specify, but on small data like iris, there will be more variability","2343":"@SimonSchmid Explained here: http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/data-munging\/splitting-datasets.html","2344":null,"2345":"@syam3526 Check out http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/cloud-integration.html","2346":"thanks @cdagnino ","2347":"@cdagnino an example of batch csv prediction, in what language?  Not sure if you are talking about using MOJO\/POJO models or binary models in H2O memory.  Let me know...","2348":"@geislefc Thanks for pointing this out. I'm not web developer, but I guess it may be hard to change models (you need to shut down\/run multiple instances and control scaling by some third party tools I suppose). For example, there exist other frameworks like Openscoring which lets you deploy PMML model files to production and it scales without problems natively, this is very helpful. Now for me H2O Steam Prediction Service Builder will not be useful enough, I will still need to do java coding in order to build scalable REST API around MOJO files i guess. Maybe there are other options there?","2349":"@ledell Oh sorry, I meant MOJO\/POJO to predict on batch `.csv` (for example, using `java -cp .:h2o-genmodel-5.jar hex.genmodel.tools.PredictCsv --mojo mojo_file.zip --input input.csv --output output.csv`). I can get toy examples to work, but when I try with the real thing I get java null pointer exceptions. Many of the columns are categorical, so I'm wondering if that's an issue. I Imagine they might get coded in a different way in the `.csv` than how `h2o` expects them, but I don't know where to check that (it might be something different though, of course)","2350":"I haven't found a clear tutorial or documentation on this","2351":"Also, it seems to me that the `mojo` for `xgboost`doesn't work. If that's also an unkown bug I can put it on `jira`","2352":"Does xgboost in CPU mode should scale to available cores or there are issues with that? Because now on Linux xgboost doesnt scale, but native H2O GBM scales to all cores.","2353":"Hi All, Could you please confirm if I can score H2o MOJO and PJO models in UNIX (AIX, Solaris, HP-Itanium) platfroms apart from Linux and Windows ?\\n\\nMy team is using the Linux and windows machines to fit the h2o models. They are generating the MOJO and POJO models and some of the MOJO and POJO model need to be deployed on Solaris, AIX and HP-itanimum platforms having Java 8. I believe it should be fine as MOJO and POJO are only dependent on Java 7\/8 and h2o-genmodel.jar.\\n\\n**From H2o doc:-**\\nH2O-generated MOJO and POJO models are intended to be easily embeddable in any Java environment. The only compilation and runtime dependency for a generated model is the h2o-genmodel.jar file produced as the build output of these packages. This file is a library that supports scoring. For POJOs, it contains the base classes from which the POJO is derived from. (You can see \\u201cextends GenModel\\u201d in a POJO class. The GenModel class is part of this library.) For MOJOs, it also contains the required readers and interpreters. The h2o-genmodel.jar file is required when POJO\/MOJO models are deployed to production.   ","2354":"@gediminaszylius I remember reading `xgboost` on `h2o` wasn't yet multi-core (but don't take my word for it)","2355":"@cdagnino Thank you for approval. At the time I read the docs to me it seemed that multicore is not supported for iOS and should work on Linux. ","2356":"@gediminaszylius Regarding your comment, \\I will still need to do java coding in order to build scalable REST API around MOJO files i guess. Maybe there are other options there?\\u201d  There is a function in R called `h2o.predict_json` which allows you to score using a MOJO file in R (no Java needed).  I don\\u2019t think there is a python equivalent at the moment","2357":"@ggauravuee yeah the H2O POJO\/MOJO works on all unix platforms that i am aware of, wherever you can install Java","2358":"@ledell Thanks Erin !\\n","2359":"Let me how can download the h2o-bindings source code for 3.14.x and 3.15.x versions. I know in the previuos versions of h2o (h2o-3.12.0.1.zip) it comes under the zip file (like - h2o-bindings-3.12.0-sources.jar). But it's not in the h2o-3.15.0.4007.zip file.  Can I get it from Maven repository of h2o?","2360":"@ggauravuee this page has links to all our stable version download pages and the zip files are there https:\/\/github.com\/h2oai\/h2o-3\/blob\/master\/Changes.md","2361":"Nightly versions you can find by changing the URL for the current nightly:  http:\/\/h2o-release.s3.amazonaws.com\/h2o\/master\/4007\/index.html","2362":"i think that\\u2019s teh one you\\u2019re looking for","2363":"are you sure its not in that zip file?","2364":"@ledell I haved looked into it but I can see that latest h2o versions zip file doesn't contain the source code jar for h2o-bindings. These only have the compiled classes  in\\h2o-bindings-3.16.0.jar\\ . I am looking for a source code (java files) for the h2o-bindings as I need to fix\/change some behaviour in the h2o-bindings java source code.","2365":"@cdagnino support for multicore already exists, multi-node is on the roadmap for Q1","2366":"@ledell Ahhm, thanks for letting us know","2367":"@ggauravuee let me try downloading the latest nightly zip real quick to verify, i dont know why we would have removed that, but if its gone, ill find out what happened to it..","2368":"@gediminaszylius How are you using `xgboost`? Are you using a `mojo` or `pojo` of it? I've been unable to use it that way","2369":"@cdagnino docs say that we have a MOJO for xgboost: http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/data-science\/xgboost.html so it should be working","2370":"you can also check if a model has MOJO support by inspecting the model.  in R its like this:\\n```\\n> fit <- h2o.xgboost(x = 1:4, y = 5, training_frame = as.h2o(iris))\\n  |=======================================================| 100%\\n  |=======================================================| 100%\\n> fit@have_mojo\\n[1] TRUE\\n```","2371":"I need some advise for - how to handle data larger than h2o cluster memory (RAM). I have a dataset of 50 GB+ (20 Million rows and 505 columns) but I can allocate maximum 55 GB to h2o cluster. As per h2o doc, I need 4 times of the memory in h2o cluster. Is there any workaorund for it like - spill data over harddisk\/virtual memory (SSD based harddisk) or any other alternative apart from adding more memory to the h2o cluster. I am running GLM (Logistic Regression), RF etc.","2372":"Hi @all - I am trying to launch Driverless Ai after `docker - run` but localhost:12345 is not loading in Chrome","2373":"@ledell Thanks for the answer. Still, i need to deploy scalable REST API so it doesn't solve my case. Anyway, are there any plans to make xgboost scalable at least in multi core - single node setting?","2374":"@ggauravuee no H2O does not spill to disk.  you need more memory\\u2026 doesn\\u2019t have to be on a single machine though\\u2026 ","2375":"an alternative is to use the checkpointing feature","2376":"you can load 25% of the data into H2O, train a model and save the model.  then remove that data and load the next 25% (or simply restart the H2O cluster), and then use the checkpointing feature to restart training with the new data","2377":"this works better on GLM, DNN, works okay on RF and doesn\\u2019t work that well on GBM","2378":"@gediminaszylius yes we are working on improving xgboost performance in H2O.  what\\u2019s the bottleneck that you\\u2019re having?  are you doing multiclass and trying to predict a lot of classes (thats a known scalability limitation in xgboost)","2379":"ok sorry i read your post above, you\\u2019re saying that xgboost is not working on multiple cores?","2380":"hey @michalkurka I thought you said that h2o xgboost works on multicore (just not yet in multimode)?  @gediminaszylius mentioned above that he\\u2019s not seeing it scale to multiple cores\\u2026 not sure if that\\u2019s expected (if i got my information mixed up when I asked you about multicore xgb a few weeks ago)","2381":"@ledell Thanks for pointing out. Now I only care about single instance xgboost scaling during training on MULTI CORE processor (specifically EC2 instance with 32 cores) and it only uses 1 core on Linux, even though native H2O GBM uses all 32 cores like a charm. ","2382":"About MOJO REST API multithreading issue that i asked earlier:  i found solution to simply remove ```synchronized``` keyword from ```predictModel``` and ```predict```  methods and commented timing statistics functionality for now (it seems that synchronization was done only due to time statistics feature) in ```ServletUtil-TEMPLATE.java``` file. After rebuilding, MOJO REST API it scales without problems. I haven't investigated much but I guess there should be other way to implement timing statistics features without sacrificing scalability of API. I see that H2O - Steam repository is not maintained much, but I would suggest to fix this issue as deploying scalable REST API directly is necessary requirement for production-ready ML APIs and those relatively simple changes are really necessary for data scientist that don't code in java.","2383":"@ledell Thanks for the link! From a quick read, it seems that the `MOJO` for `xgboost` requires a different `h20-genmodel`? \\n\\nSaving it this way\\n`h2o.download_mojo(xgboostmodel, get_genmodel_jar = TRUE)`\\n\\nand then trying it with `java java -cp .:h2o-genmodel.jar`(etc etc) game me an error (while the exact same code with the native `h2o` `gbm` works fine.\\n\\nI can write a `stackoverflow` question if that's better, I just wanna make sure I even understand the issue\\n\\n","2384":"@cdagnino I guess you got error that i got related to logging class not found. I have solved that by manually adding apache-commons-logging.jar downloaded manually to class path","2385":"There is already a [ticket](https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-5195) for this bug if you are getting it too.","2386":"@gediminaszylius I got a different error, but it does seem related, thanks for pointing this out! Could you be a bit more explicit about your solution? I see you used a command like this:\\n\\n`--form mojo=@tmp_dir\/XGBoost_model_python_1514898693837_59.zip --form jar=@tmp_dir\/h2o-genmodel.jar`\\n\\nHow do you add `apache-commons-logging.jar` to the class path?","2387":"@cdagnino For this particular case I havent, because I dont know how (started learning java recenlty only because of issues I face :)). I added this library during simple csv prediction not via REST API but csv prediciton tool provided: ```java -Xmx4g -cp .:\/path\/to\/MOJO\/h2o-genmodel.jar:\/path\/to\/MOJO\/apache-commons-logging.jar hex.genmodel.tools.PredictCsv --mojo \/path\/to\/mojo\/XGBoost_model_python_1507724679829_1.zip --input \/path\/to\/MOJO\/input_test.csv --output \/path\/to\/MOJO\/output.csv --decimal```","2388":"@ledell xgboost in H2O does support multicore, thanks to OpenMP. The multicore implementation will only be available if the system itself supports it (it has the right version of libraries). If the requirements are not satisfied we will use a fallback that is single core only.","2389":"thanks for the clarification @michalkurka let me make sure we add this footnote to the docs","2390":"@michalkurka So what would be requirements to support for xgboost to work fine on multiple cores?","2391":"Dowes anyone get sparkling-water to work on multiple machines?","2392":"when I setup mesos cluster on 1 machine (with zoo keeper, master, and slave all in the same machine), the following command works\\nMASTER=mesos:\/\/zk:\/\/192.168.2.3:2181\/mesos .\/bin\/run-sparkling.sh\\nand the flow notebook started perfectly.\\nBut when another mesos agent (slave) joined the mesos pool, I no longer can start sparkling water by the same command","2393":"The list of variables I set in spark-env.sh in both machines includes: JAVA_HOME,   HADOOP_CLASSPATH,    SPARK_LOCAL_IP,    MESOS_NATIVE_JAVA_LIBRARY,    SPARK_WORKER_DIR","2394":"Haha, sorry guys, as it turned out, it is a network error","2395":"@gediminaszylius Thanks!! I added this comment to your bug report in case it helps anyone","2396":"@schwannden FYI, there is a dedicated sparkling-water Gitter too, best to ask questions over there bc that\\u2019s where the SW devs hang out :)","2397":"> @ggauravuee let me try downloading the latest nightly zip real quick to verify, i dont know why we would have removed that, but if its gone, ill find out what happened to it.. @ledell ,  Did you get a chance to look into it. Thanks","2398":"@ggauravuee here\\u2019s what i see in the folder, is this what you see\/expect?\\n```\\nme@mbp: h2o-3.17.0.4169 \\ud83d\\udcbe  tree .\\n.\\n\\u251c\\u2500\\u2500 R\\n\\u2502\\u00a0\\u00a0 \\u2514\\u2500\\u2500 h2o_3.17.0.4169.tar.gz\\n\\u251c\\u2500\\u2500 bindings\\n\\u2502\\u00a0\\u00a0 \\u2514\\u2500\\u2500 java\\n\\u2502\\u00a0\\u00a0     \\u2514\\u2500\\u2500 h2o-bindings-3.17.0.zip\\n\\u251c\\u2500\\u2500 h2o.jar\\n\\u2514\\u2500\\u2500 python\\n    \\u2514\\u2500\\u2500 h2o-3.17.0.4169-py2.py3-none-any.whl\\n\\n4 directories, 4 files\\n```","2399":"[![blob](https:\/\/files.gitter.im\/h2oai\/h2o-3\/I24S\/thumb\/blob.png)](https:\/\/files.gitter.im\/h2oai\/h2o-3\/I24S\/blob)","2400":"@ledell , In h2o-3.2.5.zip, there was a source code also for the java binding APIs (REST webservices)\\n  ","2401":"As it was mentioned: \\xgboost in H2O does support multicore, thanks to OpenMP. The multicore implementation will only be available if the system itself supports it (it has the right version of libraries). If the requirements are not satisfied we will use a fallback that is single core only.\\ How can i check if my system has OpenMP, do i need to add ```omp4j.jar``` in class path when i launch h2o or what? I use h2o on aws ec2 Linux system. Are there any more requirements to support multicore xgboost on aws Linux?","2402":"@ggauravuee ok yes i see the difference.  3.8.* was a long while ago, not sure why we made the change.  perhaps @michalkurka or @mmalohlava knows.  Can you remind me what it is that you\\u2019re trying to do with sources.jar that you can\\u2019t do now?","2403":"I'm trying to get the AUC on a holdout set using a particular threshold (not default max-f1). Does H2O in R have the ability to calculate that or will I need to calculate it myself?","2404":"`h2o.metrics()` has a lot of metrics for different thresholds, but doesn't include AUC. `h2o.performance()` doesn't have a parameter for thresholds. Neither does `h2o.auc()`, but `h2o.confusionMatrix()` does have a parameter for thresholds","2405":"@tmcfl are you sure you have a binary classification model?  id expect that AUC would be there\\u2026 can you post some code to show what it returns?","2406":"Sure! I use \\n`tune2_test_performance <- h2o.performance(gbm_tune2, newdata = jan_test.hex)` to create a H2OBinomialMetrics object using my holdout set: `jan_test.hex`\\n\\nThe standard AUC returned is for the F1-optimal threshold, but I'd like to get the AUC using a different threshold","2407":"when I print `tune2_test_performance` or use `h2o.auc(tune2_test_performance)` it's always the AUC for the max F1 threshold","2408":"with `h2o.confusionMatrix(tune2_test_performance, thresholds = myThreshold)` I can specify a threshold, so I was wondering if there's a way to get AUC in a similar way","2409":"[![Screenshot of RStudio (1-17-18, 4-52-31 PM).png](https:\/\/files.gitter.im\/h2oai\/h2o-3\/d4y5\/thumb\/Screenshot-of-RStudio-_1-17-18_-4-52-31-PM_.png)](https:\/\/files.gitter.im\/h2oai\/h2o-3\/d4y5\/Screenshot-of-RStudio-_1-17-18_-4-52-31-PM_.png)","2410":"```\\n> tune2_test_performance\\nH2OBinomialMetrics: gbm\\n\\nMSE:  0.03704854\\nRMSE:  0.19248\\nLogLoss:  0.1308815\\nMean Per-Class Error:  0.2533689\\nAUC:  0.9234187\\nGini:  0.8468374\\n\\nConfusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\\n          0   1    Error       Rate\\n0      3040  94 0.029994   =94\/3134\\n1        82  90 0.476744    =82\/172\\nTotals 3122 184 0.053237  =176\/3306\\n\\nMaximum Metrics: Maximum metrics at their respective thresholds\\n                        metric threshold    value idx\\n1                       max f1  0.232956 0.505618 137\\n2                       max f2  0.040720 0.613208 282\\n3                 max f0point5  0.309795 0.513006  99\\n4                 max accuracy  0.359951 0.951906  67\\n5                max precision  0.539542 1.000000   0\\n6                   max recall  0.000866 1.000000 397\\n7              max specificity  0.539542 1.000000   0\\n8             max absolute_mcc  0.232956 0.477822 137\\n9   max min_per_class_accuracy  0.034457 0.860465 293\\n10 max mean_per_class_accuracy  0.034457 0.869926 293\\n```","2411":"if i want to use h2o to develop neural network by java, what denpences do i have?","2412":"the docmention of java is so bad","2413":" there is no guide to tell how to develop this by java","2414":"```\\n<properties>\\n        <h2o.version>3.16.0.4<\/h2o.version>\\n    <\/properties>\\n\\n    <dependencies>\\n        <dependency>\\n            <groupId>ai.h2o<\/groupId>\\n            <artifactId>h2o-core<\/artifactId>\\n            <version>${h2o.version}<\/version>\\n        <\/dependency>\\n\\n        <dependency>\\n            <groupId>ai.h2o<\/groupId>\\n            <artifactId>h2o-genmodel<\/artifactId>\\n            <version>${h2o.version}<\/version>\\n        <\/dependency>\\n\\n        <dependency>\\n            <groupId>ai.h2o<\/groupId>\\n            <artifactId>h2o-algos<\/artifactId>\\n            <version>${h2o.version}<\/version>\\n        <\/dependency>\\n\\n    <\/dependencies>\\n```\\nthe dependencies now i have, but it is not enough","2415":"> @ggauravuee ok yes i see the difference.  3.8.* was a long while ago, not sure why we made the change.  perhaps @michalkurka or @mmalohlava knows.  Can you remind me what it is that you\\u2019re trying to do with sources.jar that you can\\u2019t do now? \\n@ledell I am mainly using the H2o binding APIs (java APIs) and not the python or R. It's mostly working fine but I need to change some of the behaviour\/logic of the h2o binding APIs (like making some classes public which are private by default, extra validation code etc.). So, it will be good to have source code available for h2o binding APIs (or let me know how I can generate it from h2o source from the git hub) ","2416":"@ggauravuee hello, i haven seen your talk. you are mainly using java APIs, do you have some examples to help me learn how to use? Very Thanks","2417":"whick class can help me to convert  `Frame` to `Key<Frame>`\\uff1f","2418":"Hi I am trying to use h20 for classification with labels being 0 or 1 in svmlight file, and it says labels need to be two class categorical. I changed it to \\YES\\ and  \\NO\\ and it still doesn't work. Documentation is not helpful at all in this regard. Any help will be appreciated.","2419":"@sjsdfg \\n```java\\nFrame f = ...\\nKey key = f._key\\n```","2420":"@sjsdfg there is project called h2o-droplets - which contains examples of Java projects:  https:\/\/github.com\/h2oai\/h2o-droplets","2421":"@ggauravuee  i do not remember motivation, but found the change: https:\/\/github.com\/h2oai\/h2o-3\/pull\/1278\/files (CC: @michalkurka @abal5). However, we can include source code ","2422":"I see that final backend is compiled c++ code with documentation mentioning g++ 4.7 and Ubuntu 14.04, my question reduces to: 1) should I include OpenMP c++ libraries somewhere in order to support multithreaded xgboost; 2) After some digging into h2o code for xgboost I see ```NativeLibLoader``` usage and after digging more it seems that it is searching for native xgboost packages or something, is it possible to compile xgboost separately and use via h2o then? And how could i include it in h2o search path?\\n> As it was mentioned: \\xgboost in H2O does support multicore, thanks to OpenMP. The multicore implementation will only be available if the system itself supports it (it has the right version of libraries). If the requirements are not satisfied we will use a fallback that is single core only.\\ How can i check if my system has OpenMP, do i need to add ```omp4j.jar``` in class path when i launch h2o or what? I use h2o on aws ec2 Linux system. Are there any more requirements to support multicore xgboost on aws Linux?","2423":"@gediminaszylius  regarding your questions:\\n1) `libomp` needs to be available for linker - normally you do not need to do anything, however, you can help by setting LD_LIBRARY _PATH (linux, for osx, the variable is slightly different)","2424":"2) yes, you can compile your own xgboost (you need to get JVM binding library - output of `jvm_packages\/xgboost4j` ) and put it on classpath: `java -cp 'my-xgb.jar:h2o.jar`\\n\\nmy-xgb.jar need to have binding library which follows the following pattern: `lib\/linux_64\/libxgboost4j.so`","2425":"@sjsdfg yeah sorry our Java docs are so sparse\\u2026 we focus most of our time on making the R and Python docs great (at the expense of Java\\u2026) :-(","2426":"if you\\u2019d like to help us improve our docs, let me know and i can show you where they are located in the h2o-3 repo\\u2026 easy to update via a pull request","2427":"@tmcfl oops i missed the obvious answer to your question which is\\u2026 AUC is determined w\/o respect to any threshold, that\\u2019s why it\\u2019s not there","2428":"AUC is a global summary (across all thresholds) of the ability to properly rank positve vs negative examples","2429":"most metrics don\\u2019t rely on thresholds, only the ones that deal with 0\/1 loss","2430":"@mmalohlava thanks a lot","2431":"i realized the Java is not a good option for H2O,  so i changed to Python.","2432":"hello, i want to do a regression job with deeplearning, and i read the docs about `H2ODeepLearningEstimator`. i found the list of activations are \\tanh\\ \\tanh_with_dropout\\ \\rectifier\\ \\rectifier_with_dropout\\ \\maxout\\ \\maxout_with_dropout\\ there is no \\None\\ or \\IDENTITY\\ function for last layer.","2433":"which one should be my choice?","2434":"Or i need to use the backend native APIs, such as \\mxnet\\ \\caffe\\ \\tensorflow\\. ","2435":"@sjsdfg Are you trying to use H2ODeepLearningEstimator or DeepWater?","2436":"H2ODeepLearningEstimator doesn\\u2019t use those third-party backends, it uses native H2O Java code ","2437":"If you\\u2019re new to H2O DL, I recommend checking out the DL booklet: http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/booklets\/DeepLearningBooklet.pdf","2438":"btw, the activation functions apply to the hidden layers of the network, you don\\u2019t set different ones at each layer (therefore there is no need to have an different set of options for the last layer).","2439":"oh, thanks. The `H2ODeepLearningEstimator` and `H2ODeepWaterEstimator` are all in the same page. i thought that is an attribute of  `H2ODeepLearningEstimator`. It is my fault","2440":"that part is correct... `activation` is an argumnet to `H2ODeepLearningEstimator`","2441":"i still can't understand if i don't set specific activation for last layer,  how to distinguish what they do?\\ni mean normally `softmax`,`sigmoid` for classfication and `identity` for regression.","2442":"it will do the right thing automatically, no need to worry about it","2443":"all you need to do is specify which activation function you want for internal\/hidden layers","2444":"thank you very much","2445":"H2O does a lot of stuff automatically\\u2026 another thing you will notice is that you don\\u2019t need to encode your categorical features.  also happens automatically","2446":"i'll try","2447":"or normalize the inputs, etc","2448":"more attention on feature enginner? i get it.","2449":"```\\nExamples\\n    --------\\n      >>> import h2o\\n      >>> from h2o.estimators.deeplearning import H2ODeepLearningEstimator\\n      >>> h2o.connect()\\n      >>> rows = [[1,2,3,4,0], [2,1,2,4,1], [2,1,4,2,1], [0,1,2,34,1], [2,3,4,1,0]] * 50\\n      >>> fr = h2o.H2OFrame(rows)\\n      >>> fr[4] = fr[4].asfactor()\\n      >>> model = H2ODeepLearningEstimator()\\n      >>> model.train(x=range(4), y=4, training_frame=fr)\\n```\\n\\ni can't find description of method `train` on docs http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-py\/docs\/modeling.html#h2odeeplearningestimator or source code http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-py\/docs\/_modules\/h2o\/estimators\/deeplearning.html#H2ODeepLearningEstimator","2450":"i find the docs, it is inherited","2451":"what's the meaning of epochs and iterations in this framework?","2452":"normally, iteration is a subset of epoch.  But i call `H2ODeepLearningEstimator.scoring_history()`, i found the iteration is larger than epoch.","2453":"@mmalohlava Thanks for detailed response! I will try things out","2454":"@sjsdfg from the DeepLearnign booklet: \\n> epochs: Specifies the number of iterations or passes over the training dataset (can be fractional). For initial grid searches, we recommend starting with lower values. The value allows continuation of selected models and can be modified during checkpoint restarts. The default is 10.","2455":"> train samples per iteration: Specifies the number of training samples (globally) per MapReduce iteration.","2456":"iteration == map reduce iteration","2457":"more info in the Deep Learning Booklet","2458":"@ledell thank you so much","2459":"@mmalohlava I have tried option 2) and tried to add my compiled xgboost version, however i have noticed that ```NativeLibLoader``` java class, which is loaded by ```XGBoostExtension``` doesn't have methods like ```NativeLibLoader.getLoadedLibraryName()``` in recent xgboost4j versions, I only found it in xgboost distribution forked by H2O. In order not to change code manually, i like to try option 1), when I launch ```g++ --version``` i get ```g++ (Ubuntu 5.4.1-2ubuntu1~16.04) 5.4.1 20160904```, so as your documentation says that xgboost is compiled with g++ 4.7 version, do I need to downgrade g++ from 5.4.1 to g++ 4.7 and xgboost then should find necessary openmp libraries and multithreading should work?","2460":"Regarding comment:\\n> \\nmy-xgb.jar need to have binding library which follows the following pattern: `lib\/linux_64\/libxgboost4j.so`\\n\\nAfter xgboost4j is compiled I see `lib\/libxgboost4j.so` instead of `lib\/linux_64\/libxgboost4j.so`, do I need to change settings somewhere to strictly meet `lib\/linux_64\/libxgboost4j.so` and cannot use `lib\/libxgboost4j.so` as it wont be activated?","2461":"Does anybody know how we get model's cross validation summary in python?\\nIn Scala it's\\nleader._output._cross_validation_metrics_summary\\nWe get a frame with rows being name of score, and column being the result of each cv","2462":"i think this @schwannden http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-py\/docs\/model_categories.html?highlight=cross_validation#h2o.model.ModelBase.cross_validation_metrics_summary","2463":"@ledell  Thanks, this is the one I am looking for!","2464":":thumbsup: ","2465":"Does anybody know why there is no cross validation metrics summary for stacked ensembled model in AutoML (I am using the python library)?\\nAfter running autoML, the leader (which is a stacked ensembled model) does not contain cv metrics summary, but then I get the model that ranked 4th (XRT model), and I got the cv scores I needed.","2466":"@schwannden i just replicated this and was able to get the cv metrics...","2467":"after you train AutoML, grab the model id for one of the SEs:\\n\\n```\\nIn [7]: se = h2o.get_model(\\StackedEnsemble_BestOfFamily_0_AutoML_20180122_233116\\)\\nIn [8]: se.cross_validation_metrics_summary\\nOut[8]: Model Details\\n=============\\nH2OStackedEnsembleEstimator :  Stacked Ensemble\\nModel Key:  StackedEnsemble_BestOfFamily_0_AutoML_20180122_233116\\nNo model summary for this model\\n\\n\\nModelMetricsBinomialGLM: stackedensemble\\n** Reported on train data. **\\n\\nMSE: 0.0466445569031\\nRMSE: 0.215973509725\\nLogLoss: 0.235988104268\\nNull degrees of freedom: 302\\nResidual degrees of freedom: 301\\nNull deviance: 411.422034256\\nResidual deviance: 143.008791187\\nAIC: 147.008791187\\nAUC: 1.0\\nGini: 1.0\\n```","2468":"@schwannden if you can make a reproducible example using the example from the AutoML User Guide page that shows it not there, i will take a second look","2469":"but on my end it looks like it\\u2019s there","2470":"this should also work (if your leader is SE):\\n```\\naml.leader.cross_validation_metrics_summary\\n```","2471":"Hi, @ledell \\nYou forget the parenthesis, so what you have in the output is the model summary. Cross validation summary will have scores for each validation round","2472":"```\\nIn [1]   h2o.get_model('StackedEnsemble_AllModels_0_AutoML_20180123_142131').cross_validation_metrics_summary()\\nout[1]\\nNo cross-validation metrics summary for this model\\nIn [2]   h2o.get_model('XRT_0_AutoML_20180123_113936').cross_validation_metrics_summary()\\nout[2]\\nCross-Validation Metrics Summary: \\n\\t\\t\\tmean\\tsd\\tcv_1_valid\\tcv_2_valid\\tcv_3_valid\\naccuracy\\t0.6416076\\t0.0071293\\t0.6442777\\t0.6281426\\t0.6524024\\nauc\\t\\t0.7372624\\t0.0080708\\t0.7349331\\t0.7245943\\t0.7522596\\nerr\\t\\t0.3583924\\t0.0071293\\t0.3557223\\t0.3718574\\t0.3475976\\nerr_count\\t955.0\\t19.087517\\t948.0\\t991.0\\t926.0\\n```","2473":"The 2dimDataTable returned by cross_validation_metrics_summary() for XRT model is what I am looking for","2474":"Haha @ledell  here is why\\nhttps:\/\/github.com\/h2oai\/h2o-3\/blob\/ce0308a33234759443672f660ad81fc0442372ba\/h2o-automl\/src\/main\/java\/ai\/h2o\/automl\/AutoML.java#L1022\\nSo H2O team haven't implement cross validation for StackedEnsemble yet, they should add this line\\n```\\nstackedEnsembleParameters._nfolds = buildSpec.build_control.nfolds\\n```","2475":"I want to develope H2O with Pycharm and view source code by `ctril +Left mouse click`.  How do i do?","2476":"I am developing it with vim, and I use the vim command (gd), it worked","2477":"@schwannden thank you.I am not familiar with vim","2478":"> this works better on GLM, DNN, works okay on RF and doesn\\u2019t work that well on GBM\\n@ledell , It looks that h2o doc is not updated for checkpoint feature, doc says it's available for GBM, DRF, Deep Learning.  http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/data-science\/algo-params\/checkpoint.html?highlight=checkpoint","2479":"@schwannden yes we have implemented it (i was the one who did, so i know it\\u2019s there\\u2026). you are looking at an old version of the code on github.  it\\u2019s been in H2O since 3.16, so maybe you just need to update H2O?","2480":"@sjsdfg that sounds like a PyCharm question, not an H2o question","2481":"@ledell I am looking at the code in 3.17.0 version, and it still has the TODO: Add fold_assignment comment in stack method in AutoML.java. Were you able to get the cross_validation_metrics_summary() as I mentioned before? The 2DimTable containing the detailed scores for each validation?\\n```\\nIn [1]   h2o.get_model('StackedEnsemble_AllModels_0_AutoML_20180123_142131').cross_validation_metrics_summary()\\nout[1]\\nNo cross-validation metrics summary for this model\\nIn [2]   h2o.get_model('XRT_0_AutoML_20180123_113936').cross_validation_metrics_summary()\\nout[2]\\nCross-Validation Metrics Summary: \\n\\t\\t\\tmean\\tsd\\tcv_1_valid\\tcv_2_valid\\tcv_3_valid\\naccuracy\\t0.6416076\\t0.0071293\\t0.6442777\\t0.6281426\\t0.6524024\\nauc\\t\\t0.7372624\\t0.0080708\\t0.7349331\\t0.7245943\\t0.7522596\\nerr\\t\\t0.3583924\\t0.0071293\\t0.3557223\\t0.3718574\\t0.3475976\\nerr_count\\t955.0\\t19.087517\\t948.0\\t991.0\\t926.0\\n```","2482":"@schwannden the \\u201cTODO: Add fold_assignment\\u201d controls the type of folds (random, modulo), right now its hard-coded to random.  So it\\u2019s still doing CV for the ensembles.","2483":"I do see that you\\u2019re getting `No cross-validation metrics summary for this model` but unless you post your data\/code, i don\\u2019t think i can help","2484":"not sure what\\u2019s happening there, very strange","2485":"@schwannden ok i see now what\\u2019s happening\\u2026 the python method to grab the CV metrics is not working.  you\\u2019re right!  here\\u2019s a reproducible example:\\n```\\nimport h2o\\nfrom h2o.automl import H2OAutoML\\n\\nh2o.init()\\n\\ntrain = h2o.import_file(\\https:\/\/s3.amazonaws.com\/erin-data\/higgs\/higgs_train_10k.csv\\)\\nx = train.columns\\ny = \\response\\\\nx.remove(y)\\ntrain[y] = train[y].asfactor()\\n\\naml = H2OAutoML(max_models=5)\\naml.train(x = x, y = y, training_frame = train)\\naml.leader.cross_validation_metrics_summary()\\n```","2486":"however, if you print the model, you can actually see the CV metrics in there.  they are just not accessible via `cross_validation_metrics_summary()` for some reason.  This also affects R.  Thank you for the bug report!  you can follow the progress in this JIRA.  i have also posted an example of how to access the metrics using alternate methods (which you can use in the meantime) in the JIRA description: https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-5258","2487":"@ledell With your code, I get cross validation summary, but only averaged result, the example output I gave above contains \\mean and std of each score for each fold\\.\\nThe thing I really need is the score for \\each fold.\\ And I believe this information is not provided, either on python or on Java\/Scala.","2488":"ah ok, in that case you\\u2019ll probably have to wait for the real `cross_validation_metrics_summary()` to get added, or you\\u2019d have to calculate it yourself by getting the metrics from each of the CV models","2489":"But I can't get each CV model either, neither in python nor in Scala","2490":"Ok, i see\\u2026 so none of the cv stuff is copied over properly.  so the stacked ensemble is a bit different than other models because we don\\u2019t do a full CV of the ensemble process \\u2014 so there aren\\u2019t really CV models of the ensemble, there are CV models for the metaleraner.  The metrics that you see are CV metrics for the metalearner, and so I guess another approach is to just dig into the ensemble model and grab the `cross_validation_metrics_summary()` from the metaleraner object.","2491":"```\\nmetalearner = h2o.get_model(aml.leader.metalearner()['name'])\\nmetalearner.cross_validation_metrics_summary()\\n```\\n","2492":"Cross-validation metrics and validation metrics are copied directly from the metalearner into those slots in the Stacked Ensemble.  However, training metrics need to be calculated from scratch by scoring the training frame, so although you can copy the CV\/valid metrics from metalearner, dont\\u2019 copy the training metrics.","2493":"But since we are talking only about CV metrics, that\\u2019s not really a concern (just a caveat worth pointing out).","2494":"If i remember correctly, i decided it was best to not copy the CV models from the metalearner bc the metalearner is trained on different data so it\\u2019s not acceptable to consider those \\u201cCV models for the ensemble\\u201d.  whereas the metrics object, the metrics are the same (even though they were generated with level-one data and not the original data).  ","2495":"Also, is there a way to create a H2OContext in Scala, without turning on the flow UI? Just felt it's a bit annoying with an unused service up and running.","2496":"@ledell  Thank you so much! Yes I noticed that meta learner has the cv metrics and models I needed, but wasn't sure about the relationship between metalearner and StackedEnsemble. Currently we only stack once right? So that metalearner's CV metrics represented the cv score on level one data, which is probably the closest thing I can get for CV metrics?","2497":"yes we stack once in Stacked Ensemble.  yep that\\u2019s the closest thing.  there is another more principled way to do it (which involves creating an order of magnitude more models) but we chose to do it this way because the performance estimates are pretty much the same","2498":"this way we only have to do CV once on each of the base learners + CV of metalearner.  the other way, we\\u2019d have to do CV inside CV and the computation blows up","2499":"Sounds good, thank you so much for the explanation!","2500":"Considering my previous comment. Now with newest h2o build (```Build project version: 3.17.0.4181 (latest version: 3.16.0.4)```) multicore xgboost works like a charm! Thank you guys! \\n> @mmalohlava I have tried option 2) and tried to add my compiled xgboost version, however i have noticed that ```NativeLibLoader``` java class, which is loaded by ```XGBoostExtension``` doesn't have methods like ```NativeLibLoader.getLoadedLibraryName()``` in recent xgboost4j versions, I only found it in xgboost distribution forked by H2O. In order not to change code manually, i like to try option 1), when I launch ```g++ --version``` i get ```g++ (Ubuntu 5.4.1-2ubuntu1~16.04) 5.4.1 20160904```, so as your documentation says that xgboost is compiled with g++ 4.7 version, do I need to downgrade g++ from 5.4.1 to g++ 4.7 and xgboost then should find necessary openmp libraries and multithreading should work?","2501":"However when I test xgboost with large dataset (50mln. rows, ~800 columns) it throws me an error: \\n```\\n01-24 09:50:17.421 10.10.10.17:54321     19151  FJ-1-51   INFO: Enlarging sparse data structure from 1073741824 bytes to 2147483637 bytes.\\n01-24 10:03:29.502 10.10.10.17:54321     19151  FJ-1-51   ERRR: java.lang.ArrayIndexOutOfBoundsException: 2147483637\\n01-24 10:03:29.502 10.10.10.17:54321     19151  FJ-1-51   ERRR:         at hex.tree.xgboost.XGBoost.convertFrametoDMatrix(XGBoost.java:211)\\n01-24 10:03:29.502 10.10.10.17:54321     19151  FJ-1-51   ERRR:         at hex.tree.xgboost.XGBoost$XGBoostDriver.buildModel(XGBoost.java:509)\\n01-24 10:03:29.502 10.10.10.17:54321     19151  FJ-1-51   ERRR:         at hex.tree.xgboost.XGBoost$XGBoostDriver.computeImpl(XGBoost.java:477)\\n01-24 10:03:29.502 10.10.10.17:54321     19151  FJ-1-51   ERRR:         at hex.ModelBuilder$Driver.compute2(ModelBuilder.java:206)\\n01-24 10:03:29.502 10.10.10.17:54321     19151  FJ-1-51   ERRR:         at water.H2O$H2OCountedCompleter.compute(H2O.java:1263)\\n01-24 10:03:29.502 10.10.10.17:54321     19151  FJ-1-51   ERRR:         at jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\\n01-24 10:03:29.502 10.10.10.17:54321     19151  FJ-1-51   ERRR:         at jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\\n01-24 10:03:29.502 10.10.10.17:54321     19151  FJ-1-51   ERRR:         at jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:974)\\n01-24 10:03:29.502 10.10.10.17:54321     19151  FJ-1-51   ERRR:         at jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1477)\\n01-24 10:03:29.502 10.10.10.17:54321     19151  FJ-1-51   ERRR:         at jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\\n```\\nIt works without problems when I use it with only 1mln. number of rows dataset. I have launched h2o with -Xmx200g, could this be a reason for this?","2502":"After diggin in in code I see:\\n```\\nif (data.length == newLen) {\\n                throw new IllegalArgumentException(technote(11, \\Data is too large to fit into the 32-bit Java float[] array that needs to be passed to the XGBoost C++ backend. Use H2O GBM instead.\\));\\n              }\\n```\\nwhich should have been activated because I reach 2147483637 index but wasnt I guess. So I see that up to 2147483637 values that are not null in total in DataFrame are supported only in xgboost, so this means that native xgboost only support up to 32-bit integer maximum number of (not NaN or 0) values (in sparse matrix) and there is no support for larger matrixes? Or this is current constraint in h2o's version of xgboost?\\n> However when I test xgboost with large dataset (50mln. rows, ~800 columns) it throws me an error: \\n```\\n01-24 09:50:17.421 10.10.10.17:54321     19151  FJ-1-51   INFO: Enlarging sparse data structure from 1073741824 bytes to 2147483637 bytes.\\n01-24 10:03:29.502 10.10.10.17:54321     19151  FJ-1-51   ERRR: java.lang.ArrayIndexOutOfBoundsException: 2147483637\\n01-24 10:03:29.502 10.10.10.17:54321     19151  FJ-1-51   ERRR:         at hex.tree.xgboost.XGBoost.convertFrametoDMatrix(XGBoost.java:211)\\n01-24 10:03:29.502 10.10.10.17:54321     19151  FJ-1-51   ERRR:         at hex.tree.xgboost.XGBoost$XGBoostDriver.buildModel(XGBoost.java:509)\\n01-24 10:03:29.502 10.10.10.17:54321     19151  FJ-1-51   ERRR:         at hex.tree.xgboost.XGBoost$XGBoostDriver.computeImpl(XGBoost.java:477)\\n01-24 10:03:29.502 10.10.10.17:54321     19151  FJ-1-51   ERRR:         at hex.ModelBuilder$Driver.compute2(ModelBuilder.java:206)\\n01-24 10:03:29.502 10.10.10.17:54321     19151  FJ-1-51   ERRR:         at water.H2O$H2OCountedCompleter.compute(H2O.java:1263)\\n01-24 10:03:29.502 10.10.10.17:54321     19151  FJ-1-51   ERRR:         at jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\\n01-24 10:03:29.502 10.10.10.17:54321     19151  FJ-1-51   ERRR:         at jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\\n01-24 10:03:29.502 10.10.10.17:54321     19151  FJ-1-51   ERRR:         at jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:974)\\n01-24 10:03:29.502 10.10.10.17:54321     19151  FJ-1-51   ERRR:         at jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1477)\\n01-24 10:03:29.502 10.10.10.17:54321     19151  FJ-1-51   ERRR:         at jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\\n```\\nIt works without problems when I use it with only 1mln. number of rows dataset. I have launched h2o with -Xmx200g, could this be a reason for this?","2503":"I would love to use h2o GBM, but it seems I cannot reach such level of accuracy as xgboost does for some reason, even tried many parameters and histogram types for h2o gbm. My dataset might be specific due to dense geo coordinates and large imbalance. In theory , could be there any constraints that I could not reach such level of accuracy in h2o's gbm that i can reach with xgboost (it has some regularization stuff that h2o seems to be missing)?","2504":"@gediminaszylius we've had a similar experience (though we haven't explored it thoroughly)","2505":"@gediminaszylius thanks for the reports.  i don\\u2019t know the answer but @michalkurka may know what\\u2019s going on.  he is working on improving xgboost support in H2O right now","2506":"@gediminaszylius there are just certain datasets that will do better with XGBoost vs H2O.  there are implementation differences that make one or the other better in certain cases.  sometimes it has to do with how many categoricals your data has (and the cardinality), and sometimes it depends on other aspects of the data.  that\\u2019s why we decided to add XGBoost, since it excels under slightly different circumstances as compared to H2O GBM ","2507":"so hopefully we can get XGBoost working for you!","2508":"@ledell I see, thank you for response","2509":"@gediminaszylius did you try `balance_classes` in H2O GBM?  the other params i would try are `max_depth`, `min_rows`, `nbins` ,  `learn_rate`, `learn_rate_annealing`, `sample_rate`, `col_sample_rate`, `min_split_improvement` and the early stopping params.","2510":"@gediminaszylius we are working on an improved version of xgboost in H2O, wait for 3.18 release - the issue you should be fixed in this release, we are aware of the limitations in current version, it is not really usable for bigger datasets like yours","2511":"@ledell Balancing datasets is not what I want, I need probability prediction in general, not class separation, you could say i then could reweight based on prior distribution, but in general i loose accuracy when i downsample larger class, there are upsampling methods like SMOTE but still, too much data increase is bad also. I tried all parameters you mentioned and even more, related to categorical and continuous feature binning","2512":"@michalkurka cool, thanks for information!","2513":"Trying to upload the Kaggle Toxic Comment Classification data to H2o cluster, the data is not getting properly parsed. Is anyone else facing the same problem. The h2o version is 3.16.0.4","2514":"@aruncapiot yep, see here: https:\/\/stackoverflow.com\/questions\/48538135\/h2o-parser-issue","2515":"Do we have some  REST user guide for new ?  I can't understand how to use them by http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/rest-api-reference.html#route-%2F3%2FModelBuilders%2Fdeeplearning","2516":"@sjsdfg i dont think we have anything more than just the refernce docs.  you can look inside R\/Python\/Java code to see examples of how the REST API is used.","2517":"@ledell when i send a `POST` request and get the reponse, i try to convert the reponse to `ParseSetupV3`. i got a exception`com.fasterxml.jackson.databind.exc.UnrecognizedPropertyException: Unrecognized field \\header_lines\\ (class water.api.schemas3.ParseSetupV3), not marked as ignorable (21 known properties: \\schemaType_doNotCall\\ \\column_name_filter\\ \\check_header\\ \\__meta\\ \\parse_type\\ \\number_columns\\ \\source_frames\\ \\single_quotes\\ \\column_types\\ \\chunk_size\\ \\na_strings\\ \\warnings\\ \\column_offset\\ \\_exclude_fields\\ \\column_names\\ \\separator\\ \\column_count\\ \\data\\ \\total_filtered_column_count\\ \\destination_frame\\ \\decrypt_tool\\]). Why?   `ParseSetupV3` has `header_lines`, i saw it inthe source code","2518":"```\\npublic static ParseSetupV3 parsesSetup(String url, ImportFilesV3 filesV3) {\\n        url += \\\/3\/ParseSetup\\;\\n\\n        try {\\n\\n            HttpClient client = HttpClients.createDefault();\\n            HttpPost request = new HttpPost(url);\\n\\n  \\n            List<NameValuePair> pairs = new LinkedList<>();\\n         \\n            pairs.add(new BasicNameValuePair(\\source_frames\\ Arrays.toString(filesV3.destination_frames)));\\n     \\n            UrlEncodedFormEntity formEntity = new UrlEncodedFormEntity(pairs, \\UTF-8\\);\\n   \\n            request.setEntity(formEntity);\\n\\n            HttpResponse response = client.execute(request);\\n            ParseSetupV3 parseSetupV3 = getEntity(response.getEntity(), ParseSetupV3.class);\\n\\n            return parseSetupV3;\\n        } catch (IOException e) {\\n            e.printStackTrace();\\n        }\\n        return null;\\n    }\\n\\nprivate static <T> T getEntity(HttpEntity entity, Class clazz) {\\n        try {\\n            ObjectMapper mapper = new ObjectMapper();\\n            Object result = mapper.readValue(entity.getContent(), clazz);\\n            return (T) result;\\n        } catch (IOException e) {\\n            e.printStackTrace();\\n        }\\n        return null;\\n    }\\n```","2519":"my code is above all.","2520":"and my pom.xml ","2521":"```\\n<properties>\\n        <h2o.version>3.16.0.4<\/h2o.version>\\n    <\/properties>\\n```","2522":"```\\n200\\n{\\__meta\\:{\\schema_version\\:3,\\schema_name\\:\\ParseSetupV3\\\\schema_type\\:\\ParseSetup\\},\\_exclude_fields\\:\\\\\\source_frames\\:[{\\__meta\\:{\\schema_version\\:3,\\schema_name\\:\\FrameKeyV3\\\\schema_type\\:\\Key<Frame>\\},\\name\\:\\nfs:\\\\\\\\D:\\\\\\\\workspace\\\\\\\\h2o-3.16.0.4\\\\\\\\data\\\\\\\\80.csv\\\\type\\:\\Key<Frame>\\\\URL\\:\\\/3\/Frames\/nfs:\\\\\\\\D:\\\\\\\\workspace\\\\\\\\h2o-3.16.0.4\\\\\\\\data\\\\\\\\80.csv\\}],\\parse_type\\:\\CSV\\\\separator\\:44,\\single_quotes\\:false,\\check_header\\:-1,\\column_names\\:null,\\column_types\\:[\\Numeric\\\\Numeric\\\\Numeric\\\\Numeric\\\\Numeric\\\\Numeric\\\\Numeric\\],\\na_strings\\:null,\\column_name_filter\\:null,\\column_offset\\:0,\\column_count\\:0,\\destination_frame\\:\\X80.hex\\\\header_lines\\:0,\\number_columns\\:7,\\data\\:[[\\0.0776940066034606\\\\0.07905150011688195\\\\0.14668533086646462\\\\0.3407063639881359\\\\0.348062925720039\\\\0.1277786385239933\\\\10.815382576628322\\],[\\0.41141843029641\\\\0.38634161425697255\\\\0.31587263385757247\\\\0.0730425406485618\\\\0.06302825021781006\\\\0.06307437107826996\\\\14.25973784337511\\],[\\0.45644232333847845\\\\0.2789579162325017\\\\0.09082893681281201\\\\0.21020715126188178\\\\0.10290057969369387\\\\0.05962960440043624\\\\11.821321339253041\\],[\\0.07837782097819135\\\\0.23699191588762863\\\\0.21092269350771697\\\\0.45117453423327286\\\\0.2598961463231733\\\\0.49263845844386944\\\\13.249630477965319\\],[\\0.6638489398633991\\\\0.7728644989956903\\\\0.8212784902011911\\\\0.6157580013365525\\\\0.5113503638023027\\\\0.8353265770732119\\\\33.0810807634182\\],[\\0.7031393569052793\\\\0.9225290746163712\\\\0.6627895766392394\\\\0.6158704553363532\\\\0.5026584220947743\\\\0.5238401675251576\\\\32.04113812137097\\],[\\0.571954421139266\\\\0.7247950512956105\\\\0.5700391435580127\\\\0.9136916922416782\\\\0.7593635711096374\\\\0.9861504451185177\\\\34.58490675855968\\],[\\0.5476151690813987\\\\0.9720644403949212\\\\0.6155128488287789\\\\0.7405495532625495\\\\0.6650439550060435\\\\0.9501376963862407\\\\34.575988661514316\\],[\\1.1505568477057038\\\\1.0052908513796823\\\\1.3494630645622592\\\\1.4721700796955663\\\\1.0377451462643807\\\\1.353925977891104\\\\37.61335939278678\\],[\\1.2513344769430867\\\\1.2253027935572007\\\\1.057601250539149\\\\1.1935532625575977\\\\1.2417321957509468\\\\1.092380747602157\\\\37.86195325397381\\]],\\warnings\\:null,\\chunk_size\\:4194304,\\total_filtered_column_count\\:7,\\decrypt_tool\\:null}\\n\\n```","2523":"the response has no attribute named `header_lines`","2524":"@sjsdfg sorry i dont know what the problem is, mostly i deal with REST calls from R\/Python and not Java.  someone else might know how to help!","2525":"@ledell i got a json string, but i can't convert it to the Object framework provided","2526":"i think this is a bug","2527":"can you commit it to you colleague, and help me to solve this problem?","2528":" @ledell there is no other developer here\\uff1f","2529":"@sjsdfg please file a bug report in our jira: https:\/\/0xdata.atlassian.net\/secure\/Dashboard.jspa - I think it is much better place to discuss this topic","2530":"How do I get variable importance of a model from Java API?","2531":"@michalkurka this page is so complicated.   i  want some page like git issuse to describe my problem.","2532":"@michalkurka i put my question to https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-5293","2533":"In Scala\/Java, how do we predict with Mojo using H2OFrame directly? The problem with using RowData is that it's a lot of work to the the type right. How come we can not predict with a H2OFrame?","2534":"@schwannden MOJO\/POJOs are about runtime efficiency and one of the features of using these is that you don\\u2019t have to have an H2O Cluster running.  H2OFrames only exist in the H2O Cluster so that\\u2019s why they are not supported ","2535":"thx for explaining, but how does H2O flow able to predict a H2O frame so easily? Can someone point out the source code for me to reference?","2536":"H2O Flow runs in concert with the H2O Cluster","2537":"same as R\/Py APIs","2538":"you can save a binary H2O model (isntead of MOJO\/POJO) and score those on H2OFrames, if that\\u2019s what you\\u2019d prefer","2539":"what do you mean by \\save a binary H2O model\\? I tried to use objectOutputStream in vain.... would appreciate a little more hint :)","2540":"@schwannden http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/save-and-load-model.html","2541":"but we dont list the java method in there.. :(","2542":"but hopefully that puts you on teh right track. the name of the method is prob similar in java","2543":"still can't see how I could save java model binary","2544":"@schwannden ill ask around and see if i can get an answer\/get the docs updated","2545":"i tried a seach for \\u201csave\\u201d in the Java code, but its not clear https:\/\/github.com\/h2oai\/h2o-3\/search?l=Java&p=4&q=save&type=&utf8=%E2%9C%93","2546":"ok @schwannden  its called `ModelsHandler.exportModel():` ","2547":"@schwannden good news, we are going to add a nicer function (maybe even today!) to save\/load models from Java https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-5296","2548":"Wow what a good news, thanks! For now I am using the PredictCsv utility. In order to use this I need to transform the file I want to predict to json format, which is still much less error prone than trying to get  all the column types right.","2549":"@ledell i find why, that because the source code has problem.\\n","2550":"@michalkurka the question i put it on the url you pasted, no one cares.","2551":"this is a rough question.... I'll try to provide more details later:\\nWhen training auto ML, and when dataset contains categorical feature (Enum), and when the best model is a stacked ensemble, containing other glm as base model, then using H2OPredictor to predict the same file that is used to train will result in categorical value out of range exception. it is thrown from this line: https:\/\/github.com\/h2oai\/h2o-3\/blob\/20c5002d6b6739e61eac78054e442073859a0d5c\/h2o-genmodel\/src\/main\/java\/hex\/genmodel\/algos\/glm\/GlmMojoModel.java#L41\\n","2552":"Can I ask what is the purpose of the line in GlmMojoModel checking whether ival != data[i]?","2553":"How to check in H2O (in R) for gbm if early stopping was activated during the model training?","2554":"@WitJakuczun if your final model has fewer trees than what you asked for with `ntrees`.  i think there are a few different ways to check this, but first place id look is `h2o.scoreHistory(fit)`","2555":"@ledell thanks. I will check this.","2556":"@michalkurka  The example you provided to me, it can't run. i got an Exception\\n```","2557":"@michalkurka   https:\/\/github.com\/h2oai\/h2o-3\/blob\/master\/h2o-bindings\/src\/main\/java\/water\/bindings\/examples\/Example.java\\n```\\nxception in thread \\main\\ com.google.gson.JsonSyntaxException: java.lang.IllegalStateException: Expected BEGIN_OBJECT but was BEGIN_ARRAY at line 1 column 4965 path $.parameters\\n\\tat com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$Adapter.read(ReflectiveTypeAdapterFactory.java:220)\\n\\tat com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$1.read(ReflectiveTypeAdapterFactory.java:116)\\n\\tat com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$Adapter.read(ReflectiveTypeAdapterFactory.java:216)\\n\\tat retrofit2.converter.gson.GsonResponseBodyConverter.convert(GsonResponseBodyConverter.java:37)\\n\\tat retrofit2.converter.gson.GsonResponseBodyConverter.convert(GsonResponseBodyConverter.java:25)\\n\\tat retrofit2.ServiceMethod.toResponse(ServiceMethod.java:116)\\n\\tat retrofit2.OkHttpCall.parseResponse(OkHttpCall.java:211)\\n\\tat retrofit2.OkHttpCall.execute(OkHttpCall.java:174)\\n\\tat cn.edu.ncut.h2o.main.Example.gbm_example_flow(Example.java:151)\\n```\\nthe response has json syntax error","2558":"Trying to install Deep Water on GPU docker, i get an old H2o version 3.11.0.267 installed. Is there anyway to get the latest Deep Water + H2o version on Docker","2559":"want to ask about the same thing too, how do we setup sparkling water with custom H2O version (or with a compiled jar)","2560":"Is autoencoder not yet supported on Deep Learning  algorithm?","2561":"I am working with xgboost and grid search today and running into a lot of problems with errors like `[2018-02-12 15:50:01] failure_details: Rollups not possible, because Vec was deleted: `. Using version 3.16.0.4. I found a Jira ticket PUBDEV-5286 that seems to be a similar problem with GBM's that's fixed in 3.18.0.1. GBM grid search is working for me (although it is a bit slow), but I cannot get xgboost to work without this error. Is this a known problem that's being fixed or should I spend some time trying to troubleshoot and come up with a reproducible dataset?","2562":"@cdagnino we fixed the Apache Commons dependency, h2o 3.18.0.1 should be fine","2563":"@dkincaid if your problem is similar to PUBDEV-5286 then please wait for today's release and test on the release. If the problem doesn't go away it would be great if you could file a bug. Ideally with a reproducible example.","2564":"btw: XGBoost integration changed quiet a bit between 3.16 and 3.18.","2565":"it seems similar, michal. I will do that and let you know. Thanks!","2566":"@ledell how does AutoML currently handle string and datetime columns? Is string handled differently from enum in AutoML?","2567":"Hi all, I am running H2O on Kubernetes. Is there any way to have the persistence K\/V store outside of the H2O cluster? Can I connect somehow to the external database?","2568":"@michalkurka I'm trying h2o 3.17.0.4202 (last night's build) and my xgboost grid search is crashing the H2O service with this error: \\n```\\n[09:57:12] \/home\/jenkins\/slave_dir_from_mr-0xb1\/workspace\/ibranch_michalk_xgb-cleanup-4ROAZHD4TJU6ZZS3ODLWINRLAPATIV66PAZALF74JZ5PIC6THITA\/dmlc-core\/include\/dmlc\/logging.h:300: \\n[09:57:12] \/home\/jenkins\/slave_dir_from_mr-0xb1\/workspace\/ibranch_michalk_xgb-cleanup-4ROAZHD4TJU6ZZS3ODLWINRLAPATIV66PAZALF74JZ5PIC6THITA\/src\/tree\/updater_gpu_hist.cu:266: \\nCheck failed: param.max_depth < 16 Tree depth too large.\\n```","2569":"When I reduce the `max_depth` search space to be less than 16 I then get out of memory errors.","2570":"\\n```\\n[10:07:52] \/home\/jenkins\/slave_dir_from_mr-0xb1\/workspace\/ibranch_michalk_xgb-cleanup-4ROAZHD4TJU6ZZS3ODLWINRLAPATIV66PAZALF74JZ5PIC6THITA\/dmlc-core\/include\/dmlc\/logging.h:300: \\n[10:07:52] \/home\/jenkins\/slave_dir_from_mr-0xb1\/workspace\/ibranch_michalk_xgb-cleanup-4ROAZHD4TJU6ZZS3ODLWINRLAPATIV66PAZALF74JZ5PIC6THITA\/src\/tree\/updater_gpu_hist.cu:286: GPU plugin exception: \/home\/jenkins\/slave_dir_from_mr-0xb1\/workspace\/ibranch_michalk_xgb-cleanup-4ROAZHD4TJU6ZZS3ODLWINRLAPATIV66PAZALF74JZ5PIC6THITA\/src\/tree\/..\/common\/device_helpers.cuh(469): out of memory\\n```\\n\\n","2571":"If I specify `backend = \\cpu\\` along with constraining the `max_depth` to less than 16 I am able to get it to run without the errors I was seeing before (about the Vec was deleted) at least during a 10 minute run. ","2572":"@dkincaid do I understand it correctly that the OOM errors occur if xgboost uses GPU backend?","2573":"yes, that is correct. I'm running on my laptop this morning, so there really isn't much of a GPU backend to use.","2574":"I see, thanks for the report. I am glad the grid search issues of Vec being deleted went away","2575":"You're welcome. Great to see things getting fixed (the problem with the job list and autoML jobs is fixed too). Is the max_depth limit supposed to be there?","2576":"This is a limit coming from the GPU backend. We are a little behind dmlc\/xgboost (we have our fork of xgboost that has patches making the integration with h2o easier). Current master version of xgboost doesn't seem to have the depth limitation (just based on the source code).","2577":"We are planning to upgrade the version xgboost, so this limit should eventually go away as well.","2578":"Thank you for the explanation and the quick replies.","2579":"Do you have an expected release date for 3.18?","2580":"3.18.0.1 was released yesterday and it is available for download: http:\/\/h2o-release.s3.amazonaws.com\/h2o\/rel-wolpert\/1\/index.html","2581":"Technically it is the exact same version as the nightly (3.17.0.4202). Just the version number differs","2582":"Well look at that! I totally missed it. Thank you again","2583":"Getting another error to report doing grid search with xgboost. Getting a `java.net.SocketException: too many open files` and it crashes the server process. This is after running for about 15 or 20 minutes.\\n\\n```\\n02-13 12:26:31.343 192.168.86.150:54321  2837   FJ-2-3    FATAL: XGBoost failure\\n02-13 12:26:31.343 192.168.86.150:54321  2837   FJ-2-3    FATAL: java.net.SocketException: Too many open files\\n02-13 12:26:31.343 192.168.86.150:54321  2837   FJ-2-3    FATAL: Stacktrace: \\n02-13 12:26:31.343 192.168.86.150:54321  2837   FJ-2-3    FATAL: [java.lang.Thread.getStackTrace(Thread.java:1559), water.H2O.fail(H2O.java:1016), \\nhex.tree.xgboost.XGBoost$XGBoostDriver.buildModelImpl(XGBoost.java:341), \\nhex.tree.xgboost.XGBoost$XGBoostDriver.buildModel(XGBoost.java:262), \\nhex.tree.xgboost.XGBoost$XGBoostDriver.computeImpl(XGBoost.java:252), \\nhex.ModelBuilder$Driver.compute2(ModelBuilder.java:206), \\nwater.H2O$H2OCountedCompleter.compute(H2O.java:1263),\\n jsr166y.CountedCompleter.exec(CountedCompleter.java:468),\\n jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263), \\njsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:974),\\n jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1477),\\n jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)]\\n```","2584":"@dkincaid thanks, we will investigate and try to fix asap: https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-5325","2585":"Thanks, let me know if you need any more information","2586":"It would help if you could share relevant part of your script and environment you are using (os, how many nodes, memory per node, anything relevant)","2587":"Just added that info to the Jira ticket","2588":"Thank you! This definitely helps","2589":"@aruncapiot yes deep learning autoencoder is supported.  check out our documentation ","2590":"@schwannden Strings are ignored by all H2O algos (including AutoML).  If you convert a string column to categorical (aka factor\/enum) then they can be used for prediction.  For datetime, it\\u2019s interpreted as a numeric column","2591":"> Trying to install Deep Water on GPU docker, i get an old H2o version 3.11.0.267 installed. Is there anyway to get the latest Deep Water + H2o version on Docker\\n\\n@aruncapiot @schwannden We are no longer releasing new versions of Deep Water.  ","2592":"Hello all,  I'm trying to incorporate a model into my java app using a MOJO and I'm getting the error: MOJO scoring for text classification is not yet implemented because I have a categorical column with text in it","2593":"is that expected, or am I doing something wrong?","2594":"@stealthman13 can you please confirm you have a DeepWater MOJO model?","2595":"I only see this message in DeepWater","2596":"@stealthman13 If you are using DeepWater - it is indeed not supported. Please note that  we no longer support DeepWater.","2597":"I produced the MOJO using 3.18.0.1 H2O through the GUI, so I don't think that's DeepWater","2598":"@michalkurka  I think that I found the problem. In the json file, the domains for my categorical  feature variables are all null for some reason","2599":"I'm a total beginner using H2O through python. My data set has a column with integer values {0,1,2}. When creating a model, is there a way to specify that these are categories not numerical values? Right now I'm converting {1,2,3} into strings {'a', 'b', 'c'} before building a model","2600":"@luisdelatorre012 yes, the way to do that is to convert the column into a \\u201cfactor\\u201d column so that H2O knows that they are categories.  If your column is called \\u201ccolA\\u201d, then here\\u2019s how you convert:\\n\\n```\\ndata[\\u2018colA\\u2019] = data[\\u2018colA\\u2019].as_factor()\\n```\\n\\nHere\\u2019s a link to some intro H2O Python tutorials: https:\/\/github.com\/h2oai\/h2o-tutorials\/#python-tutorials","2601":"basically it does the same thing that you\\u2019re doing but this is the proper way to do it in H2O","2602":"Does anyone know the best way to upsample data in a h2o using an h2o frame. I am looking to see if there a SMOTE implementation in python that can work on h2o frames.","2603":"@NkululekoThangelane You can just add a weights column to the H2OFrame using `cbind()` http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-py\/docs\/frame.html?highlight=cbind#h2o.frame.H2OFrame.cbind, and then use `weights_column` when you train the algorithm e.g. http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-py\/docs\/modeling.html?highlight=weights_column#h2o.estimators.gbm.H2OGradientBoostingEstimator.weights_column","2604":"You will have to decide what weights to use for each class","2605":"@NkululekoThangelane check this out for how to slice rows http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/data-munging\/slicing-rows.html\\n```\\nimport h2o\\nh2o.init()\\npath = \\http:\/\/h2o-public-test-data.s3.amazonaws.com\/smalldata\/iris\/iris_wheader.csv\\\\ndf = h2o.import_file(path=path)\\ndf[\\weight\\] = 1  #add a column of all 1\\u2019s.  \\nmask_setosa = df[\\class\\] == \\Iris-setosa\\  #boolean col to identify the setosa rows\\ndf[mask_setosa, \\weight\\] = 0.5  #let\\u2019s say you want to set everything in sets class to weight 0.5\\n```","2606":"@ledell  thanks for this .","2607":" @ledell  I am looking using the weights_column. so I create a new column with a weight and specify the column as the weight?","2608":"@NkululekoThangelane yep, there might be an example if you search \\u201cweights_column\\u201d in the h2o-3 repo","2609":"@ledell  thank you will do :smile: ","2610":"As per h2o doc, one can score the model MOJO in any OS where Java is supported. I have created the MOJO for RF and GLM in windows and trying to score the MOJO in Windows, Solaris and AIX. The MOJO of GLM is working fine all the OS but MOJO for RF is not working on Solaris and AIX.  I have created a defect for it - https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-5333\\nPlease look into it and let me know if I am missing anything.","2611":"thanks @ggauravuee we will take a look at this in our weekly meeting to review new JIRAs","2612":"Hi, I am trying to explain the decision taken by GLM model. based on idea:https:\/\/medium.com\/applied-data-science\/new-r-package-the-xgboost-explainer-51dd7d1aa211\\nI want to calculate the contribution by each feature into making a certain decision.\\nIs it possible to get each individual tree from the ensable along with the log-odds at every node? \\nalso be needing the path traverse by model while making prediction for each tree.","2613":"Hello, is there any way to predict leaf index for every tree in GBM or XGBOOST models instead of prediction value? Does MOJO\/POJO somehow support it?","2614":"@gediminaszylius if you\\u2019re using R, check out `h2o.predict_leaf_node_assignment()` i think that\\u2019s what you\\u2019re looking for.","2615":"Also if you want to predict individual contributions from predictors and are using R, check out the lime R package, that has h2o integration","2616":"@ledell  does h2o have a lime equivalent for h2o","2617":"@ledell  hi i found a good example.","2618":"@NkululekoThangelane not inside h2o, but the lime R package works with h2o ","2619":"@NkululekoThangelane we have a lot of presentation and videos about this, you should find if you google them","2620":"@ledell Thank you, but I'm using Python, so I guess there is no API for that.","2621":"@ledell  thank you","2622":"Upon using EasyPredictModelWrapper, when I need to predict a model with datetime feature, I need to manually change datetime column into Double.\\nHow should I change it? does it use millisecond epoch? Or can someone point to me the source code where AutoML treats datetime as numeric type?","2623":"@gediminaszylius yes we have nearly 100% coverage in R vs Python, so if you see something in R, you can expect that it will also be in python","2624":"just search the python module docs linked from docs.h2o.ai ","2625":"http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-py\/docs\/model_categories.html?highlight=leaf#h2o.model.ModelBase.predict_leaf_node_assignment","2626":"@schwannden yes its millisecond epoch.  this is how H2OFrame internally store datetimes","2627":"so all the algos treat them as such, including AutoML","2628":"@ledell thank you! Would be a nice enhancement to have for easy predictor if we can simply use datetime to predict :)","2629":"Hi! I\\u2019m creating a multinode h2o cluster in AWS. Any thoughts on which are the best instance types (t2, m4, m5\\u2026) for K-means, GBM, RF, XGboost, and minimal requirements for a node?  Also: What do you think is best: only a few big instances or many small instances? ","2630":"(I don\\u2019t have a lot of data, but it still takes a lot of time to train grids in my computer, that why I\\u2019m moving to multinode\/cloud)","2631":"@rcercos It\\u2019s faster if you use fewer bigger nodes bc there\\u2019s less communication overhead, but it\\u2019s prob a bit cheaper to use more small nodes.","2632":"If you can fit your data in a single machine, that\\u2019s best (and slightly easier to launch).  In general, we recommend having at least 3-4x RAM as the size of your data on disk.","2633":"If your data is small (and can fit into memory), it will not speed up by adding more nodes, it will actually just slow it down.  Multi-node is really only helpful if your data is too big to fit into memory.","2634":"For small data, I\\u2019d recommend a single instance on AWS with as many cores as you can get, e.g. c5.18xlarge","2635":"If you value speed > cost","2636":"I can echo Erin's advice from my own experience. If you are using GBM, RF or XGB and you can get enough RAM for your data to fit, get the biggest single machine you can with as many cores as possible. Additional nodes will slow it down. This is even more true if your training data has more than a few hundred features.","2637":"Re","2638":"Do you know if there is active work on h2o to visualise the GBM , DRF,XRT Trees ? With python","2639":"@NkululekoThangelane there\\u2019s a JIRA for it, but no one is working on it https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-3653","2640":"i don\\u2019t think it\\u2019s going to be done any time soon unless a customer specifically asks for it since not many people use\/need this","2641":"Hello! I'm trying to understand how h2o calculates R^2. I can calculate it manually with the formula r2 = 1-(SSE\/SST) using the .predict() method to calculate SSE, and it makes sense. But when I use the .r2() method I get a very different number. any thoughts?","2642":"To be more specific, this code returns the value -0.667:\\n~~~~\\ndf = pd.DataFrame({'x':[1,2,3,4,5],'y':[3,9,2,8,1]})\\nh2o_df=h2o.H2OFrame(df)\\nrf = H2ORandomForestEstimator()\\nrf.train('x','y',h2o_df)\\nrf.r2()\\n~~~~\\n\\nAnd this code returns the value 0.727, which makes more sense:\\n~~~~\\ny_true = df.y\\ny_pred = rf.predict(h2o_df).as_data_frame().predict\\nSSE = sum((y_pred-y_true)**2)\\nSST = sum((y_true-y_true.mean())**2)\\nr2 = 1-(SSE\/SST)\\nr2\\n~~~~","2643":"hi @logancwilson17_twitter i saw your post on stack overflow, don\\u2019t have time to look at it right now.  if you think its a bug, please file a JIRA","2644":"im curious why you\\u2019re using R^2 to evaluate a tree-based model? ","2645":"at one point we had talked about removing R^2 from all our models other than GLM since they\\u2019re not the standard metrics that people use","2646":"I think I may have figured it out? If I use `rf.model_performance(h2o_df).r2()` instead of `rf.r2()` I get the same value as calculating manually","2647":"ah, ok.  i am not pleased that we are returning some weird number for `rf.r2()` that should not be there","2648":"that\\u2019s great that you solved it, can you answer your SO question or remove it?  thx","2649":"Will do. It's not just `rf.r2()` though, `rf.mse()` returns a different result than `SSE\/len(df)` where SSE is calculated as shown above. `rf.model_performance(h2o_df).mse()` returns the correct value though.","2650":"@logancwilson17_twitter actually i don\\u2019t see this as correct either:\\n```\\nIn [13]: rf.model_performance().r2()\\nOut[13]: -0.838678469179956\\n```","2651":"that code should pull the training R2 (which is the same thing probably as what `rf.r2()` is","2652":"it should match calculating manually on the `h2o_df` like you do here:\\n```\\nIn [14]: rf.model_performance(h2o_df).r2()\\nOut[14]: 0.7073007518796992\\n```","2653":"this is a bug","2654":"@logancwilson17_twitter filed a bug https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-5347","2655":"thx for the report","2656":"@logancwilson17_twitter i saw you also posted the identical question to cross-validated.  please please don\\u2019t double post.  it makes more work for us.  please use one channel and be patient for a response\\u2026 this is open source (not customer support).","2657":"if you wouldn\\u2019t mind, i\\u2019d recommend deleting this since it\\u2019s not a stats-theory question, its a code\/bug question (more suitable for Stack Overflow): https:\/\/stats.stackexchange.com\/questions\/330468\/h2o-giving-a-different-r2-than-calculating-manually","2658":"ill post our open source support guidelines here for reference: https:\/\/groups.google.com\/forum\/#!forum\/h2ostream\\n\\n- For questions about H2O software features, \\where can I find an example of [x]?, \\how can I use GPUs with H2O?\\ etc (questions that do not involve any user code), or to communicate with H2O developers directly about a particular issue, please post those questions here on h2ostream. \\n-  For code questions, we encourage you to post a Minimal, Complete and Verifiable Example (MCVE) at StackOverflow.com.  If you are new to Stack Overflow, please visit the MCVE link to ensure you ask your question properly and that it contains all the necessary information (or if may be flagged & closed).  Please use the h2o and\/or sparkling-water tags.\\n- For algorithm or data science questions (\\what causes overfitting in GBMs?\\), please use Cross Validated (on Stack Exchange).  If the question is specific to the H2O implementations of algorithms, you can use the h2o tag.\\n- For bug reports or feature requests, you can file those directly in our issue tracking system located here: http:\/\/jira.h2o.ai  When filing a bug report, please make sure to include a reproducible example if possible and H2O version & client (R, Py, etc) information. You must create a free JIRA account using your email address to file a report.\\n\\nBefore posting a question on either site, please do the following:\\n\\n- Search h2ostream or Stack Overflow to see if your question has already been answered.\\n- Search the H2O User Guide or any of the other many documentation resources at docs.h2o.ai.\\n- Do not double-post your question: choose h2ostream --or-- Stack Overflow, but not both.\\n\\nNotice to h2ostream users:\\nFor every post please provide the following at the top of your post:\\n\\n1) What version of H2O are you using.\\n2) Specify the type of machine your using (i.e. OS X 10.11.4, Windows 10, etc).\\n3) Specify what language you are working in and what version (i.e. Python 2.7, Spark 1.6.1, etc)\\n4) The code you were executing when you received an error message (please provide a reproducible example if possible).\\n5) Copy and paste in your error message.\\n6) Type of data you are using (if applicable).","2659":":thumbsup: ","2660":"hi everyone, is anyone else running into stability issues with 3.16.0.4? I have repeatedly had the issue of \\\\\\H2OConnectionError: Local server has died unexpectedly. RIP. \\\\\\","2661":"This is delayed model training multiple times and its really making me second guess the reliability of H2o. The data being loaded is well within the memory i've allocated to h2o. furthermore i'm shutting down the cluster after every usage. ","2662":"Did not run into this issue with 3.16.0.2","2663":"For context, using h2o through python version on an ubuntu machine (aws). ","2664":"in the midst of importing a file: train_data = h2o.import_file(path=train_path)","2665":"i've allocated 40 gb to h2o when initializing. The file being imported is approximately 20gb. ","2666":"has anyone run into these reliability issues? ","2667":"I went ahead and updated to 3.18.02 (latest stable). I'm going to run the same script and see if it actually survives this time. ","2668":"Also, I am running into an issue on my mac (Mac OSX High Sierra) where upon init, it is not able to start the server: h2o.exceptions.H2OConnectionError: Could not establish link to the H2O cloud http:\/\/localhost:54321 after 5 retries ","2669":"i'm not sure why this would be an issue. Could it be because of antivirus software? ","2670":"I do not have an http proxy","2671":"@Aakash282 it might mean you have something else running on that port?  have you been able to run H2O on your mac before?","2672":"nothing else on that port confirmed by lsof. Also using ps to confirm h2o wasn't already running. very strange. But my other issue is more processing as that is on my workhorse server","2673":"@Aakash282 let us know if you continue to see the `H2OConnectionError: Local server has died unexpectedly. RIP. ` error on 3.18.","2674":"yep. In fact, its happened 32 times in a row (i obviously stopped it a while back). Is there something with h2o where when i shut down a cluster and start it back up, I have to wait a minute or two? I have a time.sleep(20) in between but is that not enough? ","2675":"@Aakash282 so it happens every time when you try to import your file?  this is unrelated as i don\\u2019t think it\\u2019s a memory issue, but you are not using enough memory if you actually want to train some algos.  we recommend at least 3-4x in H2O cluster memory (vs the size of your data).","2676":"interesting, i'll take that into account but i agree i don't think that is the issue here. ","2677":"I\\u2019d recommend writing up the problem in as much detail as possible and posting to Stack Overflow.  my guess is that it\\u2019s some sort of environment issue, but i dont know what","2678":"we can also ask @michalkurka if he has any ideas","2679":"Last week I was able to train models in this exact setup (and data) so I'm not sure what changed. The only thing I can think of is that i did a pip install of tensorflow and keras. But i can't imagine that would impact h2o? ","2680":"no that would not impact h2o (that im aware of)","2681":"when i run `h2o.cluster().shutdown()` does it actually wait for the cluster to shutdown or does it just send a shutdown signal to the java service","2682":"out of curiosity you could try importing the data in Flow or R, to see if it\\u2019s a python issue (its hard to debug on our end since we can\\u2019t repliate).  here\\u2019s some R code:\\n```\\nlibrary(h2o)\\nh2o.init(max_mem_size = \\40G\\)\\n\\ntrain_path <- \\u201c\/your\/path\\\\ntrain_data <- h2o.importFile(path=train_path)\\n```\\ndownload R package here: http:\/\/h2o-release.s3.amazonaws.com\/h2o\/rel-wolpert\/2\/index.html","2683":">  does it actually wait for the cluster to shutdown or does it just send a shutdown signal to the java service\\n\\nthose are one in the same","2684":"well actually, there is a slightly more graceful shutdown (it cleans up some tmp files), but essentially the same thing","2685":"ok i'll give some more info in case it helps: I have to train a new model for every month of data i have. I have a script that initializes h2o, imports the train and test files for the relevant month, exports the predictions and then shutdown the cluster before running the routine again on a new month. Are there any known issues with starting h2o and then shutting it down several times consecutively?","2686":"i'll try the R code you sent later, right now we are running some other models on that server","2687":"no, there\\u2019s no problem with that.  and to be clear\\u2026 H2O 3.16.0.4 and 3.18.0.1,2 is working perfectly fine across 1000 or so tests, so it\\u2019s either a really sneaky bug or a weird environment issue","2688":"this is very unusual","2689":"Btw, we may have solved the issue. We were initializing and shutting down h2o repeatedly. Still not sure why that would cause an unexpected failure. Now we initialize once and call h2o.remove_all() instead of h2o.cluster().shutdown(). ","2690":"Web servers arent usually designed to be started up and shutdown for each usage :) ","2691":"I'll post here if that ends up solving the issue. We actually have a new question now. ","2692":"When balance classes (over-sampling) and cross-validation are enabled for a model, is the class balancing only applied to the training folds of cross-validation? ","2693":"if class balancing is also applied to the validation fold then that does not give insight for the final test set error","2694":"@ledell     A question about h20-3.   I donot know how to setu p the h2o cluster,  and how to confirm that cluster works well ?","2695":"@ledell   Another question about h2o-3,    how to extend  the algos?   thanks first!","2696":"[![image.png](https:\/\/files.gitter.im\/h2oai\/h2o-3\/25p0\/thumb\/image.png)](https:\/\/files.gitter.im\/h2oai\/h2o-3\/25p0\/image.png)","2697":"Good Day   Not sure how to resolve this error. When running H2o with Sparkling Water Python. I am able to start the H2o CLoud and Access the H2o Flow but after a while when trying to view the running Jobs I get an error about h2o being unresponsive. On the Python side it seems like my model is still training but I am sure what has caused this problem.  ","2698":"@ledell Thanks so much, this is really helpful","2699":"I figured out what the problem was . If anyone get this problem its normally using Sparkling Water in Internal Model. Yarn tends to kill some containers and thus killing the whole h2o Cluster. Recommendation is to run your H2O Cluster in External Model if you can else if you need to run in Internal mode. Configure your Spark Context to have spark configs similar to these however you can change them depending on the size of your job.","2700":"conf = SparkConf().setAppName('MyApp')\\nconf.set('spark.driver.memory','20G')\\nconf.set(\\spark.driver.cores\\\\20\\)\\nconf.set(\\spark.executor.instances\\ \\20\\)\\nconf.set(\\spark.executor.cores\\ \\4\\)\\nconf.set(\\spark.executor.memory\\ '15G')\\nconf.set(\\spark.dynamicAllocation.enabled\\ , \\false\\)\\nconf.set(\\spark.sql.autoBroadcastJoinThreshold\\\\-1\\)\\nconf.set(\\spark.scheduler.minRegisteredResourcesRatio\\\\1\\)\\nconf.set(\\spark.locality.wait\\\\0\\)\\nconf.set(\\spark.driver.maxResultSize\\\\8G\\)\\nconf.set(\\spark.kryoserializer.buffer.max\\\\2047mb\\)\\nconf.set(\\spark.scheduler.minRegisteredResourcesRatio\\\\1\\)\\nconf.set(\\spark.task.maxFailures\\\\1\\)\\nconf.set(\\spark.driver.extraJavaOptions\\\\-XX:MaxPermSize=1024m\\)\\nconf.set(\\spark.executor.extraJavaOptions\\\\-XX:MaxPermSize=1024m\\)\\nconf.set(\\spark.executor.heartbeatInterva\\\\10s\\)\\nconf.set(\\spark.yarn.am.extraJavaOptions\\\\-XX:MaxPermSize=1024m\\)\\nconf.set(\\spark.yarn.driver.memoryOverhead\\\\10G\\)\\nconf.set(\\spark.yarn.executor.memoryOverhead\\\\8G\\)\\nconf.set(\\spark.yarn.am.memoryOverhead\\\\8G\\)\\nconf.set(\\spark.yarn.max.executor.failures\\\\1\\)\\nconf.set(\\spark.locality.wait\\\\3000\\)","2701":"@NkululekoThangelane glad you figured it out.  if you wanted to post your question and solution to Stack Overflow, this would probably help a lot of people.  This chat is not easily searchable from the web","2702":"@wreathcrystal_twitter how to set up an H2O cluster is covered thoroughly in our User Guide http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/index.html","2703":"@wreathcrystal_twitter extending H2O is more work\\u2026 i don\\u2019t have a reference off the top of my head that i can point you to. maybe someone else can.  i know that we have one somewhere.  maybe you can search on our google groups: https:\/\/groups.google.com\/forum\/#!forum\/h2ostream","2704":"Has any dealt with H2O Kmeans in depth. I am looking for the best way to get points that are far from cluster centroid using some distance metric like euclidean distance. I am able to cluster my data however I am doing anomoly detection by finding points that dont fit properly into a cluster. I was able to do this on Spark however I am looking to move this code to H2O Sparkling Water. ","2705":"@NkululekoThangelane if you mean in general, then i\\u2019d recommend posting to https:\/\/stats.stackexchange.com\/ and if you mean, specifically in H2O, then i\\u2019d post to stack overflow","2706":"we\\u2019d prefer questions to go up in a public channel so everyone can benefit from seeing the answers","2707":"(gitter is not easily searchable on the web)","2708":"@ledell  will do","2709":"@ledell  I have posted the question https:\/\/stackoverflow.com\/questions\/49106333\/get-distance-of-point-from-cluster-centroid-on-h2o-kmeans-clustering","2710":"thanks @NkululekoThangelane !  ","2711":"Hi, I see that LIME and Shapley diagnostics are available in Driverless AI. Any chance that these will become available in H20 too?","2712":"Hi, In h2o for categorical features, what does calling asfactor() for that feature do exactly? Is it incorrect to Split the data in train, valid and test set first, then call asfactor() with categorical features for each data-frame?","2713":"@thirdeye802  I would call as factor before the split. calling this changes the data type to an enum which can be converted during training depending on what categorical encoding you intend to do.","2714":"yes. but i don't have test data at training time. and also, valid and test data categorical features contain values that may not be present in training set.","2715":"Hey. Does anyone maintain h2oai\/h2o-flow room in gitter?","2716":"@t1nuswillemse_twitter You can use the lime package in R or Python with H2O.  We don\\u2019t have any plans at the moment to rewrite LIME or Shapley inside H2O.  ","2717":"@thirdeye802 There\\u2019s no problem to call it after as long as your the categorical columns in the split data frames contain all the levels","2718":"@thirdeye802 however, as @NkululekoThangelane said, its just better to do it on the original dataset and then split","2719":"Is there any example code where we can do cross validation in Scala? Manually assigning our own folds","2720":"I am asking of this because I need to do cv with time series, and the way time series does CV is not provided in any default methods of cv","2721":"@schwannden i dont have an example, but you just need to add a column to your training frame with the fold indices and then set `fold_column` equal to the name of that column","2722":"that probably won't work either, in time series, say, I have 5 days of data.\\nI want to do cv this way\\nuse day 1-2 to train, 3-5 to validate\\nuse day 1-3 to train, 4-5 to validate\\nuse day 1-4 to train, 5 to validate","2723":"@schwannden oh, i see\\u2026 yes. you will have to write a loop for that :(","2724":"i think we will eventually add support for proper time-series\/rolling CV, but not soon","2725":"haha alright~","2726":"thx nonthless!","2727":"this would be a wonderful example to add to our h2o-tutorials repo though, if you feel like swapping in a public dataset, someone would find it useful!  i can find a place to host it, if you create a demo script","2728":";)","2729":"one more question, is there a way to union H2O frame or Frame in Scala?","2730":"like a row-bind or column-bind?","2731":"row bind","2732":"there is, but i dont know what it\\u2019s called, let me see if i can find out","2733":"we really need a Scala tab here: http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/data-munging\/combining-rows.html  but as youve noticed, we have few scala examples","2734":"in R\/Py, its just called \\u201crbind\\u201d so i looked here https:\/\/github.com\/h2oai\/h2o-3\/search?l=Java&q=rbind&type=&utf8=%E2%9C%93","2735":"hmm, interesting, so we have to write ast, and use checkTree to evaluate","2736":"that seems overly complicated to me\\u2026  i assume there is a more direct way","2737":"that is not called \\u201crbind\\u201d and so its harder to locate","2738":"even a search of checkTree returns no result on its implementation","2739":"@michalkurka or @mmalohlava do you know how to do an rbind in Java\/Scala?  we aren\\u2019t able to find the method by searching the code for \\u201crbind\\u201d.  wondering if there is a utility method or if you have to use the Rapids call directly","2740":"@ledell The rbind API is currently not exposed directly to Java\/Scala. Users can directly invoke the Rapid Expression to work around this. Please see example code:\\n\\n\/**\\n * Concatenates (row binds) two H2O frames together.\\n *\\n * @param key the key of the resulting frame\\n * @param frame1 frame 1\\n * @param frame2 frame 2\\n * @return concatenated frame (rows of frame1 followed by rows of frame2)\\n *\/\\npublic static Frame concat(String key, Frame frame1, Frame frame2) {\\n  String rapid = String.format(\\(tmp= %1$s (rbind %2$s %3$s))\\ key, frame1._key, frame2._key);\\n  return Rapids.exec(rapid).getFrame();\\n}\\n\\n@Test\\npublic void testConcat() {\\n  Scope.enter();\\n  try {\\n    Frame fr1 = Scope.track(parse_test_file(Key.make(\\fr1.hex\\), \\smalldata\/iris\/iris_wheader.csv\\));\\n    Frame fr2 = Scope.track(parse_test_file(Key.make(\\fr2.hex\\), \\smalldata\/iris\/iris_wheader.csv\\));\\n    Frame result = concat(\\result\\ fr1, fr2);\\n    Scope.track(result);\\n    assertEquals(fr1.numRows() + fr2.numRows(), result.numRows());\\n  } finally {\\n    Scope.exit();\\n  }\\n}","2741":"We can expose this API in a more natural way.","2742":"thanks @michalkurka ","2743":"In h2o, after I get a model from the AutoML leader board, am I able to retrain the model?","2744":"Not continue training! but retrain the model~","2745":"Is there a list of previous versions of h2o (for Python) available somewhere so that we can install specific versions using pip? Because you can't load models trained and saved in different versions (why???), we need to be able to install very specific  versions in case we want to use models trained by colleagues (or even by ourselves in the past).","2746":"Also it would be great if someone is able to answer this question on cross-validated about the precise definition of deviance in h2o : https:\/\/stats.stackexchange.com\/questions\/331991\/deviances-in-h2o","2747":"I found this: https:\/\/pypi.python.org\/simple\/h2o\/ but is there a more orderly (official?) list out there?","2748":"ok looks like this is the best option: https:\/\/pypi.org\/project\/h2o\/#history","2749":"@schwannden you don\\u2019t need to retrain the models in the leaderboard\\u2026 they are already trained and you can access them using their model id.  `m  = h2o.get_model(\\u201csome_model_id\\u201d)`","2750":"@schwannden maybe i misundersatnd your question?","2751":"@ledell  recall that I asked you about the CV question? The reason why I need to retrain is because I need to get the model out, and calculate the custom CV metrics manually","2752":"So after AutoML select the best model, I need to get the model out, and retrain it on custom split of train-test sets :p\\n","2753":"@schwannden ah\\u2026 would exposing `fold_column` help?  i\\u2019ll be adding that right after i add `balance_classes` (adding now)","2754":"that way you could just train on custom folds to begin with","2755":"what you\\u2019ll have to do in the meantime is get the model, then look at the parameters used, and re-train on your custom train\/test.  are you in R or Python?","2756":"That would help a lot!\\nAnd yes, that is exactly the way I am doing right now :p ","2757":"ok well ill give you `fold_column` pretty soon (next week probably)","2758":"https:\/\/media.giphy.com\/media\/IcGkqdUmYLFGE\/giphy.gif","2759":"@ledell  I see you are working on balancing the classes on AutoML. are you able to say what would be the method of balancing the classes. Is H2o planning on looking at SMOTE for upsampling minor classes","2760":"@ledell  I also have a quick question about a problem I am starting to face. When using python for H2O. I monitor the progress of the models training on H2O flow by looking at Jobs. The problem I recently started experiencing is that the Jon is reflects as done on H2O and H2O logs but python seems to still be running.","2761":"@schwannden thanking for raising this it will also be helpful to me.","2762":"@NkululekoThangelane The `balance_classes` arg that i am adding to AutoML is just the same as the one used in all the H2O algos.  no SMOTE http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/data-science\/algo-params\/balance_classes.html","2763":"@schwannden :pray: you\\u2019re welcome","2764":"@ledell  thank you. im sure that will be helpful\\ud83d\\ude09","2765":"Any advice on installing an older version of h2o to a conda virtual environment on Windows? I've tried the following: https:\/\/stackoverflow.com\/questions\/49199204\/installing-older-version-of-h2o-in-conda-virtual-environment-on-windows","2766":"@DanGolding \\because of their insane decision to not allow you to be able to load files saved in even the most minor different version\\u201d  ??","2767":"a bit hyperbolic?","2768":"You can load models between minor versions, just not major versions","2769":"@ledell I saved models in 3.18.0.1 and colleague with 3.18.0.2 cancer load them","2770":" Apologies, my autocorrected can't to cancer. Sorry about that.","2771":"But here are other examples of the same: https:\/\/stackoverflow.com\/questions\/39567131\/is-there-a-way-to-use-saved-model-between-different-versions-of-h2o","2772":"Either way, how do I work with older models? I'm really struggling to install multiple versions","2773":"I need to read a csv file, set the column types for this csv, and for all the rows on this csv run a pretrained model to predict some feature \/ attribute","2774":"is there a good example someone can share with me on this?","2775":"@ledell I think I saw you on the h2o conference - hello","2776":"@schwannden i realized that `fold_column` is already in AutoML.  i was confusing this wtih `fold_assignment` which is missing","2777":"@DanGolding ill ask about that, but my understanding is that we guarantee model compatibility between minor versions","2778":"@DanGolding how have you dealt with this problem using other ML frameworks?","2779":"every one i\\u2019ve used has had this same issue\\u2026 i wish there were a better solution :-(","2780":"@ledell thanks, if I could get different versions installed in virtual environments I think that would be fine because then it's easy to switch to an older version. But also, a directory of older version URLs to .whl files to install with pip would be great too!","2781":"Yes, @ledell, fold assignt is what we need, we need to be able to specify an array like:\\n[(train_indices1, test_indices1), (train_indices2, test_indices2), ...]","2782":"@schwannden actually, that\\u2019s what `fold_column` does.  `fold_assignment` just says how you create `nfolds` (Random, Modulo, etc)","2783":"@schwannden but rather than give it an array, you make a column that has the fold id in there","2784":"where fold id ranges from 1-k in the case of k-folds","2785":"@DanGolding i am talking to some folks about this, we have an \\u201coverride\\u201d switch\\u2026 will get back to you about this option when i learn more about it","2786":"@ledell I can\\u2019t do it with fold column, because I need time series  style cv, meaning if I have data x1, x2, x3, x4, x5, I need the following assignments\\nx1 as train, x2 - x5 as test\\nx1 - x2 as train, x3 - x5 as test\\nx1 - x3 as train, x4 - x5 as test\\nx1 - x4 as train, x5 as test","2787":"hi~\\nI'd like to know whether h2o provides R2 metric for Automl as stopping metrics in Scala??","2788":"@ledell, @r50206v raised another question, is there a way to provide custom stopping metrics in AutoML? Since I see there is  a custom option in StooppingMetric but don\\u2019t know how to provide the custom function","2789":"@schwannden oh ok, right\\u2026 did we talk about this before?  i think i remember you talking about time series.  its going to be a while until we support time-series CV in H2O.  one thing you could do is use AutoML to do the training & validation using just a single split.  you would set `nfolds=0` which would also turn off the Stacked Ensembles.  you would create the different train\/test splits yourself and then do a new AutoML run for each combo.  then aggregate the results after","2790":"In this case the only time that AutoML will save you is that you don\\u2019t have to write all the modeling code on top of all the custom train\/test\/eval loops","2791":"@r50206v i thought we would, but then i looked at the docs for `stopping_metric` and see thar r2 is not one of the available options.  i will ask to see why we don\\u2019t have r2 as an option because in theory we should allow early stopping by any of the metrics that we support","2792":"http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/data-science\/algo-params\/stopping_metric.html","2793":"@schwannden no we can\\u2019t allow custom stopping metrics, we can only allow the ones that we compute already inside H2O","2794":"but if there is some metric that you\\u2019re interseted in, let us know.  we want to support all the popular metrics","2795":"@ledell  thanks, I use rmse as an alternative","2796":"however, I encounter another problem during running automl on scala\\nit shows this warning message\\n\\thread WARN: Unblock allocations; cache below desired, but also OOM: GC CALLBACK, (K\/V:8.3 MB + POJO:978.4 MB + FREE:N\/A (-ve) == MEM_MAX:910.5 MB), desiredKV=113.8 MB OOM!\\\\n\\nI believe this is the reason why automl stopped training.\\nDo you know where I can adjust the memory limit~??","2797":"I'm running into an issue with xgboost on h2o 3.18.0.4 run on H2o Flow.  Whenever I do CV, the results in the logs are reported incorrectly.  The validation stats are identical to the training stats","2798":"It appears the problem is with the way that it splits up the data set.  Looks like the cv_1_train == cv_1_valid","2799":"@ledell since you mentioned it, it would be nice to have an advanced metrics that evaluate tpr under certain fpr level. This is useful when accuracy is not the only concern, and we need to contro. the fpr.","2800":"@r50206v https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-5397","2801":"@stealthman13 thanks for the bug report, would you be able to file a JIRA, by chance? https:\/\/0xdata.atlassian.net\/projects\/PUBDEV\/summary","2802":"@stealthman13 have you tried this in R or Python or just Flow?","2803":"@schwannden that might be a bit difficult from an API standpoint, but i like the idea","2804":"we compute all the tpr, fpr etc for each threshold (though I cant remember where that is stored in the metrics object), you know about that, right?","2805":"so you can get all those numbers, its just not easy to use that for early stopping, unless we would allow the uesr to pass a function instead of a string for `stopping_metric`","2806":"@ledell haha yes, I understand. Just throwing the thought :))\\nBefore we could have custom metric, it would be nice to get the fold assignments.\\nCurrently in AutoML, keep_cv_fold_assignment is not exposed, and default to false, that makes it practically impossible to calculate the custom CV metric by ourself","2807":"Hi, I am using h2o prediction-services. After deploying an h2o(binary classification gbm) model, It generates the result with threshold that maximise F1 score. Is there a way to change this threshold to max 'min_per_class_accuracy'.","2808":"@ledell  I just tried it using Flow. I'll give it a try in R as well","2809":"> Currently in AutoML, keep_cv_fold_assignment is not exposed, and default to false, that makes it practically impossible to calculate the custom CV metric by ourself\\n\\n@schwannden good point, i will make a ticket to turn this on","2810":"@schwannden https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-5399","2811":"@ledell you rocks!","2812":"hi, what threshold does the h2o use for making predictions?","2813":"hi @thirdeye802 you answered your own question above (its the thres which maximizes F1 score). sorry we don\\u2019t have good documentation on this, but we are adding a whole new metrics section to our user guide in the next version. ","2814":"@thirdeye802 i dont know if you\\u2019re using R or Python or Flow.  In R, check out http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-r\/docs\/reference\/h2o.metric.html","2815":"i know in flow there is a table of thresholds and the corresponding scores, so you can choose a different threshold that way","2816":"i can\\u2019t recall in R\/Py where that table is off the top of my head but i think its stored in the model","2817":"otherwise you can use the link i sent, apply your own thresholds and get back that dataframe","2818":"hi @ledell, thanks for answering. I wasn't sure if it's the 'max f1' on validation data or training data. I did cross-checked, prediction-services uses 'max f1' on training data, i think.\\nwell i need to make predictions with prediction-services. so i am not sure how above will help.\\ni did found the variable 'default_threshold' in 'model.ini' file in mojo of the h2o model. changing this variable seems to work.","2819":"@thirdeye802 what do you mean by \\u201cprediction-services\\u201d?  are you talking about Steam?","2820":"yes. i am using this method though: http:\/\/docs.h2o.ai\/steam\/latest-stable\/prediction_service.html","2821":"Hi All,\\nCurrently im trying to install a new h2o package for R on my offline\/closed-off server, but throughout the installation of the package it gives me an error that says that it could not connect to the host-server (which is obvious since their is no port out of the server available for security reasons). Does anybody know how to solve this?","2822":"```\\ncurl: (6) Couldn't resolve host 's3.amazonaws.com'\\nError in download.file(md5_url, destfile = md5_file, mode = \\w\\ cacheOK = FALSE,  : \\n  'curl' call had nonzero exit status\\nError : unable to load R code in package \\u2018h2o\\u2019\\n```","2823":"Thats the precise error im getting","2824":"@thirdeye802 ok sorry i don\\u2019t know much about Steam.  I\\u2019d recommend posting any questions to Stack Overflow or h2ostream","2825":"@fjcarton yes, its trying to download the h2o.jar file from the internet.  i\\u2019ve herad that we have this issue with customers all the time and i know that there\\u2019s a work-around, let me see if i can find out what the solution is.","2826":"hi, can I save ROC plot as png or jpeg in python??","2827":"@r50206v yes they are enabled by matplotlib, nothing custom.  you can save them in the normal way of saving matplotlib plots (don\\u2019t remember offhand, you\\u2019ll have to check Stack Overflow)","2828":"@r50206v if you find out, feel free to post an example here and we will add it to our docs","2829":"@fjcarton ok to install offline, then just go to the downloads page, and download the zip version of h2o from the big Download H2O button http:\/\/h2o-release.s3.amazonaws.com\/h2o\/latest_stable.html.  unzip and then install like this:  ` R CMD INSTALL h2o-3.10.0.6\/R\/h2o_3.10.0.6.tar.gz`","2830":"@fjcarton you will have to also make sure you have the R package dependencies installed already: \\RCurl\\u201d, \\jsonlite\\","2831":"@ledell thank you for answering my question \\nthis is what I did \\n\\n```\\nmodel = h2o.get_model(model_id)\\nperf = model.model_performance(valid=True)\\nfpr = model.roc(valid=True)[0]\\ntpr = model.roc(valid=True)[1]\\n\\nplt.figure(figsize=(10,8))\\nplt.title('ROC Curve', fontsize=25)\\nplt.plot(fpr, tpr, color=colors[0], alpha=0.5, label = 'AUC = %0.2f' % perf.auc())\\nplt.legend(prop={'size': 13})\\nplt.plot([0, 1], [0, 1], '--', color=colors[3])\\nplt.xlim([0, 1])\\nplt.ylim([0, 1])\\nplt.ylabel('True Positive Rate', fontsize=15)\\nplt.xlabel('False Positive Rate', fontsize=15)\\nplt.savefig('roc.png')\\n```","2832":"does H2O support reading non-UTF8 encoded file?","2833":"@ledell Tnx for your quick response. I will try it your solution and will get back to you whether it works.","2834":"thanks @r50206v i was confused actually, i forgot that we don\\u2019t have a utilty function in H2O to plot ROC!!  i am goign to create a ticket for this\\u2026 its crazy that we dont have one.  i was thinking about the `model.plot()` function which plots the scoring history","2835":"@r50206v I am trying to turn this into a reproducible exmaple\\u2026 I have imported `import matplotlib.pyplot as plt` but the `colors` object is not defined, what did you use for that?","2836":"@r50206v ok so i realized that there is a way to plot the ROC curve in R or Python already, shown in this ticket https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-4449","2837":"but i dont think this is documented anywhere","2838":"Srry to bother anybody in the weekend, but im currently working on a paper which compares multiple machine learning techniques with another. Thereby comes that the H2O package + RSparkling are a real life-saver in speed and efficiency. Thank you for that! The only question that I have is:\\nDo you know what the specific settings for the h2o.randomforest are to make it a decision tree algorithm (Preferably CART or Quinlan)?\\nSince I now have ","2839":"```\\nntrees = 1\\nmtries=-1\\nsample_rate = 1\\n```","2840":"@fjcarton good question!  i have been wanting to make a DT wrapper for a long time\\u2026 i have a ticket for it here: https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-4324 which says the right values","2841":"you need to set `mtries = nfeatures` as well","2842":"Hi, some endpoints are suffixed with `.bin` and some not (e.g. `GET \/3\/DownloadDataset` vs. `GET \/3\/DownloadDataset.bin`). What does it indicate?","2843":"Hi, still looking for a reference to the formula h2o uses for deviance (i.e. how do we replicate the  calculation in Python)? https:\/\/stats.stackexchange.com\/questions\/331991\/deviances-in-h2o","2844":"I'm working with fairly large datasets - tens of millions of rows and hundreds of columns per row.  On a 48 core cloud autoML runs constrained to eleven models(the nine default models and two ensemble models) take several days to complete.  My data is all numeric except for the response category and generally limited in range from 0-1000 with no more than 4-5 sig figs.  It would all fit easily into single precision floats. Do H2O algorithms use single precision float where reasonable?  Is there any interest in avx-512 instruction support?  If there is a better forum for asking these sorts of questions please feel free to point me there.","2845":"@ledell and @fjcarton ,  Isn't we prefer GBM to create a Decision tree model as described in https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-4324 -\\n\\nOr, you can get a single decision tree by setting the following args in GBM (maybe this is better because it skips the data-dependent mtries arg):\\nntrees = 1\\nmin_rows = 1\\nsample_rate = 1\\ncol_sample_rate = 1\\nNote: min_rows defaults to 10 and max_depth to 5\\nI'm wondering if we also want to set max_depth to something large so that we don't apply regularization by default...","2846":"@DanGolding just answered on stackexchange","2847":"@ggauravuee you can use either GBM or RF to get a single DT, it doesn\\u2019t matter.  if you want your DT to not have any regularization, then yes, you should set max_depth to something large","2848":"Up.\\n> Hi, some endpoints are suffixed with `.bin` and some not (e.g. `GET \/3\/DownloadDataset` vs. `GET \/3\/DownloadDataset.bin`). What does it indicate?","2849":"@ledell  Tnx for the reference to your ticket, that really helps me out a lot. \\n@ggauravuee sounded more logical to translate a random forest to decision tree ;) but GBM could also have been used offcourse","2850":"@pcejrowski sorry i dont know the answer to this.  someone else may know","2851":"Hi, if I am using the H2O java\/scala library, how do I free all memory? Even better, is there a way to free just all dataframe or all models?","2852":"I just started using the python interface to h2o to run models on a remote server.  It seems that when I transform my pandas array to an h2o array, it writes a large temp file to my server's \/tmp\/ directory","2853":"is there any way to prevent that from happening?","2854":"@stealthman13 no, there\\u2019s not.  the only way to get data from R or Python memory into the H2O Cluster is to write to disk and then read into H2O so that\\u2019s what the conversion functions do","2855":"it should be removed from tmp once you exit the Python session, if not let us know","2856":"@schwannden i dont know the name of the method in Java\/scala, but its `h2o.remove_all()` in python http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-py\/docs\/_modules\/h2o\/h2o.html#remove_all","2857":"we also don\\u2019t have a way to only delete models OR dataframes","2858":"you\\u2019d have to remove them individually by key","2859":"i agree that would be a nice feature though","2860":"Hi all,\\nWhile trying to get a big random forest model running, I keep getting an error message","2861":"```R\\nError in .h2o.doSafeREST(h2oRestApiVersion = h2oRestApiVersion, urlSuffix = urlSuffix,  : \\n  Unexpected CURL error: couldn't connect to host\\n```\\nDoes somebody know how to fix this? Im running a Sparklyr + RSparkling + H2O instance in RStudio\\n","2862":"@ledell thanks!","2863":"@ledell  yes I saw this before, it's just is very hard, even from tracing the source code, to see how python api correspond to Scala\/Java code","2864":"@ledell thanks. I think several errored out while loading, so they didn't get deleted","2865":"hi guys, I am using h2o-flow also h2o-python. In h2o-flow, I know how to specify max_memory for heap. but i don't know how much value should i choose. I am not using this machine for anything other than h2o. It still shows, 'swapping. gc callback'. how can i use whole memory optimally.","2866":"Also, does somebody know with which algorithm the `balance_classes`-parameter works? I'm writing a paper with a highly under-sampled dataset, hence would like to use this option but since I can not find the methodology around this principle it would be hard to explain in the paper.","2867":"And I see that the `balance_classes` variable is implemented into GBM, DRF, naive Bayes and NN, but is it also possible to bootstrap data in the GLM models","2868":"Hi all! does anyone know if there is any function similar to h2o.toFrame(word2vec.model) (which is used to convert a word2vec model into a h2o dataframe in R) but in h2o-python? thanks in advance!\\n```","2869":"Error: java.lang.IllegalArgumentException: Actual column must contain binary class labels, but found cardinality 1!","2870":"> Hi all! does anyone know if there is any function similar to h2o.toFrame(word2vec.model) (which is used to convert a word2vec model into a h2o dataframe in R) but in h2o-python? thanks in advance!\\n```Found the toFrame method for python in https:\/\/github.com\/h2oai\/h2o-3\/blob\/master\/h2o-py\/h2o\/model\/word_embedding.py#L28:  it was just \\to_frame()\\u201d \\ud83d\\ude02 ","2871":"@rcercos probably just: `h2o.H2OFrame(word2vec.model)`","2872":"oops, just saw that you found the solution @rcercos ","2873":"@constantinembufung it means that there are not two classes represented in your training data response column.  double check your data...","2874":"@fjcarton we don\\u2019t get have `balance_classes` for GLM (noticed this recently).  it is not yet functional in RF (there is a ticket open for that).  so basically GBM, NN and i don\\u2019t recall NB but if the param is there, its probably working.  ","2875":"http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/data-science\/algo-params\/balance_classes.html ","2876":"@fjcarton when getting the CURL error, it means that your h2o cluster has probably crashed?  what happens if you do `h2o.clusterStatus()`","2877":"I just want to confirm my understanding that calculation for R2 (R-squared) in h2o is same as the standard formula (below) and it's same for RF regression and linear regression (in GLM). The formula is :-  R2 <- 1 - (sum((actual-predicted)^2)\/sum((actual-mean(actual))^2)) .\\nsometimes, I am observing a negative R2 value in RF regression which means the - model fits worse than a horizontal line (the null hypothesis). \\n","2878":"@ggauravuee see this issue https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-5381  will be fixed in 3.20","2879":"@ledell Thanks, it claried my doubt on negative R2 value in DRF.","2880":"@ledell  Thanks for your respons. I now created the balance class dataset myself in order to implement it into all techniques (GLM, GBM, RF, NB, NN)","2881":"Now I'm transferring the results form the models to another device. Are there any specifications to use `h2o.loadmodel`?","2882":"Do I need the same version of h2o from the created instance? Or does that make no difference?","2883":"```R\\nR is connected to the H2O cluster (in client mode): \\n    H2O cluster uptime:         16 seconds 817 milliseconds \\n    H2O cluster version:        3.10.4.6 \\n    H2O cluster version age:    11 months and 1 day !!! \\n    H2O cluster name:           sparkling-water-######_1241232303 \\n    H2O cluster total nodes:    2 \\n    H2O cluster total memory:   62.22 GB \\n    H2O cluster total cores:    29 \\n    H2O cluster allowed cores:  24 \\n    H2O cluster healthy:        TRUE \\n    H2O Connection ip:          10.194.98.13 \\n    H2O Connection port:        54321 \\n    H2O Connection proxy:       NA \\n    H2O Internal Security:      FALSE \\n    R Version:                  R version 3.4.1 (2017-06-30) \\n```\\nThese are the currently cluster specifications.","2884":"@fjcarton yes the model version must be the same ","2885":"hi. In h2o-flow, after training a model, there is a graph that helps to tune threshold. When i predict by same model on same threshold by importing that same model in python, it gives slightly different results. The confusion matrix does not exactly matches. Anyone has idea on how it's happening?","2886":"@thirdeye802 this may be a bug in the confusion matrix.  there are a few JIRAs about confusion matrix being slightly off","2887":"[![image.png](https:\/\/files.gitter.im\/h2oai\/h2o-3\/fIWq\/thumb\/image.png)](https:\/\/files.gitter.im\/h2oai\/h2o-3\/fIWq\/image.png)","2888":"Hi, the download_mojo function appears to be missing in Python? I've tried version 3.16.0.2 (the version we have to use to be compatible with some third party software) and here is a screen shot of it not appearing in 3.14.0.7 ","2889":"It does appear in older versions in R. And using these Python versions, we can export to mojo manually in flow","2890":"But is there maybe something we're doing wrong on our side that it isn't appearing in the Python api?","2891":"@DanGolding have you tried 3.18?","2892":"we try to equivalent R\/Py functions in at the same version, but it doesn\\u2019t always end up that way","2893":"maybe it was not added til later","2894":"also make sure the model you are trying to use has a MOJO to begin with (a few don\\u2019t)","2895":"Question: In `AUC2.java` line 174 the method   `void checkRecallValidity() {\\n    double x0 = recall.exec(this, 0);\\n    for (int i = 1; i < _nBins; i++) {\\n      double x1 = recall.exec(this, i);\\n      if (x0 >= x1) \\n        throw new H2OIllegalArgumentException(\\\\+i, \\recall\\ \\\\+x1 + \\<\\ + x0);\\n    }\\n  }` is defined. However, I'm wondering if it's correct (either the exception or the condition is wrong I assume). Should it be `x0>x1` instead of `x0>=x1`? In the exception it says `x1 < x0`. Why I stumbled over this: If I have a 100% correct classification, recall will remain 1 for any index. Or do I entirely miss something? ","2896":"https:\/\/github.com\/h2oai\/h2o-3\/blob\/master\/h2o-core\/src\/main\/java\/hex\/AUC2.java#L174","2897":"Hi. Can I get somehow hidden layers from Deep Learning Model when this is exported to MOJO? In Python api there is deepfeatures method for that","2898":"@ledell  Apologies, it was because download_mojo is an instance method, not a static method. So it is there if I call it on the model. Not sure why the h2o class has a download_pojo though. Sorry about the confusion. ","2899":"@DanGolding i think the reason is that not all models have a MOJO (yet) so we probably made it associated with the model for this reason","2900":"@siim-romanov this is not currently possible, but i added a feature request https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-5467","2901":"Could you advise how to create a Logistic and RF models from a large dataset without using sparking water or hadoop setup. I able to create models using 10Million records (40 GB file) in a 64 GB RAM machine. In general, is it suggested to create a model from 50M records(200 GB file) in AWS machine having around 600 GB RAM machine. I know we can create a H2o cluster using multiple nodes\/machines, but I would prefer single machine as I am need to do some fetaure engineering on large data as well.","2902":"@ggauravuee i am not sure i understand your question... you just use H2O without Spark\/Hadoop (those technologies are not necessary)","2903":"just rent the biggest instance you can on AWS if you want to use a single node","2904":"@ledell , I just want to know if single h2o node can support 600 GB of RAM\/memory or have you heard that anybody tried it.","2905":"I'm trying to run an xgboost on a large dataset and my h2o process randomly dies with no explanation.  Has anyone else experienced this?","2906":"@ggauravuee oh yeah, certainly!  AWS has some really high memory nodes these days https:\/\/aws.amazon.com\/ec2\/instance-types\/","2907":"@ggauravuee we've seen it used on terabytes of data","2908":"@stealthman13 did you post on stack overflow the other day?  there's not much we can do without logs","2909":"Nope, wasn't me","2910":"we are still working on xgboost stability... this seems to be an issue ","2911":"ah, okay.  Figured that was the case","2912":"my recommendation is to post a reproducible example as a bug report on JIRA and attach your logs","2913":"we have not seen this personally on any of our machines or tests, but we have seen a few reports of random death of cluster when using xgboost","2914":"I actually just looked in my kernel logs and found errors.\\n\\nkernel: java invoked oom-killer: gfp_mask=0x280da, order=0, oom_score_adj=0","2915":"cc @michalkurka ^^ xgboost failure, recognize this error?","2916":"@\/all We are hiring a Machine Learning Scientist at H2O.ai in Mountain View.  Please share widely! http:\/\/h2oai.applytojob.com\/apply\/vfJqT7g0Mj\/Machine-Learning-Scientist?referrer=20180410185153Q0TWI65KUNFMBBAL","2917":"@stealthman13 what version of H2O are you using? It would be great if you could test the version we are going to release today. We fixed a memory leak that could be also causing the excessive memory usage in your case. Please wait for H2O-3.18.0.6 and let us know","2918":"I'm using 3.18.0.5","2919":"I'll gladly test it","2920":"3.18.0.5 - that means you are affected, 3.18.0.6 should greatly improve memory management","2921":"great, I'll be on the lookout for it","2922":"are you running single node or multi-node?","2923":"single ","2924":"I have some single node speed-ups in the making, it won't make it in the fix release yet but it should be available soon (a week) in a nightly build","2925":"Awesome. I'll look forward to that as well.  I've run multi-node before, but I found it to be much slower than single node.  ","2926":"perhaps network overhead","2927":"mutlinode performance is not ideal, we are working on improving that as well - should be part of 3.20.0.1 (that could be a month from now)","2928":"single node should see improvements sooner","2929":"I just started using mojos instead of pojos and haven't checked yet, but are mojos compatible between versions?","2930":"because i know pojos aren't","2931":"my ops guys will love it when I can use multi-node and they don't have to keep adding ram to 1 big server","2932":"MOJOs are compatible between versions in the sense that you can take an older mojo and use it with a newer version of h2o-genmodel.jar. You cannot take a older h2o-genmodel.jar and use it with older mojo (but that use case doesn't make sense).","2933":"excellent.  Thanks","2934":"Your application can therefore have models from different versions of H2O and still use just a single h2o-genmodel.jar","2935":"np","2936":"@michalkurka any idea on my problem with the `checkRecallValidity`. See above :-)","2937":"Hi @h2oai folks :D finding some bugs in the `NewChunk::compress2` logic, making a PR for discussion purposes soon, but wanted to give ya'll heads up here","2938":"involves long -> double -> long conversions and that being lossy","2939":"PRs open, hopefully I was able to tag all the right people for review","2940":"https:\/\/github.com\/h2oai\/h2o-3\/pull\/2309\\nhttps:\/\/github.com\/h2oai\/h2o-3\/pull\/2310\\n\\nthese are fairly core","2941":"thanks @spennihana!","2942":"@thirdeye802 confusion matrix is not exact, it is a close approximation of the exact confusion matrix; we will make it exact in future versions; for now you can expect small differences","2943":"@dietzc thanks, checkRecallValidity is indeed incorrect; the comparison is wrong and there is an edge case where it throws an exception even though it should pass; this is a corrected version:\\n\\n  void checkRecallValidity() {\\n    double x0 = recall.exec(this, 0);\\n    for (int i = 1; i < _nBins; i++) {\\n      double x1 = recall.exec(this, i);\\n      if (x0 > x1)\\n        throw new H2OIllegalArgumentException(String.valueOf(i), \\recall\\ x0 + \\ < \\ + x1);\\n      x0 = x1;\\n    }\\n  }\\n","2944":"message should have :) x0 + \\ > \\ + x1","2945":"perfect. @michalkurka you want a PR or did you already fix it?","2946":"and thanks for looking into that :-)","2947":"@dietzc I have a PR, can you review please? https:\/\/github.com\/h2oai\/h2o-3\/pull\/2313","2948":"In H2O GLM, how does it treat enum feature? Does it use one-hot by default for categorical features?","2949":"I would like to know if there is a benefit of using nfold=3, 5 etc. for a really large data (over a Million records) or should I simply use Train and Validation data, say 80:20 ratio. I am asking it as I have 5Million(20 GB) and 10M(40 GB) data and using nfold=3, 5 is taking lot of memory & time. Even, many a times I can't create Logistic model on 5M(40 GB) data as i have limited memory. Will it make really significant impact on my model if I use 80% data as Training data vs 100% as Traing data with nfold=3 or 5?","2950":"@schwannden yes GLM uses one-hot encoding","2951":"@ggauravuee if the only reason you are doing CV is to get a good estimate of model performance, then you can do this instead:  use a 80:20 split and evaluate performance on a test set.  but when you train the \\real\\ model, just use 100% of the data (but don't use CV because you already have a good idea of your model performance at this point, so its no longer needed)","2952":"hi, does h2o provide thresholds that match different fpr and tpr when calling roc function(http:\/\/h2o-release.s3.amazonaws.com\/h2o\/master\/3233\/docs-website\/h2o-py\/docs\/h2o.model.html)","2953":"@r50206v yes, search \\threshold\\ in the user guide.  you can find link to user guide on docs.h2o.ai","2954":"we dont have an ROC function, but there is a way to see the rates for each threshold","2955":"sorry, i didn't specify my question. I used the roc function in this website (http:\/\/h2o-release.s3.amazonaws.com\/h2o\/master\/3233\/docs-website\/h2o-py\/docs\/h2o.model.html).\\nhowever, it only provides a tuple containing fpr and tpr.\\nI am wondering does h2o provide thresholds as sklearn.metrics.roc_curve does.\\nso far, the only way I can find matched threshold is using find_idx_by_threshold and for loop a sequence of thresholds.","2956":"One more question, in AutoML, when I select lift-top-group as stopping metrics, and I use only GLM as algorithm, which class will be treated as positive? Does H2O use the class with lesser count to be the positive class?","2957":"The thing is lift-top group is not very useful if we can not specify what category is the positive category","2958":"In scala I tried frame.vec(\\target\\).serDomain(frame.vec(\\target\\).domain().reverse) to use the smallest category as positive label, but the result is still the same, AutoML use largest category as positive label","2959":"@schwannden that's a good question.  i am pretty sure it has to do with the ordering of the levels for the factor response column.  it's alphabetical, so if you had \\yes\\ \\no\\ then \\no\\ would be the first level and \\yes\\ the second.    if you need to swap the order, then you can use `h2o.relevel()` (in R)","2960":"so to test, you could look at the AUC value to figure out which one it's using as the \\positive\\ class","2961":"when you say the \\largest\\ category, what do you mean?  i am pretty sure it doesn't look at class distributions, but i could be wrong","2962":"Hi, I am trying to build Steam, but I got many errors, like:\\n```\\nERROR in \/home\/luca\/go\/src\/github.com\/h2oai\/steam\/gui\/node_modules\/typescript\/lib\/lib.d.ts\\n(6246,14): error TS2687: All declarations of 'bodyUsed' must have identical modifiers.```\\nand\\n```\\nERROR in \/home\/luca\/go\/src\/github.com\/h2oai\/steam\/gui\/node_modules\/typescript\/lib\/lib.d.ts\\n(12257,11): error TS2300: Duplicate identifier 'Headers'.```\\n\\nAny ideas on how to fix them?","2963":"Hi, I'm trying to import csv file of size 15G in a 2 node cluster using python-client, each having more than 70G free RAM.. CSV file has around 40 million data with 25+ categorical and 30+ numerical features.. But, I'm getting Memory error with following stacktrace. I have checked the memory usage in both the nodes during the command execution and only 20GB of RAM was utilized.. Could anyone help me to figure out on what I'm missing ?","2964":"```\\nMemoryError                               Traceback (most recent call last)\\n<ipython-input-6-45e9975d59a8> in <module>()\\n----> 1 train = h2o.import_file('\/data\/train_comp.csv', header=1)\\n\\n\/usr\/lib\/python2.7\/site-packages\/h2o\/h2o.pyc in import_file(path, destination_frame, parse, header, sep, col_names, col_types, na_strings, pattern)\\n    412         return lazy_import(path, pattern)\\n    413     else:\\n--> 414         return H2OFrame()._import_parse(path, pattern, destination_frame, header, sep, col_names, col_types, na_strings)\\n    415 \\n    416 \\n\\n\/usr\/lib\/python2.7\/site-packages\/h2o\/frame.pyc in _import_parse(self, path, pattern, destination_frame, header, separator, column_names, column_types, na_strings)\\n    310             path = os.path.abspath(path)\\n    311         rawkey = h2o.lazy_import(path, pattern)\\n--> 312         self._parse(rawkey, destination_frame, header, separator, column_names, column_types, na_strings)\\n    313         return self\\n    314 \\n\\n\/usr\/lib\/python2.7\/site-packages\/h2o\/frame.pyc in _parse(self, rawkey, destination_frame, header, separator, column_names, column_types, na_strings)\\n    324                na_strings=None):\\n    325         setup = h2o.parse_setup(rawkey, destination_frame, header, separator, column_names, column_types, na_strings)\\n--> 326         return self._parse_raw(setup)\\n    327 \\n    328 \\n\\n\/usr\/lib\/python2.7\/site-packages\/h2o\/frame.pyc in _parse_raw(self, setup)\\n    353         # ... but job stats returns only a dest_key, requiring another REST call to get nrow\/ncol\\n    354         self._ex._cache._id = p[\\destination_frame\\]\\n--> 355         self._ex._cache.fill()\\n    356 \\n    357 \\n\\n\/usr\/lib\/python2.7\/site-packages\/h2o\/expr.pyc in fill(self, rows, rows_offset, cols, full_cols, cols_offset, light)\\n    344         else:\\n    345             endpoint = \\\/3\/Frames\/%s\\\\n--> 346         res = h2o.api(\\GET \\ + endpoint % self._id, data=req_params)[\\frames\\][0]\\n    347         self._l = rows\\n    348         self._nrows = res[\\rows\\]\\n\\n\/usr\/lib\/python2.7\/site-packages\/h2o\/h2o.pyc in api(endpoint, data, json, filename, save_to)\\n    101     # type checks are performed in H2OConnection class\\n    102     _check_connection()\\n--> 103     return h2oconn.request(endpoint, data=data, json=json, filename=filename, save_to=save_to)\\n    104 \\n    105 \\n\\n\/usr\/lib\/python2.7\/site-packages\/h2o\/backend\/connection.pyc in request(self, endpoint, data, json, filename, save_to)\\n    400                                     auth=self._auth, verify=self._verify_ssl_cert, proxies=self._proxies)\\n    401             self._log_end_transaction(start_time, resp)\\n--> 402             return self._process_response(resp, save_to)\\n    403 \\n    404         except (requests.exceptions.ConnectionError, requests.exceptions.HTTPError) as e:\\n\\n\/usr\/lib\/python2.7\/site-packages\/h2o\/backend\/connection.pyc in _process_response(response, save_to)\\n    711         if content_type == \\application\/json\\:\\n    712             try:\\n--> 713                 data = response.json(object_pairs_hook=H2OResponse)\\n    714             except (JSONDecodeError, requests.exceptions.ContentDecodingError) as e:\\n    715                 raise H2OServerError(\\Malformed JSON from server (%s):\\\\n%s\\ % (str(e), response.text))\\n\\n\/usr\/lib\/python2.7\/site-packages\/requests\/models.pyc in json(self, **kwargs)\\n    793             if encoding is not None:\\n    794                 try:\\n--> 795                     return json.loads(self.content.decode(encoding), **kwargs)\\n    796                 except UnicodeDecodeError:\\n    797                     # Wrong UTF codec detected; usually because it's not UTF-8\\n\\n\/usr\/lib64\/python2.7\/encodings\/utf_8.pyc in decode(input, errors)\\n     14 \\n     15 def decode(input, errors='strict'):\\n---> 16     return codecs.utf_8_decode(input, errors, True)\\n     17 \\n     18 class IncrementalEncoder(codecs.IncrementalEncoder):\\n\\nMemoryError: \\n```","2965":"@mathankumarts it looks like you are getting memory error on client and not on the server; the easiest way to check is go to H2O Flow on the server and see if it the file was parsed successfully - if it was the issue is indeed on the client side ","2966":"Hi all, is it possible to do a 2-way partial dependence plot with h2o3?","2967":"@michalkurka Yep, it worked fine in the H2O Flow and python terminal in servers.. Could you please suggest me what is the ideal specification for the client ? As of now, I'm having 2GB RAM for h2o client.. And could you explain why client requires more memory ? I thought, client is just a wrapper of REST API calls to h2o server.","2968":"Hi","2969":"Hello, why is the `jenkins-rel-wolpert-8` branch not taking changes from master? Namely, the newest release (3.18.0.8) doesn't contain `h2o-persist-gcs` module?!","2970":"Hi, I'am new to h2o and asking myself, what's the difference between H2ODeepLearningEstimator() with autoencoder enabled and H2OAutoEncoderEstimator?","2971":"Hey guys, I'm looking for a way to use AutoML with GPU's - does anyone have an idea how to run H2O on GPU's? I've seen Deep Water and H2O4GPU but the documentation on these is not great","2972":"@pcejrowski 3.18.0.8 is a fix release; fix releases don't get new features (there are exceptions) - we release new features in stable versions","2973":"@mrdbourke right now we don't support AutoML with GPUs; in the future XGBoost will be added to AutoML and it will enabled GPU support","2974":"@mathankumarts memory requirement on client will depend on your use case, the Python client is lightweight and should not require too much memory to run; if your dataset is very wide it will need more memory to hold the Frame metadata and preview data\\n\\nwe do not have official requirements on the client side AFAIK, I would double the memory and see if that helps - if not please share the script","2975":"and Frame metadata","2976":"Thanks @michalkurka !","2977":"@ledell , just want to know when you guys are planning to add XGBoost in AutoML. Is it still planned by end of Q2\/June, 2018 ? Also, I can see that MOJO for AutoML is marked completed in JIRA under Fix version 3.20.0.1. But the latest stable version in 3.18.0.7, so when is 3.20.0.1 scheduled to release ? Can I somehow try MOJO for AutoML in 3.18.0.x ?","2978":"@michalkurka thanks! When can I expect the next stable release?","2979":"@michalkurka Cool, Thanks :smile: ","2980":"As per h2o doc - AutoML is currently in experimental mode (\\u201cV99\\u201d in the REST API). Please let me know when will be stable\/production ready version fo AutoML is planned to release. Most of the AutoML JIRA  items have 3.20.0.1 as fix version, so what are the high level timelines for 3.20.0.1 ","2981":"Hi, can someone help me on my question or give me a hint to further documentation? I don't understand the difference between H2ODeepLearningEstimator() with autoencoder enabled and H2OAutoEncoderEstimator?","2982":"Hi there, does anyone know if it\\u2019s possible to change the threshold that is used in the predict() function? I need to change the threshold for a model response in steam, but, more in general, I imagine there is a way of doing this when making predictions in Python\/R\\u2026. Thanks in advance! ","2983":"@ggauravuee regarding xgboost in AutoML.  it will either be 3.20 or 3.22.  ill find out at our weekly meeting tomorrow.  its possible that it will be on the nightly releases by end of June","2984":"i think 3.20 is early june, also will find out more tomorrow at a meeting","2985":"to try out new features, use the nightly releases: http:\/\/h2o-release.s3.amazonaws.com\/h2o\/master\/latest.html","2986":"you dont' have to wait for 3.20 to come out","2987":"@ggauravuee i dont think we will break the AutoML API.  in fact, i can guarantee that we wont, so feel free to put it in prod now.  maybe we will move it out of experimental mode in 3.20","2988":"@ledell  Thanks!","2989":"Hello new here","2990":"I am interested in AutoML","2991":"And want to build a trading bot","2992":"Which one will be cost effective Google's 1 TPU or Amazon's 4 Tesla P100 ?","2993":"And does driverless AI supports TPU ?","2994":"@xyedabz if you are talking about H2O AutoML (open source) that only works on CPUs.","2995":"@xyedabz Driverless AI works on nvidia GPUs only","2996":"@ledell ok thanks","2997":"hi, I am using FrameSplitter in scala. there are four parameters in this function (frame, ratios, destination key and job key). However, I cannot set seed if I want a fixed train\/test frame. Does h2o provide set seed on FrameSplitter in scala?","2998":"@r50206v use ShuffleSplitFrame","2999":"In GLRM, I read through the paper provided in the document, and see that it works with missing value by treating it as a parameter to be estimated during model training. However, how is the missing value handled when I call predict? I noticed that prediction is very fast, so it doesn't seems like GLRM fit missing value when doing prediction","3000":"Just to want to confirm that AutoML is open source and has Apcahe 2.0 license. So, it can be used in the 3rd party products. Right? Even, I think AutoML is a part of core H2o it self and covered under Apache 2.0 license as a part of core H2o.","3001":"hi, is it possible to filter H2O dataframe by row?","3002":"Hi every one ","3003":"How to cast type of  a column from int to real in H2OFrame ?","3004":"Is h2o binding API i.e. Rest API available for AutoML ? I didn't able to locate it in the latest stable version in h2o-bingis-3.18.0.7.jar. What is the tentative timelines for it? ","3005":"Hi, does anybody know how to obtain a variable importance figure from a Naive Bayes classifier? Since it does not seem to be implemented in the machine learning model and could not find any information on it (anywhere). \\nOr does it absence involve the independence assumption that is included in Naive Bayes, which makes variables hard to compare to each other?","3006":"Hi, I'm trying to start up the latest stable version on Ubuntu and am getting the error \\java.lang.NoClassDefFoundError: Could not initialize class water.Weaver\\ is there something else I need to install?","3007":"Hi, I work for a company currently trying to integrate H2O into our mostly Java based production applications.  To facilitate this I've created a Java REST API client which aims to replicate the functionality available to the python client.  It similarly lets you construct and send Rapids abstract syntax trees, and encapsulates methods for generating other API calls within objects representing frames, models, aggregations, connections, etc.  ","3008":"I was wondering whether or not this is something that the community would like me to open source, and if so, how I can properly add it to the repo with the appropriate test cases. Since it's all client side I'm not sure whether I should be writing and including unit tests or doing integration testing instead?","3009":"Also the Rapids ast creation is transparent like in the python client so to logically select rows from an H2OFrame, for example, the client call would look like\\n```\\nH2OFrame selected = frame1.select(frame1.select(\\col1\\).compare(\\>\\5)).assign(\\selected\\);\\n```\\nCorresponding to the python statement\\n```\\nselected = frame1[frame1[\\col1\\]>5]\\n```\\nWhich both generate the Rapids ast = (assign selected(rows frame1 (> (cols frame1 'col1') 5.0)))\\n\\n","3010":"@cranella , I have the same reuirement as you have i.e. integrating H2O in java based application. I am using the h2o-bindings.jar i.e. the h2o provided Rest API but it doesn't have all the functionality available so I am interested in the REST api which you have created. Is there is link where I can get it. ","3011":"@ggauravuee The code is not yet publicly available because I have to get approval from my company before I open source it, but I will keep you updated","3012":"I am pretty new to Sparkling Water. I am trying to solve a classification problem with H2O and Spark. \\nI understand that the overall classification accuracy or error per class can be computed as follows: \\n \\nprintln(\\Classfication accuracy: \\ + (1 - dlModel.classification_error()) * 100 + \\ %\\)\\nprintln(dlModel.mean_per_class_error())\\n\\nHowever, I cannot find any example code showing how to compute precision, recall and f1 measure! \\nAny help would be appreciated.","3013":"Anyone, please :) ","3014":"model.score(X,y)\\npredictions=model.predict(X)\\nprint(classification_report(y, predictions))","3015":"Hey @cranella. I've been working with H2O integrations also. From what I've explored, H2O provides a java client through the retrofit framework. In practice you can use the H2oApi class in the h2o-bindings. But I've been finding a lot of bugs...it would be awesome to see your work open sourced :) ","3016":"now a question: while parsing a dataset into the frame format through the java API `H2OApi.parse(ParseV3)`, it is possible to define the domains for Enum features explicitly through the ParseV3.domains field. \\n\\nBut from what I'm seeing there's some encoding problem, and instead of having `domains` defined as an String[][] that should be an array with size 65 (in my specific case), and in each position it should contain another array with the domain of that feature, I have an String[][] with a single array, with a single position filled with the String representation, i.e.: `domains[0][0] == [Ljava.lang.String;@620dcbe2\\\\[Ljava.lang.String;@6632537b\\\\[Ljava.lang.String;@2330c1d9\\\\[Ljava.lang.String;@1e07bfd4\\\\[Ljava.lang.String;@12d9252d\\\\[Ljava.lang.String;@66040586\\\\[Ljava.lang.String;@431f3e96\\\\[Ljava.lang.String;@6045d03e\\\\[Ljava.lang.String;@3b6e7156\\\\[Ljava.lang.String;@7d006b88\\\\[Ljava.lang.String;@47510130\\\\[Ljava.lang.String;@95bfdc4\\\\[Ljava.lang.String;@41f7d978\\\\[Ljava.lang.String;@3fd5a6e5\\\\[Ljava.lang.String;@70c278ae\\\\[Ljava.lang.String;@26a11eaf\\\\[Ljava.lang.String;@59622f1a\\\\[Ljava.lang.String;@4b12485d\\\\[Ljava.lang.String;@28765e99\\\\[Ljava.lang.String;@68c795e\\\\[Ljava.lang.String;@4ede9c6a\\\\[Ljava.lang.String;@17d7654c\\\\[Ljava.lang.String;@d4f73b9\\\\[Ljava.lang.String;@686cbdc7\\\\[Ljava.lang.String;@52eb416c\\\\[Ljava.lang.String;@7ebaa378\\\\[Ljava.lang.String;@81ec5ad\\\\[Ljava.lang.String;@591c3ec\\\\[Ljava.lang.String;@df90213\\\\[Ljava.lang.String;@26f3d1b7\\\\[Ljava.lang.String;@583e4b69\\\\[Ljava.lang.String;@533b7d21\\\\[Ljava.lang.String;@169704cf\\\\[Ljava.lang.String;@2e5111c3\\\\[Ljava.lang.String;@41e6263\\\\[Ljava.lang.String;@c44d5b4\\\\[Ljava.lang.String;@225b198f\\\\[Ljava.lang.String;@4a2db0e\\\\[Ljava.lang.String;@73d8bc83\\\\[Ljava.lang.String;@591b3e39\\\\[Ljava.lang.String;@23f6d3f4\\\\[Ljava.lang.String;@311e162f\\\\[Ljava.lang.String;@714882b\\\\[Ljava.lang.String;@7fe9406\\\\[Ljava.lang.String;@12828e7e` \\n\\nis anyone from H2O aware of this? is there any workaround?","3017":"Hi, can anyone tell me which kind of autoencoder  (sparse, denoising etc.)h2o implements by design? Or depends this only by the used options?","3018":"hi,  I want to get predictions from each individual tree in RandomForest for my input data.  Is it possible to get access to individual trees in h2o RandomForest? ","3019":"I know that POJO file consists of tree structure. But instead of parsing the text content, is there any other way ?","3020":"Pls let me know","3021":"Can anyone help me?","3022":"Which autoencoder is h2o using default?","3023":"Im searching for the runtime of a model, is there a feature within the H2O models that registers this?","3024":"@ggauravuee yes AutoML is part of H2O-3 which is Apache 2.0 licensed.  ","3025":"@fjcarton yes we store this.  in R it's `mymodel@model$run_time`, in python it will be stored in the JSON somehwere in the model","3026":"@cranella , I would love to have that available for all Java developers to seemless integrate h2o in Java based production applications. I am extensively using the h2o-bindings.jar but it has some limitations so sometimes I have to call a low level java api directly which is not ideal. Let me know if you are planning to open source your project or any idea how one can create it by it's own.","3027":"I would like to if h2o binding API i.e. Rest API available for AutoML ? I didn't able to locate it in the latest stable version in h2o-bingis-3.18.0.7.jar. What is the tentative timelines for it?","3028":"@ggauravuee I have been making progress on writing the junit tests for my library and still plan on open sourcing it soon","3029":"Are you mainly using h2o-bindings.jar to train models or are you interested in doing data preprocessing and manipulating frames using rapids expressions?  We can talk about how to construct the rapids requests if you\\u2019d like since that was the trickiest part and definitely where the h2o-bindings are most lacking as they have no support for anything other than sending precompiled rapids strings to the API","3030":"```water.exceptions.H2OIllegalArgumentException: Failed to find ModelMetrics for criterion: mean_residual_deviance\\n\\tat hex.ModelMetrics.getMetricFromModelMetric(ModelMetrics.java:147)\\n\\tat hex.ModelMetrics.getMetricFromModel(ModelMetrics.java:124)\\n\\tat hex.ModelMetrics$MetricsComparator.compare(ModelMetrics.java:176)\\n\\tat hex.ModelMetrics$MetricsComparator.compare(ModelMetrics.java:166)\\n\\tat java.util.TimSort.binarySort(TimSort.java:296)\\n\\tat java.util.TimSort.sort(TimSort.java:239)\\n\\tat java.util.Arrays.sort(Arrays.java:1512)\\n\\tat java.util.ArrayList.sort(ArrayList.java:1460)\\n\\tat java.util.Collections.sort(Collections.java:175)\\n\\tat hex.ModelMetrics.sortModelsByMetric(ModelMetrics.java:290)\\n\\tat ai.h2o.automl.Leaderboard$1.atomic(Leaderboard.java:264)\\n\\tat ai.h2o.automl.Leaderboard$1.atomic(Leaderboard.java:219)\\n\\tat water.TAtomic.atomic(TAtomic.java:17)\\n\\tat water.Atomic.compute2(Atomic.java:56)\\n\\tat water.Atomic.fork(Atomic.java:39)\\n\\tat water.Atomic.invoke(Atomic.java:31)\\n\\tat ai.h2o.automl.Leaderboard.addModels(Leaderboard.java:296)\\n\\tat ai.h2o.automl.Leaderboard.addModel(Leaderboard.java:332)\\n\\tat ai.h2o.automl.AutoML.addModel(AutoML.java:1406)\\n\\tat ai.h2o.automl.AutoML.pollAndUpdateProgress(AutoML.java:537)\\n\\tat ai.h2o.automl.AutoML.learn(AutoML.java:1093)\\n\\tat ai.h2o.automl.AutoML.run(AutoML.java:429)\\n\\tat ai.h2o.automl.H2OJob$1.compute2(H2OJob.java:32)\\n\\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1263)\\n\\tat jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\\n\\tat jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\\n\\tat jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:974)\\n\\tat jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1477)\\n\\tat jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)```","3031":"I got this error when I try to run AutoML in H2O Flow UI  ","3032":"@ggauravuee @cranella the missing AutoML bindings in h2o-bindings jar is a bug https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-5591 but it might take a while to get fixed since so far there are only 2 people asking for it","3033":"@andyxf1029 sorry i cant help you w\/o a reproducible example.   questions about code are best for Stack Overflow as well","3034":"^I was talking about Rapids support not AutoML","3035":"@cranella can you clarify what exactly is missing from h2o-bindings?","3036":"The bindings assume you already understand how to create Rapids ASTs which is not intuitive.  Hence I reimplemented what the expression node class from the python client does in java ","3037":"Hi Erin can you tell me which kind of autoencoder  (sparse, denoising etc.)h2o implements by design? Or depends this only by the used options?","3038":"@cranella yes you're right they are not intuitive and not documented or easy to write.  but is there something missing?  i am trying to figure out if there is a bug here or not","3039":"I wouldn\\u2019t call it a bug so much as a missing feature for java developers.  I think the client I wrote solves this problem though so if I could get in touch with a developer who\\u2019d like to review it and\/or work to integrate it into a future release I\\u2019d be happy to share my code","3040":"@cranella maybe @michalkurka can take a look (or find someone else to take a look at H2O).  thanks for the suggestion","3041":"^Ok thanks I will try to push it to my public git sometime next week ","3042":"hm is my question so dump or the wrong channel or why is nobody able to answer it?","3043":"@schildjo i dont have time to answer all the questions, so i go for the quick ones first","3044":"i had to look up the names of the params to tell you how to use the autoencoder","3045":"we support both sparse and denoising.  denoising: add input dropout, sparse use these params: https:\/\/github.com\/h2oai\/h2o-3\/blob\/master\/h2o-algos\/src\/main\/java\/hex\/deeplearning\/DeepLearningModel.java#L1674-L1676","3046":"we will add this to our docs to make more clear, thx","3047":"Hi Erin thanks for your help. It would be great, if its added to the docs ;D","3048":"h2o ai steam for windows ?","3049":"or is not supported ?","3050":"@ledell I have one further question.. if I use the python implementation, and use the autoencoder (from h2o.estimators.deeplearning import H2OAutoEncoderEstimator), which one is used? Its not clear to me :worried: ","3051":"@cranella, I am using the h2o-bindings.jar for both training models and doing data frame manupulations. And yes that I am using the rapids expressions for h2o frame manipulation which are not intutive (which you also mentioned). As an example, I am using below Rapid expression to split data in my Java code :- \\n       String splitExpr = \\(, \\ +\\n\\t\\t\\  (tmp= \\ + tmpVec + \\ (h2o.runif \\ + completeFrameName + \\ \\ + seed + \\))\\ +\\n\\t\\t\\  (assign \\ + trainingFrameName +\\n\\t\\t\\    (rows \\ + completeFrameName + \\ (<= \\ + tmpVec + \\ \\ + ratio + \\)))\\ +\\n\\t\\t\\  (assign \\ + validationFrameName +\\n\\t\\t\\    (rows \\ + completeFrameName + \\ (> \\ + tmpVec + \\ \\+ ratio +\\)))\\ +\\n\\t\\t\\  (rm \\ + tmpVec + \\))\\;\\n ","3052":"Is variable selection feature available in h2o out of the box? Or is it advisable to use GLM algorithm with LASSO Regression for Variable selection? I have a really large data having large number of variables\/features, so can I use the GLM with Lasso to select the most significant variables ? Then I will use it to create a model (RF or GBM or maybe a Stacked ensembled) model in h2o .","3053":"i am new to h2o-3 but not new to AI . Quick question . i am trying to import Financial market Time Series datasets ( Forex Data ) with the following columns  Date, Time , Open, High , Low , Volume  but i am running into issues with Time column","3054":"The Time column format   hh:mm","3055":"h2o-3 does recognize it as \\enum\\  but when i try to change it to time , the column shows nothing when using h2o Flow UI  ","3056":"Example :  Date, Time, O, H, L, C, V","3057":"2018-05-29, 20:35, 1.1720, 1.1780, 1.1680, 1.1748, 356 ","3058":"@schildjo neither are used by default (the arguments i linked to is how you activate those two versions)","3059":"@ggauravuee we don't have specific feature selection algos, but there is a JIRA open for it https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-5264","3060":"@ggauravuee you can use GLM lasso or use PCA","3061":"@ledell thanks for your help :smile:  but which Version auf autoencoder is then used if i don't specify these versions? :smile: ","3062":"Quick question (I hope) - when looking at a partial dependence plot for a GBM model with 2 classes (binomial distribution) how does one tell which class is on which end of the mean response? (i.e. which is 0 and which is 1)","3063":"h2o encodes categoricals in lexicographical order, so if you have Yes, No, then No is mapped to 0 and Yes is mapped to 1.","3064":"Thanks, @laurendiperna. That is very helpful.","3065":"Hi everyone, I m just new to H2O eco. I was just bench testing the QPS of H2O REST prediction API in a single node cluster and found it was pretty low (below 200 using concurrency of 20). Therefore, is there any thing on the roadmap for H2O to improve this functionality when using in production? Thanks all!","3066":"@FrancisLiang can you tell us a little bit more about your use case? The REST API is not made for a single row scoring. Instead of using single node H2O you can download a scoring package (MOJO + genmodel.jar) and embed it in your system. This is a recommended way for high perf scoring. However, I am interested to hear about your use case - we might be able to address it as well.","3067":"@michalkurka Thanks a lot for your reply! As you mentioned, I could deploy the model in the production through the MOJO way but I was wondering if the scoring request, such as asking if the email received is a spam, could be sent to the H2O cluster directly from the client and the HTTP server in the H2O cluster could handle a high QPS traffic. I hope this makes my use case clear. Thanks again!","3068":"Also, I am wondering if there is a way to embed the tensorflow model into H2O? Thanks!","3069":"@FrancisLiang  scoring service like that is currently not supported - you can do it by creating a single row frame and score it but it won't perform well; I do like the idea - do you want to request it in our jira? https:\/\/0xdata.atlassian.net\/projects\/PUBDEV\/","3070":"@FrancisLiang tensorflow models are currently not supported, this is not something we would be planning to do in the near future","3071":"Hi,I am new to H20.I want to contribute to h20.ai","3072":"I am an active learner and implementer of machine learning and deep learning","3073":"@saidhiraj https:\/\/github.com\/h2oai\/h2o-3\/blob\/master\/CONTRIBUTING.md","3074":"Hello, I trained a model using pysparkling and I want to create a REST api for new data predictions instead of MOJO. I am not able to find any documentation for the same. I am referring the document http:\/\/docs.h2o.ai\/sparkling-water\/2.3\/latest-stable\/doc\/deployment\/pysparkling_pipeline.html","3075":"@snbhanja please refer to our productionizing documentation: http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/productionizing.html#example-design-patterns","3076":"Hello. In my company we are interested in starting to use the h2o ecosystem. And in doing our tests, we cannot find a download page for the steam tar cited here http:\/\/docs.h2o.ai\/steam\/latest-stable\/Installation.html","3077":"Hi everyone! When using the Import SQL Table function in Flow (Data -> Import SQL Table), I found that the \\select_query\\ option was not available. I am just wondering why this option is not added to the Flow? Thanks guys!","3078":"@LuizGG the open source version of steam is no longer actively supported. We provide the documentation so people who already have steam can still review it, but since it's not supported we don't provide the download link anymore.","3079":"@FrancisLiang  this functionality is not currently available in Flow, is there a reason you can't do this through one of the other apis? You can make a feature request via jira if it is something you'd like to see in the future, though. ","3080":"@laurendiperna Thanks for your kind reply. Yes I can definitely do this via other APIs. However, I think it could be better if this functionaliy could be put in Flow since then the whole work flow could be completed through GUI. ","3081":"@FrancisLiang  I agree, actually it would be great if you make a feature request for this. are you familiar with how to make a feature request via our jira ticketing system? if yes, please go ahead and create the ticket. Otherwise I can create one for you.","3082":"@laurendiperna It will be great if you ceate one for me and let me know any code conduct to submit that request. Thanks!","3083":"@FrancisLiang here is the jira ticket: https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-5679, but please note there is no timeline currently assigned for its completion. I created a ticket so that the request is noted. In the future, please feel free to create requests, here are the instructions on how to create jira ticket: https:\/\/github.com\/h2oai\/h2o-3\/blob\/master\/CONTRIBUTING.md. Thanks again!","3084":"Hi all, how can I get the predictions of each individual trees in a random forest model. I need all trees' prediction values to do prediction uncertainty analysis (calculate prediction quantiles and confidence intervals), thank you very much for the help,","3085":"Hi @Tarrahi_gitlab, we don't currently have an API that would expose the individual predictions. I have a PR that adds this capability to MOJO, it still needs to be finished - https:\/\/github.com\/h2oai\/h2o-3\/pull\/1845\/files\\nLet me know if this would help with your problem. I can finish it.","3086":"Thanks @michalkurka , yes this will help a lot,\\nWill this capability be also for all tree based  models? meaning GBM, RF, ...?","3087":"Hi, I am trying to import a old h2o model. It showing error: \\nERROR MESSAGE: Found version 3.18.0.11, but running version 3.20.0.2\\nhow can i import this model.","3088":"@thirdeye802 you h2o model, if it was saved as a binary, needs to have come from the same version of h2o as the version you are currently running. This means you need to run h2o version 3.18.0.11 instead of 3.20.0.2 if you want to run your model, or you need to retrain your model with version 3.20.0.2. Alternatively, in the future you can download a mojo which is backwards compatible. please see the documents on saving models: http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/save-and-load-model.html?20model#saving-and-loading-a-model","3089":"@Tarrahi_gitlab yes, it will be available for both DRF and GBM","3090":"@thirdeye802 can you please share what is your use case - what is your motivation to load an older model to a newer version of H2O? Do you want to score with the model or do you have another motivation?","3091":"Thanks guys. I got the older h2o from a friend and load the model there. btw, does h2o maintains archive or something for older versions? couldn't find.\\n@michalkurka A friend made that model. He had this older h2o on his computer. I need it for comparison. ","3092":"@thirdeye802 here is an easy way to find download links to old version of h2o-3 https:\/\/github.com\/h2oai\/h2o-3\/blob\/master\/Changes.md","3093":"At our organization, we are trying to evaluate the H2O ecosystem. Based on our initial analysis, we are planning to use H2O ML library :-). We are wondering if we can use H2O steam as well for model management, evaluation, deployment etc. From this chat room, I have got an understanding that the open source version of Steam is no longer under active development (Hence download link is not available). But the enterprise edition is still available. If yes, is there any roadmap for Enterprise edition of Steam? \\n\\nAccording to the Solution Brief document for Steam, it should support cluster management, model management (Build, evaluate and promote models) and scoring service (Bulk scoring etc). However, if I check the user guide for enterprise steam, I see only cluster management is supported (The idea of Projects which used to be there in the Open Source version is missing in the enterprise edition)?\\n\\nIf Steam is not a focus area for H2O.ai, do you recommend\/suggest any other platform for model management (or machine learning life cycle management in general)?","3094":"quick bug report (won't have time now to file a PR, but wanted to report it anyway): gen_representation_key in GLRMModel in H2O 3.20.0.2 doesn't handle the case if glrm.train() is null.","3095":"Hi all, I have seen that you created template to run H2O Cluster via Google Cloud Launcher.  Have you considered bumping the version 3.18.0.8 to the latest 3.20.x.x?","3096":"In 3.20 there is GCS connector included. Moreover, if you include BigQuery JDBC driver it would be possible to seemlessly connect to BigQuery. I would be happy to contribute on that, but it's not OSS.","3097":"@thirdeye802 @laurendiperna i made a JIRA to make this more clear: https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-5698","3098":"is there any tutorial regarding rapid expressions?","3099":"Working with GBM models and while reading the docs I came across the paragraph on leaf node assignment and the `h2o.predict_leaf_node_assignment()` function. Is there some way in R to interrogate each tree in the model to ascertain what the \\rules\\ are that each leaf assignment corresponds to? Or how would one do what the docs suggest and use \\Those leaf nodes represent decision rules that can be fed to other models?","3100":"@dkincaid that section of the documentation was referencing more of an experimental feature, there is no exact way of applying this method. There is, however, a notebook that shows you how to inspect an individual tree with the mojo (the example is in python, but r would be similar) https:\/\/github.com\/h2oai\/h2o-tutorials\/blob\/master\/tutorials\/display_tree_mojo\/DisplayTreeMojoH2O.ipynb. This jupyter notebook shows how to take a Tree rule (LR) and then use it as input to a GLM. Once you have GLM mode, you can then load it into H2O FLOW, and look for \\Variable importance\\ which shows the highest coefficients for a specific tree rule.  As an additional note: The output of h2o.predict_leaf_node_assignment() function is simple LR sequence which identifies the leaf in the tree for the given observation and  this LR sequences can be used as features for GLM. It should give you a model with similar power as the original GBM\/RF model but you now have a global GLM coefficient for each leaf - i.e. giving you variable importance of that leaf.\\n","3101":"Thanks, Lauren. It is a very cool feature, so I hope that you continue to develop it. Thanks for the links and the input. The missing link is being able to tie it back to the tree. If we can generate an image of the trees from the  MOJO then there must be a way to programmatically identify the variables in the path to the leaf. This gives me some direction.","3102":"@pcejrowski an update to the template is currently being worked on to support the latest h2o release. as a side note: h2o-3 is oss so you can contribute via pr on our github repo (https:\/\/github.com\/h2oai\/h2o-3), but perhaps your change is specific to the launcher and not the h2o-3 software. ","3103":"@arnabbiswas1 Our previous model management efforts were put on hold and no longer targeting the Steam solution.  We are currently re-architecting our original thoughts on model management, but cannot provide an estimate on an initial release date.  Any early releases are typically reserved for our Enterprise Support customers.  Unfortunately, we cannot make any recommendations on any existing model management platforms.","3104":"@laurendiperna Hey...Thank you for the clarification. This is really helpful. I understand that the business priority changes over time.  However, such a clear communication is helpful for users like us.  ","3105":"@laurendiperna re: H2o in the Google Cloud. Correct me if I\\u2019m wrong but I think that this launcher is part of some closed repositories inside of h2o.ai organization. Google says that it is 3rd party software that they don\\u2019t take any responsibilty for.","3106":"Hi, Jacob from Sweden here. I am a new user of H2O and I have a question about the apply function to transform rows or columns. First a short background: I wanted to transform a date column which was not in h2o parsable format, so I tried to convert to string, apply a user-defined python lambda, and then let h2o parse. My impression is that arbitrary lambdas are not supported. So the actual question: 1) is there a way around this apart from reformating prior to import? 2) would it make sense implement arbitrary\/more general lambdas using for example Jython?","3107":"@pcejrowski at the moment it is not publicly available but we are accepting contributions to the template. if you can make a jira ticket with what you are looking for, and assign it to Nick Png, that would be great (instructions on how to make a jira are here: https:\/\/github.com\/h2oai\/h2o-3 under Open Source Resources). ","3108":"@laurendiperna Thanks for your replies. However, I don't know, how I can contribute to something that is not publicly available? Is the template itself published somewhere? My main issue would be to access BigQuery and Google Cloud Storage from H2O Cluster and this should be provided with upgrade to the latest release. Is there any ticket that I can track?","3109":"@pcejrowski unfortunately it is not yet publicly available, but we are in the process of making something available. If you make a jira ticket and assign it to Nick Png, he will be able to show his progress on the template availability there, so I think that would be your best bet for tracking the issue at the moment. If you don't want to make a ticket no worries, as you mentioned, it sounds like your main issue should be resolved in the next release.  ","3110":"@breakanalysis you are correct h2o only supports a limited number of lambda functions (this ticket shows references what is supported and includes tickets of what could be added:https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-5121). Since you have a specific timestamp that you'd like h2o to import correctly or find ways to munge the timestamp after\/before import please post on an example of what the time format currently looks like and what you'd like it to look like on stackoverflow, that way someone might be able to show you built-in functions in h2o that could help or possible workarounds. ","3111":"Hi, trying to do a grid search with autoencoders, but getting the following error from grid_search.get_grid(sort_by='mse', decreasing=False) saying \\'float' object is not iterable\\. It looks like coming from my hyperparameters (hyper_params = {'activation': [\\Tanh\\\\Rectifier\\], 'hidden' : hidden_opt,'l1' : 1e-6, 'max_w2' : 10}). Any sugestions how to fix this problem?","3112":"@ledell I am little confused about checkpointing. As per the following page checkpointing is supported for DRF, GBM and DL (http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/checkpointing-models.html) . However, in one of your messages you have mentioned that checkpointing is supported for GLM as well. I tried to explore the REST API documentation. There even for NaiveBayesParametersV3, I see checkpoint as a parameter. So, two questions : 1. What are the algorithms which support checkpointing? 2. How to check set of supported parameters for a particular algorithm (say, if I use Python)? Thanks in advance! ","3113":"@laurendiperna Thank you for your answer. ","3114":"In this particular case the dates were dot-separated in the format dd.mm.yyyy . ","3115":"I am looking for some sample to invoke a word2vec model to generate word embeddings using MOJO. Any help will be highly appreciated","3116":"> ^Ok thanks I will try to push it to my public git sometime next week \\n @cranella, let me know if I can access your java code for rapids AST. I am using the h2o-bindings.jar which is not java developer friendly for Rapids AST. Thanks in Advance","3117":"@arnabbiswas1 i guess i meant to say that GLM is iterative, but yes it seems that we don't have the normal `checkpoint` parameter available for GLM.","3118":"@arnabbiswas1 i dont think the checkpoint param is meant to be in Naive Bayes.  It's not exposed in R or Python, so it might just be inherited by mistake in Java","3119":"@arnabbiswas1 the supported params for each algo are listed in the user guide page you referenced above.","3120":"@ledell That was the confusion. The documentation \/ user guide shows those parameters for algorithms other than GBM, DRF, DL. Ideally the user guide needs to be corrected.","3121":"@arnabbiswas1 can you tell me where you see that?  i dont see it here http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/checkpointing-models.html or here http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/data-science\/algo-params\/checkpoint.html?highlight=checkpoint ","3122":"@ggauravuee Hi, sorry for the delay but my code is now tested and ready to go.  I'm just writing the javadoc but I will release it tomorrow or this weekend","3123":"@laurendiperna My bad. I wanted to refer the REST API documentation : http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/rest-api-reference.html. Ideally this should be corrected.","3124":"@cranella Thanks, will wait for the github url for your code.","3125":"@ledell I have created a Azure data Science instance as per here - http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/cloud-integration\/azure-dsvm.html?highlight=azure\\n\\nI added the TCP port 54321 as per the documentation. I can get the Jupyter notebook to open at https:\/\/<<VM DNS Name or IP Address>>:8000\/, However when I try to go to the web page http:\/\/<<VM DNS Name or IP Address>>:54321\/. I get a \\Cannot Access\\. I have tried Azure Support but their reply was \\ It can be inferred that the intended applications (i.e. H2O) is not configured to listen to inbound connections from this TCP port and there are no applications listening to said TCP port. Therefore, we can determine that your VM\\u2019s NSG is working as expected and the connectivity issues at TCP port 54321 are caused by third-party software.In order to configure your H2O software to listen to this TCP port, we recommend that you check the available documentation from the third-party provider (i.e. H2O.ai) and get in contact with their support team, if necessary.\\\\n\\nAny ideas?","3126":"Hi shot question: In https:\/\/www.kaggle.com\/imrandude\/h2o-autoencoders-and-anomaly-detection-python the author said: \\H2O cannot use columns with character datatype. Creating Dummy variables instead(for the autoencoders)\\ is this statemend correct? I can't find anything about that...","3127":"@schildjo that's not really correct.  H2O can use factor columns.  If the columns are \\string\\ type, then they cannot be used, but \\string\\ can be easily converted into \\factor\\ so yes, you can use categoricals directly and do not need to create your own dummy variables.   They also did a lot of extra work by normalizing columns which you also don't need to do in H2O (we do both dummy creation and normalization automatically)","3128":"Hi @PerformanceGenetics I don't know the answer, but ill ask the people at H2O who wrote the Azure docs","3129":"@ledell many thanks for your explanation. It helps me a lot. Is this mentioned in the doc? I couldn't find it. It would be cool if you could give me a link? ","3130":"@schildjo that's a good question... i know that we have this info scattered throughout the algo pages, but i dont think we have it summarized nicely in a single place.  i made a ticket to add it https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-5758","3131":"the automatic pre-processing differs based on which algo you are using, which is why it's scattered in the algo pages","3132":"@ledell cool. Maybe in a getting started section or at the beginning of the description of a h2o data frame? That's the point where all users come along :)","3133":"@ledell hope my last question for a time :D what would you suggest to plot if you compare different models of autoencoders. Till now, I have only plotted the different mse (compared to epochs or neurons) of the models in one graph. Any idea what also could be plotted and is interesting for other readers of my paper?","3134":"I observe that h2o-3.20.03 has exposed pr_auc (Precision Recall AUC) in addition to auc in JSON when I debug h2o-flow. Can I have more details about it? I read that - \\use Precision Recall area under curve for class imbalance problems. If not, Receiver Operating Characteristic area under curve otherwise\\","3135":"@cranella Hi, Did you published your code. Please share the url fo it.","3136":"@ggauravuee sorry for the delay.  Code is complete and tested so going to forgo the thorough documentation for now and just upload it asap ","3137":"@ggauravuee @michalkurka https:\/\/github.com\/cranella\/h2oclient-java","3138":"@pcejrowski here is a pr (https:\/\/github.com\/h2oai\/h2o-3\/pull\/2606) you can follow that relates to your prior question about the google cloud deployment template","3139":"is there a option or method to capture the memory-consuption is used during training a model? model.summary() or performance() gave me a lot, but nothing about used mem. Is there a way to get this Info out of h2o?","3140":"@cranella Thanks","3141":"@schildjo , Let me know if you find about it. There is a REST api \\\/3\/Cloud\\  and a corresponding Python\/R commnd to get h2o cloud status which tells about the Free and Total memory (JVM heap memory)","3142":"@cranella very interesting project! thanks for sharing - is some of the code generated?","3143":"@schildjo the isn't a specific function call available to get the memory consumption, but as @ggauravuee recommended you can use python\/r  `cluster_status` method or you can open Flow and go to Admin => Cluster Status and monitor how much memory you have free while you are training your model. In addition, if you are having issue with memory usage, we have an Trouble Shooting FAQ question on memory issues here: http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/faq\/general-troubleshooting.html# (search for `memory` or `memory issues`)","3144":"The h2o-3.20.0.3 doesn't support \\Naive coordinate descent\\ even for logistic\/binomial, gaussian etc. IT was supported in previous version of h2o. It is removed in recent h2o release for GLM? \\n    public void validate(GLM glm) {\\n      if (_solver.equals(Solver.COORDINATE_DESCENT_NAIVE))\\n        throw H2O.unimpl(\\Naive coordinate descent is not supported.\\);\\n\\nError calling POST \/3\/ModelBuilders\/glm\/parameters with opts {\\model_id\\:\\glm-linear\\\\training_fram...\\nERROR MESSAGE: unimplemented: Naive coordinate descent is not supported.","3145":"@michaelkurka No problem.  It\\u2019s all hand written but I used a lot of the objects provided in h2o-bindings.  Feel free to include it in the h2o project like h2o-py if it looks good to you.  I will keep updating the javadoc to make it more user friendly","3146":"@ggauravuee thanks for bringing this to our attention, I do believe it was disabled accidentally - it was not supposed to be enabled for multinomial case but it seems disabled for everything","3147":"@Pscheidl can you please look into this issue ^^^","3148":"@michalkurka Yes ! sure ! :)","3149":"There is an issue created for that: https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-5786","3150":"Posted it in h2o-flow channel two days back, but posting it here as well  : Can I execute a particular H2O Flow Notebook from command line? I want to trigger the execution of a particular instance of H2O notebook at regular interval using a cron job. Just to make my question explicit, a particular Jupyter Notenook can be executed from command line : https:\/\/stackoverflow.com\/questions\/35545402\/how-to-run-an-ipynb-jupyter-notebook-from-terminal. Please let me know.","3151":"@arnabbiswas1 yes, that is possible - we actually do the that in our automated tests, we don't officially support this functionality but if you are willing to spend some time - I would suggest to start with `cd h2o-web && ..\/scripts\/run.py --wipeall --geterrs --test lib\/h2o-flow\/build\/js\/headless-test.js --jvm.xmx 4g` and study how that works","3152":"@cranella would be great to integrate this into h2o and generate it automatically","3153":"Hi all! I would like to ask two questions:\\n1. How do I know if I run the latest version of h2o (3?)\\n2. Does automl do feature selection with the given dataset?","3154":"@gkouro_twitter hey George, it is super easy to run latest H2O - please go to the download page and follow the instructions there: http:\/\/h2o-release.s3.amazonaws.com\/h2o\/latest_stable.html\\n\\nRegarding feature selection in AutoML - we are not doing automatic feature selection yet. ","3155":"we already have it as a feature request in our JIRA system: https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-5264","3156":"(not specifically for AutoML but as a general function)","3157":"currently this JIRA is not planned for development yet","3158":"@gkouro_twitter You can see the version of H2O in the otput during startup. If you use R\/Python, you can see the output after calling init function :)","3159":"Thanks guys!","3160":"@michaelkurka Sure, I\\u2019d be happy to help but I\\u2019m not too familiar with code generation. I used retrofit to call your APIs if that\\u2019s what you mean?  Otherwise what parts do you think should be generated and what libraries do you use?","3161":"@michalkurka Thank you! I will try.","3162":"Hi, I am using the XGBoost in h2o and would like to know the difference between \\one_hot_internal\\ and \\one_hot_explicit\\. The describtion for both are almost same :-\\n-one_hot_internal or OneHotInternal: On the fly N+1 new cols for categorical features with N levels\\n-one_hot_explicit or OneHotExplicit: N+1 new columns for categorical features with N levels","3163":"@ggauravuee thanks for pointing this out. The documentation needs to be updated. Basically, with OneHotExplicit, H2O converts the frame to a numerical Frame. With OneHotInternal, categoricals are 1-hot encoded before they are passed in XGBoost.","3164":"Is check point feature available for Xgboost? I think not but need to confirm it as this article  \\https:\/\/www.analyticsvidhya.com\/blog\/2016\/03\/complete-guide-parameter-tuning-xgboost-with-codes-python\/\\ says that one can start training an XGBoost model from its last iteration. Plz confirm.\\n","3165":"@ggauravuee checkpointing is not supported in the current h2o-xgboost implementation","3166":"Hi, is max_runtime_secs applicable to all algorithms, including GLM? GLM doc doesn't has it but in flow-UI, it's available for GLM. ","3167":"@ggauravuee it's available in GLM see the docs: http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-py\/docs\/modeling.html#h2o.estimators.glm.H2OGeneralizedLinearEstimator.max_runtime_secs and http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-r\/docs\/reference\/h2o.glm.html.","3168":"Hey h2o Team, I am trying to export a model in Java but always running into \\Failed to find schema for version: 3 and type: GLMModel\\ there are some related git issues #445 and #732 but no solutions are provided, happy about any hint","3169":"ups wrong issues, the ones i am referencing are in h2oai\/sparkling-water\/issues\/445 ","3170":"hi @gafr can you take a look at the following h2o stream post and see if it helps resolve your issue: https:\/\/groups.google.com\/forum\/#!searchin\/h2ostream\/Failed$20to$20find$20schema$20for$20version$3A$203$20and$20type$3A|sort:date\/h2ostream\/gySSgKlEIvE\/7zPeI4EYBgAJ. If it doesn't answer your question, please post a new question to h2o stream or StackOverflow with a fully reproducible code snippet as well as the version of H2O you are using. Thanks!","3171":"that worked thanks!","3172":"but as mentioned in the post I am also facing the same issue: that netlib native artefacts cannot be found, this limits me to using h2o 3.16.0.12 in my pom","3173":"hi. I am facing an issue while importing a csv file. whenever i import it, it seems ok. but when that frame is parsed, An extra row gets  added on top automatically. The values of this row are column name itself for Enum type columns. And '.' for all Numerical column. i am using h2o flow. ","3174":"@thirdeye802 what version of h2o-3 are you using? If you are not using the latest version of H2O-3 i would recommend upgrading since past parsing errors like yours have been fixed.","3175":"i am using version 3.20.0.3","3176":"although i've figure out where's the problem is. It happens whenever i change the column name before parsing.","3177":"Hi all, I want to report a bug (at least I think it is a bug). The water.fvec.Vec.VectorGroup.init_key() function sometimes creates keys which do not end with a '$'. If such a vector is used in a rapids expression, this can lead to errors. In my example the key looked like \\....$}\\ or \\....$a A\\. The curly bracket in the end of the key of the first example was then interpreted as being part of the expression instead of the key. The same for the space of the second example. I didn't recognize a pattern which explains when these kind of keys are created.","3178":"@SimonSchmid can you provide an example of the rapids expression? is it generated by R\/Python? or is it hand-coded by you?","3179":"Rapids usually refer to the vectors by their index in the frame.","3180":"Yes, it is handcoded. It looks like follows and partitions a frame by a value in one of its vectors.\\n\\nfinal String frameKey = frame._key.toString();\\n\\n        \/\/ TODO this is hell of a hack, until I understand how I can make a vec available in a session w\/o copying it.\\n        String sessionId = UUID.randomUUID().toString();\\n        Session s = new Session(sessionId);\\n\\n        final String vecKey = frame.vec(targetColumn)._key.toString();\\n\\n        Key<Keyed> tmp = Key.make(\\$\\ + vecKey + \\~\\ + sessionId);\\n        DKV.put(tmp, frame.subframe(new String[]{targetColumn}));\\n        String splitExpr;\\n        if (value instanceof String) {\\n            splitExpr =\\n                \\(, \\ + \\ (assign \\ + partitionFrameKey0 + \\ (rows \\ + frameKey + \\ (== \\ + vecKey + \\ \\\\\\\\ + value + \\\\\\\\)))\\\\n                    + \\ (assign \\ + partitionFrameKey1 + \\ (rows \\ + frameKey + \\ (!= \\ + vecKey + \\ \\\\\\\\ + value + \\\\\\\\))))\\;\\n        } else {\\n            splitExpr = \\(, \\ + \\ (assign \\ + partitionFrameKey0 + \\ (rows \\ + frameKey + \\ (== \\ + vecKey + \\ \\ + value\\n                + \\)))\\ + \\ (assign \\ + partitionFrameKey1 + \\ (rows \\ + frameKey + \\ (!= \\ + vecKey + \\ \\ + value + \\))))\\;\\n        }\\n        Rapids.exec(splitExpr, s);\\n        s.end(null);\\n        DKV.remove(tmp);\\n        tmp.remove();","3181":"@michalkurka is this the wrong way to generate the expression. It works with most of the vector keys. How do I refer to a vector by its frame index?","3182":"@michalkurka I'd also be interested how to simplify this query (or implement it the \\h2o-way\\) :-)","3183":"Hi @dietzc, I will test it later today and get back to you.","3184":"@SimonSchmid I think the issue with your code is that you are using `vecKey` to refer to the Vec. `rows` operator (or any other Rapids operator) doesn't accept that - it expects a Frame on the input. The right way to do it is to use projection operator to extract the Vec to a single column Frame (it doesn't have to be in DKV, the Frame is ephemeral).\\n\\nSummary: never use Vec keys in Rapids expressions, avoid illegal character in user-specified keys:\\n\\n     static final CharSequence ILLEGAL_USER_KEY_CHARS = \\ !@#$%^&*()+={}[]|\\\\\\\\;:\\\\\\'<>,\/?\\;\\n\\nH2O doesn't enforce that but assumes the key will be correct.","3185":"Thanks @michalkurka!","3186":"@michalkurka Thanks, it works now!","3187":"I am trying to find an email address for the sales team ? I could only find a phone number but not an email address on the website. Please point me to the same.","3188":"@dparkar here you go: sales@h2o.ai","3189":"Thanks so much !","3190":"@laurendiperna  do you also happen to have a point of contact in h2o sales team ? other than the general email address and phone number","3191":"@dparkar can you provide a bit more context for who you might want to contact? do you have a specific use case or feature you'd like? I'd recommend using the main sales@h2o.ai contact and letting the sales team decide who would be best to respond. ","3192":"@dparkar if you can pass on your email address to us (here or via DM), someone can contact you.  Did you try emailing sales@h2o.ai and no one responded?","3193":"Hi, how can I manually set the build version when using \\gradlew  build -x test\\ to build h2o?\\n","3194":"@gokl if you want to build a specific version you can checkout the release branch of interest, the releases  are tagged ( https:\/\/github.com\/h2oai\/h2o-3\/tags) and then do gradlew built -x test on that branch.","3195":"Is there any exaple of  Java Word2Vec loading of GoogleNews W2V model and passing words\/labels and getting embeddings for them ?","3196":"Hi all,\\ni want to report a bug whcih appears on Windows. If you have a data set which contains either column names or column values with special characters like \\u00e8, \\u00f3, \\u00fc, \\u00e4, etc. they are not correctly read back in using\\n```\\nMojoReaderBackend backend = MojoReaderBackendFactory.createReaderBackend(mojoFile);\\nMojoModel model = MojoModel.load(backend);\\n```\\nThis problem occurs for me on Windows using Eclipse where the default encoding is not set to UTF-8. If I change the encoding to UTF-8, all works fine. \\nThe bug can be fixed by enforcing hex.genmodel.ZipfileMojoReaderBackend.getTextFile(...) to use UTF-8 as encoding:\\n```\\n@Override\\n  public BufferedReader getTextFile(String filename) throws IOException {\\n    InputStream input = zf.getInputStream(zf.getEntry(filename));\\n    return new BufferedReader(new InputStreamReader(input, \\UTF-8\\));\\n  }\\n```","3197":"i see Word2VecMojoModel but there is no example where  I can read GoogleNews W2V model and then use that model to derive word vector embeddings for input words","3198":"@SimonSchmid could you create a jira ticket for the issue you are reporting and then post the link here? Thanks!","3199":"hi @legalizenet if you'd like help writing a code script please post your question to stackoverflow. Thanks!","3200":"Is N-fold \/cross validation is supported\/working in XGBoost model in h2o? We are facing some issues in N-fold while creating XGBoost Binomial model.","3201":"@laurendiperna stackoverflow question is here - https:\/\/stackoverflow.com\/questions\/52523949\/looking-for-word2vec-java-example-for-h2o-ai-googlenews-generate-embedding","3202":"thanks @legalizenet !","3203":"@ggauravuee if you are seeing issue, it would be great if you could create a jira ticket, provide a reproducible description\/code snippet of your issue, and attach any logs that might be helpful for the debugging process. thanks!","3204":"@ggauravuee if you have issues with xval in xgboost, please make sure to upgrade to the latest stable first.  we have fixed bugs recently","3205":"@laurendiperna Jira ticket: https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-5946","3206":"thanks! @SimonSchmid ","3207":"Let me know how XGBoost handles the missing values in response colmun? It looks like xgboost doesn't support it, yet :- \\nERRR: _response_column: Response contains missing values (NAs) - not supported by XGBoost.\\nERRR: water.exceptions.H2OModelBuilderIllegalArgumentException: Illegal argument(s) for XGBoost model: xgboost-235565ec-e00b-41b0-91b2-8632bada8da1.  Details: ERRR on field: _response_column: Response contains missing values (NAs) - not supported by XGBoost.\\n\\nHowever,  the other h2o algorithms like GBM, DRF  simply igonre the the rows\/features having a missing response value, As per H2o doc :- \\nWhat happens if the response has missing values?\\nNo errors will occur, but at the same time, nothing will be learned from rows containing missing values in the response column.","3208":"@ledell , Thanks Cross validation\/nfold in xgboost is working fine after upgrading to the latest h2o version. ","3209":"Hi all, I just updated my R h2o from 3.18 to 3.20.0.9. But I can't open the Flow UI with port 54321 now. Has anyone met this problem?","3210":"If I initiate H2O from R, I can't access is. But if I  initiate from terminal I can","3211":"Is this a bug or I have some problem with config? I am running it on a EC2 server","3212":"@valkyrias_gitlab this is not a bug, the behavior was changed in h2o 3.20 to only allow connections from localhost when h2o is started from the client (r\/python)","3213":"in your h2o.init you can specify parameter ip = \\x.y.z.w\\ and set the IP where you are running R, this way h2o will bind to a non local interface and flow will be available from outside of that machine","3214":"@michalkurka Thank you. However I tried to add  ip = \\x.y.z.w\\ and it 's running for a long time without any response. Eventually it gave me an error saying cannot open h2o on that IP and can only start with local.","3215":"just to make sure - did you put in the actual IP address of the machine?","3216":"I am creating an XGBoost model in Linux and want to deploy the model in windows. Do I need to use the MOJO as described below or there are \\xgboost4j_*.dll\\ available for it:-\\n`java  -cp h2o-genmodel.jar hex.genmodel.tools.PredictCsv --mojo xgboost_diabetes_demo.zip --input dataset_diabetes\/diabetic_data.csv --output diabetes_predictions.csv`\\nAlso, I hope that XGBoost MOJO supports java multi-threading","3217":"@ggauravuee you can use XGBoost MOJO on Windows just like any other MOJO if you enable Java-based scoring, to do that you need to define a system property: -Dsys.ai.h2o.xgboost.scoring.java.enable=true","3218":"XGboost MOJO will run fine in a multithreaded environment","3219":"Hi all, How can I replece the hex structure in h2o.ai with double bytes, Thanks!","3220":"@bobknight79 can you elaborate more on your use case? I am not sure what are you referring to","3221":"@michalkurka Thanks for your help and sorry for my poor english.I am anlysising data including chinese chars in h2o.ai. And It end up with  unreadable code like  '\\ufffd\\ufffd\\ufffd\\ufffd'.And I found the reason which is the hex data structure in h2o.ai is single byte.When the hex data stucture supports double bytes, then It will deal with chinese chars correctly.So I am tring to modify the sourcecode of h2o.ai,but I couldn't find out where is the location of hex data stucture  in the h2o.ai sourcecode.","3222":"Hi, does anybody has any suggestion on it :-\\n> Let me know how XGBoost handles the missing values in response colmun? It looks like xgboost doesn't support it, yet :- \\nERRR: _response_column: Response contains missing values (NAs) - not supported by XGBoost.\\nERRR: water.exceptions.H2OModelBuilderIllegalArgumentException: Illegal argument(s) for XGBoost model: xgboost-235565ec-e00b-41b0-91b2-8632bada8da1.  Details: ERRR on field: _response_column: Response contains missing values (NAs) - not supported by XGBoost.\\n\\nHowever,  the other h2o algorithms like GBM, DRF  simply igonre the the rows\/features having a missing response value, As per H2o doc :- \\nWhat happens if the response has missing values?\\nNo errors will occur, but at the same time, nothing will be learned from rows containing missing values in the response column.","3223":"@ggauravuee current XGBoost integration in H2O doesn't support NAs in a response column. It would be a good improvement.","3224":"I need to install h2o version 3.18.0.8 to run a serialized model that was trained in that version. This doesn't seem to work:\\n`conda install -c h2oai h2o=3.18.0.8`\\nIt says\\n```\\nPackagesNotFoundError: The following packages are not available from current channels:\\n\\n  - h2o=3.18.0.8\\n\\nCurrent channels:\\n\\n  - https:\/\/conda.anaconda.org\/h2oai\/win-64\\n  - https:\/\/conda.anaconda.org\/h2oai\/noarch\\n  - https:\/\/conda.anaconda.org\/conda-forge\/win-64\\n  - https:\/\/conda.anaconda.org\/conda-forge\/noarch\\n  - https:\/\/repo.anaconda.com\/pkgs\/main\/win-64\\n  - https:\/\/repo.anaconda.com\/pkgs\/main\/noarch\\n  - https:\/\/repo.anaconda.com\/pkgs\/free\/win-64\\n  - https:\/\/repo.anaconda.com\/pkgs\/free\/noarch\\n  - https:\/\/repo.anaconda.com\/pkgs\/r\/win-64\\n  - https:\/\/repo.anaconda.com\/pkgs\/r\/noarch\\n  - https:\/\/repo.anaconda.com\/pkgs\/pro\/win-64\\n  - https:\/\/repo.anaconda.com\/pkgs\/pro\/noarch\\n  - https:\/\/repo.anaconda.com\/pkgs\/msys2\/win-64\\n  - https:\/\/repo.anaconda.com\/pkgs\/msys2\/noarch\\n```\\n\\nHow can i install that older version","3225":"`pip install http:\/\/h2o-release.s3.amazonaws.com\/h2o\/rel-wolpert\/8\/Python\/h2o-3.18.0.8-py2.py3-none-any.whl` this seems to work still. But is there some list online somewhere that shows the url for the whl files by version?","3226":"you can take a look at the changes.md file to see versions and urls: https:\/\/github.com\/h2oai\/h2o-3\/blob\/master\/Changes.md","3227":"Thanks","3228":"Hi, I used the new Python Tree API to analyze trees. Some of the tree nodes have thresholds with float numbers as split criteria for enum type variables. How can this be interpreted? Is it documented somewhere?","3229":"@gokl This is unfortunately not very well documented. We'll definitely make it better. The numerical value is in fact ordinal value of the value from column's domain. As a quick workaround, you may have a look which levels go to the left and which go to the right, if accessible.\\n\\nWhich model did you use ?","3230":"@Pscheidl  I'm using H2OGradientBoostingEstimator. The left and right values are empty for nodes with a threshold for categorical data.","3231":"@Pscheidl  Is there a way to get the mapping of numerical values to the categoricals?","3232":"Does anyone know what happened to the H2O Steam project?","3233":"@NkululekoThangelane The open source Steam project is no longer maintained. We are working on Enterprise Steam at the moment which focues more on cluster\/user management. You can find out more at https:\/\/s3.amazonaws.com\/steam-release\/enterprise-steam\/stable.html","3234":"Hi Guys, I have a dumb question about h2o in python","3235":"I pip install h2o 3.22.0.1, but there is no such a function called \\h2o.download_mojo()\\","3236":"[![image.png](https:\/\/files.gitter.im\/h2oai\/h2o-3\/lAQN\/thumb\/image.png)](https:\/\/files.gitter.im\/h2oai\/h2o-3\/lAQN\/image.png)","3237":"Instead, it can be found in older h2o R package, which I had been using","3238":"Anyone knows what's wrong?","3239":"@valkyrias_gitlab the python library for h2o is a bit different from R. In Python you get the function exposed on the model object.\\n\\nyou would do eg. `gbm_model.download_mojo(path=\\\/your\/path\\)`","3240":"@bilcus  thanks ill look into it thank you.","3241":"@bilcus  do you know if I can get an evaluation license.","3242":"@michalkurka Thank you very much! I just figured it out last night. I am just curious that why for pojo there is a h2o.download_pojo() while for mojo it has to be called from the model object...","3243":"@gokl It is possible, but it is not very convenient. In the model object, there are domains exposed. This is a two-dim array. Use the feature name is index in the first dimension. In the second dimension, use the ordinal value mentioned as an index. This way, you can tell which values go to the left and which values go to the right. Basically everything below given number\/index goe to the left and everything higher goes to the right child node.","3244":"@gokl I created an issue\/improvement to fix that. Might be an easy fix, but I can't promise when this is going to be done right now.\\n\\nhttps:\/\/0xdata.atlassian.net\/browse\/PUBDEV-6038","3245":"@NkululekoThangelane Of course, please contact us through sales@h2o.ai to get an evaluation license.","3246":"Regarding the Tweedie deviance function, it seems like the function in the docs (http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/data-science\/glm.html) is different from the function used in the code (https:\/\/github.com\/h2oai\/h2o-3\/blob\/master\/h2o-algos\/src\/main\/java\/hex\/glm\/GLMModel.java, line 395). The first term in the docs is missing a factor of 1\/(1-p). ","3247":"Hi all! Wondering whether to elevate this issue to JIRA  ticket: For AutoML, in both R and Python API, the cross-validation predictions of the top leaderboard model (\\StackedEnsemble_BestOfFamily_AutoML_20181113_133930\\) are NULL, even though I set keep_cross_validation_predictions=True in the call to train(). Does that sound like a bug or a feature?","3248":"Clarification: in my h2o.ls list of keys, I see \\prediction_metalearner_AUTO_StackedEnsemble_BestOfFamily_AutoML_20181113_135902_cv_1\\ 2, 3, etc, so it did seem to save something, and I see the predictions in there, however when I call aml.leader.cross_validation_holdout_predictions() it returns null","3249":"Hello I would like to contribute code to H20 And would like someone to guide me into the right direction.","3250":"Hi all,\\nI have a question, not sure if it is intended behavior. If I train, e.g., a GBM model and use as categroical encoding \\Eigen\\ with a categorical feature named \\feature1\\ and I then convert this model to a MOJO, this MOJO expects in the test data a feature named \\feature1.Eigen\\ i.e., I have to do the encoding by myself. Is this a bug or intended?","3251":"Hello @hassaanseeker, if you already have a code ready to review, just create a pull-request on GitHub, we will have a look and give further comments; but maybe you are just missing some functionality in the current version, and need to know where it can be added or fixed - in that case, I recommend you to share more details, so that we can navigate you correctly. Thanks for your interest!","3252":"@hassaanseeker check out the Contributing.md file in github","3253":"hi guys,  i have a general modeling question : how H2o handle rare levels (unseen when training model) on categorical variables, in moment of prediction ?","3254":"Hi @mmejdoubi  please see the documentation, here is an example of the FAQ for Random Forest but if you look up the algo you are interested you should be able to find a similar FAQ with your question answered: http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/data-science\/drf.html#faq","3255":"@laurendiperna many thanks, the FAQ is very well structured (as H2O help in general). and link you've provided is a perfect answer for my question.","3256":"hi guys, I am wondering if anybody has any idea how to resolve a GC overhead limit issue on the Automl. I have about a 2.9 GB file I am using and the training almost completes but at the end returns a 500 error and often complains about a GC overhead limit.","3257":"try providing more memory to your h2o cluster. GC overhead means the jvm is running out of memory and it is spending too much time cleaning up unused objects.","3258":"thanks I am trying that now we will see how it goes","3259":"does it happen that the leaderboard for a model after it was trained is empty?","3260":"or do I need to specify something if the response columns has three different values instead of 2?","3261":"@laurendiperna ","3262":"hmm the leaderboard shouldn't be empty, maybe make sure that the variable you are pointing to actually contains the automl object","3263":"I am calling it but the leaderboard is always empty after training","3264":"@timdunn22 if you think this might be a bug please either provide a fully reproducible code snippet and post the issue to StackOverflow or create a jira ticket with all your information so we can try to reproduce it. Thanks!","3265":"Having a weird issue with what looks to be a lock not releasing on an H2OFrame in Scala","3266":"I build an H2OFrame from a spark dataframe","3267":"and then call myFrame.colToEnum(Array(\\target\\))","3268":"and it never returns for some datasets, but works fine for others going through the same code path","3269":"I can open up Flow and it has successfully converted it to an enum but my code never gets to the next line","3270":"really liking H2O BTW, about to go live with a product using it (as soon as I can figure out this issue)","3271":"now I'm getting an exception finally: Cannot update - Lockable is not write-locked!","3272":"not sure how to start debugging this","3273":"I made a JIRA issue with reproducible example here: https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-6135","3274":"Hi, new H2O user here. I have troubles making autoML work on my dataset (11K rows and 1K features). When I launch it with base parameters and maximum running time of 10 seconds per model it get stalled. When this happens the program becomes unresponsive even when I try to stop it (with ctrl+c in R), so I need to kill it. Is it a normal behavior? When I exclude all algo excepting GBM then it runs but in at least 10 minutes. Is it a problem with the size of my dataset? Normalization? Or certain algorithms that cannot deal with so many features? \\n","3275":"10 seconds in total I meant (max_runtime_secs = 10)","3276":"@Bioninbo `max_runtime_secs` is for all the models.  It's not able to do anything in 10 seconds.  Instead, try using `max_models = 10` to start and see how it goes and then increase from there.  There is a default stopping time of 3600 seconds, so if you want to go longer than that, you must also increase that number.","3277":"@jbentleyEG thanks for the jira, looks like a bug to me - I am asking Kuba to take care of it","3278":"@timdunn22 can you tell me more about the issue with the empty leaderboard?  do you have a very large dataset and it's not able to train a single model in 1 hour?  please provide some more details and maybe we can help","3279":"Hi @ledell , I see thanks for the help! When launching a single model it took already 1h so I guess my dataset is just too big (I will try some feature selection methods). Anyway congrats for this great tool!  ","3280":"I was wondering: is there a way to know the order in which each model was tested and the runtime of models in an H2OAutoML object?","3281":"@ledell I do have a very large dataset with 3 million records and 80 features could that be why there is no leaderboard?","3282":"hi. i'm trying to use data.Table, reading a csv, my date column is a string : 23may2018... what is recommended way to convert to datetime stamp, like pandas pd.to_datetime() ?","3283":"@Bioninbo Also make sure to give your cluster more memory if you have more available on your machine.  Set the `max_mem_size` param in `h2o.init()` to something bigger than the default.","3284":"@timdunn22 Why don't you try setting `max_models = 1` and `max_runtime_secs = 999999999` to see how long one model takes and then adjust from there.  Also make sure to give your cluster enough memory (see my comment to @Bioninbo above)","3285":"Has anyone looked into exposing the terminal node indices for XGBoost?","3286":"otherwise I am going to make an attempt to add them and do a pull request, it looks like it shouldn't be especially difficult since XGBoost4J already supports it","3287":"https:\/\/0xdata.atlassian.net\/browse\/PUBDEV-6158","3288":"https:\/\/github.com\/h2oai\/h2o-3\/pull\/3179","3289":"Hi, I am using Java H2O, can I split frame based on a datetime column? I see H2O Frame in Python can do such a thing, but wasn't sure how to do so in Java directly?","3290":"Is there any plan to re-merge the main xgboost git repo back in to the h2o fork (https:\/\/github.com\/h2oai\/xgboost)?","3291":"there are some pull requests open on the dmlc repo that are promising some major performance improvements for the fast hist algorithm","3292":"and it looks like the h2o xgboost fork hasn't been merged in a while","3293":"Has anyone managed to build a working docker image if h2o steam","3294":"Of*","3295":"@jbentleyEG yes, we are behind xgboost and we are planning to update in the next 2 moths","3296":"@rwatts3 open source  steam is not supported anymore; which docker image are you trying to build?\\nthis one?\\nhttps:\/\/github.com\/h2oai\/steam\/blob\/master\/etc\/docker\/standalone\/Dockerfile","3297":"Can H2O deeplearning function use different activation functions for different layers?","3298":"@zhenyiy no","3299":"Hello. I'm looking for some answer about H2O. I want to try implementing new metric. Let's say A-metric. I need to access it from Python. Is there any way of adding it to \\model\\ object of python's h2o module? I can't find a place where any values are passed to Python (I suspect REST API, but can't find a place where JSON is build neither). Any help would be very appreciated. Thanks!","3300":"@ledell  Hi Erin, I have a process running AutoML and it seems to be idle in \\GBM hyperparameter search\\.  Is there any way to control that search? ","3301":"@lukasz-gosiewski yes there is a way to define a custom metric in a python file... example https:\/\/github.com\/h2oai\/h2o-3\/blob\/43f8ab952a69a8bc9484bd0ffac909b6e3e820ca\/h2o-py\/tests\/pyunit_utils\/utils_model_metrics.py","3302":"@gponce-ars no","3303":"Is there any way to make deep learning grid search in AutoML more efficient (less time consuming)? In the case of deeplearning the epochs for each iteration it changes by decimals from one iteration to another.   ","3304":"[![image.png](https:\/\/files.gitter.im\/h2oai\/h2o-3\/mkmM\/thumb\/image.png)](https:\/\/files.gitter.im\/h2oai\/h2o-3\/mkmM\/image.png)","3305":"Is a training dataset with 167million rows x 19 columns too big for deep learning (regression)?   ","3306":"@gponce-ars i would probably skip Deep Learning in AutoML unless it's giving you better models than GBMs","3307":"its very resource intensive","3308":"@ledell Thanks, I'll do that. ","3309":"Based on my experience (still little), deep learning  doesn't perform well with nonperceptual data, agree?","3310":"@ledell Thanks, that was super helpful. \\nAnother question - when i use Flow and enable cross validation i can see 2 outputs \\OUTPUT - CROSS_VALIDATION_METRICS\\ and \\OUTPUT - CROSS_VALIDATION_METRICS_SUMMARY_\\. What's the difference between them? When i use Python I can get only model.cross_validation_metrics_summary(). Is there any way to tell if these metrics were calculated based on training data or test data?","3311":"Is there any guidance on how best to allocate memory when running sparkling water on yarn?","3312":"I am starting it from within spark (val h2oContext = H2OContext.getOrCreate(spark)) and running out of memory when I try to build models despite being on a very large spark cluster","3313":"nvm I think this has all the answers I need http:\/\/h2o-release.s3.amazonaws.com\/h2o\/rel-xu\/3\/docs-website\/h2o-docs\/booklets\/SparklingWaterBooklet.pdf","3314":"really useful document btw, I think this answers a lot of deployment questions I've been having","3315":"Hi. I trained automl with the following settings:\\n`aml = H2OAutoML(sort_metric=\\MAE\\max_models=10, seed = 1, project_name = \\EURUSD 1H ASK\\)`\\nand when it finished I ran: \\n`aml.leaderboard.head()`\\nbut got nothing:\\n`aml.leaderboard.head()`\\n`\\nOut[2]: \\n`","3316":"is this the right place to ask questions about http:\/\/docs.h2o.ai\/driverless-ai\/latest-stable\/docs\/userguide\/install\/aws.html?","3317":"@gkourogiorgas does something appear if you do `print(aml.leaderboard)`?","3318":"are you using really big data?  the default is that it will stop after 1 hour, so if you can't train a single model in an hour, then you will have an empty leaderboard","3319":"Hi @ledell . Thanks for your reply. Nothing shows. However, `aml.leader.model_performance(test)` shows results. So if I don't set a max time in secs it sets it for 1 hour? ","3320":"@gkourogiorgas ok maybe its a printing issue?  what format are you using?","3321":"@gkourogiorgas you can check number of rows of the frame to see if there is actually any data in there","3322":"and yes the default for `max_runtime_secs = 3600` so it will kill itself after 1 hour unless you change it","3323":"@ledell You are right. I converted leaderboard to a pandas data frame and I could see the models and the metrics. weird. Thanks!","3324":"@gkourogiorgas is this happening with all H2OFrames in your environment? (not able to see anything with `.head()`)","3325":"i wonder what's going on there...","3326":"@ledell You are right. I cannot see anything with `.head()` for H2o frames. However I can perfectly see everything on Flow even if I ran them on python","3327":"Hey guys. I want to get one prediction for an entry from H2O. Can I do this without creating a new frame, etc.? ","3328":"Any idea why h2o doesn't recognize the variable name pointing to the model when trying to save several models using h2o.saveModel within  lapply such as this: \\n```\\nlv  <- dt_ob[like(V1,\\fit\\),]$V1    # lv contains all the variables with models\\nsaved_models <- lapply(lv,  function(x) {\\n   h2o.saveModel(object=substitute(i, list(i=as.name(x))),  \\n                path='.\/H2O\/MODELS\/')\\n})\\n```","3329":"**Solved** \\nThe issue was with the variables used to save the `h2o.automl` runs.  I just filtered out for the `@leader` and extracted only that one to save it.\\n \\n``` r\\nl_models <-noquote(dt_ob[like(V1,\\fit\\),]$V1)\\n# Save models by calling each variable\\nsave_all_models <- lapply(l_models, function(x) {\\n    dt_tmp <- as.character(x)\\n    if (grepl(\\aml\\ x)) {  # Check for those model variables with \\aml\\ pattern\\n      dt_modid <- eval(parse(text=x))@leader@model_id \\n      h2o.saveModel(object=eval(parse(text=x))@leader, path='.\/H2O\/MODELS\/')\\n      # Rename AutoML, the leader has specific ID and need to append some info\\n      output_file <- paste0(\\\/PATH_TO\/INPUTS\/H2O\/MODELS\/\\\\n                     dt_modid)\\n      renamed_file <- paste0(\\\/PATH_TO\/INPUTS\/H2O\/MODELS\/\\\\n                     dt_tmp,\\_\\ dt_modid)\\n      file.rename(output_file, renamed_file)\\n    }  else \\n      # Save individual models where model id is managed with variable name\\n      h2o.saveModel(object=eval(parse(text=x)), path='.\/H2O\/MODELS\/')\\n      cat(paste0(\\Saving model \\ as.character(x),\\...\\\\n\\))\\n})\\n```","3330":"@ledell Hi again. I finished autumn and I found a very good GLM (!) model. I want to retrain this model but not by using checkpoint. Is there any way I can save the params of that particular model in python and retrain it at will?","3331":"*automl not autumn!","3332":"Hi all, I am running Pysparkling 2.4 on Azure Databricks. I am training XGBoost model but i can only see the normal log from one of the worker. The rest of the workers are all outputing GC (Allocation Failure). Is this normal?","3333":"In other word, do i have any way to make sure that algorithm is running in all workers but only one? ","3334":"@valkyrias_gitlab \\GC (Allocation Failure)\\ doesn't necessarily mean there is anything wrong with the JVM. It is an unfortunately names GC debug message. This explains it in a nutshell: https:\/\/stackoverflow.com\/a\/28357523\/7301183\\n\\nIf you start seeing OOM errors then something is not right.","3335":"@gkourogiorgas I would just save the binary model and extract the model parameters in Python. The model object has the parameters embedded in it.","3336":"@michalkurka Thank you! I saw plenty old document says XGBoost is not supporting distributed system. Does it support distributed system now? ","3337":"the very first version of XGBoost integration was single node but the more recent do support multinode, both in Standalone and on Hadoop\/Spark","3338":"@valkyrias_gitlab \\n> In other word, do i have any way to make sure that algorithm is running in all workers but only one? \\n\\nyou can check the Water Meter in H2O Flow - it should show activity on all nodes\\nthere won't be meaningful messages on the non-leader nodes","3339":"@michalkurka Unfortunately I can't access H2O Flow since I am working on Azure Databricks. Is there any other way?","3340":"hmm, one way would be to enable debug logging, then you would see messages like `Treating matrix as ...` on all that participate in XGBoost training","3341":"other than that I don't think we output the information anywhere","3342":"Hi there, I am looking for any published H2O performance numbers for Image Classification (using ResNet50, VGG<X>, AlexNet, etc) using FP32 models for Inference. Google was of no help so far.  Can someone point me to that data if any? ","3343":"just curious, what do yall use H2O for specifically? like how does an AI platform fit into different workflows in different industries?","3344":"> Hi there, I am looking for any published H2O performance numbers for Image Classification (using ResNet50, VGG<X>, AlexNet, etc) using FP32 models for Inference. Google was of no help so far.  Can someone point me to that data if any? ","3345":"@ledell ^^^^^","3346":"@michalkurka ^^^^","3347":"Hi all, i am working with pysparkling on databricks fixed number of workers cluster. Sometimes when training model I get error \\java.lang.ArrayIndexOutOfBoundsException: 65535\\ but not always. Does anyone know the reason? Thanks","3348":"Also, anyone knows any way to access H2O Flow for cluster running on Azure Databricks?","3349":"@dollarHome we do not have such numbers for image classification as far as I know","3350":"@valkyrias_gitlab can you please share the full stacktrace and your version of SW?","3351":"@valkyrias_gitlab  yes, please follow tutorial http:\/\/docs.h2o.ai\/sparkling-water\/2.4\/latest-stable\/doc\/deployment\/pysparkling_azure_dbc.html","3352":"I am using h2o_pysparkling_2.4 on databricks install via PyPi","3353":"@michalkurka OSError: Job with key $0300ffffffff$_8f1999751e4afc2d944bb411f16147c7 failed with an exception: java.lang.ArrayIndexOutOfBoundsException: 2147483637\\nstacktrace: \\njava.lang.ArrayIndexOutOfBoundsException: 2147483637\\n\\tat hex.tree.xgboost.XGBoostUtils.initalizeFromChunkIds(XGBoostUtils.java:553)\\n\\tat hex.tree.xgboost.XGBoostUtils.csr(XGBoostUtils.java:504)\\n\\tat hex.tree.xgboost.XGBoostUtils.csr(XGBoostUtils.java:464)\\n\\tat hex.tree.xgboost.XGBoostUtils.convertFrameToDMatrix(XGBoostUtils.java:120)\\n\\tat ml.dmlc.xgboost4j.java.XGBoostSetupTask.makeLocalMatrix(XGBoostSetupTask.java:56)\\n\\tat ml.dmlc.xgboost4j.java.XGBoostSetupTask.execute(XGBoostSetupTask.java:40)\\n\\tat ml.dmlc.xgboost4j.java.AbstractXGBoostTask.setupLocal(AbstractXGBoostTask.java:35)\\n\\tat water.MRTask.setupLocal0(MRTask.java:550)\\n\\tat water.MRTask.dfork(MRTask.java:409)\\n\\tat water.MRTask.doAll(MRTask.java:401)\\n\\tat water.MRTask.doAllNodes(MRTask.java:414)\\n\\tat ml.dmlc.xgboost4j.java.AbstractXGBoostTask.run(AbstractXGBoostTask.java:46)\\n\\tat hex.tree.xgboost.XGBoost$XGBoostDriver.buildModelImpl(XGBoost.java:304)\\n\\tat hex.tree.xgboost.XGBoost$XGBoostDriver.buildModel(XGBoost.java:261)\\n\\tat hex.tree.xgboost.XGBoost$XGBoostDriver.computeImpl(XGBoost.java:251)\\n\\tat hex.ModelBuilder$Driver.compute2(ModelBuilder.java:218)\\n\\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1395)\\n\\tat jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\\n\\tat jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\\n\\tat jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:974)\\n\\tat jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1477)\\n\\tat jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)","3354":"training data dimension is (33144459, 486)","3355":"@michalkurka ---------------------------------------------------------------------------\\nOSError                                   Traceback (most recent call last)\\n<command-208848996741003> in <module>()\\n     24               y = target,\\n     25               training_frame = hex_train,\\n---> 26               validation_frame = hex_test)\\n     27   print(\\training finished. Appending to model_list...\\)\\n     28   model_list.append(model)\\n\\n\/databricks\/python\/lib\/python3.5\/site-packages\/h2o\/estimators\/estimator_base.py in train(self, x, y, training_frame, offset_column, fold_column, weights_column, validation_frame, max_runtime_secs, ignored_columns, model_id, verbose)\\n    235             return\\n    236 \\n--> 237         model.poll(verbose_model_scoring_history=verbose)\\n    238         model_json = h2o.api(\\GET \/%d\/Models\/%s\\ % (rest_ver, model.dest_key))[\\models\\][0]\\n    239         self._resolve_model(model.dest_key, model_json)\\n\\n\/databricks\/python\/lib\/python3.5\/site-packages\/h2o\/job.py in poll(self, verbose_model_scoring_history)\\n     75             if (isinstance(self.job, dict)) and (\\stacktrace\\ in list(self.job)):\\n     76                 raise EnvironmentError(\\Job with key {} failed with an exception: {}\\\\nstacktrace: \\\\n---> 77                                        \\\\\\n{}\\.format(self.job_key, self.exception, self.job[\\stacktrace\\]))\\n     78             else:\\n     79                 raise EnvironmentError(\\Job with key %s failed with an exception: %s\\ % (self.job_key, self.exception))\\n\\nOSError: Job with key $0300ffffffff$_8f1999751e4afc2d944bb411f16147c7 failed with an exception: java.lang.ArrayIndexOutOfBoundsException: 2147483637\\nstacktrace: \\njava.lang.ArrayIndexOutOfBoundsException: 2147483637\\n\\tat hex.tree.xgboost.XGBoostUtils.initalizeFromChunkIds(XGBoostUtils.java:553)\\n\\tat hex.tree.xgboost.XGBoostUtils.csr(XGBoostUtils.java:504)\\n\\tat hex.tree.xgboost.XGBoostUtils.csr(XGBoostUtils.java:464)\\n\\tat hex.tree.xgboost.XGBoostUtils.convertFrameToDMatrix(XGBoostUtils.java:120)\\n\\tat ml.dmlc.xgboost4j.java.XGBoostSetupTask.makeLocalMatrix(XGBoostSetupTask.java:56)\\n\\tat ml.dmlc.xgboost4j.java.XGBoostSetupTask.execute(XGBoostSetupTask.java:40)\\n\\tat ml.dmlc.xgboost4j.java.AbstractXGBoostTask.setupLocal(AbstractXGBoostTask.java:35)\\n\\tat water.MRTask.setupLocal0(MRTask.java:550)\\n\\tat water.MRTask.dfork(MRTask.java:409)\\n\\tat water.MRTask.doAll(MRTask.java:401)\\n\\tat water.MRTask.doAllNodes(MRTask.java:414)\\n\\tat ml.dmlc.xgboost4j.java.AbstractXGBoostTask.run(AbstractXGBoostTask.java:46)\\n\\tat hex.tree.xgboost.XGBoost$XGBoostDriver.buildModelImpl(XGBoost.java:304)\\n\\tat hex.tree.xgboost.XGBoost$XGBoostDriver.buildModel(XGBoost.java:261)\\n\\tat hex.tree.xgboost.XGBoost$XGBoostDriver.computeImpl(XGBoost.java:251)\\n\\tat hex.ModelBuilder$Driver.compute2(ModelBuilder.java:218)\\n\\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1395)\\n\\tat jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\\n\\tat jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\\n\\tat jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:974)\\n\\tat jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1477)\\n\\tat jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)","3356":"oh, oh - that is a bug - it is interesting to because 2147483637  == ARRAY_MAX in our code https:\/\/github.com\/h2oai\/h2o-3\/blob\/master\/h2o-extensions\/xgboost\/src\/main\/java\/hex\/tree\/xgboost\/XGBoostUtils.java#L345 - this is something we can probably fix quickly\\n\\ncan you please make bug in our bug tracking system? https:\/\/0xdata.atlassian.net\/secure\/Dashboard.jspa","3357":"Sure.","3358":"@michalkurka However, it only shows up when my data is too big. My colleague was using (100M, 10) and I was using (33M, 500)","3359":"And  i only saw it when using xgboost","3360":"yeah, we should handle unlimited data sizes - the APIs are in place to handle that, this looks like off-by-one bug to me","3361":"XGBoost will be the only one affected because we don't have to move data to the native memory for other algos like we do in XGBoost's case","3362":"thanks for the bug report","3363":"That sounds great. it will definitely solve my problem now","3364":"so when the new version is updated. I just need to update my jar file on databricks?","3365":"yes, you will just need to update the jar","3366":"Nice! thank you ","3367":"When can i expect this next update?","3368":"my initial assessment is that it won't be hard to fix but I cannot promise a date just yet","3369":"it might be included in this weeks release","3370":"I see. that will be great ","3371":"actually i have one more question, ","3372":"H2OConnectionError: Unexpected HTTP error: HTTPConnectionPool(host='10.139.64.17', port=54321): Max retries exceeded with url: \/99\/Models.bin\/XGBoost_model_python_1553620967027_1?force=True&dir=dbfs%3A%2Fmnt%2Fcatmktg-edl-prod%2Fsandbox%2Faz-pr-adls-ml1%2Fvwei%2FMFD%2Fmodel_object%2F19%2F50001%2FXGBoost_model_python_1553620967027_1 (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7f56151746d8>: Failed to establish a new connection: [Errno 111] Connection refused',))","3373":"please post the jira ticket here - I will assign it","3374":"i was using h2o.save_model() and it gave me this error","3375":"do you have the logs for that?","3376":"no stacktrace, nothing","3377":"just this error","3378":"yeah, I am just interested in the previous requests and how H2O was started","3379":"I ceased an on-going model building process","3380":"that could help ","3381":"would that be the problem?","3382":"hmm, that definitely could be","3383":"So should I shutdown the cluster and restart? it happens quite often ","3384":"#Start h2o-spark cluster\\nconf = SparkConf()\\\\\\n        .set(\\spark.driver.maxResultSize\\ \\80g\\)\\\\\\n        .set(\\spark.serializer\\ \\org.apache.spark.serializer.KryoSerializer\\)\\\\\\n        .set(\\spark.speculation\\ \\true\\)\\\\\\n        .set(\\spark.shuffle.manager\\ \\sort\\)\\\\\\n        .set(\\spark.shuffle.service.enabled\\ \\true\\)\\nspark = SparkSession.builder.master(\\yarn\\).appName(\\SparklingWaterApp\\).config(conf=conf).getOrCreate()\\nhc = H2OContext.getOrCreate(spark)","3385":"I think the logs would be helpful here","3386":"This is my code to start the cluster","3387":"okay, I am not super familiar with how to start XGBoost correctly on Sparkling Water - it might needs some memory configs","3388":"I see...well i guess ill have to re-start it","3389":"https:\/\/h2o-release.s3.amazonaws.com\/sparkling-water\/rel-2.4\/2\/doc\/tutorials\/sw_xgboost.html","3390":"it seems like you are running on yarn and thus you should enable the extra memory configuration","3391":"this link will take you to the relevant section: https:\/\/h2o-release.s3.amazonaws.com\/sparkling-water\/rel-2.4\/2\/doc\/tutorials\/sw_xgboost.html#xgboost-memory-configuration","3392":"i checked through spark UI and my memory config are basically tuned to max","3393":"I think it might be me stoping the training in the middle","3394":"I would file a bug in SW anyway - it is weird that it is giving you connection error","3395":"I would expect it to say something better :)","3396":"Gotcha","3397":"Thank you!","3398":"np","3399":"@michalkurka  are there any ResNet50 pretrained models for H2O that I can use in my code? In the examples, all I saw was the usage of Lenet with TF backend. Can i do the same with ResNet50? Refering to ex: h2o-3\/examples\/deeplearning\/notebooks\/deeplearning_tensorflow_cat_dog_mouse_lenet.ipynb","3400":"@michalkurka  The example above uses DeepWater, but as per https:\/\/github.com\/h2oai\/deepwater, \\Deep Water is a legacy project (as of December 2017), which means that it is no longer under active development. \\. What is your recommendation to use pretrained models?","3401":"I have my Sparkling Water instance set up on my YARN EMR cluster and instantiated through RSparkling. When I look in the cluster status through flow I see all of the executors listed, and with the expected amount of memory and cores allocated.","3402":"but when I build a model, such as XGBoost, I barely see any activity across my nodes","3403":"any thoughts on what I might be missing?","3404":"I tried a distributed random forest as well and automl","3405":"Any thoughts? I am still having issues with this","3406":"@jbentleyEG its really sad to see this group is not active at all unlike other opensource projects. My questions have been sitting unanswered too. ","3407":"@jbentleyEG it depends on the dataset - if it is small it won't be distributed on all nodes and some nodes won't be doing anything","3408":"you can either check how the H2OFrame is distributed in Flow or check the H2O logs","3409":"ok, I will look at that, thanks","3410":"it's being made from a spark DataFrame so I would think that it would be distributed, unless there is another step that needs to be done","3411":"definitely not a small dataset","3412":"not necessarily, it depends how the Spark frame was created","3413":"please do check how the H2O Frame looks like, we can investigate further","3414":"you mentioned that DRF behaves the same way as XGBoost - which really makes me think the issue is with the dataset distribution, DRF can definitely utilize the resources well","3415":"ok","3416":"and please collect the h2o logs, it will have  info about the dataset distribution + it will say why h2o didn't decide to rebalance (redistribute) the dataset","3417":"ok, I'm away from my setup ATM but will do later and let you know how it goes","3418":"thanks","3419":"perfect, thanks","3420":"@michalkurka Hi, I am trying to convert a large spark dataframe to h2o dataframe. And it should me error","3421":"Py4JJavaError: An error occurred while calling o758.asH2OFrame.\\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1208 in stage 10.0 failed 4 times, most recent failure: Lost task 1208.3 in stage 10.0 (TID 67081, 10.139.64.6, executor 5): java.lang.ArrayIndexOutOfBoundsException: 65535\\n\\tat water.DKV.get(DKV.java:209)\\n\\tat water.DKV.get(DKV.java:182)\\n\\tat water.Key.get(Key.java:84)\\n\\tat water.fvec.Frame.createNewChunks(Frame.java:989)\\n\\tat water.fvec.FrameUtils$class.createNewChunks(FrameUtils.scala:45)\\n\\tat water.fvec.FrameUtils$.createNewChunks(FrameUtils.scala:72)\\n\\tat org.apache.spark.h2o.backends.internal.InternalWriteConverterCtx.createChunks(InternalWriteConverterCtx.scala:37)\\n\\tat org.apache.spark.h2o.converters.SparkDataFrameConverter$.org$apache$spark$h2o$converters$SparkDataFrameConverter$$perSQLPartition(SparkDataFrameConverter.scala:109)\\n\\tat org.apache.spark.h2o.converters.SparkDataFrameConverter$$anonfun$toH2OFrame$2$$anonfun$apply$1.apply(SparkDataFrameConverter.scala:81)\\n\\tat org.apache.spark.h2o.converters.SparkDataFrameConverter$$anonfun$toH2OFrame$2$$anonfun$apply$1.apply(SparkDataFrameConverter.scala:81)\\n\\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\\n\\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:139)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:112)\\n\\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$13.apply(Executor.scala:497)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1432)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:503)\\n\\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\\n\\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\\n\\tat java.lang.Thread.run(Thread.java:748)\\n\\nDriver stacktrace:\\n\\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:2100)\\n\\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2088)\\n\\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2087)\\n\\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\\n\\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\\n\\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2087)\\n\\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:1076)\\n\\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:1076)\\n\\tat scala.Option.foreach(Option.scala:257)\\n\\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1076)\\n\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2319)\\n\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2267)\\n\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2255)\\n\\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\\n\\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:873)\\n\\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2252)\\n\\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2274)\\n\\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2306)\\n\\tat org.apache.spark.h2o.converters.WriteConverterCtxUtils$.convert(WriteConverterCtxUtils.scala:87)\\n\\tat org.apache.spark.h2o.converters.SparkDataFrameConverter$.toH2OFrame(SparkDataFrameConverter.scala:80)\\n\\tat org.apache.spark.h2o.H2OContext$$anonfun$asH2OFrame$2.apply(H2OContext.scala:221)\\n\\tat org.apache.spark.h2o.H2OContext$$anonfun$asH2OFrame$2.apply(H2OContext.scala:221)\\n\\tat org.apache.spark.h2o.utils.H2OContextUtils$class.withConversionDebugPrints(H2OContextUtils.scala:93)\\n\\tat org.apache.spark.h2o.H2OContext.withConversionDebugPrints(H2OContext.scala:65)\\n\\tat org.apache.spark.h2o.H2OContext.asH2OFrame(H2OContext.scala:221)\\n\\tat org.apache.spark.h2o.H2OContext.asH2OFrame(H2OContext.scala:223)\\n\\tat org.apache.spark.h2o.JavaH2OContext.asH2O","3422":"I am using pysparkling 2.4.8. Is this a bug? Or there is a limit on h2o dataframe size","3423":"Also, I am wondering if there a way that i can train and predict without converting data to H2O dataframe? it takes a few hours everytime which is not good for my production process","3424":"@valkyrias_gitlab are you sure just the conversion takes few hours? is the dataframe materialized before you start converting? if so this is something we should look into","3425":"As a workaround - can you please try exporting your Spark frame into a CSV\/Parquet and then import into H2O?","3426":"you cannot directly use Spark frame to train a model, but you can use Spark frame for a pure predict: http:\/\/docs.h2o.ai\/sparkling-water\/2.4\/latest-stable\/doc\/deployment\/scoring_mojo_pipeline.html","3427":"I also wanted to confirm - there is no limitation of how large can an H2O Frame be.","3428":"the failure you are seeing is similar to https:\/\/github.com\/h2oai\/sparkling-water\/issues\/597 - looks like this can happen when one of the executors dies"}}