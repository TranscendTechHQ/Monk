{"message":{"0":"56567a463a7600fd2f87789c","1":"56567a610d627297620cd9ff","2":"56567a7c92aa9746647b93c9","3":"56567b573a7600fd2f8778a7","4":"56567b900d627297620cda0c","5":"565682ebf59a8f0758a6ef39","6":"565682fe0d143098620f4123","7":"5656830f92aa9746647b9477","8":"5658dc8b28c5280777268851","9":"5658ddbb9991fe124e1581fa","10":"5658e0e349e74fad21eb72cb","11":"5658fa3628c5280777268aab","12":"5658fa5428c5280777268ab1","13":"5658faa128c5280777268ab9","14":"5659013d49fc2afe4a4f7de3","15":"565a32252753fafb4af5ee1d","16":"565a59d349e74fad21eb8f03","17":"565a953028c528077726a6df","18":"565ad722c3d575114e6c9270","19":"565c9df03734bd42649a2ad5","20":"565c9e703a0962562964a458","21":"565c9e9bfd59645429ec3c5f","22":"565c9eea84678bd7053fb3bb","23":"565c9f8cf0893e5f6b729649","24":"565c9fecf0893e5f6b72965c","25":"565ca0206693bfd6058dcb5a","26":"565cc058fd59645429ec42a1","27":"565de2fe19eee17f78e269bd","28":"565de30222df37d14f93593c","29":"565de45f5993bcb005d2c832","30":"565de6996ddbc1b32747c36b","31":"565e04ad480c6db2051725db","32":"565e0a376ddbc1b32747cadb","33":"565e0d28480c6db2051727f4","34":"565e0d535993bcb005d2d07c","35":"565e1867480c6db205172a72","36":"565e189f480c6db205172a7f","37":"565e3e26480c6db205173069","38":"565e3e4722df37d14f936a42","39":"565e3f005993bcb005d2d8ed","40":"565e3fcb5993bcb005d2d906","41":"565e4f882488cc8078749137","42":"565e7cb219eee17f78e280a5","43":"565e81d0480c6db2051736a3","44":"565e82979a969fd24f3c11cf","45":"565e86a422df37d14f937104","46":"565e8aac2488cc807874968c","47":"565e8ab165c2a5b027d73b4e","48":"565e8ad819eee17f78e281d5","49":"565e8b0f22df37d14f937167","50":"565e8b1f65c2a5b027d73b5a","51":"565e8b282488cc8078749697","52":"565e8b5465c2a5b027d73b5d","53":"565e8b7d19eee17f78e281e0","54":"565f257e22df37d14f938953","55":"565f274a19eee17f78e29a41","56":"565f2933480c6db205175059","57":"565f4224480c6db2051755b9","58":"565f42285993bcb005d2fde5","59":"565f423f65c2a5b027d7585c","60":"565f42c922df37d14f938f62","61":"565f42f49a969fd24f3c3055","62":"565f4310480c6db2051755d3","63":"565f436c22df37d14f938f78","64":"565f43fd65c2a5b027d75894","65":"565f440522df37d14f938f8d","66":"565f4441480c6db2051755fc","67":"565f4468480c6db2051755ff","68":"565f447522df37d14f938f9f","69":"565f44e79a969fd24f3c30a9","70":"565f450522df37d14f938fb1","71":"565f453e9a969fd24f3c30b7","72":"565f45509a969fd24f3c30bb","73":"565f459a22df37d14f938fd4","74":"565f45ae22df37d14f938fd9","75":"565f45af9a969fd24f3c30c9","76":"565f45cb480c6db205175641","77":"565f45d12488cc807874b468","78":"565f460c6ddbc1b32747f8a8","79":"565f460f22df37d14f938fea","80":"565f462c2488cc807874b473","81":"565f46369a969fd24f3c30de","82":"565f463f480c6db205175658","83":"565f464622df37d14f938ffe","84":"565f466b2488cc807874b485","85":"565f46816ddbc1b32747f8b6","86":"565f468a65c2a5b027d758f7","87":"565f46af6ddbc1b32747f8be","88":"565f46cb5993bcb005d2fe7d","89":"565f46cc6ddbc1b32747f8c0","90":"565f46de19eee17f78e2a0c7","91":"565f46e59a969fd24f3c30fd","92":"565f471419eee17f78e2a0cb","93":"565f4719480c6db205175673","94":"565f474e6ddbc1b32747f8dc","95":"565f476d6ddbc1b32747f8de","96":"565f47842488cc807874b4b1","97":"565f47955993bcb005d2fea0","98":"565f479d480c6db20517568e","99":"565f47d32488cc807874b4c2","100":"565f484219eee17f78e2a0fa","101":"565f484719eee17f78e2a0fb","102":"565f48532488cc807874b4db","103":"565f485b22df37d14f939073","104":"565f48649a969fd24f3c3143","105":"565f48a5480c6db2051756bf","106":"565f48b065c2a5b027d7595e","107":"565f4a5c5993bcb005d2ff0e","108":"565f4a7b5993bcb005d2ff17","109":"565f4c6a5993bcb005d2ff50","110":"565f4ce42488cc807874b58e","111":"565f4cf02488cc807874b590","112":"566f64146a17cd3b36dcf77a","113":"566f6a203078c07476513429","114":"566f8c196a17cd3b36dcfaf9","115":"566f8cb2de55367176819972","116":"5671becfa95dea5d4215098d","117":"5671c102a95dea5d421509e5","118":"5671e12acc068a5e42f1b333","119":"5671febe4a9f5f6772abb77f","120":"5671fecea95dea5d42151241","121":"5671fed7cc068a5e42f1b6da","122":"5671fee837169e856a753547","123":"5671ff03f31bbe91555ae8cc","124":"5671ff76f31bbe91555ae8db","125":"5671ff87a95dea5d4215125e","126":"567200a6f31bbe91555ae904","127":"56720190a95dea5d42151298","128":"56720191c505c2687288604a","129":"567201b8c505c2687288604d","130":"567201c5cc068a5e42f1b726","131":"567201d6f99ceb846ae65706","132":"567201f169a89a8f552ee639","133":"56720200f99ceb846ae65707","134":"56720221f99ceb846ae6570a","135":"5672022b4a9f5f6772abb7d6","136":"56720249a95dea5d421512ae","137":"5672025469a89a8f552ee642","138":"56720290cc068a5e42f1b731","139":"567202b1f99ceb846ae65715","140":"567202b837169e856a7535b3","141":"5672034869a89a8f552ee658","142":"567204c2c505c26872886089","143":"5672050169a89a8f552ee68f","144":"5672050869a89a8f552ee690","145":"56720526cc068a5e42f1b772","146":"56720541a95dea5d421512fa","147":"56720553c505c26872886095","148":"56720558cc068a5e42f1b777","149":"5672058637169e856a7535e1","150":"56720592cc068a5e42f1b77f","151":"5672059469a89a8f552ee69c","152":"567205b1cc068a5e42f1b781","153":"5672061569a89a8f552ee6a6","154":"5672061f69a89a8f552ee6aa","155":"56720647c505c268728860b1","156":"5672064e4a9f5f6772abb836","157":"567206704a9f5f6772abb83f","158":"567206744a9f5f6772abb840","159":"567888da69a89a8f552f94d9","160":"56788918f240f5a004179802","161":"567889365155bfb75b17a7c2","162":"5678a297091b6f9e043a1f54","163":"5678a2a169a89a8f552f9742","164":"56799d053acb611716ff6dda","165":"56799e4e35e1a316162ddce9","166":"56799e67653b30761d75bc0c","167":"5679ba01653b30761d75c15c","168":"5679ba883acb611716ff7330","169":"5679baaa35e1a316162de25f","170":"5679bacb3c6894026924745a","171":"5679bad73acb611716ff7343","172":"5679bae2653b30761d75c198","173":"5679bafa0171d1791d01ce45","174":"5679bb464f069158055b7d09","175":"5679bb889606b15a055d4ccc","176":"5679bc150171d1791d01ce8b","177":"5679bc1d0171d1791d01ce93","178":"5679bc250199d70069df5ba3","179":"5679bc320199d70069df5ba9","180":"5679bc7e9606b15a055d4cf3","181":"5679bc81653b30761d75c1f2","182":"5679bc8a35e1a316162de2c8","183":"5679bce34f069158055b7d54","184":"5679bd383c689402692474d6","185":"5679bd593c689402692474e1","186":"5679bd659606b15a055d4d2d","187":"5679bd7f0199d70069df5c02","188":"5679bd9c9606b15a055d4d41","189":"5679bde635e1a316162de319","190":"5679bdf53acb611716ff73f8","191":"5679be039606b15a055d4d54","192":"5679be16653b30761d75c245","193":"5679be1935e1a316162de327","194":"5679be1e3acb611716ff73ff","195":"5679be2a9606b15a055d4d5c","196":"5679be3735e1a316162de32d","197":"5679be380171d1791d01cf0f","198":"5679be584f069158055b7dc0","199":"5679bea03acb611716ff741b","200":"5679bead0199d70069df5c46","201":"5679beb29606b15a055d4d78","202":"5679beba4f069158055b7dd3","203":"5679bec235e1a316162de342","204":"5679bece9606b15a055d4d83","205":"5679bed19606b15a055d4d85","206":"5679bee435e1a316162de34c","207":"5679bef40171d1791d01cf3a","208":"5679bf0f3acb611716ff742b","209":"5679bf2835e1a316162de35e","210":"5679bf343c68940269247545","211":"5679bf404f069158055b7df9","212":"5679bf524f069158055b7dfc","213":"5679bfb53acb611716ff744e","214":"5679bfd1653b30761d75c2c2","215":"5679c03b3c68940269247577","216":"5679c0700171d1791d01cf9c","217":"5679c0a63c6894026924758d","218":"5679c11f9606b15a055d4df8","219":"5679c1250171d1791d01cfbe","220":"5679e18c0199d70069df6186","221":"567b88394f069158055bafbd","222":"567b88ff3c6894026924a628","223":"567ba2c635e1a316162e13cd","224":"567baa81653b30761d75f4d9","225":"567baab44f069158055bb231","226":"567baac8653b30761d75f4e0","227":"567baad59606b15a055d810f","228":"567bab333c6894026924a858","229":"56819b823c689402692515e8","230":"5681b6d435e1a316162e7aad","231":"5681b7189606b15a055dee21","232":"5681b76c35e1a316162e7ab9","233":"5681c2520199d70069e00118","234":"5681c29f9606b15a055def1e","235":"5681c2d39606b15a055def23","236":"5681de804f069158055c23b6","237":"568306880199d70069e0267f","238":"568309340171d1791d029924","239":"568309943c68940269254248","240":"568312f29606b15a055e1527","241":"56836d673c68940269254b79","242":"56836e283acb6117160034fc","243":"56836ee89606b15a055e1d2f","244":"56836f844f069158055c4e01","245":"56836fa34f069158055c4e03","246":"56836fb33c68940269254ba6","247":"56836fba0199d70069e0307d","248":"56836fcf9606b15a055e1d42","249":"56836ff10171d1791d02a28f","250":"568370033c68940269254bad","251":"568370580199d70069e0308a","252":"568370b1653b30761d7695f4","253":"568372500171d1791d02a2be","254":"568373e00171d1791d02a2e0","255":"5686de363c68940269259dba","256":"5689062a653b30761d771434","257":"56893e48653b30761d771a86","258":"568941fd9606b15a055ea247","259":"5689420d3acb61171600b5a1","260":"568942333acb61171600b5a7","261":"568942374f069158055cd421","262":"568971823c6894026925d84b","263":"568971c43acb61171600bb77","264":"56898944653b30761d772417","265":"56899c8f35e1a316162f30c4","266":"56899caa4f069158055cdfdf","267":"56899d8f9606b15a055eada5","268":"56899da335e1a316162f30e8","269":"56899e7735e1a316162f3101","270":"56899e854f069158055ce012","271":"56899e903acb61171600c104","272":"56899ea335e1a316162f3106","273":"56899ec30199d70069e0c0be","274":"56899f3d0171d1791d033517","275":"56899f703c6894026925de21","276":"56899f870199d70069e0c0ce","277":"56899fb8653b30761d77269b","278":"56899fbd0171d1791d03352b","279":"56899fc90171d1791d033531","280":"56899fcd0171d1791d033532","281":"5689a01f3c6894026925de30","282":"5689a0500199d70069e0c0e4","283":"5689a0580199d70069e0c0e6","284":"5689a06a3acb61171600c133","285":"5689a07a9606b15a055eadfc","286":"5689a0910199d70069e0c0ee","287":"5689a0973acb61171600c13a","288":"568a389d9606b15a055ebb9e","289":"568a389f9606b15a055ebb9f","290":"568ade5c653b30761d77518b","291":"568bf7320ee564e145a0e75a","292":"568bf7ff0ee564e145a0e792","293":"568bf8650e1485c45b47b56d","294":"568bffb51c4d7bfd6864ba22","295":"568c04800e1485c45b47b862","296":"568c04a12597fafe6870b5b2","297":"568c05290e1485c45b47b894","298":"568c05330ee564e145a0ea96","299":"568c054e0ee564e145a0eaa1","300":"568c1cf00ee564e145a0efa6","301":"568c1d262597fafe6870bb01","302":"568c21148aafa1e4459c4e64","303":"568c21545dd644c75b6e12fe","304":"568c3a760e1485c45b47c34b","305":"568c447417dc78be338701fb","306":"568c44b3881538d260acd838","307":"568c44bde8598dd060154bf7","308":"568c56e5262659750bce73d7","309":"568c5a75e8598dd060154ee6","310":"568c5b3d9a5f8fe839215b9b","311":"568c5eec17dc78be338705c3","312":"568c618cd9a9d7ea39cf8ff2","313":"568c65e617dc78be33870663","314":"568c670984fa46770b24cad3","315":"568c7070881538d260acdd09","316":"568c78b717dc78be3387082e","317":"568c793517dc78be3387083d","318":"568c7957262659750bce7748","319":"568c9ddbc5bdc5ba338e1ac7","320":"568c9deb17dc78be33870c2e","321":"568d44dd9a5f8fe839217934","322":"568d4a44d9a9d7ea39cfaed0","323":"568d73119a5f8fe839218430","324":"56903eb087cb99b53b880991","325":"56903ed98fdd3c0c382d96d7","326":"56903ef687cb99b53b8809a0","327":"56903f0187cb99b53b8809a2","328":"56903f2ed739f50a36028b0c","329":"56903f5987cb99b53b8809b1","330":"56903f908fdd3c0c382d96fd","331":"56903f9ab1f439094a071c93","332":"56903fa887cb99b53b8809bd","333":"56903fbcee13050b38a27b71","334":"56903fe9766922073602afa6","335":"569040fbb1f439094a071ced","336":"569437527669220736031fcc","337":"569484db5fd2ae3c32b502a7","338":"5694a7bb87cb99b53b888998","339":"56953a10b1f439094a07bbd8","340":"5695407b5fd2ae3c32b5237e","341":"569546fc8fdd3c0c382e3ad2","342":"56997fd659e3d04215bc0a37","343":"56997ff03165a6af1a3c103d","344":"569a942ec391361d48eb7bb7","345":"569a95255de13b3f15e373f1","346":"569a96c128b4586d1c8d0ac3","347":"569a96d05de13b3f15e37448","348":"569a96dc28b4586d1c8d0acb","349":"569a96e0c391361d48eb7c2f","350":"569c012e28b4586d1c8d2f4b","351":"569c037a59e3d04215bc49d0","352":"569c0db7c391361d48eba3c9","353":"569c13bc5de13b3f15e39ce3","354":"569c13d828b4586d1c8d31fd","355":"569c1ab528b4586d1c8d3323","356":"569c1acdc391361d48eba5ef","357":"569c1d4e28b4586d1c8d336f","358":"569c1dc32bc35f6c1c1aa156","359":"569c20692bc35f6c1c1aa1b4","360":"569c20d4a03e28ad1adf44a8","361":"569c217f3165a6af1a3c5381","362":"569e6df1c391361d48ec01b0","363":"569e84d22bc35f6c1c1b00e5","364":"569e84fa2bc35f6c1c1b00f2","365":"569e850ec391361d48ec076b","366":"569e8528da358920486fa0a0","367":"569e854959e3d04215bcb05d","368":"569e855e3165a6af1a3cb308","369":"569e85643165a6af1a3cb30a","370":"569e8578a03e28ad1adfa55e","371":"569e858bc391361d48ec0788","372":"569e859fda358920486fa0c2","373":"569e85abda358920486fa0c9","374":"569e85ad28b4586d1c8d9338","375":"569e85c459e3d04215bcb070","376":"569e85cdc391361d48ec0799","377":"569e85d15de13b3f15e3ffe5","378":"569e85ef3165a6af1a3cb328","379":"569e85fc59e3d04215bcb081","380":"569e860428b4586d1c8d934e","381":"569e8608c391361d48ec07ad","382":"569e8626c391361d48ec07b4","383":"569e8632da358920486fa0e6","384":"569e863cc391361d48ec07b8","385":"569e864e2bc35f6c1c1b0135","386":"569e8656a03e28ad1adfa597","387":"569e865da03e28ad1adfa598","388":"569e86735de13b3f15e4000c","389":"569e868ba03e28ad1adfa5a6","390":"569e868d59e3d04215bcb0a8","391":"569e87edc391361d48ec082c","392":"569e882c3165a6af1a3cb3b6","393":"569e889128b4586d1c8d93d0","394":"569e889d5de13b3f15e4006e","395":"569e8b453165a6af1a3cb485","396":"569e8e3d2bc35f6c1c1b0306","397":"569eba78a03e28ad1adfb1e2","398":"569eba833165a6af1a3cbfe7","399":"569eba91da358920486fad51","400":"569ebac4c391361d48ec1394","401":"569ebaeb28b4586d1c8da05a","402":"569ebaf9a03e28ad1adfb1ff","403":"569ebb1259e3d04215bcbd2c","404":"569ebb255de13b3f15e40d1c","405":"569ebb3228b4586d1c8da06e","406":"569ebb4cda358920486fad72","407":"569ebb662bc35f6c1c1b0e06","408":"569ebb9b59e3d04215bcbd4d","409":"569ebbe4a03e28ad1adfb232","410":"569ebbf459e3d04215bcbd58","411":"569ebc055de13b3f15e40d45","412":"569ebc21c391361d48ec13e1","413":"569ebcb1da358920486fadb9","414":"569ebd07a03e28ad1adfb264","415":"569ebd3259e3d04215bcbd93","416":"569ebd3f2bc35f6c1c1b0e78","417":"569ebd943165a6af1a3cc07b","418":"569ebd9b3165a6af1a3cc07e","419":"569ebe832bc35f6c1c1b0eab","420":"569ebe8d59e3d04215bcbdd4","421":"569ebe94a03e28ad1adfb2a5","422":"569ebea928b4586d1c8da111","423":"569ebec4da358920486fae13","424":"569ebedf5de13b3f15e40dbf","425":"569ebeedda358920486fae1d","426":"569ebf1c2bc35f6c1c1b0ebe","427":"569ebf563165a6af1a3cc0b6","428":"569ebf8828b4586d1c8da12e","429":"569ec017c391361d48ec1497","430":"569ecb583165a6af1a3cc28a","431":"569ecb8828b4586d1c8da328","432":"569ecba259e3d04215bcbffb","433":"569ecbaa59e3d04215bcbffc","434":"569ecbae3165a6af1a3cc296","435":"569ecbb5da358920486fb05d","436":"569ecbbac391361d48ec166c","437":"569ecbbfda358920486fb062","438":"569ecc63da358920486fb085","439":"569ecc7ac391361d48ec168b","440":"569ed5295de13b3f15e4113a","441":"569ee9755de13b3f15e41373","442":"569eee6e3165a6af1a3cc6db","443":"569f06a83165a6af1a3cc97f","444":"569f112bc391361d48ec1e43","445":"569f113559e3d04215bcc753","446":"569f189eda358920486fb8b4","447":"569f18a32bc35f6c1c1b1978","448":"569f18abc391361d48ec1ee8","449":"569f18e228b4586d1c8dabb7","450":"569f19393165a6af1a3ccb17","451":"569f19622bc35f6c1c1b198f","452":"569f19915de13b3f15e41855","453":"569f1a2128b4586d1c8dabcf","454":"569fe84459e3d04215bcedc1","455":"56a003aec391361d48ec4a6b","456":"56a003bb5de13b3f15e44482","457":"56a00b5cda358920486fe668","458":"56a00b6628b4586d1c8dd969","459":"56a0358359e3d04215bcfb1e","460":"56a45bb08fbaf4220af8fb53","461":"56a4639e6b6468374a092b1e","462":"56a46d438fbaf4220af8fc8c","463":"56a46d646b6468374a092ba6","464":"56a46d89c54bc2bf180bb094","465":"56a513a9eaf741c118d49ba3","466":"56a9aaee80ad69394a7ae84f","467":"56aac3eeaaae7a3a7593c43b","468":"56aac400dc33b33c754888ff","469":"56aac424aaae7a3a7593c441","470":"56aaee31dc33b33c75488e1f","471":"56abef8d6b6468374a0a5f88","472":"56abf8eac54bc2bf180ce872","473":"56abf907c54bc2bf180ce875","474":"56abf90aeaf741c118d5c1a1","475":"56abf965c54bc2bf180ce87f","476":"56cdfceabfb1cf9a7ff2cb91","477":"56ce048bbfb1cf9a7ff2cd8b","478":"57475cff80352f204df27de3","479":"57f2a7cc91d6af115227309b","480":"57f54335d45d7f0f52662e44","481":"57f5433e0ec6f9457da4c5d7","482":"58d08bc86d7eb18404ebe235","483":"590a3d3f8bb56c2d110a5a1c","484":"590a50898e4b63533d2c8205","485":"590cdd75d1a7716a0a985c35","486":"590d289ce2285d3b163187d1","487":"5919a4e1631b8e4e61d9b1d0","488":"5919a4e72b926f8a6758e61b","489":"591e985e33e9ee771cc0f41d","490":"591e989c92217cca588ff2e6","491":"591e98d300efc2bb3e81c919","492":"591e98d633e9ee771cc0f62a","493":"591ec74f2b926f8a676f14e6","494":"591ec752631b8e4e61f005c5","495":"591ec76592217cca5890aae9","496":"591f1242f3001cd3423a4c6c","497":"592107725e34568d5e75d213","498":"593a68edf31c8ced0c1b1db4","499":"594b875e746f1fd6632c3430","500":"596dba163230e14f3a6cd68e","501":"596dba6cf5b3458e3059804f","502":"5993d0e09acddb2407950880","503":"59b96d5dcfeed2eb6505978b","504":"59ba14c8614889d475f6beb0","505":"59ba7997bc46472974323c0d","506":"59bac2c77b7d98d30df6121b","507":"59bbdbebcfeed2eb6511e934","508":"59bbdc6fbac826f054bf9a92","509":"59bbdc76210ac26920354f1a","510":"59bbeddacfeed2eb65124f13","511":"59bbee32210ac2692035b82b","512":"59bc6ff4177fb9fe7ec7cc16","513":"59c585757b7d98d30d280b10","514":"59d7050901110b7231817c95","515":"59fb9c3d614889d475324e62","516":"59fb9e5a32e080696e5a280a","517":"5a02a1a5b20c6424299ffa20","518":"5a4b214d03838b2f2a5e5947","519":"5a4b21515355812e573ffa12","520":"5a4f847ace68c3bc7480a23e","521":"5a4f84990163b02810b675d7","522":"5a4f84b2ce68c3bc7480a31e","523":"5a4f84d803838b2f2a74119c","524":"5a56d0a5ae53c15903d2f550","525":"5a5d3078ae53c15903f03055","526":"5a5d40931dcb91f17754e2a5","527":"5a65c3bfd9f895c36046255c","528":"5a65c41a5a9ebe4f75bb0dcc","529":"5a7c4d8f93be87284d9029f9","530":"5a7dbaf1b3c4a0d37600b9d6","531":"5a81f43be217167e2c763368","532":"5a81f4764a6b0dd32bc0f243","533":"5ac33c76c574b1aa3e5f9f26","534":"5ae053305d7286b43a66ebfc","535":"5ae053645d7286b43a66ecb9","536":"5aea96b46d98e53e044aa822","537":"5aea96d85cf0b83004513d1f","538":"5b051ca2aaafa25932abc7d2","539":"5b262d0647559749102f891e","540":"5c126bb35e409525035eb58c","541":"5c349aed82a6c30b90a37ac9","542":"5c34f37082a6c30b90a5e825","543":"5c9bc4aae820b6470b733fa4","544":"5c9bc4b8e7341060caf0f5a0"},"time":{"0":"2015-11-26T03:19:34.353Z","1":"2015-11-26T03:20:01.644Z","2":"2015-11-26T03:20:28.938Z","3":"2015-11-26T03:24:07.640Z","4":"2015-11-26T03:25:04.590Z","5":"2015-11-26T03:56:27.576Z","6":"2015-11-26T03:56:46.503Z","7":"2015-11-26T03:57:03.385Z","8":"2015-11-27T22:43:23.412Z","9":"2015-11-27T22:48:27.576Z","10":"2015-11-27T23:01:55.538Z","11":"2015-11-28T00:49:58.430Z","12":"2015-11-28T00:50:28.860Z","13":"2015-11-28T00:51:45.408Z","14":"2015-11-28T01:19:57.442Z","15":"2015-11-28T23:00:53.827Z","16":"2015-11-29T01:50:11.387Z","17":"2015-11-29T06:03:28.184Z","18":"2015-11-29T10:44:50.507Z","19":"2015-11-30T19:05:20.625Z","20":"2015-11-30T19:07:28.495Z","21":"2015-11-30T19:08:11.023Z","22":"2015-11-30T19:09:30.716Z","23":"2015-11-30T19:12:12.952Z","24":"2015-11-30T19:13:48.593Z","25":"2015-11-30T19:14:40.615Z","26":"2015-11-30T21:32:08.257Z","27":"2015-12-01T18:12:14.203Z","28":"2015-12-01T18:12:18.177Z","29":"2015-12-01T18:18:07.763Z","30":"2015-12-01T18:27:37.331Z","31":"2015-12-01T20:35:57.707Z","32":"2015-12-01T20:59:35.613Z","33":"2015-12-01T21:12:08.751Z","34":"2015-12-01T21:12:51.830Z","35":"2015-12-01T22:00:07.760Z","36":"2015-12-01T22:01:03.420Z","37":"2015-12-02T00:41:10.015Z","38":"2015-12-02T00:41:43.883Z","39":"2015-12-02T00:44:48.620Z","40":"2015-12-02T00:48:11.256Z","41":"2015-12-02T01:55:20.856Z","42":"2015-12-02T05:08:02.508Z","43":"2015-12-02T05:29:52.346Z","44":"2015-12-02T05:33:11.130Z","45":"2015-12-02T05:50:28.400Z","46":"2015-12-02T06:07:40.238Z","47":"2015-12-02T06:07:45.863Z","48":"2015-12-02T06:08:24.473Z","49":"2015-12-02T06:09:19.622Z","50":"2015-12-02T06:09:35.108Z","51":"2015-12-02T06:09:44.808Z","52":"2015-12-02T06:10:28.341Z","53":"2015-12-02T06:11:09.677Z","54":"2015-12-02T17:08:14.521Z","55":"2015-12-02T17:15:54.774Z","56":"2015-12-02T17:24:03.103Z","57":"2015-12-02T19:10:28.451Z","58":"2015-12-02T19:10:32.175Z","59":"2015-12-02T19:10:55.705Z","60":"2015-12-02T19:13:13.131Z","61":"2015-12-02T19:13:56.054Z","62":"2015-12-02T19:14:24.448Z","63":"2015-12-02T19:15:56.637Z","64":"2015-12-02T19:18:21.197Z","65":"2015-12-02T19:18:29.359Z","66":"2015-12-02T19:19:29.592Z","67":"2015-12-02T19:20:08.568Z","68":"2015-12-02T19:20:21.435Z","69":"2015-12-02T19:22:15.122Z","70":"2015-12-02T19:22:45.511Z","71":"2015-12-02T19:23:42.434Z","72":"2015-12-02T19:24:00.717Z","73":"2015-12-02T19:25:14.050Z","74":"2015-12-02T19:25:34.086Z","75":"2015-12-02T19:25:35.966Z","76":"2015-12-02T19:26:03.176Z","77":"2015-12-02T19:26:09.435Z","78":"2015-12-02T19:27:08.115Z","79":"2015-12-02T19:27:11.302Z","80":"2015-12-02T19:27:40.358Z","81":"2015-12-02T19:27:50.573Z","82":"2015-12-02T19:27:59.324Z","83":"2015-12-02T19:28:06.654Z","84":"2015-12-02T19:28:43.229Z","85":"2015-12-02T19:29:05.126Z","86":"2015-12-02T19:29:14.717Z","87":"2015-12-02T19:29:51.555Z","88":"2015-12-02T19:30:19.517Z","89":"2015-12-02T19:30:20.952Z","90":"2015-12-02T19:30:38.961Z","91":"2015-12-02T19:30:45.733Z","92":"2015-12-02T19:31:32.369Z","93":"2015-12-02T19:31:37.068Z","94":"2015-12-02T19:32:30.406Z","95":"2015-12-02T19:33:01.438Z","96":"2015-12-02T19:33:24.469Z","97":"2015-12-02T19:33:41.146Z","98":"2015-12-02T19:33:49.792Z","99":"2015-12-02T19:34:43.560Z","100":"2015-12-02T19:36:34.952Z","101":"2015-12-02T19:36:39.184Z","102":"2015-12-02T19:36:51.638Z","103":"2015-12-02T19:36:59.401Z","104":"2015-12-02T19:37:08.486Z","105":"2015-12-02T19:38:13.364Z","106":"2015-12-02T19:38:24.208Z","107":"2015-12-02T19:45:32.252Z","108":"2015-12-02T19:46:03.739Z","109":"2015-12-02T19:54:18.997Z","110":"2015-12-02T19:56:20.086Z","111":"2015-12-02T19:56:32.483Z","112":"2015-12-15T00:51:32.227Z","113":"2015-12-15T01:17:20.884Z","114":"2015-12-15T03:42:17.052Z","115":"2015-12-15T03:44:50.860Z","116":"2015-12-16T19:43:11.881Z","117":"2015-12-16T19:52:34.038Z","118":"2015-12-16T22:09:46.139Z","119":"2015-12-17T00:15:58.630Z","120":"2015-12-17T00:16:14.208Z","121":"2015-12-17T00:16:23.272Z","122":"2015-12-17T00:16:40.126Z","123":"2015-12-17T00:17:07.804Z","124":"2015-12-17T00:19:02.674Z","125":"2015-12-17T00:19:19.551Z","126":"2015-12-17T00:24:06.484Z","127":"2015-12-17T00:28:00.390Z","128":"2015-12-17T00:28:01.049Z","129":"2015-12-17T00:28:40.059Z","130":"2015-12-17T00:28:53.840Z","131":"2015-12-17T00:29:10.352Z","132":"2015-12-17T00:29:37.414Z","133":"2015-12-17T00:29:52.397Z","134":"2015-12-17T00:30:25.336Z","135":"2015-12-17T00:30:35.232Z","136":"2015-12-17T00:31:05.140Z","137":"2015-12-17T00:31:16.392Z","138":"2015-12-17T00:32:16.954Z","139":"2015-12-17T00:32:49.520Z","140":"2015-12-17T00:32:56.566Z","141":"2015-12-17T00:35:20.938Z","142":"2015-12-17T00:41:38.013Z","143":"2015-12-17T00:42:41.724Z","144":"2015-12-17T00:42:48.484Z","145":"2015-12-17T00:43:18.123Z","146":"2015-12-17T00:43:45.675Z","147":"2015-12-17T00:44:03.114Z","148":"2015-12-17T00:44:08.336Z","149":"2015-12-17T00:44:54.555Z","150":"2015-12-17T00:45:06.152Z","151":"2015-12-17T00:45:08.584Z","152":"2015-12-17T00:45:37.728Z","153":"2015-12-17T00:47:17.069Z","154":"2015-12-17T00:47:27.024Z","155":"2015-12-17T00:48:07.043Z","156":"2015-12-17T00:48:14.880Z","157":"2015-12-17T00:48:48.092Z","158":"2015-12-17T00:48:52.561Z","159":"2015-12-21T23:18:50.864Z","160":"2015-12-21T23:19:52.660Z","161":"2015-12-21T23:20:22.695Z","162":"2015-12-22T01:08:39.842Z","163":"2015-12-22T01:08:49.473Z","164":"2015-12-22T18:57:09.738Z","165":"2015-12-22T19:02:38.505Z","166":"2015-12-22T19:03:03.840Z","167":"2015-12-22T21:00:49.465Z","168":"2015-12-22T21:03:04.310Z","169":"2015-12-22T21:03:38.953Z","170":"2015-12-22T21:04:11.887Z","171":"2015-12-22T21:04:23.263Z","172":"2015-12-22T21:04:34.574Z","173":"2015-12-22T21:04:58.998Z","174":"2015-12-22T21:06:14.947Z","175":"2015-12-22T21:07:20.148Z","176":"2015-12-22T21:09:41.952Z","177":"2015-12-22T21:09:49.987Z","178":"2015-12-22T21:09:57.843Z","179":"2015-12-22T21:10:10.371Z","180":"2015-12-22T21:11:26.522Z","181":"2015-12-22T21:11:29.711Z","182":"2015-12-22T21:11:38.415Z","183":"2015-12-22T21:13:07.887Z","184":"2015-12-22T21:14:32.513Z","185":"2015-12-22T21:15:05.442Z","186":"2015-12-22T21:15:17.828Z","187":"2015-12-22T21:15:43.795Z","188":"2015-12-22T21:16:12.437Z","189":"2015-12-22T21:17:26.800Z","190":"2015-12-22T21:17:41.231Z","191":"2015-12-22T21:17:55.624Z","192":"2015-12-22T21:18:14.619Z","193":"2015-12-22T21:18:17.821Z","194":"2015-12-22T21:18:22.127Z","195":"2015-12-22T21:18:34.704Z","196":"2015-12-22T21:18:47.271Z","197":"2015-12-22T21:18:48.255Z","198":"2015-12-22T21:19:20.108Z","199":"2015-12-22T21:20:32.154Z","200":"2015-12-22T21:20:45.855Z","201":"2015-12-22T21:20:50.822Z","202":"2015-12-22T21:20:58.184Z","203":"2015-12-22T21:21:06.390Z","204":"2015-12-22T21:21:18.001Z","205":"2015-12-22T21:21:21.763Z","206":"2015-12-22T21:21:40.001Z","207":"2015-12-22T21:21:56.889Z","208":"2015-12-22T21:22:23.330Z","209":"2015-12-22T21:22:48.842Z","210":"2015-12-22T21:23:00.813Z","211":"2015-12-22T21:23:12.661Z","212":"2015-12-22T21:23:30.292Z","213":"2015-12-22T21:25:09.603Z","214":"2015-12-22T21:25:37.556Z","215":"2015-12-22T21:27:23.417Z","216":"2015-12-22T21:28:16.398Z","217":"2015-12-22T21:29:10.556Z","218":"2015-12-22T21:31:11.158Z","219":"2015-12-22T21:31:17.344Z","220":"2015-12-22T23:49:32.115Z","221":"2015-12-24T05:52:57.460Z","222":"2015-12-24T05:56:15.892Z","223":"2015-12-24T07:46:14.084Z","224":"2015-12-24T08:19:13.940Z","225":"2015-12-24T08:20:04.099Z","226":"2015-12-24T08:20:24.452Z","227":"2015-12-24T08:20:37.515Z","228":"2015-12-24T08:22:11.448Z","229":"2015-12-28T20:28:50.033Z","230":"2015-12-28T22:25:24.967Z","231":"2015-12-28T22:26:32.692Z","232":"2015-12-28T22:27:56.039Z","233":"2015-12-28T23:14:26.333Z","234":"2015-12-28T23:15:43.119Z","235":"2015-12-28T23:16:35.624Z","236":"2015-12-29T01:14:40.760Z","237":"2015-12-29T22:17:44.230Z","238":"2015-12-29T22:29:08.595Z","239":"2015-12-29T22:30:44.327Z","240":"2015-12-29T23:10:42.557Z","241":"2015-12-30T05:36:39.396Z","242":"2015-12-30T05:39:52.323Z","243":"2015-12-30T05:43:04.330Z","244":"2015-12-30T05:45:40.889Z","245":"2015-12-30T05:46:11.698Z","246":"2015-12-30T05:46:27.279Z","247":"2015-12-30T05:46:34.086Z","248":"2015-12-30T05:46:55.060Z","249":"2015-12-30T05:47:29.170Z","250":"2015-12-30T05:47:47.864Z","251":"2015-12-30T05:49:12.939Z","252":"2015-12-30T05:50:41.196Z","253":"2015-12-30T05:57:36.997Z","254":"2015-12-30T06:04:16.505Z","255":"2016-01-01T20:14:46.699Z","256":"2016-01-03T11:29:46.406Z","257":"2016-01-03T15:29:12.724Z","258":"2016-01-03T15:45:01.003Z","259":"2016-01-03T15:45:17.365Z","260":"2016-01-03T15:45:55.032Z","261":"2016-01-03T15:45:59.600Z","262":"2016-01-03T19:07:46.908Z","263":"2016-01-03T19:08:52.927Z","264":"2016-01-03T20:49:08.108Z","265":"2016-01-03T22:11:27.319Z","266":"2016-01-03T22:11:54.345Z","267":"2016-01-03T22:15:43.717Z","268":"2016-01-03T22:16:03.340Z","269":"2016-01-03T22:19:35.665Z","270":"2016-01-03T22:19:49.743Z","271":"2016-01-03T22:20:00.657Z","272":"2016-01-03T22:20:19.197Z","273":"2016-01-03T22:20:51.223Z","274":"2016-01-03T22:22:53.531Z","275":"2016-01-03T22:23:44.441Z","276":"2016-01-03T22:24:07.656Z","277":"2016-01-03T22:24:56.255Z","278":"2016-01-03T22:25:01.579Z","279":"2016-01-03T22:25:13.571Z","280":"2016-01-03T22:25:17.535Z","281":"2016-01-03T22:26:39.225Z","282":"2016-01-03T22:27:28.028Z","283":"2016-01-03T22:27:36.138Z","284":"2016-01-03T22:27:54.949Z","285":"2016-01-03T22:28:10.831Z","286":"2016-01-03T22:28:33.959Z","287":"2016-01-03T22:28:39.271Z","288":"2016-01-04T09:17:17.754Z","289":"2016-01-04T09:17:19.869Z","290":"2016-01-04T21:04:28.795Z","291":"2016-01-05T17:02:42.721Z","292":"2016-01-05T17:06:07.228Z","293":"2016-01-05T17:07:49.524Z","294":"2016-01-05T17:39:01.872Z","295":"2016-01-05T17:59:28.868Z","296":"2016-01-05T18:00:01.476Z","297":"2016-01-05T18:02:17.478Z","298":"2016-01-05T18:02:27.896Z","299":"2016-01-05T18:02:54.098Z","300":"2016-01-05T19:43:44.363Z","301":"2016-01-05T19:44:38.963Z","302":"2016-01-05T20:01:24.812Z","303":"2016-01-05T20:02:28.575Z","304":"2016-01-05T21:49:42.049Z","305":"2016-01-05T22:32:20.461Z","306":"2016-01-05T22:33:23.229Z","307":"2016-01-05T22:33:33.365Z","308":"2016-01-05T23:51:01.543Z","309":"2016-01-06T00:06:13.491Z","310":"2016-01-06T00:09:33.866Z","311":"2016-01-06T00:25:16.290Z","312":"2016-01-06T00:36:28.071Z","313":"2016-01-06T00:55:02.984Z","314":"2016-01-06T00:59:53.808Z","315":"2016-01-06T01:40:00.897Z","316":"2016-01-06T02:15:19.598Z","317":"2016-01-06T02:17:25.064Z","318":"2016-01-06T02:17:59.003Z","319":"2016-01-06T04:53:47.451Z","320":"2016-01-06T04:54:03.734Z","321":"2016-01-06T16:46:21.983Z","322":"2016-01-06T17:09:24.018Z","323":"2016-01-06T20:03:29.605Z","324":"2016-01-08T22:56:48.538Z","325":"2016-01-08T22:57:29.537Z","326":"2016-01-08T22:57:58.522Z","327":"2016-01-08T22:58:09.533Z","328":"2016-01-08T22:58:54.049Z","329":"2016-01-08T22:59:37.303Z","330":"2016-01-08T23:00:32.483Z","331":"2016-01-08T23:00:42.250Z","332":"2016-01-08T23:00:56.782Z","333":"2016-01-08T23:01:16.218Z","334":"2016-01-08T23:02:01.983Z","335":"2016-01-08T23:06:35.535Z","336":"2016-01-11T23:14:26.532Z","337":"2016-01-12T04:45:15.645Z","338":"2016-01-12T07:14:03.234Z","339":"2016-01-12T17:38:24.462Z","340":"2016-01-12T18:05:47.720Z","341":"2016-01-12T18:33:32.756Z","342":"2016-01-15T23:25:10.896Z","343":"2016-01-15T23:25:36.829Z","344":"2016-01-16T19:04:14.932Z","345":"2016-01-16T19:08:21.143Z","346":"2016-01-16T19:15:13.552Z","347":"2016-01-16T19:15:28.487Z","348":"2016-01-16T19:15:40.022Z","349":"2016-01-16T19:15:44.862Z","350":"2016-01-17T21:01:34.857Z","351":"2016-01-17T21:11:22.957Z","352":"2016-01-17T21:55:03.691Z","353":"2016-01-17T22:20:44.877Z","354":"2016-01-17T22:21:12.327Z","355":"2016-01-17T22:50:29.993Z","356":"2016-01-17T22:50:53.623Z","357":"2016-01-17T23:01:34.524Z","358":"2016-01-17T23:03:31.447Z","359":"2016-01-17T23:14:49.080Z","360":"2016-01-17T23:16:36.549Z","361":"2016-01-17T23:19:27.207Z","362":"2016-01-19T17:10:09.122Z","363":"2016-01-19T18:47:46.543Z","364":"2016-01-19T18:48:26.648Z","365":"2016-01-19T18:48:46.552Z","366":"2016-01-19T18:49:12.846Z","367":"2016-01-19T18:49:45.362Z","368":"2016-01-19T18:50:06.224Z","369":"2016-01-19T18:50:12.685Z","370":"2016-01-19T18:50:32.505Z","371":"2016-01-19T18:50:51.955Z","372":"2016-01-19T18:51:11.697Z","373":"2016-01-19T18:51:23.411Z","374":"2016-01-19T18:51:25.939Z","375":"2016-01-19T18:51:48.464Z","376":"2016-01-19T18:51:57.159Z","377":"2016-01-19T18:52:01.216Z","378":"2016-01-19T18:52:31.152Z","379":"2016-01-19T18:52:44.130Z","380":"2016-01-19T18:52:52.448Z","381":"2016-01-19T18:52:56.229Z","382":"2016-01-19T18:53:26.633Z","383":"2016-01-19T18:53:38.710Z","384":"2016-01-19T18:53:48.852Z","385":"2016-01-19T18:54:06.800Z","386":"2016-01-19T18:54:14.972Z","387":"2016-01-19T18:54:21.840Z","388":"2016-01-19T18:54:43.109Z","389":"2016-01-19T18:55:07.365Z","390":"2016-01-19T18:55:09.806Z","391":"2016-01-19T19:01:01.057Z","392":"2016-01-19T19:02:04.821Z","393":"2016-01-19T19:03:45.687Z","394":"2016-01-19T19:03:57.951Z","395":"2016-01-19T19:15:17.981Z","396":"2016-01-19T19:27:57.801Z","397":"2016-01-19T22:36:40.221Z","398":"2016-01-19T22:36:51.431Z","399":"2016-01-19T22:37:05.020Z","400":"2016-01-19T22:37:56.892Z","401":"2016-01-19T22:38:35.808Z","402":"2016-01-19T22:38:49.688Z","403":"2016-01-19T22:39:14.476Z","404":"2016-01-19T22:39:33.170Z","405":"2016-01-19T22:39:46.632Z","406":"2016-01-19T22:40:12.527Z","407":"2016-01-19T22:40:38.730Z","408":"2016-01-19T22:41:31.054Z","409":"2016-01-19T22:42:44.285Z","410":"2016-01-19T22:43:00.462Z","411":"2016-01-19T22:43:17.357Z","412":"2016-01-19T22:43:45.459Z","413":"2016-01-19T22:46:09.283Z","414":"2016-01-19T22:47:35.363Z","415":"2016-01-19T22:48:18.953Z","416":"2016-01-19T22:48:31.070Z","417":"2016-01-19T22:49:56.414Z","418":"2016-01-19T22:50:03.708Z","419":"2016-01-19T22:53:55.209Z","420":"2016-01-19T22:54:05.237Z","421":"2016-01-19T22:54:12.792Z","422":"2016-01-19T22:54:33.505Z","423":"2016-01-19T22:55:00.192Z","424":"2016-01-19T22:55:27.291Z","425":"2016-01-19T22:55:41.576Z","426":"2016-01-19T22:56:28.415Z","427":"2016-01-19T22:57:26.007Z","428":"2016-01-19T22:58:16.291Z","429":"2016-01-19T23:00:39.494Z","430":"2016-01-19T23:48:40.464Z","431":"2016-01-19T23:49:28.207Z","432":"2016-01-19T23:49:54.337Z","433":"2016-01-19T23:50:02.010Z","434":"2016-01-19T23:50:06.654Z","435":"2016-01-19T23:50:13.522Z","436":"2016-01-19T23:50:18.731Z","437":"2016-01-19T23:50:23.142Z","438":"2016-01-19T23:53:07.427Z","439":"2016-01-19T23:53:30.562Z","440":"2016-01-20T00:30:33.639Z","441":"2016-01-20T01:57:09.030Z","442":"2016-01-20T02:18:22.021Z","443":"2016-01-20T04:01:44.960Z","444":"2016-01-20T04:46:35.549Z","445":"2016-01-20T04:46:45.541Z","446":"2016-01-20T05:18:22.142Z","447":"2016-01-20T05:18:27.230Z","448":"2016-01-20T05:18:35.530Z","449":"2016-01-20T05:19:30.983Z","450":"2016-01-20T05:20:57.329Z","451":"2016-01-20T05:21:38.050Z","452":"2016-01-20T05:22:25.190Z","453":"2016-01-20T05:24:49.510Z","454":"2016-01-20T20:04:20.648Z","455":"2016-01-20T22:01:18.720Z","456":"2016-01-20T22:01:31.185Z","457":"2016-01-20T22:34:04.182Z","458":"2016-01-20T22:34:14.615Z","459":"2016-01-21T01:33:55.907Z","460":"2016-01-24T05:05:52.769Z","461":"2016-01-24T05:39:42.140Z","462":"2016-01-24T06:20:51.183Z","463":"2016-01-24T06:21:24.867Z","464":"2016-01-24T06:22:01.371Z","465":"2016-01-24T18:10:49.485Z","466":"2016-01-28T05:45:18.451Z","467":"2016-01-29T01:44:14.490Z","468":"2016-01-29T01:44:32.548Z","469":"2016-01-29T01:45:08.887Z","470":"2016-01-29T04:44:33.983Z","471":"2016-01-29T23:02:37.106Z","472":"2016-01-29T23:42:34.485Z","473":"2016-01-29T23:43:03.565Z","474":"2016-01-29T23:43:06.643Z","475":"2016-01-29T23:44:37.821Z","476":"2016-02-24T18:56:42.927Z","477":"2016-02-24T19:29:15.802Z","478":"2016-05-26T20:30:55.352Z","479":"2016-10-03T18:47:40.643Z","480":"2016-10-05T18:15:17.446Z","481":"2016-10-05T18:15:26.342Z","482":"2017-03-21T02:11:20.388Z","483":"2017-05-03T20:27:43.165Z","484":"2017-05-03T21:50:01.454Z","485":"2017-05-05T20:15:49.146Z","486":"2017-05-06T01:36:28.663Z","487":"2017-05-15T12:53:53.103Z","488":"2017-05-15T12:53:59.400Z","489":"2017-05-19T07:01:50.256Z","490":"2017-05-19T07:02:52.538Z","491":"2017-05-19T07:03:47.893Z","492":"2017-05-19T07:03:50.042Z","493":"2017-05-19T10:22:07.287Z","494":"2017-05-19T10:22:10.086Z","495":"2017-05-19T10:22:29.508Z","496":"2017-05-19T15:41:54.014Z","497":"2017-05-21T03:20:18.164Z","498":"2017-06-09T09:22:53.699Z","499":"2017-06-22T09:01:18.058Z","500":"2017-07-18T07:34:46.571Z","501":"2017-07-18T07:36:12.016Z","502":"2017-08-16T04:58:08.519Z","503":"2017-09-13T17:39:41.432Z","504":"2017-09-14T05:34:00.364Z","505":"2017-09-14T12:44:07.487Z","506":"2017-09-14T17:56:23.266Z","507":"2017-09-15T13:55:55.136Z","508":"2017-09-15T13:58:07.688Z","509":"2017-09-15T13:58:14.734Z","510":"2017-09-15T15:12:26.020Z","511":"2017-09-15T15:13:54.010Z","512":"2017-09-16T00:27:32.345Z","513":"2017-09-22T21:49:41.288Z","514":"2017-10-06T04:22:33.578Z","515":"2017-11-02T22:29:17.388Z","516":"2017-11-02T22:38:18.618Z","517":"2017-11-08T06:18:13.735Z","518":"2018-01-02T06:06:05.706Z","519":"2018-01-02T06:06:09.859Z","520":"2018-01-05T13:58:18.805Z","521":"2018-01-05T13:58:49.695Z","522":"2018-01-05T13:59:14.124Z","523":"2018-01-05T13:59:52.835Z","524":"2018-01-11T02:49:09.515Z","525":"2018-01-15T22:51:36.873Z","526":"2018-01-16T00:00:19.150Z","527":"2018-01-22T10:58:07.242Z","528":"2018-01-22T10:59:38.135Z","529":"2018-02-08T13:15:59.078Z","530":"2018-02-09T15:14:57.980Z","531":"2018-02-12T20:08:27.727Z","532":"2018-02-12T20:09:26.020Z","533":"2018-04-03T08:33:58.027Z","534":"2018-04-25T10:06:40.480Z","535":"2018-04-25T10:07:32.932Z","536":"2018-05-03T04:57:24.281Z","537":"2018-05-03T04:58:00.986Z","538":"2018-05-23T07:47:46.864Z","539":"2018-06-17T09:42:30.425Z","540":"2018-12-13T14:24:51.427Z","541":"2019-01-08T12:43:25.736Z","542":"2019-01-08T19:01:04.822Z","543":"2019-03-27T18:44:58.139Z","544":"2019-03-27T18:45:12.653Z"},"user":{"0":"SamLau95","1":"SamLau95","2":"SamLau95","3":"stefanv","4":"SamLau95","5":"cboettig","6":"SamLau95","7":"SamLau95","8":"cboettig","9":"cboettig","10":"cboettig","11":"SamLau95","12":"SamLau95","13":"cboettig","14":"SamLau95","15":"cboettig","16":"SamLau95","17":"cboettig","18":"SamLau95","19":"cboettig","20":"stefanv","21":"cboettig","22":"stefanv","23":"stefanv","24":"cboettig","25":"cboettig","26":"SamLau95","27":"tap2k","28":"tap2k","29":"tap2k","30":"tap2k","31":"SamLau95","32":"tap2k","33":"tap2k","34":"SamLau95","35":"tap2k","36":"tap2k","37":"cboettig","38":"cboettig","39":"stefanv","40":"cboettig","41":"tap2k","42":"henryem","43":"cboettig","44":"henryem","45":"cboettig","46":"henryem","47":"henryem","48":"henryem","49":"henryem","50":"henryem","51":"henryem","52":"henryem","53":"henryem","54":"cboettig","55":"henryem","56":"cboettig","57":"cboettig","58":"stefanv","59":"stefanv","60":"cboettig","61":"cboettig","62":"cboettig","63":"stefanv","64":"stefanv","65":"cboettig","66":"stefanv","67":"cboettig","68":"stefanv","69":"cboettig","70":"cboettig","71":"stefanv","72":"stefanv","73":"cboettig","74":"cboettig","75":"stefanv","76":"stefanv","77":"cboettig","78":"stefanv","79":"cboettig","80":"stefanv","81":"stefanv","82":"stefanv","83":"stefanv","84":"cboettig","85":"stefanv","86":"cboettig","87":"stefanv","88":"stefanv","89":"cboettig","90":"cboettig","91":"stefanv","92":"stefanv","93":"stefanv","94":"cboettig","95":"cboettig","96":"stefanv","97":"stefanv","98":"stefanv","99":"stefanv","100":"cboettig","101":"stefanv","102":"cboettig","103":"cboettig","104":"stefanv","105":"stefanv","106":"stefanv","107":"cboettig","108":"cboettig","109":"stefanv","110":"cboettig","111":"stefanv","112":"cboettig","113":"cboettig","114":"stefanv","115":"SamLau95","116":"cboettig","117":"cboettig","118":"cboettig","119":"choldgraf","120":"choldgraf","121":"choldgraf","122":"choldgraf","123":"choldgraf","124":"cboettig","125":"cboettig","126":"choldgraf","127":"choldgraf","128":"choldgraf","129":"choldgraf","130":"choldgraf","131":"choldgraf","132":"choldgraf","133":"cboettig","134":"cboettig","135":"choldgraf","136":"choldgraf","137":"choldgraf","138":"cboettig","139":"choldgraf","140":"choldgraf","141":"cboettig","142":"cboettig","143":"choldgraf","144":"choldgraf","145":"choldgraf","146":"choldgraf","147":"choldgraf","148":"choldgraf","149":"cboettig","150":"choldgraf","151":"choldgraf","152":"cboettig","153":"choldgraf","154":"choldgraf","155":"choldgraf","156":"choldgraf","157":"choldgraf","158":"choldgraf","159":"cboettig","160":"cboettig","161":"cboettig","162":"SamLau95","163":"SamLau95","164":"choldgraf","165":"choldgraf","166":"choldgraf","167":"SamLau95","168":"cboettig","169":"choldgraf","170":"cboettig","171":"choldgraf","172":"choldgraf","173":"choldgraf","174":"SamLau95","175":"cboettig","176":"choldgraf","177":"choldgraf","178":"choldgraf","179":"choldgraf","180":"SamLau95","181":"SamLau95","182":"SamLau95","183":"choldgraf","184":"choldgraf","185":"choldgraf","186":"choldgraf","187":"cboettig","188":"cboettig","189":"choldgraf","190":"choldgraf","191":"choldgraf","192":"choldgraf","193":"cboettig","194":"cboettig","195":"cboettig","196":"cboettig","197":"choldgraf","198":"cboettig","199":"choldgraf","200":"cboettig","201":"SamLau95","202":"SamLau95","203":"SamLau95","204":"SamLau95","205":"cboettig","206":"SamLau95","207":"SamLau95","208":"choldgraf","209":"SamLau95","210":"choldgraf","211":"SamLau95","212":"SamLau95","213":"choldgraf","214":"choldgraf","215":"cboettig","216":"cboettig","217":"cboettig","218":"choldgraf","219":"choldgraf","220":"SamLau95","221":"cboettig","222":"cboettig","223":"SamLau95","224":"choldgraf","225":"SamLau95","226":"choldgraf","227":"choldgraf","228":"SamLau95","229":"cboettig","230":"henryem","231":"henryem","232":"cboettig","233":"henryem","234":"henryem","235":"henryem","236":"choldgraf","237":"cboettig","238":"henryem","239":"cboettig","240":"cboettig","241":"henryem","242":"cboettig","243":"cboettig","244":"henryem","245":"henryem","246":"henryem","247":"cboettig","248":"henryem","249":"henryem","250":"henryem","251":"cboettig","252":"cboettig","253":"cboettig","254":"henryem","255":"choldgraf","256":"SamLau95","257":"henryem","258":"choldgraf","259":"choldgraf","260":"choldgraf","261":"choldgraf","262":"SamLau95","263":"SamLau95","264":"choldgraf","265":"SamLau95","266":"SamLau95","267":"SamLau95","268":"SamLau95","269":"choldgraf","270":"choldgraf","271":"choldgraf","272":"choldgraf","273":"choldgraf","274":"SamLau95","275":"SamLau95","276":"SamLau95","277":"choldgraf","278":"choldgraf","279":"choldgraf","280":"SamLau95","281":"SamLau95","282":"choldgraf","283":"choldgraf","284":"choldgraf","285":"choldgraf","286":"choldgraf","287":"SamLau95","288":"SamLau95","289":"SamLau95","290":"choldgraf","291":"cboettig","292":"cboettig","293":"cboettig","294":"cboettig","295":"henryem","296":"henryem","297":"henryem","298":"henryem","299":"henryem","300":"choldgraf","301":"choldgraf","302":"SamLau95","303":"SamLau95","304":"cboettig","305":"henryem","306":"SamLau95","307":"SamLau95","308":"cboettig","309":"cboettig","310":"cboettig","311":"SamLau95","312":"cboettig","313":"cboettig","314":"SamLau95","315":"henryem","316":"choldgraf","317":"choldgraf","318":"choldgraf","319":"SamLau95","320":"SamLau95","321":"cboettig","322":"cboettig","323":"SamLau95","324":"cboettig","325":"SamLau95","326":"SamLau95","327":"SamLau95","328":"cboettig","329":"cboettig","330":"SamLau95","331":"SamLau95","332":"SamLau95","333":"SamLau95","334":"cboettig","335":"cboettig","336":"cboettig","337":"SamLau95","338":"choldgraf","339":"cboettig","340":"choldgraf","341":"SamLau95","342":"choldgraf","343":"choldgraf","344":"SamLau95","345":"SamLau95","346":"choldgraf","347":"SamLau95","348":"choldgraf","349":"SamLau95","350":"clcarson","351":"choldgraf","352":"clcarson","353":"choldgraf","354":"choldgraf","355":"choldgraf","356":"choldgraf","357":"choldgraf","358":"choldgraf","359":"clcarson","360":"clcarson","361":"choldgraf","362":"cboettig","363":"SamLau95","364":"SamLau95","365":"cboettig","366":"cboettig","367":"cboettig","368":"SamLau95","369":"cboettig","370":"SamLau95","371":"cboettig","372":"SamLau95","373":"SamLau95","374":"cboettig","375":"SamLau95","376":"SamLau95","377":"cboettig","378":"cboettig","379":"SamLau95","380":"cboettig","381":"SamLau95","382":"cboettig","383":"SamLau95","384":"SamLau95","385":"SamLau95","386":"SamLau95","387":"cboettig","388":"cboettig","389":"SamLau95","390":"SamLau95","391":"AndrejGitHub","392":"AndrejGitHub","393":"SamLau95","394":"SamLau95","395":"AndrejGitHub","396":"SamLau95","397":"choldgraf","398":"choldgraf","399":"choldgraf","400":"cboettig","401":"choldgraf","402":"choldgraf","403":"cboettig","404":"cboettig","405":"choldgraf","406":"cboettig","407":"choldgraf","408":"cboettig","409":"cboettig","410":"choldgraf","411":"cboettig","412":"choldgraf","413":"choldgraf","414":"cboettig","415":"choldgraf","416":"choldgraf","417":"choldgraf","418":"choldgraf","419":"cboettig","420":"choldgraf","421":"choldgraf","422":"choldgraf","423":"cboettig","424":"choldgraf","425":"choldgraf","426":"cboettig","427":"choldgraf","428":"cboettig","429":"choldgraf","430":"SamLau95","431":"SamLau95","432":"choldgraf","433":"choldgraf","434":"choldgraf","435":"SamLau95","436":"SamLau95","437":"SamLau95","438":"choldgraf","439":"choldgraf","440":"anthonysuen","441":"henryem","442":"SamLau95","443":"choldgraf","444":"SamLau95","445":"SamLau95","446":"choldgraf","447":"choldgraf","448":"choldgraf","449":"SamLau95","450":"choldgraf","451":"SamLau95","452":"choldgraf","453":"SamLau95","454":"choldgraf","455":"choldgraf","456":"choldgraf","457":"SamLau95","458":"SamLau95","459":"choldgraf","460":"elaine84","461":"choldgraf","462":"SamLau95","463":"SamLau95","464":"SamLau95","465":"elaine84","466":"elaine84","467":"anthonysuen","468":"anthonysuen","469":"anthonysuen","470":"elaine84","471":"cboettig","472":"choldgraf","473":"choldgraf","474":"choldgraf","475":"cboettig","476":"codexdelta","477":"henryem","478":"cpoptic","479":"skynode","480":"choldgraf","481":"choldgraf","482":"pminkov","483":"FlyElephant-M31","484":"ryanlovett","485":"choldgraf","486":"Adrianzo","487":"ioyusuke_twitter","488":"ioyusuke_twitter","489":"KokuKUSIAKU","490":"KokuKUSIAKU","491":"KokuKUSIAKU","492":"KokuKUSIAKU","493":"pomodoros","494":"pomodoros","495":"pomodoros","496":"KokuKUSIAKU","497":"punitaojha","498":"blink1217","499":"bhaveshAn","500":"990InziyaD","501":"990InziyaD","502":"captaincrunch21","503":"MikCrillz_twitter","504":"Pasquinell","505":"souravsingh","506":"GrydNotebooks_twitter","507":"Pasquinell","508":"Pasquinell","509":"Pasquinell","510":"GrydNotebooks_twitter","511":"GrydNotebooks_twitter","512":"Pasquinell","513":"Assencastrillo","514":"990InziyaD","515":"des-augustine","516":"des-augustine","517":"azizasm","518":"akosuadenell","519":"akosuadenell","520":"KokuKUSIAKU","521":"KokuKUSIAKU","522":"KokuKUSIAKU","523":"KokuKUSIAKU","524":"mihinsumaria","525":"KokuKUSIAKU","526":"mihinsumaria","527":"dataskilled","528":"dataskilled","529":"a1Gupta","530":"codexdelta","531":"NikitaMandhani_twitter","532":"NikitaMandhani_twitter","533":"naaioa","534":"aoayoola_twitter","535":"aoayoola_twitter","536":"renatomarinho","537":"renatomarinho","538":"GitTorres_twitter","539":"renatomarinho","540":"rballiwal","541":"Prerna611","542":"gautam1858","543":"SadiaAman","544":"SadiaAman"},"message.1":{"0":"hello world! this is the chat room for the datascience library","1":"feel free to ping me or the other devs here","2":"i hope this room serves as a useful alternative to email for simpler tasks for this library","3":"Hey, everyone! ","4":"in the ideal case, this room will lower the overhead of asking questions for the connector faculty","5":"Hey Sam, thanks for setting this up (and for your earlier answers).","6":"my pleasure! hope this is helpful","7":"ping me anytime and i\\u2019ll do my best to respond","8":"Hi folks -- where does that `tabledemos` repo that David Culler mentioned on the mailing list live? I'm not seeing it in github.com\/dsten","9":"Aha, looks like it's https:\/\/github.com\/deculler\/TableDemos I believe.","10":"Hmm, don't seem to be able to paste into the jupyter terminal.  Looks like that was a known issue https:\/\/github.com\/jupyter\/notebook\/issues\/104 but since resolved? ","11":"@cboettig looks like david has a bunch of IPython notebooks in his repo","12":"to open those notebooks, you can go to https:\/\/ds8.berkeley.edu\/hub\/home and upload them","13":"@SamLau95 thanks; I've just been using git through the Jupyter terminal to get things over.  nice, but the lack of copy-paste makes that a bit of a nuisance though","14":"@cboettig i don\\u2019t think i\\u2019m familiar with the Jupyter terminal. to clarify, you have the `.ipynb` files on your local machine and want to run the notebooks, right?\\n\\nif you\\u2019re okay with running the notebooks on ds8, the method i described is the easiest way to do so.\\n\\nif you want to run them on your own computer, you\\u2019ll have to run `ipython notebook` in your terminal to start a jupyter server locally to view them","15":"@SamLau95 From the Jupyter homepage there's an option to open a new Python 3 notebook, and under it an option to open a terminal which runs in the browser.  It's really convenient since I can then move my notebooks between my local machine, github, the hosted ds8.berkeley.edu site; seems to be pretty much a fully functional bash terminal except for the lack of copy-paste which is a bit of a nuisance.  ","16":"@cboettig ah i see, this is running on your local machine (eg. localhost)? it looks like if you open a terminal window and run\\n\\n    git clone https:\/\/github.com\/deculler\/TableDemos\\n\\nyou can switch back to the \\u2018Files\\u2019 tab and open the notebooks locally","17":"nope, terminal is running on ds8.berkeley.edu instance (though also works locally)","18":"ah, gotcha. that command should work both on ds8 and locally","19":"@SamLau95 Any recommendation for a style guide for python?  In particular, looking for clarification on when to use the notation `x.method()` vs the notation `method(x)`","20":"Is this specifically wrt numpy? ","21":"anything really, it's all pretty new to me.  does style differ wrt different modules?","22":"I think numpy has both class and normal methods available due to history, but in most other packages you have only one or the other. ","23":"Most of the time, we try to use Python's rich containers in combination with functions. Only when there's a lot of state being dragged around the system do we start looking at objects even. ","24":"that seems like a good starting point.  so just to be clear, you call `method(object)` function notation, and `object.method` to be object notation?","25":"it seems that plotting starts off with method notation in the textbook, but switch later into object notation?","26":"@cboettig do you have an example? we use stuff like\\n\\n    foo_table.hist()\\n\\nquite a bit, but when we needed plotting functionality that the table didn\\u2019t provide we switched to using matplotlib directly instead (the `plots` variable). for example, in http:\/\/data8.org\/text\/4_prediction.html#correlation we make a scatter plot using\\n\\n    plots.scatter(ht_pw['mat_ht'], ht_pw['mat_pw'], s=5, color='gold')\\n    plots.xlabel('height (inches)')\\n    plots.ylabel('pregnancy weight (pounds)\\u2019)\\n\\nthis is because the table class didn\\u2019t provide the functionality we wanted in order to make these plots; we typically try to use the Table class as much as possible","27":"Do I need to do anything special to show a Marker once Ive called the function?","28":"for maps","29":"basically the functionality Im looking for is to add circles one by one and then show the resulting map. possible?","30":"also - is there a way to change the datatype of a column? I need the lat, long values to be treated as floats for Circle.map to work","31":"@tap2k i believe they\\u2019ll show up automatically \\u2014 checkout david wagner\\u2019s lecture on privacy: http:\/\/data8.org\/text\/slides\/lec10.pdf\\n\\ni think what you want has been done before\\n\\nif you have a table called `foo_table` and a column called `x` with integers, you can change the type to floats with `Table.apply` like:\\n\\n    foo_table.apply(float, 'x')\\n","32":"thanks! helpful","33":"when I use the Circle.map or Marker.map functions how do I set the map center and zoom?","34":"not super sure myself \\u2014 @papajohn @alvinwan , do you know how?","35":"figured that out","36":"one issue I had is that Circle or Marker.map is not the last expression in the cell the map doesnt show. this makes it hard to wrap in a function unless someone has a workaround","37":"Curious if any connectors are touching on sql databases.  Just need some very simple imports from postgres, doesn't look like `psycopg2` is available.","38":"Guess I could just export the data to csv for them, but torn between wanting to give a light exposure to databases vs just streamlining things","39":"@cboettig Is postgres the system you have to use?  Because Python has built in sqlite, if you can port the DB to that.","40":"yeah, in this particular case data is already in postgres, though pedagogically maybe sqlite makes more sense then","41":"ok got it - chalk it up to the stupid question dept","42":"@cboettig Tables support a lot of SQL-like things (join, group by, where) that they learn about in the first month or so of the base class.   Could be easier to introduce database operations that way, without a new language.  (Sorry if you're already aware of that!)","43":"@henryem right, yes, and I'd probably stick with doing most of these manipulations in `tables` (though I'm still learning those myself!).  More just wondering about it as a data ingest step -- I often see students struggle with importing data from databases even when they are already well equipped to manipulate the data within a given framework once the data are imported.  Teaching all that is of course beyond the scope of what I can get into a connector, but just wondering if it's worth giving some glimpse of data read\/parse command that isn't `csv`.  More a pedagogy issue than a technical one I suppose, and I'm still on the fence.","44":"Ah, I see.  That sounds cool.","45":"Hmm, struggling to figure out the best python way to do an operation that is pretty simple in R's `dplyr`.... I have a table in which one column is a grouping factor, so for each group I want to apply a summary function.  Here's my R version: https:\/\/gist.github.com\/cboettig\/7ce0f311daa428b023f9","46":"I'm not 100% familiar with the dplyr syntax, but I think you would say:\\nvalues.select(['assessid', 'ssb']).group('assessid', collapsed)","47":"where collapsed is","48":"def collapsed(an_array):\\n  return an_array[-1] < 0.1*max(an_array)","49":"the main difference, as far as I can tell, is that the `tables` group() will apply the summary function to every column, whereas group_by lets you apply it only to some columns","50":"though I'm not sure what happens to the columns that are not summarized","51":"in dplyr's group_by, I mean","52":"anyway, the .select(['assessid', 'ssb']) pares down the columns to just the grouping factor and the column you wanted to summarize","53":"if you want to summarize several columns in different ways (or the same column in multiple ways) it takes several steps","54":"@henryem Thanks!  That looks very promising --  However, I'm a puzzled why I get different results in R vs python now!  how is `max` handling the `nan` values in python?","55":"Ah, it propagates them, so it will return `nan`.  Looks like there are two options: for `max` in particular there is `nanmax`, which ignores `nan`s.  In general you could use `np.ma.masked_array(my_array, np.isnan(my_array))` to get a view of `my_array` that doesn't include that `nan`s, and then do whatever computation you wanted on that view.","56":"thanks, that sounds handy.  Curiously I don't get any nans in the output from the original python version, but I get a different set of `True\/False` values in the new column... ","57":"hmm, looks like I just get an error on calling `np.ma.masked_array` on a datascience `Table` object","58":"I\\u2019d steer clear of masked arrays unless you really need them.It\\u2019s another layer of complexity on an already complex operation.","59":"Yes, that almost certainly won\\u2019t work.  NumPy does not know anything about Tables.","60":"right, okay, will avoid that.  Meanwhile still puzzled by the handling of nas and the different results between R and python here.","61":"e.g. starting from the gist, https:\/\/gist.github.com\/cboettig\/7ce0f311daa428b023f9 ,  I see the group`x = values.select([\\assessid\\ \\ssb\\]).where(\\assessid\\ \\AFSC-BKINGCRABPI-1960-2008-JENSEN\\)\\ncollapsed(x[\\ssb\\])` returns `False`","62":"note that `x` has `nan` values, so I'd have expected it to return `nan`.  And in R, when dropping nans, it returns true.","63":"Let me install R quickly and take a look at what you\\u2019re expecting","64":"What is \\u201ccollapsed\\u201d supposed to do?  Check whether the last element is smalled than 0.1 * max of the array, ignoring nans?","65":"yup","66":"Try replacing ``max(an_array)`` with ``np.nanmax(an_array)``","67":"throws error","68":"Can you show me the error?","69":"https:\/\/github.com\/boettiger-lab\/espm-88b\/blob\/master\/modules\/fish\/fish.ipynb","70":"(think the error shows up there, from `In [14]`)","71":"Hah, I did not expect an_array to be \\u201ca_list\\u201d :)","72":"I\\u2019ll take a quick look at what\\u2019s happening underneath the hood","73":"yeah, guess columns in Tables are `list` objects?  I'm still a bit foggy on the difference between a list and an array.  is an `array` a numpy object? for doubles only?","74":"and thanks much for the help!","75":"I\\u2019ve just tried it with the latest version of datascience and it seems to work OK for me","76":"Are you using the same dataset as in the gist?","77":"yup","78":"So, it looks like there\\u2019s at least one column with all NaNs","79":"is the latest version what is on ds8.berkeley.edu?  I could switch to that; I'm running Juypter from the jupyter\/datascience-notebook docker image, just did a `pip install datascience`.... not quite sure how to check my module version info","80":"Ah, I\\u2019m running the latest dev version, 0.3.dev21","81":"You can check the version with:","82":"``import datascience as ds\\nds.__version__\\n``","83":"At least, you can do that in the latest version ;)","84":"errors for me. guess that confirms I have an earlier version","85":"Also, in this version \\u201can_array\\u201d is an array","86":"that's good","87":"You should be able to pip install the latest version directly from git, but I guess it is important for you that your students can make it work, and I presume they\\u2019ll be running the latest released version.","88":"Perhaps this is a good time to release a new version\\u2014there\\u2019s been quite a few bug-fixes etc.","89":"looks like the berkeley server isn't up to date either, though I'm sure it will be by spring.  ","90":"hmm, how do  I tell pip to install from git?","91":"Let me find the magic incantation","92":"pip install git\u822b\ufffd:\/\/github.com\/dsten\/datascience.git","93":"Untested","94":":thumbsup:  seems to be working","95":"looks like I'm missing some dependencies.  apt-get time","96":"You\\u2019ll need:\\n```\\nfolium\\nsphinx\\nnumpy\\nscipy\\nmatplotlib\\npandas\\nIPython\\n```","97":"I\\u2019d apt-get numpy, scipy, matplotlib, and pandas, and pip install the rest","98":"IPython should be replaced by ``jupyter``","99":"Unless you are running anaconda, in which case you should prefer ``conda install package_name``","100":"Looks like I'm on conda.  I'm on this build: https:\/\/github.com\/jupyter\/docker-stacks\/blob\/master\/datascience-notebook\/Dockerfile","101":"@cboettig I\\u2019m trying to test your R snippet.  How do I install dplyr?","102":"`install.packages(\\dplyr\\)`","103":"(From within R)","104":"In that case, you want to do ``conda install numpy scipy matplotlib pandas jupyter``","105":"and ``sphinx``","106":"and then ``pip install folium``","107":"hmm, conda installs worked, installing from git still failing I think","108":"complaining it cannot find blas libraries, which seems unlikely...","109":"Sorry, can you paste the error message here?","110":"@stefanv  are you in BIDS? maybe I can swing by","111":"Sure, that\\u2019d be good!","112":"Hi folks, silly question, looking how to count the number of re-occuring values in a column of a table","113":"e.g. could convert to `table.to_df()['column'].value_counts()`","114":"I haven\\u2019t tested this, but I guess something like ``len(np.unique(table[\\u2018column\\u2019])))`` would also work","115":"@cboettig you could do\\n\\n```\\nfrom collections import Counter\\nCounter(table['column'])\\n```","116":"@SamLau95 thanks for the `Counter` idea.  Another silly question: getting strange parsing errors from `ds.Table.read_table` on a local file, but works fine when I read the same file from a URL...","117":"e.g. see https:\/\/github.com\/dsten\/ecology-connector\/blob\/030eb47fb172e9fc0bc1e9cbb31a27f71f2c14ba\/extinction\/extinction.ipynb","118":"Unrelated to the previous question, but I continually trip up with NaNs in python.  I've gotten familiar with `np.isnan`, but it seems to only know about `nan` for numeric values.  Booleans\/logical data and strings\/factor data can be missing too! but `np.isnan(\\string\\)` throws and error... How is one supposed to deal with this?","119":"@cboettig that read_table error looks to be related to string encoding rather than something internal to Table. It looks like Table is actually calling Pandas under the hood.","120":"It looks like all the *args and **kwargs passed to read_table are in turn passed to the pandas read function","121":"```python\\nencoding : string, default None\\n    Encoding to use for UTF when reading\/writing (ex. 'utf-8'). `List of Python\\n    standard encodings\\n    <https:\/\/docs.python.org\/3\/library\/codecs.html#standard-encodings>`_\\n```","122":"that's a kw argument in the pandas `read_csv` function...I wonder if you chose a different encoding if you could get past the error","123":"so you'd do `ds.read_table(my_file, encoding='magical_bugfree_encoding')`","124":"Hmm,  wonder why it's not necessary to mess with that coming from the web version (and @deculler's examples in TableDemos also read from file without manually handling encoding..)  Maybe those .csvs are funny somehow, but nothing obvious to me.","125":"Can you replicate the error I'm getting there?","126":"hmm, lemme see what I can figure out","127":"It looks like the file is encoded in `latin-1` rather than `utf-8`","128":"`extinct = ds.Table.read_table(\\data\/extinct.csv\\ encoding='latin-1')`","129":"Try that","130":"it tells pandas to change how it parses the bytecode depending on the encoding you supply","131":"when you read from a URL, there must be some intelligent stuff happening under the hood that infers this","132":"I feel like these are the kind of problems that make people hate coding :P","133":"ha, thanks! yeah, that works.  ","134":"I suspect the html version is actually somehow getting converted to utf-8","135":"yeah that could be","136":"but in general if you get an error along these lines, it's often an encoding problem","137":"btw, SO answer I used for this was here: http:\/\/stackoverflow.com\/questions\/5552555\/unicodedecodeerror-invalid-continuation-byte","138":"wonder if I can do some operation on the file itself (e.g. outside of python) to fix the encoding of that file?  Never quite had a good grasp of where encodings are set; I always thought they were more a property of assumptions made by the parser about the file than a filetype property....","139":"well, in python I believe you can change the string encodings manually","140":"though it's something that has generally confused me over the years","141":"Right.  I guess there must be a character somewhere in that csv file that is unique to latin-1, but I don't spot it","142":"okay, well I can have vim rewrite the encoding... interesting to see the git diff to see what changes:  https:\/\/github.com\/dsten\/ecology-connector\/commit\/aed261bf5a8b0aa12ed86fa800c628955816dd1f Makes the non-UTF8 characters obvious...","143":"interesting","144":"looks like this could be used to detect the character encodings: https:\/\/pypi.python.org\/pypi\/chardet","145":"and then for encoding there may also be this: http:\/\/pandas.pydata.org\/pandas-docs\/version\/0.17.0\/generated\/pandas.Series.str.encode.html","146":"e.g.: df['Kingdom'].str.encode('utf-8')","147":"so you could loop through your columns, and if it's a column of strings change the encoding to utf-8","148":"then write back to disk","149":"Cool.  Though for the students I think it's best if I can give them utf-8 encoded data whenever possible; like you say, it's kind of the dark underbelly, I'm sure no one actually enjoys battling string encodings...","150":"oh definitely","151":"I meant just for you\/me","152":"right","153":"[![blob](https:\/\/files.gitter.im\/dsten\/datascience\/Ljj8\/thumb\/blob.png)](https:\/\/files.gitter.im\/dsten\/datascience\/Ljj8\/blob)","154":"e.g. that seems to work properly","155":"and if I write that dataframe to file, I can now read it back in like before","156":"but w\/o the extra 'encoding' flag","157":"```python\\ndf = extinct.to_df()\\nfor col, vals in df.iteritems():\\n    try:\\n        df.loc[:, col] = vals.str.encode('utf-8')      \\n    except:\\n        print(col)\\ndf.to_csv('.\/test.csv')\\nds.Table.read_table('.\/test.csv')\\n```","158":"there's the code to do it","159":"@choldgraf @SamLau95 Hmm, somehow I can no longer do an apply with a function that takes multiple arguments:","160":"```py\\nletter = ['a', 'b', 'c', 'z']\\ncount = [9, 3, 3, 1]\\npoints = [1, 2, 2, 10]\\n\\nt = Table([letter, count, points], ['letter', 'count', 'points'])\\n\\n# Works\\nt.apply(lambda x: x * x, 'count')\\n\\n## throws error\\nt.apply(lambda x, y: x * y, ['count', 'points'])\\n\\n```","161":"Error is: \\n\\n```py\\n\\n---------------------------------------------------------------------------\\nTypeError                                 Traceback (most recent call last)\\n<ipython-input-7-8fe518b79c55> in <module>()\\n      7 t.apply(lambda x: x * x, 'count')\\n      8 \\n----> 9 t.apply(lambda x, y: x * y, ['count', 'points'])\\n     10 \\n     11 #array([ 9,  6,  6, 10])\\n\\n\/usr\/local\/lib\/python3.4\/dist-packages\/datascience\/tables.py in apply(self, fn, column_label)\\n    447         \\\\\\Returns an array where fn is applied to each element\\n    448         of a specified column.\\\\\\\\n--> 449         return np.array([fn(v) for v in self[column_label]])\\n    450 \\n    451     ############\\n\\n\/usr\/local\/lib\/python3.4\/dist-packages\/datascience\/tables.py in __getitem__(self, label)\\n    352 \\n    353     def __getitem__(self, label):\\n--> 354         return self.values(label)\\n    355 \\n    356     def __setitem__(self, label, values):\\n\\n\/usr\/local\/lib\/python3.4\/dist-packages\/datascience\/tables.py in values(self, label)\\n    438             An instance of ``numpy.array``.\\n    439         \\\\\\\\n--> 440         return self._columns[label]\\n    441 \\n    442     def column_index(self, column_label):\\n\\nTypeError: unhashable type: 'list'\\n\\n```","162":"looks like you might have an old version of the package @cboettig ","163":"do you have 0.3.dev21?","164":"I can confirm that @cboettig's code works on the latest version for me","165":"Also - quick quibble, but I often forget to open this package with python 3 sourced, and the error message you get for doing so is a bit cryptic (it just throws an import error)","166":"think we could just put:\\n```py\\nimport sys\\nif sys.version_info < (3, 0):\\n    raise ValueError('This package requires python >= 3.0')\\n```\\nat the root `__init__.py`?","167":"ah, that\\u2019s a good idea","168":"@SamLau95   yup, running on `ds8.berkeley.edu` and it says `'0.3.dev21'`\\n","169":"@SamLau95 want me to make a PR?","170":"It's very strange.  I have in my git history successful runs of the notebook with the very same code that works with multiple columns, so I'm not sure why it is failing for me now.","171":"hmm, that is weird - and it works for me","172":"problem is I can't really debug it w\/o the code breaking for me","173":"maybe just to be sure you can pull the latest changes from the git repo","174":"@choldgraf that\\u2019d be great","175":"You can see the error here in context, if that helps: https:\/\/github.com\/dsten\/ecology-connector\/blob\/0947c5464e76998d135babdb92c5321e8ac9cc76\/climate\/climate.ipynb","176":"@SamLau95 hrmmm, actually it might be more complicated","177":"because it looks like some of the changes actually result in a syntaxerror in 2.7","178":"so it won't get to the point that it's running any code","179":"perhaps a better option would be to prevent it from installing on any versions of python < 3.0?","180":"ah i see","181":"would you like to look into that?","182":"if not, feel free to make an issue","183":"@cboettig so it looks like the problem is that the function is passing a list of column names to the table. E.g., this returns the same error you get:\\n```py\\nt[['letter', 'count', 'points']]\\n```","184":"and it looks like that function has indeed been updated. Here's the new code for it: `np.array([fn(*[self.take(i)[col][0] for col in column_label]) for i in range(self.num_rows)])`","185":"note that there is another `for` loop: `for col in column_label` so now it's passing each column that you give individually, that way it never tries to pass a list","186":"so try pulling and it should work","187":"interesting...   so somehow I am running an old version of datascience even though it says `0.3.dev21` ?","188":"I'm running this on `ds8.berkeley.edu`, so I have no ability to install there, but let me try locally.  What version are you on?","189":"ah interesting","190":"same version","191":"but w\/o knowing much about how the repo is organized, that's probably just the current dev branch","192":"and presumably the version of that code being used in ds8 is a few commits behind the branch on github","193":"maybe version number didn't get bumped;","194":"right.","195":"um, so can you reproduce the error on your ds8.berkeley.edu account?","196":"(and I'll try pulling and installing locally)","197":"I.......haven't figured that out yet :)","198":"hehe, what happens when you go to ds8.berkeley.edu and try to log in with your berkeley google account?","199":"ooo it works","200":"nice","201":"oh, you know what?","202":"it\\u2019s possible that we haven\\u2019t pushed a new version to the servers","203":"i mean","204":"we haven\\u2019t incremented the version number after making that change","205":"right","206":"blah, that\\u2019s a pain","207":"maybe there\\u2019s a way to locally install the datascience package from the github repo on ds8","208":"yeah I get the error on the ds8 servers","209":"that makes sense","210":"I mean, could you theoretically just glone the datascience repo using a terminal in the ipyntbk and then make install from there?","211":"yeah, that might work","212":"i have to bother ryan manually to update the package version on the ds8 server so it\\u2019s not something i can take care of right this minute","213":"hmmm, I just tried cloning  make install and it threw a permissions error","214":"I guess I could try to specify a folder w\/in my home directory, but now we are getting into the territory of \\too much of a hassle to be a solution for instructors\\ I think","215":"Okay, well at least my code is running successfully after pulling the latest github copy and running make","216":"(I'm running the the jupyter\/datascience-notebook docker image, so I just `docker exec`'d in and ran `make` as root, so no permissions error for me ;-) )","217":"So once the update hits the ds8 server, my issue should be resolved.  though bumping the version would be good too.","218":"cool","219":"@SamLau95 PR made for the python3 check","220":"merged! thanks","221":"@choldgraf Another quick puzzle for you: ","222":"```py\\nnasa_temp = \\http:\/\/climate.nasa.gov\/system\/internal_resources\/details\/original\/647_Global_Temperature_Data_File.txt\\\\ntemp = ds.Table.read_table(nasa_temp, skiprows=range(4), na_values = \\*\\ delim_whitespace=True, \\n                    names=[\\Year\\ \\Annual\\ \\FiveYear\\])\\n\\n## Pandas plots this just fine\\ntemp.to_df().plot()\\n\\n## datascience not so much\\ntemp.plot(\\Year\\)\\nplt.plot(temp[\\Year\\], temp[\\Annual\\])\\n\\n```\\nSome error about getting a string when it expects a float.  I still haven't made sense of the idea that a column in Tables need not have a consistent type.  Is that really the case? why?\\n\\n\\n","223":"@cboettig this is what i get from the last 5 rows of the `temp` table:\\n\\n```\\nYear                                 | Annual | FiveYear\\n2012                                 | 0.63   | 0.67\\n2013                                 | 0.66   | nan\\n2014                                 | 0.75   | nan\\n2015                                 | nan    | nan\\n------------------------------------ | nan    | nan\\n```\\n\\nlooks like you have some missing values and a string, too","224":"Yeah it looks like that big ------- is the problem. You could always drop the last row, aka this works:\\n```py\\ntemp = temp.take(range(temp.num_rows-1))\\ntemp.plot('Year')\\n```","225":"or, for a slightly more succinct first line:\\n\\n```\\ntemp = temp.take[:-1]\\n```","226":"or you could write a function that does \\for each row in this column, try to cast it as an integer. If it errors, return np.nan. Then you could make one more pass and drop any rows == nan","227":"oo @SamLau95 thanks for the tip, didn't know that Table `take` behaves like pandas `iloc`","228":"yup, it was done in #120","229":"@SamLau95 @choldgraf Really nice, thanks for catching that.  Also good to know that `take` can use `[]` like `iloc`, pretty cool; but I agree with the thread in that PR that having both notations is confusing to a beginner; I've already made that mistake on `iloc` before.  Will have to decide what is better to teach the students.","230":"FYI, for the main course, we're talking about not using square bracket indexing at all, at least for the first few weeks","231":"Since that was very confusing for students last semester","232":"@henryem thanks, good to know!  Then I probably shouldn't introduce square brackets on my first lesson!  I suppose I should just pre-clean the data so none of that is necessary; though I really do hope to convey some sense of \\where data comes from\\ in my area, even if it does mean teaching a little bit of simple data cleaning...","233":"We'll still do indexing, just with method calls instead of []","234":"Also, FYI, they'll see arrays in week 2 and tables in week 3","235":"So if you'll use that stuff earlier then you'll get to teach them however you want","236":"I'm \ufffd on using methods associated with Table objects first...I think one of the main confusions of pandas is the fact that there are so many ways to do the same thing","237":"@henryem Thanks for the heads up about how material will be introduced; that's really helpful (particularly for the first few weeks). Sounds like things might be slightly different than how they were taught in the Fall, at least in the first few weeks then?  I'm trying to avoid being needlessly inconsistent with what is taught in the class; (hopefully the students can just tell me the way they have learned if I start doing something unorthodox).  Is this description flushed out any further now (at least for the first few weeks)?  Or is data8.org and data8.org\/text still the best guide for that?","238":"This is just from conversations with John last week, but yes, we're hoping to shave some of the complicated syntax.  I don't think there will be huge changes.  The only thing written up, afaik, is a rough draft of lab 1 I'm working on, though John might be working on the text.  I'm afk at the moment but I definitely agree we should pin down the early curriculum asap.","239":"e.g. one question I have right now is whether I should start with a module on \\simulation\\ (which puts of Tables but needs both loops & function declarations) or a module starting with \\real data\\ that means Tables from the get-go.  ","240":"@SamLau95 Any update on when the ds8.berkeley.edu site might get the newer version of `datascience` Tables?","241":"Tables will still come before function declarations and for loops in the main class, I think","242":"@henryem good, that makes sense, I'll start with manipulating real data in Tables then; hopefully will reinforce rather than confuse what they learn in the main class...  Finding it hard already to write an intro lesson without `[]` subsetting...","243":"for instance, which plot for a timeseries is less confusing \/ most consistent with the core class:  \\n\\n```py\\n## Tables method: (needs to select column first otherwise it still plots all columns!?)\\nco2.select([\\decimal.date\\ \\average\\]).plot(\\decimal.date\\)\\n\\n## matplotlib style, also requires [] subsetting\\nplt.plot(co2[\\decimal.date\\], co2[\\average\\])\\n```","244":"The first one","245":"Though we'll still do everything you can do with [] indexing, except we'll use method calls instead","246":"It's purely a syntactic simplification","247":"cool.  It would be nice if `Tables.plot` were as intelligent as `pandas.plot` for these line objects though","248":"I don't know if the get-a-column method exists yet","249":"Yeah that's not my department :-\/","250":"What's the problem in this case?","251":"no worries.  the data.frame we read in has extra columns, and the Tables.plot method tries to plot all columns as additional lines in different colors if we don't select them out.  ","252":"Pandas syntax is more consise, it would just be `co2.plot(\\decimal.date\\ \\average\\)` without the repetition needed in the `datascience` call","253":"but that's all pretty minor.  I think you've got me on the right path by focusing on the `datascience` method calls and trying to avoid `[]` indexing... it does get tricky very fast though; keep wanting to introduce pandas functions here & there where `datascience` doesn't have an easy way (that I know of) to do what  I need.  (and I'm just learning python as I go myself; coming from R mostly)","254":"I think there's nothing wrong with using Pandas or matplotlib stuff here and there if it's substantially easier.  For example, there's currently no way to label a plot without using matplotlib functions, so we did that in labs.  I think some degree of magical thinking about library functions is inevitable anyway.","255":"happy new year data science people!","256":"@cboettig @henryem to get column values from a table without brackets, you can use\\n\\n```\\ntable.values(\\u2018my_column\\u2019)\\n```","257":"Cool, thanks","258":"hey folks - how up-to-date will the pip version of this class be?","259":"in previous pip builds there have been some nasty bugs that had already been fixed on the dev branch, but pip wasn't updated","260":"I'm trying to figure out which I should tell an instructor to use...`git clone` or `pip`. They're not super familiar with the shell\/git\/etc so I'd prefer pip, but not if it's going to lag considerably behind the dev branch","261":"@SamLau95 maybe you have thoughts?","262":"@choldgraf last semester we were actively developing the package and were releasing new versions every week because oftentimes students needed the fixes to complete labs. i think using the pip version for class should be fine if for no other reason than parity between instructor \/ student code output","263":"right now releasing a new version has a lot of friction (depends on both john to update the Pypi version and ryan to update  push the dockerfile) which is why it\\u2019s been delayed so long. i\\u2019m actually waiting on john to push a bunch of changes the pypi at the moment","264":"ok cool - so you think the pip version is stable enough to use primarily...I'll pass that along to instructors","265":"yup, thanks for that :)","266":"is there a place where this conversation is happening? i\\u2019d be willing to listen in and answer questions directly if needed","267":"i think i\\u2019d like to push out a written, consolidated, collaborative guide of how an instructor can be productive in creating material using juypter and datascience","268":" how can i start contributing to open source","269":"there's no consolidated place for discussion, more just little conversations here and there","270":"I think a guide will be useful, especially for some instructors who have no background at all in computing","271":"E.g., I've been writing up a short post on how to do scientific computing in windows","272":"because somebody was confused about people saying \\bring up a terminal and type XXX\\ which didn't work in windows","273":"but it sounds like having some materials for instructors will be almost just as important (at least early on) as material for students...at least if we want to attract instructors who don't already do scientific computing in python","274":"gotcha. personally i lean towards helping instructors without background in scientific computing since i think long-term that\\u2019ll result in more diversity in terms of courses and students addressed","275":"maybe i\\u2019ll just throw up a github page on the dsten org with some info","276":"what are some things that are absolutely necessary for a page like that?","277":"that's a good question, I think after the previous and this iteration it'll be clearer what the main pain points are","278":"but it might be worth a brainstorm","279":"either way, we should be documenting what people have questions about","280":"agreed","281":"are there some particular topics that would be the best bang for the buck for instructors right now?","282":"well, one would be coding in a windows environment :)","283":"the Table tutorial is going to be a useful one","284":"I think that there should also be a page for \\so you want to learn about scientific computing in general, check out these tutorials:\\","285":"because there's already a lot of great content out there for people wanting to learn python, the shell, numpy\/scipy\/pandas\/etc","286":"and if we can just point people to the right place that would alleviate some of the burden","287":"yup","288":"hooray! the tutorial is finally pulled into master and up on data8","289":"http:\/\/data8.org\/datascience\/tutorial.html","290":"looks really nice - way to go!","291":"@choldgraf @SamLau95 Good points about material being needed for instructors","292":"@choldgraf Re: computing on Windows -- I'm curious: what's the primary reason instructors don't want to work directly on ds8.berkeley.edu and sidestep the install issues?","293":"(particularly for those instructors not coming from a scientific computing perspective)","294":"@henryem @SamLau95 how does `table.values('my_column')` differ from `table.select('my_column')`?  Is there a reason to use one over the other?","295":"Yeah, they're very different.  The first returns an array (the column) and the second returns a table with only the column 'my_column' in it.","296":"Huge source of confusion for students, but can't think of a good way to avoid that :-\/","297":"Hmm @SamLau95 what if we had an alias for select called something like subtable_with_columns?","298":"Wonder if it would be easier to teach initially","299":"Then give them the shorter alias later","300":"@cboettig I'm not sure why people wouldn't use the ds8 environment...to be honest I don't know much about it yet either. It could just be that people default to doing things on their own computers, but maybe it can be fixed by pushing people towards the ds8.berkeley.edu resources","301":"if somebody wants to point me to a guide on using the online ds8 environment, I can figure it out and then start telling instructors that as necessary","302":"@cboettig i personally don\\u2019t see much benefit from using a local install other than needing dependencies that aren\\u2019t on ds8 (eg. I have some extensions to jupyter installed locally). i imagine it\\u2019d be a lot easier for people who don\\u2019t want to deal with installation issues to use ds8","303":"@henryem not sure \\u2014 i feel like having one method name and then switching to another could result in some confusion itself ","304":"hmm, `Table has no attribute 'value'`","305":"Typo?  Should be values, not value","306":"@choldgraf i was planning to write that up today, will ping you when it\\u2019s done","307":"@cboettig try `.values` instead of `value`","308":"whoops, thanks!","309":"@choldgraf What kind of guide would be helpful?  Basically it's just (1) request account (2) go to ds8.berkeley.edu and log in (3) see Jupyter documentation.  I do think it would be worth addressing how to do common things like get data \/ notebooks \/ files on and off the ds8 environment.  I find Jupyter terminal\u1a2b\ufffd a good solution for that, but obviously not a good entry-level solution.  ","310":"Also I'm not clear on how installing dependencies works in the ds8 environment, or in jupyter more generally.  For instance, does python have a good system for installing packages without root credentials, or is root access usually needed \/ assumed (e.g. for `pip install` to work)?   ","311":"@cboettig  i\\u2019m writing up an overview of a simple workflow from start to finish:\\n\\n1. creating notebooks\\n2. uploading notebooks\\n3. distribute notebooks to students\\n4. students work on notebooks\\n5. collect submissions from students\\n\\ni\\u2019m thinking from there we can expand on each step as needed\\n\\npython does have a system for installing without root credentials http:\/\/stackoverflow.com\/a\/7143496 but it looks like each student will have to run some commands manually\\n\\nto install globally, right now we have to contact ryan about it. this is unscalable so we\\u2019re looking for a better system","312":"Thanks @SamLau95 , an overview of how to do that workflow would be a great thing to have.  ","313":"hmm, generic Jupyter question:  is there an easy way to split a Jupyter notebook into two separate notebooks (preferably without copy-pasting raw .json)?\\ne.g. a way to select a group of cells, click 'copy cells', and then paste them into a new notebook?\\n\\n","314":"not that i know of :(","315":"@cboettig copy the notebook, delete half from each? :-\/","316":"@cboettig I'm not sure what kind of guide would be useful because I've probably got too much coding experience to have the right perspective. I'll try to pay attention to any pain points that come up and maybe can help out @SamLau95 in building some tutorials. ","317":"also @cboettig see this issue on github: https:\/\/github.com\/ipython\/ipython\/issues\/5746","318":"looks like it's something people are working on, but in the meantime you might just do File->Make a copy and then delete half the cells in the copy","319":"workflow guide is up at https:\/\/github.com\/dsten\/connector-instructors\/blob\/master\/README.md","320":"let me know what you\\u2019d like to add! (or just make a PR)","321":"@henryem so simple yet so brilliant. you're a good guy to know","322":"@SamLau95 Workflow guide looks very nice!  Do you know if the plan is to have better support for step 5 (submitting student notebooks to instructors?)  Also, you mention just using bcourses or email, but just to be comprehensive you might point out how a student should download their completed notebook, if they want to submit it via email etc.  (e.g. pointing out that notebooks can be downloaded as pdf as well as ipython \/jupyter format)","323":"@cboettig we haven\\u2019t talked about this at length but i believe for the main class the plan was to use okpy https:\/\/ok-server.appspot.com\/landing for submission \/ autograding. we haven\\u2019t yet set it up ourselves, so it\\u2019s hard to write about that process in the tutorial\\n\\nthat\\u2019s a good point! i\\u2019ll add it","324":"@SamLau95 Nice, okpy looks pretty slick.  Will students be able to get a \\submit\\ button in their actual Jupyter notebook instance? Or do they submit using the okpy web interface (which somehow knows how to find\/access their notebooks?)","325":"as of right now i don\\u2019t know of any plans to implement a \\u201csubmit\\ button","326":"in fact, as of right now students don\\u2019t do anything to submit. last semester we just pulled all the students\\u2019 files  straight up from the ds8 servers","327":"and ran the autograder on their files","328":"right, sure, but that didn't involve any `okpy`, I assume that was just some bash script on the server.","329":"I imagine students would prefer to `submit` instead of having their work just sucked up at some date and submitted for them? or maybe not?","330":"we formatted the test cases to work with the okclient https:\/\/github.com\/Cal-CS-61A-Staff\/ok-client so submitting to the okpy server shouldn\\u2019t be super hard","331":"although last semester we only used the local autograding functionality","332":"and yeah, that\\u2019s what i think we\\u2019re aiming for","333":"last semester we only had enough time to do the bare minimum","334":"cool.  right.  for a small connector like mine it's probably easier for me to grade notebooks by hand then running by writing automatic tests anyhow.","335":"If a little script just copied the working directories of all my students into appropriate sub-directories of my account on the server, I'd probably be set.  Of course I can approximate that if they (1) email me the notebooks, (2) I drop them into a private github repo, and (3) then pull them onto the ds8 server to grade them.  Also assumes more knowledge of git (or knowledge to run jupyter locally and risk having different software versions etc)","336":"@SamLau95 is there a function like `Table.apply` that returns a `Table` instead of an array? (e.g. a function that behaves like `pandas.applymap()`?)","337":"@cboettig not built-in, unfortunately. you\\u2019ll have to write one yourself","338":"@cboettig @SamLau95 see https:\/\/github.com\/dsten\/datascience\/pull\/175 for a quick implementation of what you mentioned. Would that work?","339":"@choldgraf nice thanks.  @SamLau95 right, but writing it myself rather defeats the pedagogy, since we are then back to dealing with cognitive load of multiple data structures.  ","340":"That makes sense to me - I think the trick with things like `apply` functions is that it can become confusing if you, e.g., have different datatypes in your columns. I could see it becoming a hassle if it's taught as a primary method of a `Table` object, though also quite useful too (guess that's the challenge of pandas in general)","341":"@choldgraf thanks! i\\u2019ll take a look later today","342":"hey @SamLau95, I was speaking with Edwin, who is teaching the literature connector course. He said that he still doesn't have a data8 account...is that something you can set up?","343":"he also mentioned that he doesn't have access to bCourses etc. Maybe this is because his Berkeley account was recently created, but who's a good person to talk to in order to make sure this happens?","344":"@choldgraf sorry i didn\\u2019t see this until now! what\\u2019s his calnet ID? alternatively i added you to data8.berkeley.edu as an admin so you can add him yourself at https:\/\/data8.berkeley.edu\/hub\/admin","345":"oh just kidding, found it (trloand) and added him","346":"Ah sorry, yeah I think his Cal name is teddy actually ","347":"ah, i\\u2019ll try that","348":"Cool thanks, I'll just add on my own in the future ","349":"cool, added","350":"Could someone (@SamLau95, @choldgraf) add me to the new data8.org so I don't get a 500 internal server error?","351":"Hmmm, I'm already seeing your name in there ","352":"It now looks like I can log in, but I still get a message 500 : Internal Server Error\\nFailed to start your server. Please contact admin. What I'm trying to do is just look at the link Maddie sent for the Smart Cities connector","353":"Hmmm, that sounds like a permissions issue ","354":"Could you just visit that repo on github instead? ","355":"e.g., here's the smart cities connector link on github https:\/\/github.com\/data-8\/smart-cities-connector","356":"though looks like it's not updated, so I don't think that's what she's working on","357":"actually, FWIW I just tried to start my server as well and got the same error. @SamLau95 any idea what's going on?","358":"I went into the admin page and clicked on \\stop server\\ and it returned an error saying that the server wasn't actually running. So it seems like it thinks that some servers are running when they're not","359":"I had that same experience as @choldgraf  with trying to start and stop servers. I got to the admin page and decided I shouldn't be mucking around in there because it looked like I could break stuff.","360":"In theory I could visit the repo on github, but I don't understand github well enough to know what that means to do. (I figure we'll have a lot of instructors who are in the same boat. If they find our support system hard to use, they'll opt out.)","361":"yeah I agree - it sounds like the issue with data8 is a bug. And I'm not positive how exactly the github repos \/ data8 sync with one another.","362":"@SamLau95 Just a heads up that it looks like my home directory on data8.org  has been wiped (presumably someone was clearing out the Fall student directories and instructor directories look just like students...).  I had everything backed up so no problem, but we probably need a better process in place so that connector instructors don't have their directories removed when  that happens","363":"@choldgraf @clcarson are you still running into issues? ryan pushed in some fixes last night","364":"@cboettig how about on https:\/\/ds8.berkeley.edu\/hub\/home ? data8 is just a new set of servers and we haven't done any copying over of files","365":"@SamLau95 Ah, thanks, stuff is at the new link","366":"@SamLau95 I'm still trying to figure out how the new import API will impact my workflow","367":"It looks like the instructions you have on https:\/\/github.com\/data-8\/connector-instructors assume I have 1 branch and that branch is gh-pages","368":"it assumes you have a `gh-pages` branch but you can have other branches too","369":"In reality I have a master branch where I keep private things like answer keys and a gh-pages branch I want to use to distribute public Notebooks","370":"unfortunately i haven't set it up so that private repos can be cloned","371":"So how do I construct the `import` link to tell it to import from the gh-pages branch?","372":"it's hardcoded to pull from `gh-pages` ","373":"so no other branch will get pulled in","374":"okay, that's good, but like you say authentication will be a problem","375":"right. for the time being i can make you a private repo where you can put your secret files","376":"and you can keep a public one where you release assignments","377":"since it's gh-pages the notebook is already accessbile on a public data-8 url, which would have worked in the old system, but I guess not in the new system","378":"well currently my `ecology-connector` repo *is* private and has my secret files (on the master branch)","379":"yeah; the old system still works though, so you can fall back to that ","380":"ah, that's good to know!","381":"and okay, i can make a public repo for you if you'd like","382":"I'd prefer to have two branches then a public repo, hmm, will think about it","383":"i think the new system is more beginner-friendly and robust (eg. updates to files work) and eventually we'd like to only use that (hence why the old system isn't mentioned)","384":"and yeah, what we can do is","385":"we'll let data8.berkeley.edu see our private repos","386":"but only allow pulling from the gh-pages branch","387":"Right, I agree, though it still has some learning curve.  I think the default will be that instructors need private as well as public content.  Anyway, off to teach now (but no notebooks today)!","388":"nice, sounds like a good solution","389":"yup; we're still working on ways to make the system easier to use, although at the moment we're focused on getting data8 up and running","390":"have a good class!","391":"Hello, and perhaps a simpler query -- when I tried to log-in at 105 Cory last week, this was not possible. Also, the instructors machine seemed to have a monitor that did not quite work. As I'm teaching at 2pm, I wanted to check in about the status of accounts,  ","392":"Thanks, and I do not plan to do any work on the machines, like Carl","393":"@AndrejGitHub hmm. what did you try to log in with? i believe you'll need an account form (with the username  password) from Kevin in the EECS department to log into the machines there","394":"i'll forward your problem to him and cc you","395":"Thank you!","396":"also @AndrejGitHub , if you're just planning to use the projector i think that you can bring your laptop and use the VGA cable that's in the room","397":"hey @SamLau95, mmahoney tried logging in but got a 403 error when he tried to start his server","398":"It looks like he does have an account in data8","399":"(which, btw, there has been some confusion about the difference between data8 and ds8...is there a difference?)","400":"@choldgraf I believe data8.org is the domain name associated with the `gh-pages` websites, while `ds8.berkeley.edu` is the computational server environment","401":"so, instructors should log into ds8? I'm getting two different experiences for data8 vs. ds8","402":"(e.g., one gives me admin privileges, one doesn't)","403":"wow, I see","404":"I didn't realize that data8.berkeley.edu was also a thing","405":"and at least one connector instructor (mmahoney) has a username in \\data8\\ but is apparently getting a 403 error in ds8","406":"yeah, looks like they are separate server banks with separate accounts","407":"yeah I think you're right - I assume one of them is the \\right\\ one and one is the \\old\\ one, but not which is which","408":"ds8 was the one used last semester.  Looks like I have regular user accounts on both, but ds8 has my content from the Fall and data8.berkeley.edu brings me to an empty environment","409":"So I guess that means 'data8.berkeley.edu' is the right one for the Spring?  Guess we need @SamLau95 to confirm.","410":"hrmmm ok cool...it looks like mmahoney is getting 403 errors on both of them","411":"@AndrejGitHub  Good luck!  hope your class is going well.  I wasn't able to get the VGA working, but was able to connect over HDMI (nicer anyway since it gives me higher resolution)","412":"even though there's a username of mmahoney. @SamLau95 when we \\add a user\\ do we just pick the username for their @berkeley.edu account? And does it matter if it's @stat.berkeley.edu?","413":"so I'll tell mmahoney to give it a shot tonight once we've figured it out. Would be good sooner than later so that he can start teaching himself notebooks and the datascience package etc.","414":"(@choldgraf just guessing but I'd bet @stat might be a problem. A quick look suggests that mmahoney isn't the Mike's calnet id -- looks like it might belong to someone else in fact.  I think his username has to be his calnet id, e.g. the one with @berkeley.edu)","415":"ahhhhh","416":"I just asked him, he has a different username for @berkeley  ","417":"and apparently there is another mmahoney@berkeley.edu ","418":"ok and now he's getting a 500 internal server error","419":"guess that's progress! um, just try again?  `4**` errors are usually  'you screwed up' `but 5**` errors are usually 'server screwed up'","420":"yeah that's what it sounds like","421":"I just created an account for Anthony and there's also a 500 error there","422":"so maybe there's something going on under the scenes that we need to set up above and beyond just adding their name to the list","423":"yeah, out of my depth.  are you sure that the user you create gets ownership permissions of the working dir that Jupyter is launching them into?","424":"that is a good question and one that I cannot answer :)","425":"(cannot as in \\don't have the information for\\)","426":"are users added in the standard linux way  (`adduser username` kind of thing) or through some other mechanism?","427":"that's a question for @SamLau95 ...I haven't had any hand in setting this up","428":"right, cool. I think they're scrambling on stuff for the main course now but hopefully can all get ironed out soon","429":"ok cool","430":"data8.berkeley.edu is the new system that we're going to use from now on","431":"sorry about the confusion","432":"ok cool","433":"either way, I added those usernames under the data8 admin account","434":"and they're getting 500 errors","435":"hmm","436":"that's odd","437":"let me ping ryan","438":"ok cool","439":"this happened w\/ the recently created accounts: \\mahoneymw\\ and \\anthonysuen\\","440":"for some reason i am getting an \\503: Proxy Target Missing\\u201d error","441":"I think everyone is getting that, at least an hour ago","442":"we\\u2019re looking into it; it\\u2019s being a difficult to catch issue","443":"@SamLau95 any updates? ","444":"@choldgraf looks like it\\u2019s resolved now","445":"does data8.b.e work for you?","446":"It does work for me, though it was working for me before","447":"@anthonysuen how about you?","448":"is the data8 server working?","449":"anthony was able to start his server a few hours ago after we worked out some issues","450":"ah cool, ok I'll assume this is working and tell Michael then","451":"yup. i\\u2019m gonna test it on a couple of students tonight and then we\\u2019ll cross our fingers for tomorrow","452":"sounds great, thanks for the quick turnaround!","453":"no prob, thank ryan and anthony for staying after the meeting for a few hours to sort it out","454":"hey @SamLau95, can you add mmahoney to the connector instructors git repository? ","455":"@SamLau95 I just tried to ping mahoney on a github issue but his name didn't pop up, you said you added him to the connector-instructors repo, right?","456":"his username is: mahoneymw","457":"oops, i added mmahoney ","458":"mahoneymw is added now \\u2014 he\\u2019ll have to accept his invitation first","459":"ok sounds good, thanks","460":"elaine here!  trying to get up to speed with tables... should i ask my questions here?  (or start a separate channel or somewhere else?)","461":"I'd say ask away, either here or in the slack room","462":"@elaine84 you can check out the tutorial at http:\/\/datascience.readthedocs.org\/en\/v0.4.0\/tutorial.html","463":"david culler also has demos at https:\/\/github.com\/deculler\/TableDemos","464":"and last but not least we embed a bunch of tables in the textbook like: http:\/\/www.inferentialthinking.com\/chapter1\/example-plotting-the-classics.html","465":"@SamLau95 thanks for the links!","466":"hey, do i need special privileges to push to https:\/\/github.com\/data-8\/connector-instructors ?","467":"i dont think so?","468":"let me check","469":"I just made you admin","470":"thanks @anthonysuen !","471":"Preference for what gets discussed in gitter vs slack connectors?","472":"I think the hope is to keep gitter for technical questions and development stuff, while slack is a more general purpose discussion \/ Q&A tool","473":"so maybe if you think it's a conversation that might result in a PR, or a discussion of the code in the repository, then this is the right place for it...otherwise I think Slack is the way to go","474":"(someone correct me if I'm wrong)","475":"Sounds good to me (since gitter is public & more closely linked with the datascience module's github repo). I'll ask my clever questions here and save my stupid questions for slack ;-)","476":"how can I join the slack group ?","477":"Email John Denero, I think","478":"I've used pip to install datascience library onto my Win 10 machine, running Python 3.5 (also has Python 2.7).  The install appears to have worked, as >>pip show datascience      displays the following:  Metadata-Version: 2.0\\nName: datascience\\nVersion: 0.5.19\\nLocation: c:\\\\anaconda3\\\\envs\\\\py35\\\\lib\\\\site-packages\\n\\nUnfortunately, when I run >>jupyter notebook on the lab1 notebook that I cloned from the data8 repo, and execute the first cell, I get the error message \\AttributeError: module 'datascience' has no attribute 'maps'\\.  Any clue what could be throwing this error?  Thanks","479":"Lol. Apparently this room is dead...","480":"but it doesn't have to be!","481":"or maybe everybody has moved to slack....","482":"Hello. I was looking at the jupyterhub-k8s project - was this used successfully for a class or is it still in development?","483":"DataScience Digest, Issue #7 - http:\/\/bit.ly\/2p9NaRc  Please share;)","484":"@pminkov Sorry for missing this, most communications have moved to slack. This has been used successfully for several courses. @choldgraf has been documenting it at https:\/\/zero-to-jupyterhub-with-kubernetes.readthedocs.io\/en\/latest\/","485":"(we should close this room if it isn't being used, yeah?)","486":"hey, is there any chance that we integrate this with an IRC like freenode? I'm lurking at #julia and would like to join this room too if available :\ufffd: ","487":"Hello Everyone","488":"Glad to be here","489":"hi all ","490":"I am looking for data science plateform like freecodecamp for website and possibly based on python ","491":"Could someone suggest me any detailed ressources ? ","492":"thank you ","493":"Hi! :D You can try the Data Science Learning Club or Data Camp","494":"http:\/\/www.becomingadatascientist.com\/learningclub\/","495":"https:\/\/www.datacamp.com","496":"thank you  @pomodoros ","497":null,"498":"How do I get started with data8?","499":"Hi everyone. Want to start learning data science skills so that to develop and contribute on open source projects of data science. Recently participated and contributed code in GSoC 2017 for kivy org in Python Software Foundation. Please help.","500":"Hello people! Anyone interested in ML in robotics? Or self automated cars?","501":"No one available? K u can mail me at inziyadad@gmail.com","502":" how can i start contributing to open source","503":"@pminkov @ryanlovett have you heard of or tried gryd? (https:\/\/gryd.us)","504":"@MikCrillz_twitter Hi, I am trying gryd.us but I haven't been able to install tensorflow. Do you know why?","505":"gryd looks quite similar to cocalc(https:\/\/cocalc.com)","506":"@Pasquinell Tensorflow should now work on Gryd. Also, we have fixed some permission issues that were preventing you from installing packages. For instructions, refer to https:\/\/gryd.us\/faq\/.","507":"@GrydNotebooks_twitter Hi! Yeah, I was able to install tensorflow. I am having other problem now. I am able to install libraries like nltk and unidecode using pip install (not pip3), but they are only available in a python3 notebook (so  I am struggling modifying my code from python2 to python3), is there a way to make it work for python2?","508":"[![image.png](https:\/\/files.gitter.im\/data-8\/datascience\/MON5\/thumb\/image.png)](https:\/\/files.gitter.im\/data-8\/datascience\/MON5\/image.png)","509":"@GrydNotebooks_twitter ","510":"@Pasquinell You should be able to install `nltk` using `!conda install -c anaconda --name py27 --yes nltk` and `unidecode` using `!conda install -c conda-forge --name py27 --yes unidecode`. As I mentioned, check out the instructions at https:\/\/gryd.us\/faq\/. You should be able to install any packages available through conda for Python 2 or 3 using `!conda install [-c <repo_name>] [--name py27] --yes <package_name>`.","511":"@Pasquinell Not sure if you are looking to use GPUs to train neural nets but I should clarify we don't support GPUs yet. However, given enough demand, we will add GPU support .","512":"@GrydNotebooks_twitter Thank you! Yes, I know you don't have GPU support and you will add it later. Cheers!","513":"Hi guys I\\u00b4m new, any advice to connect python with a DB oracle12c ","514":"Hey guys! Just wanted to ask that how is ML useful in making a satellite?","515":"any recommendations on which compiler to use for anaconda?","516":"nevermind, need to open my eyes, is a script","517":"@Assencastrillo may try with Python driver for Oracle 12c\\n as described in  https:\/\/stackoverflow.com\/questions\/17872307\/python-driver-for-oracle-12c ","518":"[![Screen Shot 2018-01-02 at 12.47.49 AM.png](https:\/\/files.gitter.im\/data-8\/datascience\/AqhI\/thumb\/Screen-Shot-2018-01-02-at-12.47.49-AM.png)](https:\/\/files.gitter.im\/data-8\/datascience\/AqhI\/Screen-Shot-2018-01-02-at-12.47.49-AM.png)","519":"can anyone tell me whats wrong? see error message in Bottom of shell. using python3","520":"there is no error you got a generator object at the at the addresss  after at ","521":"long time i don't python but use print(list(chuncky(...)) ","522":"you should get the value you generate","523":"oups so quite here you message is from 2nd january i think you got it already ","524":"Is anyone willing to collaborate for a DS project?","525":"@mihinsumaria why not ! If still looking for a contributor PM me ","526":"@KokuKUSIAKU  Hi! What kind of projects would you be willing to contribute to? ","527":"Hi everyone","528":"Yes at Mihin Sumaria","529":"Hi everyone, I created a list of 200 Data Science blogs - https:\/\/www.cybrhome.com\/topic\/data-science-blogs","530":"@a1Gupta thanks for sharing. ","531":"Hi.. ","532":"@mihinsumaria still is there any opportunity to contribute in DS project?? ","533":"Hi , I am a beginner and I try to predict an anomaly in different systems, I have different parameters, which I can use to do more precise prediction. I have a general question, is there a way to do prediction without know with parameters should I use ? sometimes, I don't have all parameters values, so I am thinking if there is a away to do prediction with a minimum parameters","534":"Hello people, I'm new to Data Science and would like to know where to begin from","535":"@aoayoola","536":null,"537":null,"538":"hey everyone.  stumbled across this community.  curious - why would I want to use this package over Pandas? I scanned the docs, admittedly very briefly, and it seems that it's supposed to be a slightly-more-user-friendly table structure? Is there some other context that I'm missing?","539":null,"540":"HEllo everyone","541":"hi","542":"Python-Awesome tutorial for Machine Learning as part of a Graduate Program in Machine Learning. Pull requests\/changes\/stars would be very much helpful. https:\/\/github.com\/gautam1858\/python-awesome","543":"Hi","544":"How can i install anaconda on Ubuntu"},"predicted topic":{"0":"Introduction and Setup","1":"Introduction and Setup","2":"Introduction and Setup","3":"Introduction and Setup","4":"Introduction and Setup","5":"UNDEFINED","6":"Introduction and Setup","7":"Introduction and Setup","8":"Introduction and Setup","9":"Introduction and Setup","10":"Questions about Git and GitHub","11":"UNDEFINED","12":"UNDEFINED","13":"Questions about Git and GitHub","14":"UNDEFINED","15":"Questions about Git and GitHub","16":"Questions about Git and GitHub","17":"Questions about Git and GitHub","18":"Introduction and Setup","19":"Questions about Git and GitHub","20":"Introduction and Setup","21":"UNDEFINED","22":"Introduction and Setup","23":"Introduction and Setup","24":"Questions about Git and GitHub","25":"Questions about Git and GitHub","26":"Questions about Git and GitHub","27":"Introduction and Setup","28":"Introduction and Setup","29":"Introduction and Setup","30":"Introduction and Setup","31":"Introduction and Setup","32":"UNDEFINED","33":"Introduction and Setup","34":"Introduction and Setup","35":"Introduction and Setup","36":"Introduction and Setup","37":"Introduction and Setup","38":"Introduction and Setup","39":"Questions about Databases","40":"Discussion about using SQLite vs PostgreSQL for data manipulation","41":"UNDEFINED","42":"UNDEFINED","43":"UNDEFINED","44":"UNDEFINED","45":"UNDEFINED","46":"UNDEFINED","47":"UNDEFINED","48":"UNDEFINED","49":"UNDEFINED","50":"UNDEFINED","51":"UNDEFINED","52":"UNDEFINED","53":"UNDEFINED","54":"UNDEFINED","55":"UNDEFINED","56":"UNDEFINED","57":"UNDEFINED","58":"UNDEFINED","59":"UNDEFINED","60":"UNDEFINED","61":"UNDEFINED","62":"UNDEFINED","63":"UNDEFINED","64":"UNDEFINED","65":"UNDEFINED","66":"UNDEFINED","67":"UNDEFINED","68":"UNDEFINED","69":"UNDEFINED","70":"UNDEFINED","71":"UNDEFINED","72":"UNDEFINED","73":"UNDEFINED","74":"UNDEFINED","75":"UNDEFINED","76":"UNDEFINED","77":"UNDEFINED","78":"UNDEFINED","79":"UNDEFINED","80":"Discussion about installing and updating datascience package","81":"Discussion about installing and updating datascience package","82":"Discussion about installing and updating datascience package","83":"Discussion about installing and updating datascience package","84":"Discussion about installing and updating datascience package","85":"Discussion about installing and updating datascience package","86":"UNDEFINED","87":"Discussion about installing and updating datascience package","88":"Discussion about installing and updating datascience package","89":"Discussion about installing and updating datascience package","90":"Discussion about installing and updating datascience package","91":"Discussion about installing and updating datascience package","92":"Discussion about installing and updating datascience package","93":"Discussion about installing and updating datascience package","94":"Discussion about installing and updating datascience package","95":"Discussion about installing and updating datascience package","96":"Discussion about installing and updating datascience package","97":"Discussion about installing and updating datascience package","98":"Discussion about installing and updating datascience package","99":"Discussion about installing and updating datascience package","100":"Discussion about installing and updating datascience package","101":"Discussion about installing and updating datascience package","102":"Discussion about installing and updating datascience package","103":"Discussion about installing and updating datascience package","104":"Discussion about installing and updating datascience package","105":"Discussion about installing and updating datascience package","106":"Discussion about installing and updating datascience package","107":"UNDEFINED","108":"UNDEFINED","109":"Discussion about installing and updating datascience package","110":"Discussion about installing and updating datascience package","111":"Discussion about installing and updating datascience package","112":"Question about counting the number of recurring values in a column of a table","113":"Question about counting the number of recurring values in a column of a table","114":"Question about counting the number of recurring values in a column of a table","115":"Question about counting the number of recurring values in a column of a table","116":"Question about counting the number of recurring values in a column of a table","117":"Question about read_table error","118":"Question about read_table error","119":"Discussion about installing and updating datascience package","120":"Encoding issues in reading CSV files","121":"Encoding issues in reading CSV files","122":"Encoding issues in reading CSV files","123":"Encoding issues in reading CSV files","124":"UNDEFINED","125":"UNDEFINED","126":"UNDEFINED","127":"UNDEFINED","128":"UNDEFINED","129":"Encoding issues in reading CSV files","130":"Encoding issues in reading CSV files","131":"Encoding issues in reading CSV files","132":"UNDEFINED","133":"UNDEFINED","134":"UNDEFINED","135":"UNDEFINED","136":"Encoding issues in reading CSV files","137":"Encoding issues in reading CSV files","138":"Encoding issues in reading CSV files","139":"UNDEFINED","140":"UNDEFINED","141":"UNDEFINED","142":"UNDEFINED","143":"UNDEFINED","144":"UNDEFINED","145":"Encoding issues in reading CSV files","146":"Encoding issues in reading CSV files","147":"Encoding issues in reading CSV files","148":"Encoding issues in reading CSV files","149":"Encoding issues in reading CSV files","150":"Encoding issues in reading CSV files","151":"Encoding issues in reading CSV files","152":"Encoding issues in reading CSV files","153":"Encoding issues in reading CSV files","154":"Encoding issues in reading CSV files","155":"Encoding issues in reading CSV files","156":"Encoding issues in reading CSV files","157":"Encoding issues in reading CSV files","158":"UNDEFINED","159":"Error with apply function and multiple arguments","160":"Code Error","161":"Code Error","162":"Code Discussion","163":"Code Discussion","164":"UNDEFINED","165":"Code Error","166":"Code Error","167":"Code Discussion","168":"Code Error","169":"Code Error","170":"Code Error","171":"Code Error","172":"Code Error","173":"Code Error","174":"Code Discussion","175":"UNDEFINED","176":"UNDEFINED","177":"UNDEFINED","178":"UNDEFINED","179":"Code Error","180":"Code Discussion","181":"UNDEFINED","182":"Code Discussion","183":"UNDEFINED","184":"Code Development","185":"Code Development","186":"Code Development","187":"Code Error","188":"Code Error","189":"UNDEFINED","190":"UNDEFINED","191":"UNDEFINED","192":"UNDEFINED","193":"UNDEFINED","194":"Code Error","195":"Code Error","196":"Code Error","197":"Code Error","198":"Code Error","199":"Code Error","200":"Discussion about datascience package version and installation","201":"Discussion about datascience package version and installation","202":"Discussion about datascience package version and installation","203":"Discussion about datascience package version and installation","204":"Discussion about datascience package version and installation","205":"Discussion about datascience package version and installation","206":"Discussion about datascience package version and installation","207":"Discussion about datascience package version and installation","208":"Discussion about datascience package version and installation","209":"UNDEFINED","210":"Discussion about datascience package version and installation","211":"Discussion about datascience package version and installation","212":"Discussion about datascience package version and installation","213":"Discussion about datascience package version and installation","214":"Discussion about datascience package version and installation","215":"Discussion about datascience package version and installation","216":"Discussion about datascience package version and installation","217":"Discussion about datascience package version and installation","218":"UNDEFINED","219":"Mention of PR for Python3 check","220":"Discussion about datascience package version and installation","221":"Mention of PR for Python3 check","222":"Discussion about handling '-------' value in temperature data","223":"Discussion about handling '-------' value in temperature data","224":"UNDEFINED","225":"Discussion about handling '-------' value in temperature data","226":"UNDEFINED","227":"Discussion about handling '-------' value in temperature data","228":"Discussion about handling '-------' value in temperature data","229":"Discussion about handling '-------' value in temperature data","230":"Discussion about handling '-------' value in temperature data","231":"Discussion about handling '-------' value in temperature data","232":"Discussion about handling '-------' value in temperature data","233":"Discussion about teaching approach in the course","234":"Discussion about teaching approach in the course","235":"Discussion about teaching approach in the course","236":"Discussion about teaching approach in the course","237":"Discussion about teaching approach in the course","238":"Discussion about teaching approach in the course","239":"Discussion about handling '-------' value in temperature data","240":"Updating `datascience` Tables","241":"Updating `datascience` Tables","242":"Updating `datascience` Tables","243":"Updating `datascience` Tables","244":"Updating `datascience` Tables","245":"Updating `datascience` Tables","246":"Updating `datascience` Tables","247":"Updating `datascience` Tables","248":"Updating `datascience` Tables","249":"Updating `datascience` Tables","250":"Updating `datascience` Tables","251":"Updating `datascience` Tables","252":"Updating `datascience` Tables","253":"Updating `datascience` Tables","254":"Updating `datascience` Tables","255":"UNDEFINED","256":"Updating `datascience` Tables","257":"Updating `datascience` Tables","258":"Updating `datascience` Tables","259":"Updating `datascience` Tables","260":"Updating `datascience` Tables","261":"Discussion on using `pip` vs `git clone` for instructors","262":"Discussion on using `pip` vs `git clone` for instructors","263":"Discussion on using `pip` vs `git clone` for instructors","264":"Discussion on using `pip` vs `git clone` for instructors","265":"Discussion on using `pip` vs `git clone` for instructors","266":"UNDEFINED","267":"Discussion on using `pip` vs `git clone` for instructors","268":"Discussion on using `pip` vs `git clone` for instructors","269":"Discussion on using `pip` vs `git clone` for instructors","270":"Discussion on using `pip` vs `git clone` for instructors","271":"Discussion on using `pip` vs `git clone` for instructors","272":"Discussion on using `pip` vs `git clone` for instructors","273":"Discussion on using `pip` vs `git clone` for instructors","274":"Discussion on using `pip` vs `git clone` for instructors","275":"Discussion on using `pip` vs `git clone` for instructors","276":"Discussion on using `pip` vs `git clone` for instructors","277":"Discussion on using `pip` vs `git clone` for instructors","278":"Discussion on using `pip` vs `git clone` for instructors","279":"Discussion on using `pip` vs `git clone` for instructors","280":"UNDEFINED","281":"Discussion about instructors and useful tutorials","282":"Discussion about instructors and useful tutorials","283":"Discussion about instructors and useful tutorials","284":"Discussion about instructors and useful tutorials","285":"Discussion about instructors and useful tutorials","286":"Discussion about instructors and useful tutorials","287":"Discussion about instructors and useful tutorials","288":"Discussion about instructors and useful tutorials","289":"Discussion about instructors and useful tutorials","290":"Discussion about using ds8.berkeley.edu environment vs local install","291":"UNDEFINED","292":"Discussion about using ds8.berkeley.edu environment vs local install","293":"Discussion about using ds8.berkeley.edu environment vs local install","294":"Question about Table.values() and Table.select()","295":"UNDEFINED","296":"Question about Table.values() and Table.select()","297":"Question about Table.values() and Table.select()","298":"Question about Table.values() and Table.select()","299":"Question about Table.values() and Table.select()","300":"Question about Table.values() and Table.select()","301":"Discussion about instructors and useful tutorials","302":"Discussion about using ds8.berkeley.edu environment vs local install","303":"Discussion about using ds8.berkeley.edu environment vs local install","304":"Question about Table.values() and Table.select()","305":"Question about Table.values() and Table.select()","306":"Question about Table.values() and Table.select()","307":"Discussion about instructors and useful tutorials","308":"Discussion about instructors and useful tutorials","309":"Discussion about instructors and useful tutorials","310":"Discussion about instructors and useful tutorials","311":"Discussion about creating and distributing notebooks for students","312":"Discussion about creating and distributing notebooks for students","313":"Question about splitting Jupyter Notebooks","314":"Question about splitting Jupyter Notebooks","315":"Question about splitting Jupyter Notebooks","316":"Discussion about instructors and useful tutorials","317":"Discussion about instructors and useful tutorials","318":"Discussion about instructors and useful tutorials","319":"Discussion about instructors and useful tutorials","320":"UNDEFINED","321":"UNDEFINED","322":"Discussion about okpy and student submissions","323":"Discussion about okpy and student submissions","324":"Discussion about okpy and student submissions","325":"Discussion about okpy and student submissions","326":"Discussion about okpy and student submissions","327":"Discussion about okpy and student submissions","328":"Discussion about okpy and student submissions","329":"Discussion about okpy and student submissions","330":"Discussion about okpy and student submissions","331":"Discussion about okpy and student submissions","332":"Discussion about okpy and student submissions","333":"Discussion about okpy and student submissions","334":"Discussion about okpy and student submissions","335":"Discussion about okpy and student submissions","336":"Discussion about okpy and student submissions","337":"Question about Table.apply function","338":"Question about Table.apply function","339":"Question about Table.apply function","340":"UNDEFINED","341":"Discussion about okpy and student submissions","342":"Discussion about okpy and student submissions","343":"Discussion about okpy and student submissions","344":"Adding users to data8.berkeley.edu","345":"Adding users to data8.berkeley.edu","346":"Discussion about okpy and student submissions","347":"Adding users to data8.berkeley.edu","348":"Discussion about okpy and student submissions","349":"Adding users to data8.berkeley.edu","350":"Adding users to data8.berkeley.edu","351":"Discussion about okpy and student submissions","352":"Discussion about okpy and student submissions","353":"Discussion about okpy and student submissions","354":"Discussion about okpy and student submissions","355":"Discussion about okpy and student submissions","356":"Discussion about okpy and student submissions","357":"Discussion about okpy and student submissions","358":"Discussion about okpy and student submissions","359":"UNDEFINED","360":"Github and Data8 Issues","361":"Github and Data8 Issues","362":"Github and Data8 Issues","363":"Github and Data8 Issues","364":"Github and Data8 Issues","365":"Github and Data8 Issues","366":"UNDEFINED","367":"Github and Data8 Issues","368":"Github and Data8 Issues","369":"Github and Data8 Issues","370":"Github and Data8 Issues","371":"Github and Data8 Issues","372":"Github and Data8 Issues","373":"Github and Data8 Issues","374":"Github and Data8 Issues","375":"Github and Data8 Issues","376":"Github and Data8 Issues","377":"Github and Data8 Issues","378":"Github and Data8 Issues","379":"Github and Data8 Issues","380":"Github and Data8 Issues","381":"Github and Data8 Issues","382":"Github and Data8 Issues","383":"Github and Data8 Issues","384":"Github and Data8 Issues","385":"Github and Data8 Issues","386":"Github and Data8 Issues","387":"Github and Data8 Issues","388":"Github and Data8 Issues","389":"Github and Data8 Issues","390":"Github and Data8 Issues","391":"Login Issues","392":"Login Issues","393":"Login Issues","394":"Login Issues","395":"Login Issues","396":"Login Issues","397":"UNDEFINED","398":"UNDEFINED","399":"Difference between Data8 and ds8","400":"DS8 vs. data8.berkeley.edu","401":"DS8 vs. data8.berkeley.edu","402":"DS8 vs. data8.berkeley.edu","403":"DS8 vs. data8.berkeley.edu","404":"UNDEFINED","405":"DS8 vs. data8.berkeley.edu","406":"DS8 vs. data8.berkeley.edu","407":"DS8 vs. data8.berkeley.edu","408":"DS8 vs. data8.berkeley.edu","409":"DS8 vs. data8.berkeley.edu","410":"DS8 vs. data8.berkeley.edu","411":"DS8 vs. data8.berkeley.edu","412":"Adding users to DS8 or data8.berkeley.edu","413":"UNDEFINED","414":"DS8 vs. data8.berkeley.edu","415":"Adding users to DS8 or data8.berkeley.edu","416":"Adding users to DS8 or data8.berkeley.edu","417":"DS8 vs. data8.berkeley.edu","418":"DS8 vs. data8.berkeley.edu","419":"DS8 vs. data8.berkeley.edu","420":"DS8 vs. data8.berkeley.edu","421":"500 internal server errors","422":"500 internal server errors","423":"UNDEFINED","424":"Adding users to DS8 or data8.berkeley.edu","425":"Adding users to DS8 or data8.berkeley.edu","426":"Adding users to DS8 or data8.berkeley.edu","427":"DS8 vs. data8.berkeley.edu","428":"Adding users to DS8 or data8.berkeley.edu","429":"DS8 vs. data8.berkeley.edu","430":"Adding users to DS8 or data8.berkeley.edu","431":"Adding users to DS8 or data8.berkeley.edu","432":"DS8 vs. data8.berkeley.edu","433":"500 internal server errors","434":"500 internal server errors","435":"UNDEFINED","436":"UNDEFINED","437":"UNDEFINED","438":"UNDEFINED","439":"UNDEFINED","440":"503 Error","441":"503 Error","442":"503 Error","443":"503 Error","444":"503 Error","445":"UNDEFINED","446":"503 Error","447":"503 Error","448":"503 Error","449":"503 Error","450":"503 Error","451":"503 Error","452":"UNDEFINED","453":"UNDEFINED","454":"Adding Users to GitHub Repository","455":"Adding Users to GitHub Repository","456":"Adding Users to GitHub Repository","457":"Adding Users to GitHub Repository","458":"Adding Users to GitHub Repository","459":"Adding Users to GitHub Repository","460":"UNDEFINED","461":"Technical Questions and Development","462":"Technical Questions and Development","463":"Technical Questions and Development","464":"Technical Questions and Development","465":"UNDEFINED","466":"UNDEFINED","467":"UNDEFINED","468":"UNDEFINED","469":"UNDEFINED","470":"UNDEFINED","471":"Technical Questions and Development","472":"Technical Questions and Development","473":"Technical Questions and Development","474":"Technical Questions and Development","475":"Technical Questions and Development","476":"Joining Slack Group","477":"Joining Slack Group","478":"Installing Datascience Library","479":"UNDEFINED","480":"UNDEFINED","481":"Questions about using specific tools and platforms for data science","482":"Discussion about Jupyterhub-k8s project","483":"Questions about using specific tools and platforms for data science","484":"Discussion about Jupyterhub-k8s project","485":"Discussion about Jupyterhub-k8s project","486":"Discussion about Jupyterhub-k8s project","487":"UNDEFINED","488":"UNDEFINED","489":"UNDEFINED","490":"UNDEFINED","491":"UNDEFINED","492":"Help and support for specific issues","493":"UNDEFINED","494":"UNDEFINED","495":"UNDEFINED","496":"Discussion about Jupyterhub-k8s project","497":"Questions about using specific tools and platforms for data science","498":"UNDEFINED","499":"Questions about using specific tools and platforms for data science","500":"UNDEFINED","501":"Discussion about Machine Learning in Robotics and Self-Automated cars","502":"Discussion about contributing to open source projects","503":"Discussion about contributing to open source projects","504":"UNDEFINED","505":"UNDEFINED","506":"UNDEFINED","507":"Help and support for specific issues","508":"Help and support for specific issues","509":"Help and support for specific issues","510":"Help and support for specific issues","511":"Help and support for specific issues","512":"Help and support for specific issues","513":"Discussion about contributing to open source projects","514":"Discussion about contributing to open source projects","515":"UNDEFINED","516":"Help and support for specific issues","517":"UNDEFINED","518":"UNDEFINED","519":"UNDEFINED","520":"Python Error and Code Snippets","521":"Python Error and Code Snippets","522":"Python Error and Code Snippets","523":"Python Error and Code Snippets","524":"Data Science Project Collaboration","525":"Data Science Project Collaboration","526":"Data Science Project Collaboration","527":"Data Science Project Collaboration","528":"Data Science Project Collaboration","529":"Data Science Blogs","530":"Data Science Blogs","531":"UNDEFINED","532":"UNDEFINED","533":"UNDEFINED","534":"UNDEFINED","535":"Data Science Project Collaboration","536":"Python Error and Code Snippets","537":"Python Error and Code Snippets","538":"Python Error and Code Snippets","539":"Python Error and Code Snippets","540":"UNDEFINED","541":"UNDEFINED","542":"Python Error and Code Snippets","543":"Data Science Project Collaboration","544":"Data Science Project Collaboration"}}